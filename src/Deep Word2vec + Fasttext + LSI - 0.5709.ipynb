{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from growing_instability_lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub = pd.read_csv('../data/sampleSubmission.csv')\n",
    "topics = sorted(set(sample_sub.columns.difference(['id'])))\n",
    "\n",
    "topic2actual = {}\n",
    "for i in sample_sub.columns:\n",
    "    if 'id' == i:\n",
    "        continue\n",
    "    topic2actual[i] = segment(i)\n",
    "    \n",
    "target_columns = sorted(topics)\n",
    "len(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.3 s, sys: 3.74 s, total: 14 s\n",
      "Wall time: 18.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wvec_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'wvec_trainingX')\n",
    "fvec_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'fvec_trainingX')\n",
    "\n",
    "tfidf_wvec_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'tfidf_wvec_trainingX')\n",
    "tfidf_fvec_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'tfidf_fvec_trainingX')\n",
    "tfidf_lsi_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'tfidf_lsi_trainingX')\n",
    "\n",
    "word2idx_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'word2idx_trainingX')\n",
    "_word2idx = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', '_word2idx')\n",
    "trainingY = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'trainingY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://192.168.1.25:9999/notebooks/kaggle/data-science-challenge-growing-instability-05-13-2017/src/Topic%20Modeling%20and%20Clustering.ipynb\n",
    "train_test_df = pd.read_hdf('train_test_df_3.hdf', 'train_test_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_topics(df, topics):\n",
    "    topics = sorted(topics)\n",
    "#     v = np.zeros(shape=(df.shape[0], len(topics)))\n",
    "    v = []\n",
    "    for ix, tp in enumerate(df.topics):\n",
    "        tt = []\n",
    "        for t in tp:\n",
    "            tt.append(topics.index(t))\n",
    "#             v[ix][topics.index(t)] = 1\n",
    "        v.append(tt)\n",
    "\n",
    "    return pd.Series(v, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fs features...\n",
      "Current batch in main thread: 102\n",
      "Current batch in main thread: 221\n",
      "Computing wv features...\n",
      "Current batch in main thread: 102\n",
      "Current batch in main thread: 221\n",
      "Mapping word indices...\n",
      "Computing tfidf fs features...\n",
      "Current batch in main thread: 102\n",
      "Current batch in main thread: 221\n",
      "Computing tfidf wv features...\n",
      "Current batch in main thread: 102\n",
      "Current batch in main thread: 221\n",
      "Computing tfidf lsi features...\n",
      "Current batch in main thread: 102\n",
      "Current batch in main thread: 221\n"
     ]
    }
   ],
   "source": [
    "train_test_word_indices, train_test_wvec, train_test_fvec, train_test_tfidf_wvec, train_test_tfidf_fvec, train_test_tfidf_lsi = extract_features_for(\n",
    "    train_test_df\n",
    ")\n",
    "\n",
    "train_test_y = transform_topics(train_test_df, topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.9 s, sys: 328 ms, total: 11.2 s\n",
      "Wall time: 11.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ind2word = {j:i for i, j in _word2idx.iteritems()}\n",
    "ind2class = dict(enumerate(topics))\n",
    "class2ind = {j: i for i, j in ind2class.items()}\n",
    "\n",
    "num_samples = trainingY.shape[0]\n",
    "\n",
    "# ---------------------------------\n",
    "training_X = word2idx_trainingX.head(num_samples)\n",
    "training_Y = pd.DataFrame(zip(*np.where(trainingY.head(num_samples) == 1)), columns=['iloc', 'topics'])\n",
    "\n",
    "training_WV = wvec_trainingX.head(num_samples)\n",
    "training_FS = fvec_trainingX.head(num_samples)\n",
    "\n",
    "training_tfidf_WV = tfidf_wvec_trainingX.head(num_samples)\n",
    "training_tfidf_FS = tfidf_fvec_trainingX.head(num_samples)\n",
    "training_tfidf_LSI = tfidf_lsi_trainingX.head(num_samples)\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "training_Y = training_Y.groupby('iloc')['topics'].apply(list)\n",
    "training_Y.index = trainingY.head(num_samples).index\n",
    "\n",
    "indices = sorted(training_Y.index[training_Y.index.str.contains('^201[0-9]')])\n",
    "# np.random.shuffle(indices)\n",
    "indices = pd.Index(indices)\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "training_X = training_X.ix[indices]\n",
    "training_Y = training_Y.ix[indices]\n",
    "\n",
    "training_WV = training_WV.ix[indices]\n",
    "training_FS = training_FS.ix[indices]\n",
    "\n",
    "training_tfidf_WV = training_tfidf_WV.ix[indices]\n",
    "training_tfidf_FS = training_tfidf_FS.ix[indices]\n",
    "training_tfidf_LSI = training_tfidf_LSI.ix[indices]\n",
    "# ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 8.82 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wv_sc = StandardScaler()\n",
    "fs_sc = StandardScaler()\n",
    "\n",
    "tfidf_wv_sc = StandardScaler()\n",
    "tfidf_fs_sc = StandardScaler()\n",
    "tfidf_lsi_sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.8 s, sys: 140 ms, total: 1.94 s\n",
      "Wall time: 1.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "maxlen = 500\n",
    "\n",
    "\n",
    "def build_target(y, size):\n",
    "    e = np.zeros(size)\n",
    "    e[y] = 1\n",
    "    return e\n",
    "\n",
    "\n",
    "def build_input_output_data(X, WV, FS, TWV, TFS, TLSI, Y, maxlen):\n",
    "    x = sequence.pad_sequences(X, maxlen=maxlen)\n",
    "    y = np.vstack(Y.map(lambda x: build_target(x, len(topics))))\n",
    "\n",
    "    wv = np.vstack(WV)\n",
    "    fs = np.vstack(FS)\n",
    "\n",
    "    twv = np.vstack(TWV)\n",
    "    tfs = np.vstack(TFS)\n",
    "    tlsi = np.vstack(TLSI)\n",
    "\n",
    "    return x, wv, fs, twv, tfs, tlsi, y\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "train_ix = training_Y.index.str.contains('^201[2-4]')\n",
    "val_ix = training_Y.index.str.contains('^2014[b]')\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "x_train, wv_train, fs_train, tfidf_wv_train, tfidf_fs_train, tfidf_lsi_train, y_train = build_input_output_data(\n",
    "    training_X.ix[train_ix],\n",
    "\n",
    "    training_WV.ix[train_ix],\n",
    "    training_FS.ix[train_ix],\n",
    "\n",
    "    training_tfidf_WV.ix[train_ix],\n",
    "    training_tfidf_FS.ix[train_ix],\n",
    "    training_tfidf_LSI.ix[train_ix],\n",
    "\n",
    "    training_Y.ix[train_ix],\n",
    "    maxlen=maxlen\n",
    ")\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "x_val, wv_val, fs_val, tfidf_wv_val, tfidf_fs_val, tfidf_lsi_val, y_val = build_input_output_data(\n",
    "    training_X.ix[val_ix],\n",
    "\n",
    "    training_WV.ix[val_ix],\n",
    "    training_FS.ix[val_ix],\n",
    "\n",
    "    training_tfidf_WV.ix[val_ix],\n",
    "    training_tfidf_FS.ix[val_ix],\n",
    "    training_tfidf_LSI.ix[val_ix],\n",
    "\n",
    "    training_Y.ix[val_ix],\n",
    "    maxlen=maxlen\n",
    ")\n",
    "# ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "train_test_x_train, train_test_wv_train, train_test_fs_train, train_test_tfidf_wv_train, train_test_tfidf_fs_train, train_test_tfidf_lsi_train, train_test_y_train = build_input_output_data(\n",
    "    train_test_word_indices,\n",
    "\n",
    "    train_test_wvec,\n",
    "    train_test_fvec,\n",
    "\n",
    "    train_test_tfidf_wvec,\n",
    "    train_test_tfidf_fvec,\n",
    "    train_test_tfidf_lsi,\n",
    "\n",
    "    train_test_y,\n",
    "    maxlen=maxlen\n",
    ")\n",
    "# ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def upsample(x, N=3):\n",
    "    return np.vstack([x for i in xrange(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tt_x_train = np.vstack([x_train, upsample(train_test_x_train)])\n",
    "\n",
    "tt_wv_train = np.vstack([wv_train, upsample(train_test_wv_train)])\n",
    "tt_fs_train = np.vstack([fs_train, upsample(train_test_fs_train)])\n",
    "\n",
    "tt_tfidf_wv_train = np.vstack([tfidf_wv_train, upsample(train_test_tfidf_wv_train)])\n",
    "tt_tfidf_fs_train = np.vstack([tfidf_fs_train, upsample(train_test_tfidf_fs_train)])\n",
    "tt_tfidf_lsi_train = np.vstack([tfidf_lsi_train, upsample(train_test_tfidf_lsi_train)])\n",
    "\n",
    "tt_y_train = np.vstack([y_train, upsample(train_test_y_train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "wv_train = wv_sc.fit_transform(wv_train)\n",
    "fs_train = fs_sc.fit_transform(fs_train)\n",
    "\n",
    "tfidf_wv_train = tfidf_wv_sc.fit_transform(tfidf_wv_train)\n",
    "tfidf_fs_train = tfidf_fs_sc.fit_transform(tfidf_fs_train)\n",
    "tfidf_lsi_train = tfidf_lsi_sc.fit_transform(tfidf_lsi_train)\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "wv_val = wv_sc.transform(wv_val)\n",
    "fs_val = fs_sc.transform(fs_val)\n",
    "\n",
    "tfidf_wv_val = tfidf_wv_sc.transform(tfidf_wv_val)\n",
    "tfidf_fs_val = tfidf_fs_sc.transform(tfidf_fs_val)\n",
    "tfidf_lsi_val = tfidf_lsi_sc.transform(tfidf_lsi_val)\n",
    "# ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "tt_wv_train = wv_sc.transform(tt_wv_train)\n",
    "tt_fs_train = fs_sc.transform(tt_fs_train)\n",
    "\n",
    "tt_tfidf_wv_train = tfidf_wv_sc.transform(tt_tfidf_wv_train)\n",
    "tt_tfidf_fs_train = tfidf_fs_sc.transform(tt_tfidf_fs_train)\n",
    "tt_tfidf_lsi_train = tfidf_lsi_sc.transform(tt_tfidf_lsi_train)\n",
    "# ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((94731,), (9424,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_Y.shape, training_Y.ix[training_Y.index.str.contains('^2014[b]')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = pd.DataFrame(y_train, columns=topics).sum()  #, index=training_Y.ix[train_ix].index).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activism                       0.0\n",
       "bastilledaytruckattack         0.0\n",
       "berlinchristmasmarketattack    0.0\n",
       "brusselsattacks                0.0\n",
       "charliehebdoattack             0.0\n",
       "francetrainattack              0.0\n",
       "munichshooting                 0.0\n",
       "orlandoterrorattack            0.0\n",
       "parisattacks                   0.0\n",
       "peaceandreconciliation         0.0\n",
       "sanbernardinoshooting          0.0\n",
       "tunisiaattack2015              0.0\n",
       "turkeycoupattempt              0.0\n",
       "zikavirus                      0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[q == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print q[q > 0]['parisattacks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute for co-occurence probability and apply to the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  1., ...,  3.,  1.,  2.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as K\n",
    "import keras.backend as KB\n",
    "\n",
    "\n",
    "def f1_micro(y_true, y_pred):\n",
    "    TP = K.metrics.true_positives(y_true, K.round(y_pred))\n",
    "    FP = K.metrics.false_positives(y_true, K.round(y_pred))\n",
    "    FN = K.metrics.false_negatives(y_true, K.round(y_pred))\n",
    "    \n",
    "    p = K.reduce_sum(TP) / (K.reduce_sum(TP) + K.reduce_sum(FP))\n",
    "    r = K.reduce_sum(TP) / (K.reduce_sum(TP) + K.reduce_sum(FN))\n",
    "    \n",
    "    return (2.0 * p * r) / (p + r)\n",
    "\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    # http://stackoverflow.com/questions/43345909/when-using-mectrics-in-model-compile-in-keras-report-valueerror-unknown-metr\n",
    "    # Count positive samples.\n",
    "    c1 = KB.sum(KB.round(KB.clip(y_true * y_pred, 0, 1)))\n",
    "    c2 = KB.sum(KB.round(KB.clip(y_pred, 0, 1)))\n",
    "    c3 = KB.sum(KB.round(KB.clip(y_true, 0, 1)))\n",
    "\n",
    "    # If there are no true samples, fix the F1 score at 0.\n",
    "    if c3 == 0:\n",
    "        return 0\n",
    "\n",
    "    # How many selected items are relevant?\n",
    "    precision = c1 / c2\n",
    "\n",
    "    # How many relevant items are selected?\n",
    "    recall = c1 / c3\n",
    "\n",
    "    # Calculate f1_score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense, Dropout, Convolution1D, MaxPooling1D, Flatten\n",
    "from keras.models import Model\n",
    "import itertools as it\n",
    "\n",
    "\n",
    "def build_deep_input_stack(input_node):\n",
    "    x = Dense(128, activation='tanh')(input_node)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(256, activation='relu')(input_node)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def entangle_inputs(input_nodes=[]):\n",
    "    assert(len(input_nodes) > 1)\n",
    "    \n",
    "    entangled_inputs = []\n",
    "\n",
    "    for n1, n2 in it.combinations(input_nodes, 2):\n",
    "        entangled_inputs.append(\n",
    "            keras.layers.dot([n1, n2], 1, normalize=True)\n",
    "        )\n",
    "    \n",
    "    return entangled_inputs\n",
    "\n",
    "\n",
    "wv_input = Input(shape=(300,), name='wv_input')\n",
    "fs_input = Input(shape=(300,), name='fs_input')\n",
    "\n",
    "tfidf_wv_input = Input(shape=(300,), name='tfidf_wv_input')\n",
    "tfidf_fs_input = Input(shape=(300,), name='tfidf_fs_input')\n",
    "tfidf_lsi_input = Input(shape=(300,), name='tfidf_lsi_input')\n",
    "\n",
    "\n",
    "wv_x = build_deep_input_stack(wv_input)\n",
    "fs_x = build_deep_input_stack(fs_input)\n",
    "tfidf_wv_x = build_deep_input_stack(tfidf_wv_input)\n",
    "tfidf_fs_x = build_deep_input_stack(tfidf_fs_input)\n",
    "tfidf_lsi_x = build_deep_input_stack(tfidf_wv_input)\n",
    "\n",
    "stacked_inputs_x = [wv_x, fs_x, tfidf_wv_x, tfidf_fs_x, tfidf_lsi_x]\n",
    "# stacked_inputs_x = [tfidf_wv_x, tfidf_fs_x, tfidf_lsi_x]\n",
    "entangled_inputs_x = entangle_inputs(stacked_inputs_x)\n",
    "\n",
    "x = keras.layers.concatenate(stacked_inputs_x + entangled_inputs_x)\n",
    "\n",
    "# We stack a deep densely-connected network on top\n",
    "x = Dense(128, activation='tanh')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "# And finally we add the main logistic regression layer\n",
    "main_output = Dense(len(class2ind), activation='sigmoid', name='main_output')(x)\n",
    "\n",
    "model = Model(\n",
    "    inputs=[\n",
    "        wv_input,\n",
    "        fs_input,\n",
    "        tfidf_wv_input,\n",
    "        tfidf_fs_input,\n",
    "        tfidf_lsi_input,\n",
    "    ],\n",
    "    outputs=[main_output]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer='rmsprop',  # keras.optimizers.RMSprop(lr=0.005),  # , rho=0.9, epsilon=1e-08, decay=0.0, clipnorm=1),\n",
    "    loss={'main_output': 'categorical_crossentropy'},\n",
    "    loss_weights={'main_output': 1.},\n",
    "    metrics=['accuracy', f1_micro]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "wv_input (InputLayer)            (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "fs_input (InputLayer)            (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "tfidf_wv_input (InputLayer)      (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "tfidf_fs_input (InputLayer)      (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_55 (Dense)                 (None, 256)           77056                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_58 (Dense)                 (None, 256)           77056                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_61 (Dense)                 (None, 256)           77056                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_64 (Dense)                 (None, 256)           77056                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_67 (Dense)                 (None, 256)           77056                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)             (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)             (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)             (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)             (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)             (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_56 (Dense)                 (None, 512)           131584                                       \n",
      "____________________________________________________________________________________________________\n",
      "dense_59 (Dense)                 (None, 512)           131584                                       \n",
      "____________________________________________________________________________________________________\n",
      "dense_62 (Dense)                 (None, 512)           131584                                       \n",
      "____________________________________________________________________________________________________\n",
      "dense_65 (Dense)                 (None, 512)           131584                                       \n",
      "____________________________________________________________________________________________________\n",
      "dense_68 (Dense)                 (None, 512)           131584                                       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)             (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)             (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)             (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)             (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)             (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_21 (Dot)                     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_22 (Dot)                     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_23 (Dot)                     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_24 (Dot)                     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_25 (Dot)                     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_26 (Dot)                     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_27 (Dot)                     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_28 (Dot)                     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_29 (Dot)                     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_30 (Dot)                     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 2570)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_69 (Dense)                 (None, 128)           329088                                       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)             (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_70 (Dense)                 (None, 256)           33024                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)             (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_71 (Dense)                 (None, 256)           65792                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)             (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_72 (Dense)                 (None, 128)           32896                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)             (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 160)           20640                                        \n",
      "====================================================================================================\n",
      "Total params: 1,524,640\n",
      "Trainable params: 1,524,640\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense, Dropout, Convolution1D, MaxPooling1D, Flatten\n",
    "from keras.models import Model\n",
    "import itertools as it\n",
    "\n",
    "\n",
    "def build_deep_input_stack(input_node):\n",
    "    x = Dense(128, activation='tanh')(input_node)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(256, activation='relu')(input_node)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def entangle_inputs(input_nodes=[]):\n",
    "    assert(len(input_nodes) > 1)\n",
    "    \n",
    "    entangled_inputs = []\n",
    "\n",
    "    for n1, n2 in it.combinations(input_nodes, 2):\n",
    "        entangled_inputs.append(\n",
    "            keras.layers.dot([n1, n2], 1, normalize=True)\n",
    "        )\n",
    "    \n",
    "    return entangled_inputs\n",
    "\n",
    "\n",
    "test_wv_input = Input(shape=(300,), name='wv_input')\n",
    "test_fs_input = Input(shape=(300,), name='fs_input')\n",
    "\n",
    "test_tfidf_wv_input = Input(shape=(300,), name='tfidf_wv_input')\n",
    "test_tfidf_fs_input = Input(shape=(300,), name='tfidf_fs_input')\n",
    "test_tfidf_lsi_input = Input(shape=(300,), name='tfidf_lsi_input')\n",
    "\n",
    "\n",
    "test_wv_x = build_deep_input_stack(test_wv_input)\n",
    "test_fs_x = build_deep_input_stack(test_fs_input)\n",
    "test_tfidf_wv_x = build_deep_input_stack(test_tfidf_wv_input)\n",
    "test_tfidf_fs_x = build_deep_input_stack(test_tfidf_fs_input)\n",
    "test_tfidf_lsi_x = build_deep_input_stack(test_tfidf_wv_input)\n",
    "\n",
    "test_stacked_inputs_x = [test_wv_x, test_fs_x, test_tfidf_wv_x, test_tfidf_fs_x, test_tfidf_lsi_x]\n",
    "# stacked_inputs_x = [tfidf_wv_x, tfidf_fs_x, tfidf_lsi_x]\n",
    "test_entangled_inputs_x = entangle_inputs(test_stacked_inputs_x)\n",
    "\n",
    "test_x = keras.layers.concatenate(test_stacked_inputs_x + test_entangled_inputs_x)\n",
    "\n",
    "# We stack a deep densely-connected network on top\n",
    "test_x = Dense(128, activation='tanh')(test_x)\n",
    "test_x = Dropout(0.1)(test_x)\n",
    "test_x = Dense(256, activation='relu')(test_x)\n",
    "test_x = Dropout(0.1)(test_x)\n",
    "test_x = Dense(256, activation='relu')(test_x)\n",
    "test_x = Dropout(0.1)(test_x)\n",
    "test_x = Dense(128, activation='relu')(test_x)\n",
    "test_x = Dropout(0.1)(test_x)\n",
    "\n",
    "# And finally we add the main logistic regression layer\n",
    "test_main_output = Dense(len(class2ind), activation='sigmoid', name='main_output')(test_x)\n",
    "\n",
    "test_model = Model(\n",
    "    inputs=[\n",
    "        test_wv_input,\n",
    "        test_fs_input,\n",
    "        test_tfidf_wv_input,\n",
    "        test_tfidf_fs_input,\n",
    "        test_tfidf_lsi_input,\n",
    "    ],\n",
    "    outputs=[test_main_output]\n",
    ")\n",
    "\n",
    "test_model.compile(\n",
    "    optimizer='rmsprop',  # keras.optimizers.RMSprop(lr=0.005),  # , rho=0.9, epsilon=1e-08, decay=0.0, clipnorm=1),\n",
    "    loss={'main_output': 'categorical_crossentropy'},\n",
    "    loss_weights={'main_output': 1.},\n",
    "    metrics=['accuracy', f1_micro]\n",
    ")\n",
    "\n",
    "test_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_training_inputs(wv, fs, tfidf_wv, tfidf_fs, tfidf_lsi):\n",
    "    training_inputs = {\n",
    "        'wv_input': wv,\n",
    "        'fs_input': fs,\n",
    "        'tfidf_wv_input': tfidf_wv,\n",
    "        'tfidf_fs_input': tfidf_fs,\n",
    "        'tfidf_lsi_input': tfidf_lsi,\n",
    "    }\n",
    "    \n",
    "    return training_inputs\n",
    "    \n",
    "\n",
    "training_inputs = build_training_inputs(\n",
    "    wv_train,\n",
    "    fs_train,\n",
    "    tfidf_wv_train,\n",
    "    tfidf_fs_train,\n",
    "    tfidf_lsi_train,\n",
    ")\n",
    "\n",
    "training_outputs = {\n",
    "    'main_output': y_train,\n",
    "}\n",
    "\n",
    "\n",
    "tt_training_inputs = build_training_inputs(\n",
    "    tt_wv_train,\n",
    "    tt_fs_train,\n",
    "    tt_tfidf_wv_train,\n",
    "    tt_tfidf_fs_train,\n",
    "    tt_tfidf_lsi_train,\n",
    ")\n",
    "\n",
    "tt_training_outputs = {\n",
    "    'main_output': tt_y_train,\n",
    "}\n",
    "\n",
    "\n",
    "validation_data=(\n",
    "    build_training_inputs(\n",
    "        wv_val,\n",
    "        fs_val,\n",
    "        tfidf_wv_val,\n",
    "        tfidf_fs_val,\n",
    "        tfidf_lsi_val,\n",
    "    ),\n",
    "    {\n",
    "        'main_output': y_val,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.2976 - acc: 0.7517 - f1_micro: 0.7575 - val_loss: 1.1297 - val_acc: 0.7928 - val_f1_micro: 0.7580\n",
      "Epoch 2/100\n",
      "43000/56877 [=====================>........] - ETA: 0s - loss: 1.3010 - acc: 0.7536 - f1_micro: 0.7584"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# And trained it via:\n",
    "batch_size = 1000\n",
    "epochs = 100\n",
    "\n",
    "hist = model.fit(\n",
    "    training_inputs,\n",
    "    training_outputs,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    validation_data=validation_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 57243 samples, validate on 9424 samples\n",
      "Epoch 1/100\n",
      "57243/57243 [==============================] - 2s - loss: 5.5912 - acc: 0.1311 - f1_micro: 0.0623 - val_loss: 4.1323 - val_acc: 0.3859 - val_f1_micro: 0.0986\n",
      "Epoch 2/100\n",
      "57243/57243 [==============================] - 1s - loss: 3.6871 - acc: 0.4257 - f1_micro: 0.1272 - val_loss: 3.1396 - val_acc: 0.5214 - val_f1_micro: 0.1534\n",
      "Epoch 3/100\n",
      "57243/57243 [==============================] - 1s - loss: 3.1277 - acc: 0.5146 - f1_micro: 0.1772 - val_loss: 2.8967 - val_acc: 0.5552 - val_f1_micro: 0.1998\n",
      "Epoch 4/100\n",
      "57243/57243 [==============================] - 1s - loss: 2.8610 - acc: 0.5510 - f1_micro: 0.2206 - val_loss: 2.6817 - val_acc: 0.5861 - val_f1_micro: 0.2402\n",
      "Epoch 5/100\n",
      "57243/57243 [==============================] - 1s - loss: 2.6815 - acc: 0.5749 - f1_micro: 0.2582 - val_loss: 2.5960 - val_acc: 0.6004 - val_f1_micro: 0.2755\n",
      "Epoch 6/100\n",
      "57243/57243 [==============================] - 1s - loss: 2.5482 - acc: 0.5919 - f1_micro: 0.2915 - val_loss: 2.3847 - val_acc: 0.6325 - val_f1_micro: 0.3066\n",
      "Epoch 7/100\n",
      "57243/57243 [==============================] - 1s - loss: 2.4493 - acc: 0.6063 - f1_micro: 0.3204 - val_loss: 2.2740 - val_acc: 0.6517 - val_f1_micro: 0.3337\n",
      "Epoch 8/100\n",
      "57243/57243 [==============================] - 1s - loss: 2.3741 - acc: 0.6138 - f1_micro: 0.3458 - val_loss: 2.2174 - val_acc: 0.6473 - val_f1_micro: 0.3577\n",
      "Epoch 9/100\n",
      "57243/57243 [==============================] - 1s - loss: 2.2980 - acc: 0.6243 - f1_micro: 0.3687 - val_loss: 2.1907 - val_acc: 0.6580 - val_f1_micro: 0.3792\n",
      "Epoch 10/100\n",
      "57243/57243 [==============================] - 1s - loss: 2.2374 - acc: 0.6306 - f1_micro: 0.3891 - val_loss: 2.1049 - val_acc: 0.6603 - val_f1_micro: 0.3986\n",
      "Epoch 11/100\n",
      "57243/57243 [==============================] - 1s - loss: 2.1822 - acc: 0.6379 - f1_micro: 0.4075 - val_loss: 2.0515 - val_acc: 0.6619 - val_f1_micro: 0.4161\n",
      "Epoch 12/100\n",
      "57243/57243 [==============================] - 1s - loss: 2.1317 - acc: 0.6436 - f1_micro: 0.4241 - val_loss: 2.0262 - val_acc: 0.6813 - val_f1_micro: 0.4320\n",
      "Epoch 13/100\n",
      "57243/57243 [==============================] - 1s - loss: 2.0922 - acc: 0.6509 - f1_micro: 0.4394 - val_loss: 1.9382 - val_acc: 0.6744 - val_f1_micro: 0.4468\n",
      "Epoch 14/100\n",
      "57243/57243 [==============================] - 1s - loss: 2.0463 - acc: 0.6539 - f1_micro: 0.4537 - val_loss: 1.9946 - val_acc: 0.6767 - val_f1_micro: 0.4604\n",
      "Epoch 15/100\n",
      "57243/57243 [==============================] - 1s - loss: 2.0103 - acc: 0.6613 - f1_micro: 0.4668 - val_loss: 1.8826 - val_acc: 0.7048 - val_f1_micro: 0.4730\n",
      "Epoch 16/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.9779 - acc: 0.6619 - f1_micro: 0.4789 - val_loss: 1.8512 - val_acc: 0.7073 - val_f1_micro: 0.4846\n",
      "Epoch 17/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.9401 - acc: 0.6698 - f1_micro: 0.4901 - val_loss: 1.7720 - val_acc: 0.6961 - val_f1_micro: 0.4954\n",
      "Epoch 18/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.9103 - acc: 0.6738 - f1_micro: 0.5004 - val_loss: 1.7938 - val_acc: 0.7046 - val_f1_micro: 0.5054\n",
      "Epoch 19/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.8924 - acc: 0.6755 - f1_micro: 0.5101 - val_loss: 1.7133 - val_acc: 0.7006 - val_f1_micro: 0.5147\n",
      "Epoch 20/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.8589 - acc: 0.6793 - f1_micro: 0.5192 - val_loss: 1.7476 - val_acc: 0.7102 - val_f1_micro: 0.5236\n",
      "Epoch 21/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.8340 - acc: 0.6841 - f1_micro: 0.5278 - val_loss: 1.7387 - val_acc: 0.7155 - val_f1_micro: 0.5319\n",
      "Epoch 22/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.8116 - acc: 0.6870 - f1_micro: 0.5358 - val_loss: 1.6685 - val_acc: 0.7267 - val_f1_micro: 0.5397\n",
      "Epoch 23/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.7949 - acc: 0.6899 - f1_micro: 0.5434 - val_loss: 1.6064 - val_acc: 0.7362 - val_f1_micro: 0.5471\n",
      "Epoch 24/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.7772 - acc: 0.6927 - f1_micro: 0.5507 - val_loss: 1.5902 - val_acc: 0.7275 - val_f1_micro: 0.5542"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# And trained it via:\n",
    "batch_size = 1000\n",
    "epochs = 100\n",
    "\n",
    "tt_hist = test_model.fit(\n",
    "    tt_training_inputs,\n",
    "    tt_training_outputs,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    validation_data=validation_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.81847799925922604, 1.2065972358170178)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history['f1_micro'][-1], hist.history['loss'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.74855364079020836, 1.3025726030314513)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_hist.history['f1_micro'][-1], tt_hist.history['loss'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = keras.models.load_model(\n",
    "#     'models/lstm-word2vec-fasttext_2010-2014-data_categorical-crossentropy-2014-b-val-standard_scaled_wv_fs.model',\n",
    "#     custom_objects={'f1_micro': f1_micro}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = test_model.predict(\n",
    "    build_training_inputs(\n",
    "        wv_train,\n",
    "        fs_train,\n",
    "        tfidf_wv_train,\n",
    "        tfidf_fs_train,\n",
    "        tfidf_lsi_train,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score as sk_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 896 ms, sys: 20 ms, total: 916 ms\n",
      "Wall time: 915 ms\n",
      "CPU times: user 420 ms, sys: 16 ms, total: 436 ms\n",
      "Wall time: 430 ms\n",
      "CPU times: user 420 ms, sys: 8 ms, total: 428 ms\n",
      "Wall time: 428 ms\n",
      "CPU times: user 420 ms, sys: 8 ms, total: 428 ms\n",
      "Wall time: 428 ms\n",
      "CPU times: user 432 ms, sys: 0 ns, total: 432 ms\n",
      "Wall time: 428 ms\n",
      "CPU times: user 432 ms, sys: 0 ns, total: 432 ms\n",
      "Wall time: 427 ms\n",
      "CPU times: user 412 ms, sys: 16 ms, total: 428 ms\n",
      "Wall time: 427 ms\n",
      "CPU times: user 432 ms, sys: 0 ns, total: 432 ms\n",
      "Wall time: 426 ms\n",
      "CPU times: user 444 ms, sys: 12 ms, total: 456 ms\n",
      "Wall time: 452 ms\n",
      "CPU times: user 432 ms, sys: 20 ms, total: 452 ms\n",
      "Wall time: 449 ms\n",
      "CPU times: user 440 ms, sys: 12 ms, total: 452 ms\n",
      "Wall time: 448 ms\n",
      "CPU times: user 452 ms, sys: 0 ns, total: 452 ms\n",
      "Wall time: 448 ms\n",
      "CPU times: user 448 ms, sys: 0 ns, total: 448 ms\n",
      "Wall time: 445 ms\n",
      "CPU times: user 420 ms, sys: 8 ms, total: 428 ms\n",
      "Wall time: 428 ms\n",
      "CPU times: user 424 ms, sys: 8 ms, total: 432 ms\n",
      "Wall time: 426 ms\n",
      "CPU times: user 424 ms, sys: 20 ms, total: 444 ms\n",
      "Wall time: 440 ms\n",
      "CPU times: user 420 ms, sys: 12 ms, total: 432 ms\n",
      "Wall time: 431 ms\n",
      "CPU times: user 448 ms, sys: 8 ms, total: 456 ms\n",
      "Wall time: 453 ms\n",
      "CPU times: user 452 ms, sys: 4 ms, total: 456 ms\n",
      "Wall time: 451 ms\n",
      "CPU times: user 444 ms, sys: 4 ms, total: 448 ms\n",
      "Wall time: 446 ms\n",
      "CPU times: user 444 ms, sys: 4 ms, total: 448 ms\n",
      "Wall time: 448 ms\n",
      "CPU times: user 444 ms, sys: 8 ms, total: 452 ms\n",
      "Wall time: 449 ms\n",
      "CPU times: user 444 ms, sys: 8 ms, total: 452 ms\n",
      "Wall time: 448 ms\n",
      "CPU times: user 444 ms, sys: 8 ms, total: 452 ms\n",
      "Wall time: 449 ms\n",
      "CPU times: user 436 ms, sys: 4 ms, total: 440 ms\n",
      "Wall time: 435 ms\n",
      "CPU times: user 432 ms, sys: 0 ns, total: 432 ms\n",
      "Wall time: 427 ms\n",
      "CPU times: user 424 ms, sys: 8 ms, total: 432 ms\n",
      "Wall time: 427 ms\n",
      "CPU times: user 432 ms, sys: 0 ns, total: 432 ms\n",
      "Wall time: 431 ms\n",
      "CPU times: user 440 ms, sys: 8 ms, total: 448 ms\n",
      "Wall time: 448 ms\n",
      "CPU times: user 436 ms, sys: 12 ms, total: 448 ms\n",
      "Wall time: 445 ms\n",
      "CPU times: user 424 ms, sys: 4 ms, total: 428 ms\n",
      "Wall time: 426 ms\n",
      "CPU times: user 436 ms, sys: 16 ms, total: 452 ms\n",
      "Wall time: 449 ms\n",
      "CPU times: user 448 ms, sys: 4 ms, total: 452 ms\n",
      "Wall time: 449 ms\n",
      "CPU times: user 440 ms, sys: 16 ms, total: 456 ms\n",
      "Wall time: 450 ms\n",
      "CPU times: user 436 ms, sys: 0 ns, total: 436 ms\n",
      "Wall time: 431 ms\n",
      "CPU times: user 440 ms, sys: 12 ms, total: 452 ms\n",
      "Wall time: 447 ms\n",
      "CPU times: user 448 ms, sys: 4 ms, total: 452 ms\n",
      "Wall time: 449 ms\n",
      "CPU times: user 432 ms, sys: 20 ms, total: 452 ms\n",
      "Wall time: 448 ms\n",
      "CPU times: user 452 ms, sys: 0 ns, total: 452 ms\n",
      "Wall time: 448 ms\n",
      "CPU times: user 440 ms, sys: 8 ms, total: 448 ms\n",
      "Wall time: 444 ms\n",
      "CPU times: user 428 ms, sys: 4 ms, total: 432 ms\n",
      "Wall time: 427 ms\n",
      "CPU times: user 440 ms, sys: 12 ms, total: 452 ms\n",
      "Wall time: 450 ms\n",
      "CPU times: user 432 ms, sys: 16 ms, total: 448 ms\n",
      "Wall time: 446 ms\n",
      "CPU times: user 416 ms, sys: 16 ms, total: 432 ms\n",
      "Wall time: 429 ms\n",
      "CPU times: user 440 ms, sys: 12 ms, total: 452 ms\n",
      "Wall time: 446 ms\n",
      "CPU times: user 444 ms, sys: 8 ms, total: 452 ms\n",
      "Wall time: 447 ms\n",
      "CPU times: user 436 ms, sys: 12 ms, total: 448 ms\n",
      "Wall time: 446 ms\n",
      "CPU times: user 444 ms, sys: 4 ms, total: 448 ms\n",
      "Wall time: 444 ms\n",
      "CPU times: user 428 ms, sys: 0 ns, total: 428 ms\n",
      "Wall time: 426 ms\n",
      "CPU times: user 416 ms, sys: 12 ms, total: 428 ms\n",
      "Wall time: 426 ms\n",
      "CPU times: user 440 ms, sys: 12 ms, total: 452 ms\n",
      "Wall time: 450 ms\n",
      "CPU times: user 440 ms, sys: 16 ms, total: 456 ms\n",
      "Wall time: 450 ms\n",
      "CPU times: user 424 ms, sys: 8 ms, total: 432 ms\n",
      "Wall time: 428 ms\n",
      "CPU times: user 436 ms, sys: 12 ms, total: 448 ms\n",
      "Wall time: 446 ms\n",
      "CPU times: user 436 ms, sys: 16 ms, total: 452 ms\n",
      "Wall time: 447 ms\n",
      "CPU times: user 440 ms, sys: 8 ms, total: 448 ms\n",
      "Wall time: 446 ms\n",
      "CPU times: user 440 ms, sys: 8 ms, total: 448 ms\n",
      "Wall time: 446 ms\n",
      "CPU times: user 400 ms, sys: 28 ms, total: 428 ms\n",
      "Wall time: 425 ms\n",
      "CPU times: user 420 ms, sys: 12 ms, total: 432 ms\n",
      "Wall time: 429 ms\n",
      "CPU times: user 456 ms, sys: 4 ms, total: 460 ms\n",
      "Wall time: 454 ms\n",
      "CPU times: user 428 ms, sys: 20 ms, total: 448 ms\n",
      "Wall time: 445 ms\n",
      "CPU times: user 27 s, sys: 564 ms, total: 27.6 s\n",
      "Wall time: 27.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dt = 0.01\n",
    "s = 0.0\n",
    "e = 0.6\n",
    "th = np.arange(s, e + dt, dt)\n",
    "mean_fscores = []\n",
    "for t in th:\n",
    "#     fscores = []\n",
    "#     for ix in range(g.shape[0]):\n",
    "#         y_a = y_train[ix]\n",
    "#         y_p = 1.0 * (g[ix] > t)\n",
    "#         fscores.append(sk_f1_score(y_a, y_p))\n",
    "#     mean_fscores.append(np.mean(fscores))\n",
    "    %time mean_fscores.append((t, sk_f1_score(y_train, 1.0 * (g > t), average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.56000000000000005, 0.95136369056745207)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh, thresh_score = sorted(mean_fscores, key=lambda x: x[1], reverse=True)[0]\n",
    "thresh, thresh_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[78, 87, 125, 136, 150]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_Y.ix[train_ix].iloc[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iraq'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics[76]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbe5ad56090>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nS9D/A57Kq5pktPOQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbdb6acc150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "ix = 15\n",
    "sd = -20\n",
    "pd.Series(g[sd:][ix]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([76]),), (array([76]),))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# thresh = 0.5\n",
    "np.where(y_train[sd:][ix] == 1), np.where(g[sd:][ix] > thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "from gensim.models.lsimodel import LsiModel\n",
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = TfidfModel.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.dictionary')\n",
    "tfidf = TfidfModel.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.tfidf')\n",
    "lsi = LsiModel.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.lsi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wvmodel = Word2Vec.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fsmodel = fasttext.load_model('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.fasttext.model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_fsmodel_cache = {}\n",
    "def get_fsvec(word):\n",
    "    if word in _fsmodel_cache:\n",
    "        fv = _fsmodel_cache[word]\n",
    "    else:\n",
    "        fv = fsmodel[word]\n",
    "        _fsmodel_cache[word] = fv\n",
    "\n",
    "    return fv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_tfidf_word2vec(tokens, stopwords=[]):\n",
    "#     global wvmodel\n",
    "#     global tfidf\n",
    "    # This requires wvmodel to be present in the namespace.\n",
    "    wv_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords and w in wvmodel.wv.vocab)]\n",
    "    ).map(\n",
    "        lambda x: tfidf[dictionary.doc2bow(x)]\n",
    "    ).map(\n",
    "        lambda x: np.array([wvmodel[dictionary.id2token[id]] * w for id, w in x]).mean(axis=0) if len(x) > 0 else np.nan\n",
    "    )\n",
    "\n",
    "    return wv_feature_vec\n",
    "\n",
    "\n",
    "def transform_tfidf_fasttext(tokens, stopwords=[]):\n",
    "#     global fsmodel\n",
    "#     global tfidf\n",
    "    # This requires wvmodel to be present in the namespace.\n",
    "    fs_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    ).map(\n",
    "        lambda x: tfidf[dictionary.doc2bow(x)]\n",
    "    ).map(\n",
    "        lambda x: np.array([np.array(get_fsvec(dictionary.id2token[id])) * w for id, w in x]).mean(axis=0) if len(x) > 0 else np.nan\n",
    "    )\n",
    "\n",
    "    return fs_feature_vec\n",
    "\n",
    "\n",
    "def build_lsi_vector(l):\n",
    "    v = np.zeros(lsi.num_topics)\n",
    "    \n",
    "    for ix, vv in lsi[tfidf[dictionary.doc2bow(l)]]:\n",
    "        v[ix] = vv\n",
    "        \n",
    "    return v\n",
    "\n",
    "\n",
    "def transform_tfidf_lsi(tokens, stopwords=[]):\n",
    "#     global fsmodel\n",
    "#     global tfidf\n",
    "    # This requires wvmodel to be present in the namespace.\n",
    "    lsi_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    ).map(\n",
    "        lambda x: build_lsi_vector(x) if len(x) > 0 else np.nan\n",
    "    )\n",
    "\n",
    "    return lsi_feature_vec\n",
    "\n",
    "\n",
    "def transform_fasttext(tokens, stopwords=[]):\n",
    "    global fsmodel\n",
    "    # This requires fsmodel to be present in the namespace.\n",
    "    fs_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    ).map(lambda x: np.array([get_fsvec(w) for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return fs_feature_vec\n",
    "\n",
    "\n",
    "def transform_unsupervised_sentiment_neuron(tokens, stopwords=[]):\n",
    "    # This requires fsmodel to be present in the namespace.\n",
    "    \n",
    "    usn_feature_vec = usnmodel.transform(tokens)\n",
    "\n",
    "    # usn_feature_vec = tokens.map(\n",
    "    #     lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    # ).map(lambda x: np.array([usnmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return usn_feature_vec\n",
    "\n",
    "\n",
    "def transform_word2vec(tokens, stopwords=[]):\n",
    "    global wvmodel\n",
    "    # This requires wvmodel to be present in the namespace.\n",
    "    wv_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords and w in wvmodel.wv.vocab)]\n",
    "    ).map(lambda x: np.array([wvmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return wv_feature_vec\n",
    "\n",
    "\n",
    "def parallel_generate_word_vectors(samp, transformer, stopwords, batch, num_proc):\n",
    "    with Parallel(n_jobs=num_proc) as parallel:\n",
    "        dataset = []\n",
    "        is_break = False\n",
    "        i = 0\n",
    "\n",
    "        while not is_break:\n",
    "            payload = []\n",
    "\n",
    "            for j in xrange(num_proc):\n",
    "                t_df = samp[(i + j) * batch: (i + 1 + j) * batch]\n",
    "\n",
    "                if t_df.empty:\n",
    "                    is_break = True\n",
    "                    continue\n",
    "\n",
    "                payload.append(\n",
    "                    delayed(transformer)(\n",
    "                        t_df, stopwords\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            print('Current batch in main thread: {}'.format((i + j) * batch))\n",
    "\n",
    "            if payload:\n",
    "                results = parallel(payload)\n",
    "                dataset.extend(results)\n",
    "                i += num_proc\n",
    "\n",
    "    return pd.concat(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_classes(pred, scale_param=0.75, min_thresh=0.05, thresh = 0.5):\n",
    "#     mx = pred.mean() + 3 * pred.std()\n",
    "    return np.where(pred > thresh)[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2idx_transform(word, _word2idx):\n",
    "    return _word2idx.get(word, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features_for(df, min_batch=2000, stopwords=[], num_proc=7):\n",
    "    df_tokens = transform_text(df)\n",
    "    \n",
    "    batch = min(df_tokens.shape[0] / num_proc, min_batch)\n",
    "\n",
    "    print('Computing fs features...')\n",
    "    fvec = parallel_generate_word_vectors(df_tokens, transform_fasttext, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Computing wv features...')\n",
    "    wvec = parallel_generate_word_vectors(df_tokens, transform_word2vec, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Mapping word indices...')\n",
    "    word_indices = df_tokens.map(lambda x: [word2idx_transform(i, _word2idx) for i in x.split()])\n",
    "\n",
    "    print('Computing tfidf fs features...')\n",
    "    tfidf_fvec = parallel_generate_word_vectors(df_tokens, transform_tfidf_fasttext, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Computing tfidf wv features...')\n",
    "    tfidf_wvec = parallel_generate_word_vectors(df_tokens, transform_tfidf_word2vec, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Computing tfidf lsi features...')\n",
    "    tfidf_lsi = parallel_generate_word_vectors(df_tokens, transform_tfidf_lsi, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "    \n",
    "    return word_indices, wvec, fvec, tfidf_wvec, tfidf_fvec, tfidf_lsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/TestData.json') as fl:\n",
    "    data = json.load(fl)\n",
    "    test_df = pd.DataFrame(data['TestData']).T\n",
    "    del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fs features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Computing wv features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Mapping word indices...\n",
      "Computing tfidf fs features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Computing tfidf wv features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Computing tfidf lsi features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "CPU times: user 46.8 s, sys: 4.34 s, total: 51.2 s\n",
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_word_indices,test_wvec, test_fvec, test_tfidf_wvec, test_tfidf_fvec, test_tfidf_lsi = extract_features_for(\n",
    "    test_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert(np.all(test_wvec[test_wvec.isnull()].index == test_fvec[test_fvec.isnull()].index))\n",
    "test_null_index = test_wvec[test_wvec.isnull()].index.union(test_fvec[test_fvec.isnull()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'TestData_02543', u'TestData_05012', u'TestData_05830'], dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_null_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 356 ms, sys: 20 ms, total: 376 ms\n",
      "Wall time: 376 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "valid_test_index = test_word_indices.index.difference(test_null_index)\n",
    "x_test = test_word_indices.ix[valid_test_index]  # .map(lambda x: [top_token2ind.get(i, 0) for i in x])\n",
    "\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "wv_test = np.vstack(test_wvec.ix[valid_test_index])\n",
    "fs_test = np.vstack(test_fvec.ix[valid_test_index])\n",
    "\n",
    "tfidf_wv_test = np.vstack(test_tfidf_wvec.ix[valid_test_index])\n",
    "tfidf_fs_test = np.vstack(test_tfidf_fvec.ix[valid_test_index])\n",
    "tfidf_lsi_test = np.vstack(test_tfidf_lsi.ix[valid_test_index])\n",
    "\n",
    "wv_test = wv_sc.transform(wv_test)\n",
    "fs_test = fs_sc.transform(fs_test)\n",
    "\n",
    "tfidf_wv_test = tfidf_wv_sc.transform(tfidf_wv_test)\n",
    "tfidf_fs_test = tfidf_fs_sc.transform(tfidf_fs_test)\n",
    "tfidf_lsi_test = tfidf_lsi_sc.transform(tfidf_lsi_test)\n",
    "\n",
    "test_inputs = build_training_inputs(\n",
    "    wv_test,\n",
    "    fs_test,\n",
    "    tfidf_wv_test,\n",
    "    tfidf_fs_test,\n",
    "    tfidf_lsi_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_probas = model.predict(test_inputs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tt_test_probas = test_model.predict(test_inputs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_test_probas = test_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2542, 5011, 5829]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_index = [int(s.split('_')[1]) - 1 for s in test_null_index]  # Subtract 1 since test index starts at 1 while enumerate starts at 0\n",
    "skip_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7578, 160), (7581, 3))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_test_probas.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32 ms, sys: 4 ms, total: 36 ms\n",
      "Wall time: 32.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# valid_test_feature_vec found below!\n",
    "# thresh = 0.3\n",
    "test_values = np.zeros([main_test_probas.shape[0], len(topics)])\n",
    "for ix, pred in enumerate(main_test_probas):\n",
    "    for v in get_classes(pred, thresh=thresh):\n",
    "        test_values[ix][v] = 1\n",
    "\n",
    "test_sub_df = pd.DataFrame(\n",
    "    test_values,\n",
    "    index=test_df.ix[test_df.index.difference(test_null_index)].index,\n",
    "    columns=topics\n",
    ")\n",
    "\n",
    "null_test_df = pd.DataFrame(\n",
    "    np.zeros((len(test_null_index), len(topics))),\n",
    "    index=test_null_index,\n",
    "    columns=topics\n",
    ")\n",
    "\n",
    "test_sub_df = test_sub_df.append(null_test_df)\n",
    "test_sub_df = test_sub_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36 ms, sys: 0 ns, total: 36 ms\n",
      "Wall time: 31.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# valid_test_feature_vec found below!\n",
    "thresh = 0.3\n",
    "test_values = np.zeros([main_test_probas.shape[0], len(topics)])\n",
    "for ix, pred in enumerate(tt_test_probas):\n",
    "    for v in get_classes(pred, thresh=thresh):\n",
    "        test_values[ix][v] = 1\n",
    "\n",
    "tt_test_sub_df = pd.DataFrame(\n",
    "    test_values,\n",
    "    index=test_df.ix[test_df.index.difference(test_null_index)].index,\n",
    "    columns=topics\n",
    ")\n",
    "\n",
    "null_test_df = pd.DataFrame(\n",
    "    np.zeros((len(test_null_index), len(topics))),\n",
    "    index=test_null_index,\n",
    "    columns=topics\n",
    ")\n",
    "\n",
    "tt_test_sub_df = tt_test_sub_df.append(null_test_df)\n",
    "tt_test_sub_df = tt_test_sub_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13311.0"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.iloc[3319].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 160)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = test_sub_df[test_sub_df.berlinchristmasmarketattack == 1]\n",
    "print u.shape\n",
    "u.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6552, 0.56000000000000005)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6552, thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12761.0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activism                                    0.0\n",
       "afghanistan                               126.0\n",
       "aid                                        60.0\n",
       "algerianhostagecrisis                      21.0\n",
       "alqaida                                   165.0\n",
       "alshabaab                                  35.0\n",
       "antiwar                                     0.0\n",
       "arabandmiddleeastprotests                 227.0\n",
       "armstrade                                  87.0\n",
       "australianguncontrol                        0.0\n",
       "australiansecurityandcounterterrorism     100.0\n",
       "bastilledaytruckattack                      0.0\n",
       "belgium                                    42.0\n",
       "berlinchristmasmarketattack                 0.0\n",
       "bigdata                                    12.0\n",
       "biometrics                                  0.0\n",
       "bokoharam                                  38.0\n",
       "bostonmarathonbombing                      71.0\n",
       "britisharmy                                 5.0\n",
       "brusselsattacks                             0.0\n",
       "cameroon                                    1.0\n",
       "carers                                      1.0\n",
       "charliehebdoattack                          0.0\n",
       "chemicalweapons                            35.0\n",
       "clusterbombs                                2.0\n",
       "cobra                                       2.0\n",
       "conflictanddevelopment                     61.0\n",
       "controversy                                 2.0\n",
       "criminaljustice                            18.0\n",
       "cybercrime                                 81.0\n",
       "                                          ...  \n",
       "somalia                                    55.0\n",
       "southafrica                                40.0\n",
       "southchinasea                               6.0\n",
       "stopandsearch                               0.0\n",
       "surveillance                              145.0\n",
       "sydneysiege                                23.0\n",
       "syria                                    1404.0\n",
       "taliban                                    55.0\n",
       "terrorism                                 225.0\n",
       "thailand                                   35.0\n",
       "torture                                    17.0\n",
       "traincrashes                                6.0\n",
       "transport                                  85.0\n",
       "tunisiaattack2015                           0.0\n",
       "turkey                                    254.0\n",
       "turkeycoupattempt                           0.0\n",
       "ukcrime                                   289.0\n",
       "uksecurity                                507.0\n",
       "uksupremecourt                              6.0\n",
       "undercoverpoliceandpolicing                 2.0\n",
       "unitednations                             233.0\n",
       "usguncontrol                              237.0\n",
       "values                                      0.0\n",
       "warcrimes                                  36.0\n",
       "warreporting                               13.0\n",
       "weaponstechnology                          10.0\n",
       "womeninbusiness                             0.0\n",
       "woolwichattack                             40.0\n",
       "worldmigration                             16.0\n",
       "zikavirus                                   0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9520.0"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activism                                    0.0\n",
       "afghanistan                               100.0\n",
       "aid                                        66.0\n",
       "algerianhostagecrisis                       9.0\n",
       "alqaida                                   115.0\n",
       "alshabaab                                  35.0\n",
       "antiwar                                     0.0\n",
       "arabandmiddleeastprotests                 209.0\n",
       "armstrade                                  80.0\n",
       "australianguncontrol                        0.0\n",
       "australiansecurityandcounterterrorism      42.0\n",
       "bastilledaytruckattack                     24.0\n",
       "belgium                                     5.0\n",
       "berlinchristmasmarketattack                21.0\n",
       "bigdata                                     9.0\n",
       "biometrics                                  0.0\n",
       "bokoharam                                  39.0\n",
       "bostonmarathonbombing                      52.0\n",
       "britisharmy                                 2.0\n",
       "brusselsattacks                            50.0\n",
       "cameroon                                    0.0\n",
       "carers                                      2.0\n",
       "charliehebdoattack                         62.0\n",
       "chemicalweapons                            22.0\n",
       "clusterbombs                                2.0\n",
       "cobra                                       0.0\n",
       "conflictanddevelopment                     50.0\n",
       "controversy                                 0.0\n",
       "criminaljustice                            25.0\n",
       "cybercrime                                 58.0\n",
       "                                          ...  \n",
       "somalia                                    45.0\n",
       "southafrica                                30.0\n",
       "southchinasea                               4.0\n",
       "stopandsearch                               0.0\n",
       "surveillance                              101.0\n",
       "sydneysiege                                14.0\n",
       "syria                                    1170.0\n",
       "taliban                                    38.0\n",
       "terrorism                                  83.0\n",
       "thailand                                   31.0\n",
       "torture                                    12.0\n",
       "traincrashes                                2.0\n",
       "transport                                  84.0\n",
       "tunisiaattack2015                          35.0\n",
       "turkey                                    187.0\n",
       "turkeycoupattempt                          43.0\n",
       "ukcrime                                   188.0\n",
       "uksecurity                                306.0\n",
       "uksupremecourt                              8.0\n",
       "undercoverpoliceandpolicing                 2.0\n",
       "unitednations                             183.0\n",
       "usguncontrol                              130.0\n",
       "values                                      0.0\n",
       "warcrimes                                  23.0\n",
       "warreporting                                5.0\n",
       "weaponstechnology                           4.0\n",
       "womeninbusiness                             0.0\n",
       "woolwichattack                             15.0\n",
       "worldmigration                             22.0\n",
       "zikavirus                                   4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_test_sub_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf_wv_300-fs_300-lsi_300-deep_stack_net-low_dropout-rmsprop-epochs_300-tanh_init_activation-f1_0.8185-loss_1.2066-data_2012_2014_test_augmented_3_upsample-val_data_2014-thresh_0.3-with_sc_wv_fs_lsi.csv\n"
     ]
    }
   ],
   "source": [
    "# 1.1745 - acc: 0.7750 - f1_micro: 0.7891\n",
    "sub_filename = 'tfidf_wv_300-fs_300-lsi_300-deep_stack_net-low_dropout-rmsprop-epochs_300-tanh_init_activation-f1_{:.4f}-loss_{:.4f}-data_2012_2014_test_augmented_3_upsample-val_data_2014-thresh_{}-with_sc_wv_fs_lsi.csv'.format(hist.history['f1_micro'][-1], hist.history['loss'][-1], thresh)\n",
    "print sub_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_sub_df.astype(int).reset_index().rename(\n",
    "    columns={'index': 'id'}\n",
    ").sort_values('id').to_csv(\n",
    "    sub_filename, \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7581, 160)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfd = pd.read_csv('tfidf_wv_300-fs_300-lsi_300-deep_stack_net-low_dropout-rmsprop-epochs_110-tanh_init_activation-f1_0.7528-data_2012_2014_test_augmented_10_upsample-val_data_2014-thresh_0.48-with_sc_wv_fs_lsi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfd.set_index('id').iloc[7262]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activism                                   0\n",
       "afghanistan                               -4\n",
       "aid                                        4\n",
       "algerianhostagecrisis                     22\n",
       "alqaida                                   36\n",
       "alshabaab                                  0\n",
       "antiwar                                    2\n",
       "arabandmiddleeastprotests                 30\n",
       "armstrade                                 -2\n",
       "australianguncontrol                       0\n",
       "australiansecurityandcounterterrorism     37\n",
       "bastilledaytruckattack                   -24\n",
       "belgium                                   82\n",
       "berlinchristmasmarketattack              -21\n",
       "bigdata                                   -1\n",
       "biometrics                                 2\n",
       "bokoharam                                 -1\n",
       "bostonmarathonbombing                     52\n",
       "britisharmy                                2\n",
       "brusselsattacks                          -50\n",
       "cameroon                                   1\n",
       "carers                                     1\n",
       "charliehebdoattack                       -62\n",
       "chemicalweapons                           16\n",
       "clusterbombs                               1\n",
       "cobra                                      0\n",
       "conflictanddevelopment                     5\n",
       "controversy                                4\n",
       "criminaljustice                           14\n",
       "cybercrime                                -3\n",
       "                                        ... \n",
       "somalia                                   -5\n",
       "southafrica                                6\n",
       "southchinasea                              2\n",
       "stopandsearch                              2\n",
       "surveillance                              28\n",
       "sydneysiege                               24\n",
       "syria                                    229\n",
       "taliban                                   16\n",
       "terrorism                                 97\n",
       "thailand                                   1\n",
       "torture                                    0\n",
       "traincrashes                               1\n",
       "transport                                  1\n",
       "tunisiaattack2015                        -35\n",
       "turkey                                    68\n",
       "turkeycoupattempt                        -43\n",
       "ukcrime                                   78\n",
       "uksecurity                               109\n",
       "uksupremecourt                             1\n",
       "undercoverpoliceandpolicing                1\n",
       "unitednations                             31\n",
       "usguncontrol                             133\n",
       "values                                     0\n",
       "warcrimes                                  1\n",
       "warreporting                              12\n",
       "weaponstechnology                          2\n",
       "womeninbusiness                            0\n",
       "woolwichattack                            20\n",
       "worldmigration                            -9\n",
       "zikavirus                                 -4\n",
       "dtype: object"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dfd.sum() - tt_test_sub_df.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TestData_04490\tThe World Health Organisation has convened an ...\t[]\t28-01-2016\n",
    "TestData_04550\tSpraying pesticides will fail to deal with the...\t[]\t02-02-2016\n",
    "TestData_05683\tViolent protests at Trump rally in California ...\t[]\t03-06-2016\n",
    "TestData_05869\tLast weekend, we saw the darkest side of human...\t[]\t17-06-2016\n",
    "TestData_06148\tAs dusk falls over Copacabana beach, Ubira San...\t[]\t16-07-2016\n",
    "TestData_06291\tIt is 3pm and yet another patient is brought t...\t[]\t27-07-2016\n",
    "TestData_06610\tHuddled around their hives, beekeepers around ...\t[]\t04-09-2016\n",
    "TestData_06708\tA United Nations high-level panel on access to...\t[]\t14-09-2016\n",
    "TestData_07263\tWHO: Zika virus is no longer a world threat Th...\t[]\t19-11-2016\n",
    "TestData_07478\t1 World Health Organisation declares a public ...\t[]\t18-12-2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "guncrime        1.0\n",
       "usguncontrol    1.0\n",
       "Name: TestData_05869, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = 5868\n",
    "test_sub_df.iloc[ix][test_sub_df.iloc[ix] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36 ms, sys: 0 ns, total: 36 ms\n",
      "Wall time: 32.6 ms\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# adjust_index = 0\n",
    "# # valid_test_feature_vec found below!\n",
    "# test_values = np.zeros([test_df.shape[0], len(topics)])\n",
    "# for ix, pred in enumerate(main_test_probas):\n",
    "#     if ix in skip_index:\n",
    "#         test_values[ix] = np.nan\n",
    "#         # Increment adjust index so that we have the correct index for other samples\n",
    "#         adjust_index += 1\n",
    "#         continue\n",
    "\n",
    "#     for v in get_classes(pred, thresh=0.05):\n",
    "#         test_values[ix + adjust_index][v] = 1\n",
    "\n",
    "# test_sub_df = pd.DataFrame(test_values, columns=sorted(topics), index=test_df.index)\n",
    "\n",
    "# q = test_sub_df.sum(axis=1)\n",
    "# assert(len(q[q.isnull()].index.difference(test_null_index)) == 0)\n",
    "\n",
    "# test_sub_df = test_sub_df.fillna(0)\n",
    "\n",
    "# # for i in test_feature_vec[test_feature_vec.isnull()].index:\n",
    "# #     test_sub_df.ix[i] = np.zeros(len(topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestData_02543    0.0\n",
       "TestData_05012    0.0\n",
       "TestData_05830    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.ix[test_null_index].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11656.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sub_df.astype(int).reset_index().rename(\n",
    "    columns={'index': 'id'}\n",
    ").sort_values('id').to_csv(\n",
    "    'lstm_300-word2vec_300-fasttext_300-maxlen_500-dense_64_64_64-cat_cross-epoch_210-batch_size_750-val_main_output_f1_micro_0.5760-main_output_f1_micro_0.5751-main_output_loss_0.9143-data_2010_2013-val_data_2014-thresh_0.05.csv', \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: zikavirus, dtype: float64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = test_sub_df['zikavirus']\n",
    "e[e==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14328"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_submission = pd.read_csv('basic_nn_submission_0.649_accuracy_multi_class.csv')\n",
    "top_submission.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9280"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_index_lstm_sub = pd.read_csv('lstm.2014b_training_700_maxlen_64cell_100epochs_0.0025_threshold.csv')\n",
    "wrong_index_lstm_sub.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34952"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_sub = pd.read_csv('basic_nn_submission_full_training_data_0.9958_validation_accuracy_binary_crossentropy.csv')\n",
    "some_sub.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2197, 160)\n",
      "(3957, 160)\n",
      "(12, 160)\n",
      "(1503, 160)\n"
     ]
    }
   ],
   "source": [
    "print top_submission.set_index('id')[top_submission.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print wrong_index_lstm_sub.set_index('id')[wrong_index_lstm_sub.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print some_sub.set_index('id')[some_sub.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print test_sub_df[test_sub_df.sum(axis=1) == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestData_00011     0\n",
       "TestData_00012     0\n",
       "TestData_00015     0\n",
       "TestData_00027     3\n",
       "TestData_00029     0\n",
       "TestData_00038     1\n",
       "TestData_00042     5\n",
       "TestData_00053     4\n",
       "TestData_00056     1\n",
       "TestData_00060     1\n",
       "TestData_00066     0\n",
       "TestData_00085     0\n",
       "TestData_00087     1\n",
       "TestData_00090     0\n",
       "TestData_00092     0\n",
       "TestData_00107     3\n",
       "TestData_00111     0\n",
       "TestData_00114     0\n",
       "TestData_00115     1\n",
       "TestData_00118     0\n",
       "TestData_00119     0\n",
       "TestData_00121     0\n",
       "TestData_00123     0\n",
       "TestData_00125     0\n",
       "TestData_00127     0\n",
       "TestData_00128     1\n",
       "TestData_00139     1\n",
       "TestData_00140     1\n",
       "TestData_00144     0\n",
       "TestData_00147     2\n",
       "                  ..\n",
       "TestData_07445     0\n",
       "TestData_07456     3\n",
       "TestData_07461     1\n",
       "TestData_07462     4\n",
       "TestData_07465     0\n",
       "TestData_07468     0\n",
       "TestData_07471     1\n",
       "TestData_07475     0\n",
       "TestData_07486    10\n",
       "TestData_07495     1\n",
       "TestData_07509     0\n",
       "TestData_07514     3\n",
       "TestData_07515     1\n",
       "TestData_07523     0\n",
       "TestData_07533     2\n",
       "TestData_07534     2\n",
       "TestData_07542     1\n",
       "TestData_07544     2\n",
       "TestData_07545     0\n",
       "TestData_07552     2\n",
       "TestData_07556     5\n",
       "TestData_07563     1\n",
       "TestData_07565     0\n",
       "TestData_07566     0\n",
       "TestData_07569     0\n",
       "TestData_07571     3\n",
       "TestData_07572     1\n",
       "TestData_07579     6\n",
       "TestData_07580     2\n",
       "TestData_07581     3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_submission.set_index('id').ix[q[q == 0].index].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1222,)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.sum(axis=1)\n",
    "q[q==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7581.000000\n",
       "mean        2.160929\n",
       "std         1.739411\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         2.000000\n",
       "75%         3.000000\n",
       "max        13.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = trainingY.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    236286.000000\n",
       "mean          1.392787\n",
       "std           0.762577\n",
       "min           1.000000\n",
       "25%           1.000000\n",
       "50%           1.000000\n",
       "75%           2.000000\n",
       "max          15.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bodyText</th>\n",
       "      <th>topics</th>\n",
       "      <th>webPublicationDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TestData_03241</th>\n",
       "      <td>A special British police unit was put on stand...</td>\n",
       "      <td>[]</td>\n",
       "      <td>15-11-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_04088</th>\n",
       "      <td>The youngest convict in a fatal gang-rape in N...</td>\n",
       "      <td>[]</td>\n",
       "      <td>20-12-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_06306</th>\n",
       "      <td>Former New York City mayor Rudy Giuliani has s...</td>\n",
       "      <td>[]</td>\n",
       "      <td>28-07-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_06083</th>\n",
       "      <td>John Cantlie, the British journalist who has b...</td>\n",
       "      <td>[]</td>\n",
       "      <td>13-07-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_05896</th>\n",
       "      <td>Lawyers for the companies that manufactured an...</td>\n",
       "      <td>[]</td>\n",
       "      <td>20-06-2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         bodyText topics  \\\n",
       "TestData_03241  A special British police unit was put on stand...     []   \n",
       "TestData_04088  The youngest convict in a fatal gang-rape in N...     []   \n",
       "TestData_06306  Former New York City mayor Rudy Giuliani has s...     []   \n",
       "TestData_06083  John Cantlie, the British journalist who has b...     []   \n",
       "TestData_05896  Lawyers for the companies that manufactured an...     []   \n",
       "\n",
       "               webPublicationDate  \n",
       "TestData_03241         15-11-2015  \n",
       "TestData_04088         20-12-2015  \n",
       "TestData_06306         28-07-2016  \n",
       "TestData_06083         13-07-2016  \n",
       "TestData_05896         20-06-2016  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ix = 'TestData_03241'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "london                1.0\n",
       "metropolitanpolice    1.0\n",
       "police                1.0\n",
       "uksecurity            1.0\n",
       "Name: TestData_03241, dtype: float64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ukcrime    1\n",
       "Name: TestData_04088, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = top_submission.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "humanrights    1\n",
       "india          1\n",
       "protest        1\n",
       "ukcrime        1\n",
       "Name: TestData_04088, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = some_sub.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "humanrights    1\n",
       "Name: TestData_02924, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = wrong_index_lstm_sub.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Counter-terrorism policy\n",
    " \n",
    "Foreign policy\n",
    " \n",
    "Defence policy\n",
    " \n",
    "Islamic State\n",
    " \n",
    "Syria\n",
    " \n",
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = trainingY.sum()\n",
    "unseen_topics = s[s.isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activism',\n",
       " 'bastilledaytruckattack',\n",
       " 'berlinchristmasmarketattack',\n",
       " 'brusselsattacks',\n",
       " 'charliehebdoattack',\n",
       " 'francetrainattack',\n",
       " 'munichshooting',\n",
       " 'orlandoterrorattack',\n",
       " 'parisattacks',\n",
       " 'peaceandreconciliation',\n",
       " 'sanbernardinoshooting',\n",
       " 'tunisiaattack2015',\n",
       " 'turkeycoupattempt',\n",
       " 'zikavirus'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(topics).intersection(unseen_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activism\n",
      "afghanistan\n",
      "aid\n",
      "algerianhostagecrisis\n",
      "alqaida\n",
      "alshabaab\n",
      "antiwar\n",
      "arabandmiddleeastprotests\n",
      "armstrade\n",
      "australianguncontrol\n",
      "australiansecurityandcounterterrorism\n",
      "bastilledaytruckattack\n",
      "belgium\n",
      "berlinchristmasmarketattack\n",
      "bigdata\n",
      "biometrics\n",
      "bokoharam\n",
      "bostonmarathonbombing\n",
      "britisharmy\n",
      "brusselsattacks\n",
      "cameroon\n",
      "carers\n",
      "charliehebdoattack\n",
      "chemicalweapons\n",
      "clusterbombs\n",
      "cobra\n",
      "conflictanddevelopment\n",
      "controversy\n",
      "criminaljustice\n",
      "cybercrime\n",
      "cyberwar\n",
      "darknet\n",
      "dataprotection\n",
      "debate\n",
      "defence\n",
      "deflation\n",
      "drones\n",
      "drugs\n",
      "drugspolicy\n",
      "drugstrade\n",
      "earthquakes\n",
      "ebola\n",
      "economy\n",
      "egypt\n",
      "encryption\n",
      "energy\n",
      "espionage\n",
      "ethics\n",
      "europeanarrestwarrant\n",
      "europeancourtofhumanrights\n",
      "events\n",
      "extradition\n",
      "famine\n",
      "farright\n",
      "firefighters\n",
      "forensicscience\n",
      "france\n",
      "francetrainattack\n",
      "freedomofspeech\n",
      "genevaconventions\n",
      "germany\n",
      "guncrime\n",
      "hacking\n",
      "hashtags\n",
      "helicoptercrashes\n",
      "humanitarianresponse\n",
      "humanrights\n",
      "humanrightsact\n",
      "humantrafficking\n",
      "immigration\n",
      "india\n",
      "indonesia\n",
      "internallydisplacedpeople\n",
      "internationalcourtofjustice\n",
      "internationalcriminaljustice\n",
      "internetsafety\n",
      "iraq\n",
      "isis\n",
      "israel\n",
      "jordan\n",
      "jubilee\n",
      "judiciary\n",
      "july7\n",
      "justiceandsecurity\n",
      "kenya\n",
      "knifecrime\n",
      "lebanon\n",
      "libya\n",
      "localgovernment\n",
      "logistics\n",
      "london\n",
      "londonriots\n",
      "malaysia\n",
      "mali\n",
      "malware\n",
      "metropolitanpolice\n",
      "middleeastpeacetalks\n",
      "migration\n",
      "military\n",
      "ministryofdefence\n",
      "morocco\n",
      "mrsa\n",
      "mumbaiterrorattacks\n",
      "munichshooting\n",
      "naturaldisasters\n",
      "nigeria\n",
      "nuclearweapons\n",
      "occupy\n",
      "organisedcrime\n",
      "orlandoterrorattack\n",
      "osamabinladen\n",
      "paris\n",
      "parisattacks\n",
      "peaceandreconciliation\n",
      "philippines\n",
      "piracy\n",
      "planecrashes\n",
      "police\n",
      "protest\n",
      "refugees\n",
      "religion\n",
      "retirementage\n",
      "rio20earthsummit\n",
      "royalairforce\n",
      "royalnavy\n",
      "russia\n",
      "sanbernardinoshooting\n",
      "saudiarabia\n",
      "september11\n",
      "slavery\n",
      "somalia\n",
      "southafrica\n",
      "southchinasea\n",
      "stopandsearch\n",
      "surveillance\n",
      "sydneysiege\n",
      "syria\n",
      "taliban\n",
      "terrorism\n",
      "thailand\n",
      "torture\n",
      "traincrashes\n",
      "transport\n",
      "tunisiaattack2015\n",
      "turkey\n",
      "turkeycoupattempt\n",
      "ukcrime\n",
      "uksecurity\n",
      "uksupremecourt\n",
      "undercoverpoliceandpolicing\n",
      "unitednations\n",
      "usguncontrol\n",
      "values\n",
      "warcrimes\n",
      "warreporting\n",
      "weaponstechnology\n",
      "womeninbusiness\n",
      "woolwichattack\n",
      "worldmigration\n",
      "zikavirus\n"
     ]
    }
   ],
   "source": [
    "for i in topics:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsolatorio/ml-ai/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3445929"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(wvmodel['zika'], np.vstack(test_wvec.dropna())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsolatorio/ml-ai/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.38107796869050226"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(fsmodel['zika'], np.vstack(test_fvec.dropna())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              The World Health Organisation has convened an ...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           28-01-2016\n",
       "Name: TestData_04490, dtype: object"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[4488 + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              The United Nations security council has called...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           17-09-2016\n",
       "Name: TestData_06730, dtype: object"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[6727 + 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              We are deeply concerned that the counter-terro...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           02-02-2015\n",
       "Name: TestData_00360, dtype: object"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[359]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drugstrade    1.0\n",
       "Name: TestData_04490, dtype: float64"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.iloc[4488 + 1]\n",
    "q[q > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
