{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "from gensim.models.lsimodel import LsiModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "from growing_instability_lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wvmodel = Word2Vec.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub = pd.read_csv('../data/sampleSubmission.csv')\n",
    "topics = sorted(set(sample_sub.columns.difference(['id'])))\n",
    "\n",
    "topic2actual = {}\n",
    "for i in sample_sub.columns:\n",
    "    if 'id' == i:\n",
    "        continue\n",
    "    topic2actual[i] = segment(i)\n",
    "    \n",
    "target_columns = sorted(topics)\n",
    "len(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# word2idx_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'word2idx_trainingX')\n",
    "_word2idx = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', '_word2idx')\n",
    "# trainingY = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'trainingY')\n",
    "\n",
    "# indices = pd.Index(sorted(trainingY.index[trainingY.index.str.contains('^201[2-4]')]))\n",
    "\n",
    "# word2idx_trainingX = word2idx_trainingX.ix[indices]\n",
    "# trainingY = trainingY.ix[indices]\n",
    "\n",
    "# word2idx_trainingX.to_hdf('training_data_word_index_2012-2014.hdf', 'word2idx_trainingX')\n",
    "# trainingY.to_hdf('training_data_word_index_2012-2014.hdf', 'trainingY')\n",
    "\n",
    "word2idx_trainingX = pd.read_hdf('training_data_word_index_2012-2014.hdf', 'word2idx_trainingX')\n",
    "trainingY = pd.read_hdf('training_data_word_index_2012-2014.hdf', 'trainingY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test_df = pd.read_hdf('train_test_df_3.hdf', 'train_test_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_topics(df, topics):\n",
    "    topics = sorted(topics)\n",
    "#     v = np.zeros(shape=(df.shape[0], len(topics)))\n",
    "    v = []\n",
    "    for ix, tp in enumerate(df.topics):\n",
    "        tt = []\n",
    "        for t in tp:\n",
    "            tt.append(topics.index(t))\n",
    "#             v[ix][topics.index(t)] = 1\n",
    "        v.append(tt)\n",
    "\n",
    "    return pd.Series(v, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind2word = {j:i for i, j in _word2idx.iteritems()}\n",
    "ind2class = dict(enumerate(topics))\n",
    "class2ind = {j: i for i, j in ind2class.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_vector(term_vecs, vector_size, mean_window=5, sequence_length=200):\n",
    "    # 85 percentile length of docs is (198 * 5)\n",
    "\n",
    "    q = np.arange(0, len(term_vecs), mean_window)\n",
    "    \n",
    "    sequence = np.zeros([1, sequence_length, vector_size])\n",
    "    \n",
    "    for ix, inds in  enumerate(zip(q, q + mean_window)):\n",
    "        if ix < sequence_length:\n",
    "            sequence[0][ix] = np.mean(term_vecs[inds[0]: inds[1]], axis=0)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return sequence\n",
    "\n",
    "\n",
    "def process_ind2word(term_idx):\n",
    "    return [ind2word.get(idx, -1) for idx in term_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197.4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx_trainingX.map(len).quantile(0.8) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_mean_average(term_idx, stopwords=[], stack=True):\n",
    "    ret = term_idx.map(process_ind2word).map(\n",
    "        lambda x: [wvmodel[i] for i in x if i in wvmodel.wv.vocab]\n",
    "    ).map(\n",
    "        lambda x: process_vector(x, wvmodel.vector_size)\n",
    "    )\n",
    "    \n",
    "    if stack:\n",
    "        ret = np.vstack(ret)\n",
    "        \n",
    "    return ret\n",
    "\n",
    "\n",
    "def parallel_generate_word_vectors(samp, transformer, stopwords, batch, num_proc):\n",
    "    with Parallel(n_jobs=num_proc) as parallel:\n",
    "        dataset = np.zeros([samp.shape[0], 200, 300])\n",
    "        is_break = False\n",
    "        i = 0\n",
    "\n",
    "        while not is_break:\n",
    "            payload = []\n",
    "\n",
    "            for j in xrange(num_proc):\n",
    "                t_df = samp[(i + j) * batch: (i + 1 + j) * batch]\n",
    "\n",
    "                if t_df.empty:\n",
    "                    is_break = True\n",
    "                    continue\n",
    "\n",
    "                payload.append(\n",
    "                    delayed(transformer)(\n",
    "                        t_df, stopwords\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            print('Current batch in main thread: {}'.format((i + j) * batch))\n",
    "\n",
    "            if payload:\n",
    "                results = parallel(payload)\n",
    "                dataset.extend(results)\n",
    "                i += num_proc\n",
    "\n",
    "    return np.vstack(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test_word_indices = transform_text(train_test_df).map(lambda x: [_word2idx.get(i) for i in x.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 314 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_train = np.zeros(\n",
    "    [word2idx_trainingX.shape[0] + train_test_word_indices.shape[0], 200, 300], dtype=np.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 1140\n",
      "1 1140 2280\n",
      "2 2280 3420\n",
      "3 3420 4560\n",
      "4 4560 5700\n",
      "5 5700 6840\n",
      "6 6840 7980\n",
      "7 7980 9120\n",
      "8 9120 10260\n",
      "9 10260 11400\n",
      "10 11400 12540\n",
      "11 12540 13680\n",
      "12 13680 14820\n",
      "13 14820 15960\n",
      "14 15960 17100\n",
      "15 17100 18240\n",
      "16 18240 19380\n",
      "17 19380 20520\n",
      "18 20520 21660\n",
      "19 21660 22800\n",
      "20 22800 23940\n",
      "21 23940 25080\n",
      "22 25080 26220\n",
      "23 26220 27360\n",
      "24 27360 28500\n",
      "25 28500 29640\n",
      "26 29640 30780\n",
      "27 30780 31920\n",
      "28 31920 33060\n",
      "29 33060 34200\n",
      "30 34200 35340\n",
      "31 35340 36480\n",
      "32 36480 37620\n",
      "33 37620 38760\n",
      "34 38760 39900\n",
      "35 39900 41040\n",
      "36 41040 42180\n",
      "37 42180 43320\n",
      "38 43320 44460\n",
      "39 44460 45600\n",
      "40 45600 46740\n",
      "41 46740 47880\n",
      "42 47880 49020\n",
      "43 49020 50160\n",
      "44 50160 51300\n",
      "45 51300 52440\n",
      "46 52440 53580\n",
      "47 53580 54720\n",
      "48 54720 55860\n",
      "49 55860 56999\n",
      "CPU times: user 2min 33s, sys: 13.3 s, total: 2min 47s\n",
      "Wall time: 2min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "i = 0\n",
    "\n",
    "for ix, chunk in enumerate(np.array_split(pd.concat([word2idx_trainingX, train_test_word_indices]), 50)):\n",
    "    chunk = transform_mean_average(chunk)\n",
    "    j = i + chunk.shape[0]\n",
    "    x_train[i: j] = chunk\n",
    "    print ix, i, j\n",
    "\n",
    "    i = j    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "200 * 60000 * 300 * 8. / 1000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_target(y, size):\n",
    "    e = np.zeros(size)\n",
    "    e[y] = 1\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # 6853\n",
    "# # 3110\n",
    "# x_dump = parallel_generate_word_vectors(\n",
    "#     pd.concat([word2idx_trainingX, train_test_word_indices]),\n",
    "#     transform_mean_average,\n",
    "#     stopwords=[],\n",
    "#     batch=1000,\n",
    "#     num_proc=5\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.08 s, sys: 12 ms, total: 2.09 s\n",
      "Wall time: 2.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_samples = x_train.shape[0]\n",
    "\n",
    "training_Y = pd.DataFrame(zip(*np.where(trainingY.head(num_samples) == 1)), columns=['iloc', 'topics'])\n",
    "training_Y = training_Y.groupby('iloc')['topics'].apply(list)\n",
    "training_Y.index = trainingY.head(num_samples).index\n",
    "\n",
    "train_test_y = transform_topics(train_test_df, topics)\n",
    "y_train = pd.concat([training_Y, train_test_y])\n",
    "y_train = np.vstack(y_train.map(lambda x: build_target(x, len(topics))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((56999, 160), (56999, 200, 300))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as K\n",
    "import keras.backend as KB\n",
    "\n",
    "\n",
    "def f1_micro(y_true, y_pred):\n",
    "    TP = K.metrics.true_positives(y_true, K.round(y_pred))\n",
    "    FP = K.metrics.false_positives(y_true, K.round(y_pred))\n",
    "    FN = K.metrics.false_negatives(y_true, K.round(y_pred))\n",
    "    \n",
    "    p = K.reduce_sum(TP) / (K.reduce_sum(TP) + K.reduce_sum(FP))\n",
    "    r = K.reduce_sum(TP) / (K.reduce_sum(TP) + K.reduce_sum(FN))\n",
    "    \n",
    "    return (2.0 * p * r) / (p + r)\n",
    "\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    # http://stackoverflow.com/questions/43345909/when-using-mectrics-in-model-compile-in-keras-report-valueerror-unknown-metr\n",
    "    # Count positive samples.\n",
    "    c1 = KB.sum(KB.round(KB.clip(y_true * y_pred, 0, 1)))\n",
    "    c2 = KB.sum(KB.round(KB.clip(y_pred, 0, 1)))\n",
    "    c3 = KB.sum(KB.round(KB.clip(y_true, 0, 1)))\n",
    "\n",
    "    # If there are no true samples, fix the F1 score at 0.\n",
    "    if c3 == 0:\n",
    "        return 0\n",
    "\n",
    "    # How many selected items are relevant?\n",
    "    precision = c1 / c2\n",
    "\n",
    "    # How many relevant items are selected?\n",
    "    recall = c1 / c3\n",
    "\n",
    "    # Calculate f1_score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "ma_input (InputLayer)        (None, None, 300)         0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, None, 64)          93440     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 160)               20640     \n",
      "=================================================================\n",
      "Total params: 155,424\n",
      "Trainable params: 155,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense, Dropout, Convolution1D, MaxPooling1D, Flatten  # , TimeDistributedDense\n",
    "from keras.models import Model\n",
    "import itertools as it\n",
    "\n",
    "\n",
    "ma_input = Input(shape=(None, 300), name='ma_input')\n",
    "\n",
    "ma_x = LSTM(64, return_sequences=True)(ma_input)\n",
    "ma_x = LSTM(64, go_backwards=True)(ma_x)\n",
    "# We stack a deep densely-connected network on top\n",
    "\n",
    "x = Dense(128, activation='relu')(ma_x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "# And finally we add the main logistic regression layer\n",
    "main_output = Dense(len(class2ind), activation='sigmoid', name='main_output')(x)\n",
    "\n",
    "model = Model(\n",
    "    inputs=[\n",
    "        ma_input,\n",
    "    ],\n",
    "    outputs=[main_output]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "ma_input (InputLayer)        (None, None, 300)         0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, None, 64)          93440     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "main_output (Dense)          (None, 160)               20640     \n",
      "=================================================================\n",
      "Total params: 155,424\n",
      "Trainable params: 155,424\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.RMSprop(lr=0.005)\n",
    "model.compile(\n",
    "    optimizer=optimizer,  # keras.optimizers.RMSprop(lr=0.005),  # , rho=0.9, epsilon=1e-08, decay=0.0, clipnorm=1),\n",
    "    loss={'main_output': 'categorical_crossentropy'},\n",
    "    loss_weights={'main_output': 1.},\n",
    "    metrics=['accuracy', f1_micro]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56999, 160)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_batch_train_data(x, y, batch_size=1000, shuffle=True):\n",
    "    s = x.shape[0]\n",
    "    q = np.arange(0, s, batch_size)\n",
    "    indices = zip(q, q + batch_size)\n",
    "    while True:\n",
    "        if shuffle:\n",
    "            np.random.shuffle(indices)\n",
    "        for i, j in indices:\n",
    "            _y = y[i: j]\n",
    "            _x = x[i: j]\n",
    "            if _y.shape[0] > 0:\n",
    "#                 print('hello')\n",
    "                yield (np.vstack(_x), _y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 2000\n",
    "epochs = 10\n",
    "# steps_per_epoch = (x_dump.shape[0] + batch_size) / batch_size\n",
    "\n",
    "# train_data_generator = generate_batch_train_data(x_dump, y_train, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# model.fit_generator(\n",
    "#     train_data_generator,\n",
    "#     steps_per_epoch=steps_per_epoch,\n",
    "#     epochs=epochs,\n",
    "#     workers=1,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_file_name = \"bidirectional-lstm-weights\"\n",
    "filepath = base_file_name + \".{epoch:02d}-{loss:.4f}-{acc:.4f}-{f1_micro:.4f}.hdf5\"\n",
    "filename = base_file_name + \".log\"\n",
    "\n",
    "model_check_point = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=filepath,\n",
    "    monitor='f1_micro', verbose=0,\n",
    "    save_best_only=True, save_weights_only=False,\n",
    "    mode='max', period=1,\n",
    ")\n",
    "\n",
    "remote_monitor = keras.callbacks.RemoteMonitor(\n",
    "    root='http://localhost:9000',\n",
    "    path='/publish/epoch/end/',\n",
    "    field='data', headers=None\n",
    ")\n",
    "\n",
    "csv_logger = keras.callbacks.CSVLogger(filename=filename, separator=',', append=False)\n",
    "\n",
    "callbacks = [model_check_point, remote_monitor, csv_logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "56999/56999 [==============================] - 30s - loss: 2.0243 - acc: 0.6434 - f1_micro: 0.5626    \n",
      "Epoch 2/10\n",
      "56999/56999 [==============================] - 31s - loss: 1.9847 - acc: 0.6492 - f1_micro: 0.5636    \n",
      "Epoch 3/10\n",
      "56999/56999 [==============================] - 31s - loss: 1.9596 - acc: 0.6498 - f1_micro: 0.5647    \n",
      "Epoch 4/10\n",
      "56999/56999 [==============================] - 31s - loss: 1.9675 - acc: 0.6506 - f1_micro: 0.5659    \n",
      "Epoch 5/10\n",
      "56999/56999 [==============================] - 31s - loss: 1.9278 - acc: 0.6550 - f1_micro: 0.5671    \n",
      "Epoch 6/10\n",
      "56999/56999 [==============================] - 31s - loss: 1.9032 - acc: 0.6580 - f1_micro: 0.5684    \n",
      "Epoch 7/10\n",
      "56999/56999 [==============================] - 31s - loss: 1.9099 - acc: 0.6555 - f1_micro: 0.5700    \n",
      "Epoch 8/10\n",
      "56999/56999 [==============================] - 31s - loss: 1.8922 - acc: 0.6594 - f1_micro: 0.5716    \n",
      "Epoch 9/10\n",
      "56999/56999 [==============================] - 31s - loss: 1.8598 - acc: 0.6668 - f1_micro: 0.5732    \n",
      "Epoch 10/10\n",
      "56999/56999 [==============================] - 31s - loss: 1.8469 - acc: 0.6677 - f1_micro: 0.5747    \n",
      "CPU times: user 4min 43s, sys: 1min 24s, total: 6min 8s\n",
      "Wall time: 5min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 2000\n",
    "epochs = 10\n",
    "hist = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "56999/56999 [==============================] - 30s - loss: 1.4119 - acc: 0.7233 - f1_micro: 0.6582    \n",
      "Epoch 2/50\n",
      "56999/56999 [==============================] - 30s - loss: 1.4072 - acc: 0.7240 - f1_micro: 0.6595    \n",
      "Epoch 3/50\n",
      "56999/56999 [==============================] - 30s - loss: 1.3998 - acc: 0.7284 - f1_micro: 0.6607    \n",
      "Epoch 4/50\n",
      "56999/56999 [==============================] - 30s - loss: 1.3913 - acc: 0.7279 - f1_micro: 0.6620    \n",
      "Epoch 5/50\n",
      "56999/56999 [==============================] - 30s - loss: 1.4040 - acc: 0.7260 - f1_micro: 0.6632    \n",
      "Epoch 6/50\n",
      "56999/56999 [==============================] - 30s - loss: 1.3816 - acc: 0.7282 - f1_micro: 0.6644    \n",
      "Epoch 7/50\n",
      "56999/56999 [==============================] - 30s - loss: 1.3949 - acc: 0.7270 - f1_micro: 0.6656    \n",
      "Epoch 8/50\n",
      "56999/56999 [==============================] - 30s - loss: 1.3718 - acc: 0.7304 - f1_micro: 0.6669    \n",
      "Epoch 9/50\n",
      "56999/56999 [==============================] - 30s - loss: 1.3791 - acc: 0.7300 - f1_micro: 0.6681    \n",
      "Epoch 10/50\n",
      "56999/56999 [==============================] - 30s - loss: 1.3705 - acc: 0.7292 - f1_micro: 0.6692    \n",
      "Epoch 11/50\n",
      "56999/56999 [==============================] - 30s - loss: 1.3679 - acc: 0.7329 - f1_micro: 0.6704    \n",
      "Epoch 12/50\n",
      "56999/56999 [==============================] - 30s - loss: 1.3556 - acc: 0.7326 - f1_micro: 0.6716    \n",
      "Epoch 13/50\n",
      "56999/56999 [==============================] - 30s - loss: 1.3540 - acc: 0.7342 - f1_micro: 0.6727    \n",
      "Epoch 14/50\n",
      "56999/56999 [==============================] - 30s - loss: 1.3457 - acc: 0.7317 - f1_micro: 0.6738    \n",
      "Epoch 15/50\n",
      "56999/56999 [==============================] - 30s - loss: 1.3473 - acc: 0.7322 - f1_micro: 0.6750    \n",
      "Epoch 16/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.3541 - acc: 0.7339 - f1_micro: 0.6761    \n",
      "Epoch 17/50\n",
      "56999/56999 [==============================] - 30s - loss: 1.3458 - acc: 0.7329 - f1_micro: 0.6772    \n",
      "Epoch 18/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.3429 - acc: 0.7353 - f1_micro: 0.6783    \n",
      "Epoch 19/50\n",
      "56999/56999 [==============================] - 30s - loss: 1.3266 - acc: 0.7367 - f1_micro: 0.6793    \n",
      "Epoch 20/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.3365 - acc: 0.7327 - f1_micro: 0.6804    \n",
      "Epoch 21/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.3153 - acc: 0.7388 - f1_micro: 0.6815    \n",
      "Epoch 22/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.3223 - acc: 0.7386 - f1_micro: 0.6825    \n",
      "Epoch 23/50\n",
      "56999/56999 [==============================] - 30s - loss: 1.3207 - acc: 0.7369 - f1_micro: 0.6836    \n",
      "Epoch 24/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.3094 - acc: 0.7394 - f1_micro: 0.6846    \n",
      "Epoch 25/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.3198 - acc: 0.7369 - f1_micro: 0.6856    \n",
      "Epoch 26/50\n",
      "56999/56999 [==============================] - 30s - loss: 1.3097 - acc: 0.7383 - f1_micro: 0.6866    \n",
      "Epoch 27/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.3138 - acc: 0.7389 - f1_micro: 0.6876    \n",
      "Epoch 28/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.2935 - acc: 0.7392 - f1_micro: 0.6886    \n",
      "Epoch 29/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.3110 - acc: 0.7378 - f1_micro: 0.6896    \n",
      "Epoch 30/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.2916 - acc: 0.7417 - f1_micro: 0.6906    \n",
      "Epoch 31/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.2944 - acc: 0.7405 - f1_micro: 0.6915    \n",
      "Epoch 32/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.2885 - acc: 0.7402 - f1_micro: 0.6925    \n",
      "Epoch 33/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.2894 - acc: 0.7412 - f1_micro: 0.6935    \n",
      "Epoch 34/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.2848 - acc: 0.7420 - f1_micro: 0.6944    \n",
      "Epoch 35/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.2872 - acc: 0.7428 - f1_micro: 0.6953    \n",
      "Epoch 36/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.2762 - acc: 0.7414 - f1_micro: 0.6963    \n",
      "Epoch 37/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.2622 - acc: 0.7457 - f1_micro: 0.6972    \n",
      "Epoch 38/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.2783 - acc: 0.7431 - f1_micro: 0.6981    \n",
      "Epoch 39/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.2685 - acc: 0.7458 - f1_micro: 0.6990    \n",
      "Epoch 40/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.2643 - acc: 0.7468 - f1_micro: 0.7000    \n",
      "Epoch 41/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.2678 - acc: 0.7442 - f1_micro: 0.7009    \n",
      "Epoch 42/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.2600 - acc: 0.7440 - f1_micro: 0.7018    \n",
      "Epoch 43/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.2604 - acc: 0.7473 - f1_micro: 0.7026    \n",
      "Epoch 44/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.2498 - acc: 0.7480 - f1_micro: 0.7035    \n",
      "Epoch 45/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.2618 - acc: 0.7445 - f1_micro: 0.7044    \n",
      "Epoch 46/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.2522 - acc: 0.7471 - f1_micro: 0.7053    \n",
      "Epoch 47/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.2503 - acc: 0.7481 - f1_micro: 0.7061    \n",
      "Epoch 48/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.2367 - acc: 0.7485 - f1_micro: 0.7070    \n",
      "Epoch 49/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.2517 - acc: 0.7462 - f1_micro: 0.7078    \n",
      "Epoch 50/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.2417 - acc: 0.7480 - f1_micro: 0.7087    \n",
      "CPU times: user 23min 41s, sys: 6min 54s, total: 30min 35s\n",
      "Wall time: 25min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 2000\n",
    "epochs = 50\n",
    "hist = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "56999/56999 [==============================] - 30s - loss: 1.2418 - acc: 0.7488 - f1_micro: 0.7095    \n",
      "Epoch 2/50\n",
      "56999/56999 [==============================] - 30s - loss: 1.2268 - acc: 0.7505 - f1_micro: 0.7104    \n",
      "Epoch 3/50\n",
      "56999/56999 [==============================] - 30s - loss: 1.2447 - acc: 0.7463 - f1_micro: 0.7112    \n",
      "Epoch 4/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.2283 - acc: 0.7492 - f1_micro: 0.7120    \n",
      "Epoch 5/50\n",
      "56999/56999 [==============================] - 30s - loss: 1.2246 - acc: 0.7514 - f1_micro: 0.7129    \n",
      "Epoch 6/50\n",
      "56999/56999 [==============================] - 30s - loss: 1.2284 - acc: 0.7544 - f1_micro: 0.7137    \n",
      "Epoch 7/50\n",
      "56999/56999 [==============================] - 30s - loss: 1.2160 - acc: 0.7513 - f1_micro: 0.7145    \n",
      "Epoch 8/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.2272 - acc: 0.7507 - f1_micro: 0.7153    \n",
      "Epoch 9/50\n",
      "56999/56999 [==============================] - 30s - loss: 1.2294 - acc: 0.7514 - f1_micro: 0.7161    \n",
      "Epoch 10/50\n",
      "56999/56999 [==============================] - 30s - loss: 1.2101 - acc: 0.7535 - f1_micro: 0.7169    \n",
      "Epoch 11/50\n",
      "56999/56999 [==============================] - 30s - loss: 1.2189 - acc: 0.7509 - f1_micro: 0.7177    \n",
      "Epoch 12/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.2215 - acc: 0.7501 - f1_micro: 0.7184    \n",
      "Epoch 13/50\n",
      "56999/56999 [==============================] - 30s - loss: 1.2107 - acc: 0.7531 - f1_micro: 0.7192    \n",
      "Epoch 14/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.2209 - acc: 0.7515 - f1_micro: 0.7200    \n",
      "Epoch 15/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.2074 - acc: 0.7511 - f1_micro: 0.7207    \n",
      "Epoch 16/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.2154 - acc: 0.7506 - f1_micro: 0.7215    \n",
      "Epoch 17/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.1990 - acc: 0.7553 - f1_micro: 0.7222    \n",
      "Epoch 18/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.2108 - acc: 0.7524 - f1_micro: 0.7230    \n",
      "Epoch 19/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.2051 - acc: 0.7520 - f1_micro: 0.7237    \n",
      "Epoch 20/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.1919 - acc: 0.7560 - f1_micro: 0.7244    \n",
      "Epoch 21/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.1964 - acc: 0.7531 - f1_micro: 0.7252    \n",
      "Epoch 22/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.1968 - acc: 0.7540 - f1_micro: 0.7259    \n",
      "Epoch 23/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.1977 - acc: 0.7551 - f1_micro: 0.7266    \n",
      "Epoch 24/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.1804 - acc: 0.7553 - f1_micro: 0.7274    \n",
      "Epoch 25/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.1863 - acc: 0.7541 - f1_micro: 0.7281    \n",
      "Epoch 26/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.2070 - acc: 0.7538 - f1_micro: 0.7288    \n",
      "Epoch 27/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.1622 - acc: 0.7575 - f1_micro: 0.7295    \n",
      "Epoch 28/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.1880 - acc: 0.7564 - f1_micro: 0.7302    \n",
      "Epoch 29/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.1931 - acc: 0.7551 - f1_micro: 0.7309    \n",
      "Epoch 30/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.1781 - acc: 0.7554 - f1_micro: 0.7316    \n",
      "Epoch 31/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.1727 - acc: 0.7552 - f1_micro: 0.7323    \n",
      "Epoch 32/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.1798 - acc: 0.7558 - f1_micro: 0.7330    \n",
      "Epoch 33/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.1788 - acc: 0.7557 - f1_micro: 0.7337    \n",
      "Epoch 34/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.2218 - acc: 0.7520 - f1_micro: 0.7343    \n",
      "Epoch 35/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.1687 - acc: 0.7573 - f1_micro: 0.7350    \n",
      "Epoch 36/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.1767 - acc: 0.7575 - f1_micro: 0.7357    \n",
      "Epoch 37/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.1713 - acc: 0.7566 - f1_micro: 0.7363    \n",
      "Epoch 38/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.1672 - acc: 0.7572 - f1_micro: 0.7370    \n",
      "Epoch 39/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.1755 - acc: 0.7547 - f1_micro: 0.7376    \n",
      "Epoch 40/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.1749 - acc: 0.7581 - f1_micro: 0.7383    \n",
      "Epoch 41/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.1695 - acc: 0.7565 - f1_micro: 0.7389    \n",
      "Epoch 42/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.1612 - acc: 0.7592 - f1_micro: 0.7396    \n",
      "Epoch 43/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.1665 - acc: 0.7583 - f1_micro: 0.7402    \n",
      "Epoch 44/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.1569 - acc: 0.7586 - f1_micro: 0.7408    \n",
      "Epoch 45/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.1603 - acc: 0.7585 - f1_micro: 0.7414    \n",
      "Epoch 46/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.1589 - acc: 0.7590 - f1_micro: 0.7421    \n",
      "Epoch 47/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.1533 - acc: 0.7591 - f1_micro: 0.7427    \n",
      "Epoch 48/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.1586 - acc: 0.7590 - f1_micro: 0.7433    \n",
      "Epoch 49/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.1608 - acc: 0.7581 - f1_micro: 0.7439    \n",
      "Epoch 50/50\n",
      "56999/56999 [==============================] - 31s - loss: 1.1539 - acc: 0.7593 - f1_micro: 0.7445    \n",
      "CPU times: user 23min 38s, sys: 6min 57s, total: 30min 36s\n",
      "Wall time: 25min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 2000\n",
    "epochs = 50\n",
    "hist = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "56999/56999 [==============================] - 30s - loss: 1.1229 - acc: 0.7629 - f1_micro: 0.7580    \n",
      "CPU times: user 28.4 s, sys: 8.23 s, total: 36.6 s\n",
      "Wall time: 30.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 2000\n",
    "epochs = 1\n",
    "hist = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score as sk_f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = model.predict(\n",
    "    x_train,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 828 ms, sys: 76 ms, total: 904 ms\n",
      "Wall time: 899 ms\n",
      "0.0 (0.0, 0.022062077184089271)\n",
      "CPU times: user 436 ms, sys: 4 ms, total: 440 ms\n",
      "Wall time: 436 ms\n",
      "0.01 (0.01, 0.69617091085343574)\n",
      "CPU times: user 420 ms, sys: 16 ms, total: 436 ms\n",
      "Wall time: 435 ms\n",
      "0.02 (0.02, 0.73783209351753443)\n",
      "CPU times: user 424 ms, sys: 8 ms, total: 432 ms\n",
      "Wall time: 432 ms\n",
      "0.03 (0.029999999999999999, 0.7613669286413951)\n",
      "CPU times: user 412 ms, sys: 20 ms, total: 432 ms\n",
      "Wall time: 433 ms\n",
      "0.04 (0.040000000000000001, 0.77678074371821371)\n",
      "CPU times: user 428 ms, sys: 12 ms, total: 440 ms\n",
      "Wall time: 434 ms\n",
      "0.05 (0.050000000000000003, 0.78848134281671978)\n",
      "CPU times: user 424 ms, sys: 16 ms, total: 440 ms\n",
      "Wall time: 438 ms\n",
      "0.06 (0.059999999999999998, 0.79746105020196201)\n",
      "CPU times: user 432 ms, sys: 12 ms, total: 444 ms\n",
      "Wall time: 440 ms\n",
      "0.07 (0.070000000000000007, 0.80468773237886559)\n",
      "CPU times: user 436 ms, sys: 8 ms, total: 444 ms\n",
      "Wall time: 441 ms\n",
      "0.08 (0.080000000000000002, 0.81097245846692656)\n",
      "CPU times: user 428 ms, sys: 16 ms, total: 444 ms\n",
      "Wall time: 440 ms\n",
      "0.09 (0.089999999999999997, 0.8158653724307473)\n",
      "CPU times: user 440 ms, sys: 4 ms, total: 444 ms\n",
      "Wall time: 440 ms\n",
      "0.1 (0.10000000000000001, 0.82008475270226011)\n",
      "CPU times: user 436 ms, sys: 8 ms, total: 444 ms\n",
      "Wall time: 439 ms\n",
      "0.11 (0.11, 0.82366783292565859)\n",
      "CPU times: user 436 ms, sys: 28 ms, total: 464 ms\n",
      "Wall time: 460 ms\n",
      "0.12 (0.12, 0.82698477907031165)\n",
      "CPU times: user 432 ms, sys: 12 ms, total: 444 ms\n",
      "Wall time: 440 ms\n",
      "0.13 (0.13, 0.82991010424138356)\n",
      "CPU times: user 428 ms, sys: 16 ms, total: 444 ms\n",
      "Wall time: 439 ms\n",
      "0.14 (0.14000000000000001, 0.83234691134850836)\n",
      "CPU times: user 432 ms, sys: 12 ms, total: 444 ms\n",
      "Wall time: 440 ms\n",
      "0.15 (0.14999999999999999, 0.83443624331891064)\n",
      "CPU times: user 436 ms, sys: 8 ms, total: 444 ms\n",
      "Wall time: 440 ms\n",
      "0.16 (0.16, 0.83642783612380855)\n",
      "CPU times: user 428 ms, sys: 12 ms, total: 440 ms\n",
      "Wall time: 439 ms\n",
      "0.17 (0.17000000000000001, 0.83817654345482917)\n",
      "CPU times: user 428 ms, sys: 12 ms, total: 440 ms\n",
      "Wall time: 439 ms\n",
      "0.18 (0.17999999999999999, 0.83978025651116783)\n",
      "CPU times: user 420 ms, sys: 20 ms, total: 440 ms\n",
      "Wall time: 440 ms\n",
      "0.19 (0.19, 0.84129014078401188)\n",
      "CPU times: user 432 ms, sys: 12 ms, total: 444 ms\n",
      "Wall time: 439 ms\n",
      "0.2 (0.20000000000000001, 0.84250245017967984)\n",
      "CPU times: user 428 ms, sys: 16 ms, total: 444 ms\n",
      "Wall time: 440 ms\n",
      "0.21 (0.20999999999999999, 0.84383441789249192)\n",
      "CPU times: user 428 ms, sys: 16 ms, total: 444 ms\n",
      "Wall time: 439 ms\n",
      "0.22 (0.22, 0.84479187839567549)\n",
      "CPU times: user 428 ms, sys: 16 ms, total: 444 ms\n",
      "Wall time: 441 ms\n",
      "0.23 (0.23000000000000001, 0.84538801999977931)\n",
      "CPU times: user 440 ms, sys: 4 ms, total: 444 ms\n",
      "Wall time: 440 ms\n",
      "0.24 (0.23999999999999999, 0.8460835212570853)\n",
      "CPU times: user 428 ms, sys: 16 ms, total: 444 ms\n",
      "Wall time: 439 ms\n",
      "0.25 (0.25, 0.84640551969730693)\n",
      "CPU times: user 416 ms, sys: 28 ms, total: 444 ms\n",
      "Wall time: 440 ms\n",
      "0.26 (0.26000000000000001, 0.84672698838248439)\n",
      "CPU times: user 424 ms, sys: 16 ms, total: 440 ms\n",
      "Wall time: 439 ms\n",
      "0.27 (0.27000000000000002, 0.84719511921584467)\n",
      "CPU times: user 428 ms, sys: 12 ms, total: 440 ms\n",
      "Wall time: 438 ms\n",
      "0.28 (0.28000000000000003, 0.8475274725274724)\n",
      "CPU times: user 428 ms, sys: 16 ms, total: 444 ms\n",
      "Wall time: 438 ms\n",
      "0.29 (0.28999999999999998, 0.84767717870464565)\n",
      "CPU times: user 412 ms, sys: 28 ms, total: 440 ms\n",
      "Wall time: 438 ms\n",
      "0.3 (0.29999999999999999, 0.84778995024480464)\n",
      "CPU times: user 428 ms, sys: 16 ms, total: 444 ms\n",
      "Wall time: 438 ms\n",
      "0.31 (0.31, 0.84744045179213923)\n",
      "CPU times: user 420 ms, sys: 20 ms, total: 440 ms\n",
      "Wall time: 438 ms\n",
      "0.32 (0.32000000000000001, 0.84744697744292186)\n",
      "CPU times: user 428 ms, sys: 12 ms, total: 440 ms\n",
      "Wall time: 437 ms\n",
      "0.33 (0.33000000000000002, 0.84719992661560339)\n",
      "CPU times: user 428 ms, sys: 12 ms, total: 440 ms\n",
      "Wall time: 438 ms\n",
      "0.34 (0.34000000000000002, 0.84682559771728383)\n",
      "CPU times: user 416 ms, sys: 28 ms, total: 444 ms\n",
      "Wall time: 438 ms\n",
      "0.35 (0.35000000000000003, 0.84679900486599746)\n",
      "CPU times: user 420 ms, sys: 20 ms, total: 440 ms\n",
      "Wall time: 438 ms\n",
      "0.36 (0.35999999999999999, 0.84648889094826574)\n",
      "CPU times: user 424 ms, sys: 20 ms, total: 444 ms\n",
      "Wall time: 438 ms\n",
      "0.37 (0.37, 0.84620926881420533)\n",
      "CPU times: user 428 ms, sys: 12 ms, total: 440 ms\n",
      "Wall time: 437 ms\n",
      "0.38 (0.38, 0.84584883436155189)\n",
      "CPU times: user 416 ms, sys: 28 ms, total: 444 ms\n",
      "Wall time: 438 ms\n",
      "0.39 (0.39000000000000001, 0.84540328052975178)\n",
      "CPU times: user 424 ms, sys: 16 ms, total: 440 ms\n",
      "Wall time: 438 ms\n",
      "0.4 (0.40000000000000002, 0.84463797373270266)\n",
      "CPU times: user 432 ms, sys: 12 ms, total: 444 ms\n",
      "Wall time: 438 ms\n",
      "0.41 (0.41000000000000003, 0.84420921250941972)\n",
      "CPU times: user 428 ms, sys: 12 ms, total: 440 ms\n",
      "Wall time: 438 ms\n",
      "0.42 (0.41999999999999998, 0.84359422618063273)\n",
      "CPU times: user 436 ms, sys: 8 ms, total: 444 ms\n",
      "Wall time: 439 ms\n",
      "0.43 (0.42999999999999999, 0.84245337252786978)\n",
      "CPU times: user 420 ms, sys: 20 ms, total: 440 ms\n",
      "Wall time: 438 ms\n",
      "0.44 (0.44, 0.84136979621932428)\n",
      "CPU times: user 420 ms, sys: 20 ms, total: 440 ms\n",
      "Wall time: 437 ms\n",
      "0.45 (0.45000000000000001, 0.84047491199809077)\n",
      "CPU times: user 416 ms, sys: 24 ms, total: 440 ms\n",
      "Wall time: 438 ms\n",
      "0.46 (0.46000000000000002, 0.83942947094982434)\n",
      "CPU times: user 436 ms, sys: 4 ms, total: 440 ms\n",
      "Wall time: 437 ms\n",
      "0.47 (0.47000000000000003, 0.83873717575444695)\n",
      "CPU times: user 428 ms, sys: 8 ms, total: 436 ms\n",
      "Wall time: 437 ms\n",
      "0.48 (0.47999999999999998, 0.83765913114694857)\n",
      "CPU times: user 432 ms, sys: 8 ms, total: 440 ms\n",
      "Wall time: 437 ms\n",
      "0.49 (0.48999999999999999, 0.83643922364827306)\n",
      "CPU times: user 424 ms, sys: 16 ms, total: 440 ms\n",
      "Wall time: 438 ms\n",
      "0.5 (0.5, 0.83550226995835886)\n",
      "CPU times: user 22.2 s, sys: 828 ms, total: 23 s\n",
      "Wall time: 22.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dt = 0.01\n",
    "s = 0.0\n",
    "e = 0.5\n",
    "th = np.arange(s, e + dt, dt)\n",
    "mean_fscores = []\n",
    "for t in th:\n",
    "    %time mean_fscores.append((t, sk_f1_score(y_train, 1.0 * (g > t), average='micro')))\n",
    "    print t, mean_fscores[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.29999999999999999, 0.84778995024480464)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh, thresh_score = sorted(mean_fscores, key=lambda x: x[1], reverse=True)[0]\n",
    "thresh, thresh_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9749337a90>"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIQZ3IqISYnAnIiohBnciohL6/w+XDhQubyYnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9749339710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "ix = 15\n",
    "sd = -0\n",
    "pd.Series(g[sd:][ix]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([ 78,  87, 125, 136, 150]),), (array([ 78,  87, 125, 136, 150]),))"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# thresh = 0.5\n",
    "np.where(y_train[sd:][ix] == 1), np.where(g[sd:][ix] > thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'syria'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics[136]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_classes(pred, scale_param=0.75, min_thresh=0.05, thresh = 0.5):\n",
    "#     mx = pred.mean() + 3 * pred.std()\n",
    "    return np.where(pred > thresh)[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/TestData.json') as fl:\n",
    "    data = json.load(fl)\n",
    "    test_df = pd.DataFrame(data['TestData']).T\n",
    "    del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_word_indices = transform_text(test_df).map(lambda x: [_word2idx.get(i) for i in x.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_null_index = test_word_indices[test_word_indices.map(len) == 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 31.9 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_test = np.zeros(\n",
    "    [test_word_indices.shape[0], 200, 300], dtype=np.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 152\n",
      "1 152 304\n",
      "2 304 456\n",
      "3 456 608\n",
      "4 608 760\n",
      "5 760 912\n",
      "6 912 1064\n",
      "7 1064 1216\n",
      "8 1216 1368\n",
      "9 1368 1520\n",
      "10 1520 1672\n",
      "11 1672 1824\n",
      "12 1824 1976\n",
      "13 1976 2128\n",
      "14 2128 2280\n",
      "15 2280 2432\n",
      "16 2432 2584\n",
      "17 2584 2736\n",
      "18 2736 2888\n",
      "19 2888 3040\n",
      "20 3040 3192\n",
      "21 3192 3344\n",
      "22 3344 3496\n",
      "23 3496 3648\n",
      "24 3648 3800\n",
      "25 3800 3952\n",
      "26 3952 4104\n",
      "27 4104 4256\n",
      "28 4256 4408\n",
      "29 4408 4560\n",
      "30 4560 4712\n",
      "31 4712 4863\n",
      "32 4863 5014\n",
      "33 5014 5165\n",
      "34 5165 5316\n",
      "35 5316 5467\n",
      "36 5467 5618\n",
      "37 5618 5769\n",
      "38 5769 5920\n",
      "39 5920 6071\n",
      "40 6071 6222\n",
      "41 6222 6373\n",
      "42 6373 6524\n",
      "43 6524 6675\n",
      "44 6675 6826\n",
      "45 6826 6977\n",
      "46 6977 7128\n",
      "47 7128 7279\n",
      "48 7279 7430\n",
      "49 7430 7581\n",
      "CPU times: user 23.7 s, sys: 2.02 s, total: 25.8 s\n",
      "Wall time: 23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ii = 0\n",
    "\n",
    "for ix, chunk in enumerate(np.array_split(test_word_indices, 50)):\n",
    "    chunk = transform_mean_average(chunk)\n",
    "    jj = ii + chunk.shape[0]\n",
    "    x_test[ii: jj] = chunk\n",
    "    print ix, ii, jj\n",
    "\n",
    "    ii = jj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_probas = model.predict(x_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# valid_test_feature_vec found below!\n",
    "thresh = 0.4\n",
    "# pos_count = []\n",
    "# dt = 0.01\n",
    "# for thresh in  np.arange(0, 0.5 + dt, dt):\n",
    "test_values = np.zeros([test_probas.shape[0], len(topics)])\n",
    "for ix, pred in enumerate(test_probas):\n",
    "    for v in get_classes(pred, thresh=thresh):\n",
    "        test_values[ix][v] = 1\n",
    "\n",
    "test_sub_df = pd.DataFrame(\n",
    "    test_values,\n",
    "    index=test_df.index,\n",
    "    columns=topics\n",
    ")\n",
    "\n",
    "test_sub_df = test_sub_df.sort_index()\n",
    "a = test_sub_df.sum(axis=0).sum()\n",
    "#     pos_count.append((thresh, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pos_count = pd.DataFrame(pos_count, columns=['thresh', 'counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f97493589d0>"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\neXAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f974935e450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_count[pos_count.thresh > 0.01].plot(x='thresh', y='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9749339690>"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl4VeW5/vHvk4ExkDkYMhDmeY6AojKoSJ3g1OFnbRWt\nlbZq1XPsPNnpnNp6jmMdW6lyDhXRWqV1oA4oioLMQgAhzAlgAiEMMiZ5fn/shaYY2UlIsjPcn+va\nlzvvXmvtZy0hN+9637WWuTsiIiInExXpAkREpPFTWIiISFgKCxERCUthISIiYSksREQkLIWFiIiE\npbAQEZGwFBYiIhKWwkJERMKKiXQBtZWSkuI5OTmRLkNEpElZsmTJLndPrel6TTYscnJyWLx4caTL\nEBFpUsxsS23W02koEREJS2EhIiJhKSxERCSsJjtmISJy3LFjxygoKODw4cORLqXRaNOmDZmZmcTG\nxtbJ9hQWItLkFRQU0KFDB3JycjCzSJcTce7O7t27KSgooGvXrnWyTZ2GEpEm7/DhwyQnJysoAmZG\ncnJynfa0FBYi0iwoKP5VXR+PJhsWB4+WR7oEEZEWo8mGxd5DxyJdgohIg7nvvvs4ePBgxL6/yYbF\ngSNlkS5BRKTBKCxq6fCxcvZ8cjTSZYiIfGr69OkMGjSIwYMHc80117B582bGjx/PoEGDOPfcc9m6\ndSsA1113Hc8999yn68XFxQHw1ltvMXbsWC6//HL69OnDV7/6VdydBx54gO3btzNu3DjGjRtHeXk5\n1113HQMGDGDgwIHce++99b5vTXrq7Psbd3PhwPRIlyEijcgv/57H6u376nSb/Tp35M5L+p90mby8\nPH7zm9/w3nvvkZKSQklJCVOmTPn0NW3aNG699VZeeOGFk25n2bJl5OXl0blzZ0aPHs38+fO59dZb\nueeee5g7dy4pKSksWbKEwsJCVq1aBUBpaWmd7esXabI9iygz5ufvinQZIiIAvPnmm1xxxRWkpKQA\nkJSUxPvvv8/VV18NwDXXXMO7774bdjsjRowgMzOTqKgohgwZwubNmz+3TLdu3di4cSPf+c53ePXV\nV+nYsWOd7ktVmmzPon3raN7bsDvSZYhIIxOuB9AYxMTEUFFRAUBFRQVHj352Sr1169afvo+Ojqas\n7PPjs4mJiaxYsYI5c+bw6KOPMmvWLKZNm1avNTfZnkVc6xg27fqE7aWHIl2KiAjjx4/n2WefZffu\n0D9iS0pKOPPMM5k5cyYAM2bM4OyzzwZCj1hYsmQJALNnz+bYsfCzOzt06MD+/fsB2LVrFxUVFVx2\n2WX85je/YenSpfWxS/+iyfYs4lrHcACYn7+LK3KzIl2OiLRw/fv35yc/+QljxowhOjqaoUOH8uCD\nD3L99ddz9913k5qayp///GcAbrzxRiZNmsTgwYOZOHEi7du3D7v9qVOnMnHiRDp37sx9993H9ddf\n/2nv5Le//W297huAufvJFzDLAqYDnQAHHnf3+4PPvgPcDJQDL7n794P2HwE3BO23uvucoH0icD8Q\nDfzJ3e8K2rsCM4FkYAlwjbufdKpTbm6uM/m3nNUjhfuuGlqbfReRZmLNmjX07ds30mU0OlUdFzNb\n4u65Nd1WdXoWZcAd7r7UzDoAS8zsNULhMQkY7O5HzCwtKKQfcBXQH+gMvG5mvYJtPQScDxQAi8xs\ntruvBn4H3OvuM83sUUJB80i4ws7onsL8Dbtxd13qLyJSj8KOWbj7DndfGrzfD6wBMoBvA3e5+5Hg\ns6JglUnATHc/4u6bgHxgRPDKd/eNQa9hJjDJQr/lxwPHJx0/BUyuTvGjuydTvP8I+UUHqre3IiJS\nKzUa4DazHGAosBDoBZxtZgvN7G0zOz1YLAPYVmm1gqDti9qTgVJ3Lzuhvarvn2pmi81scXFxMaN7\nhKaoaQqtiIQ7pd7S1PXxqHZYmFkc8FfgdnffR+gUVhIwCvgeMMvq+VyQuz/u7rnunpuamkpWUjuy\nktoyX1NoRVq0Nm3asHv3bgVG4PjzLNq0aVNn26zWbCgziyUUFDPc/fmguQB43kP/dz4wswogBSgE\nKk9Pygza+IL23UCCmcUEvYvKy4c1unsKL63cQVl5BTHRTXYmsIicgszMTAoKCiguLo50KY3G8Sfl\n1ZWwYRH0Fp4A1rj7PZU+egEYB8wNBrBbAbuA2cBfzOweQgPcPYEPAAN6BjOfCgkNgl/t7m5mc4HL\nCY1jTAFerO4OnNkjhZmLtrFq+z6GZCVUdzURaUZiY2Pr7IlwUrXq/FN8NHANMN7MlgevC4FpQDcz\nW0XwS95D8oBZwGrgVeBmdy8Peg23AHMIDZLPCpYF+AHwH2aWT2gM44nq7sCZ3ZMBjVuIiNSnsNdZ\nNFa5ubm+ePFiACbeN4/kuFbM+MaoCFclItK41fY6i2Zxkn90jxQWbd7D4WN6ep6ISH1oJmGRzNGy\nCpZs2RPpUkREmqVmERYjuiYTE6VblouI1JdmERZxrWMYnJWg6y1EROpJswgLCN36Y2VBKXsPhb/V\nr4iI1EyzCYsze6RQ4bBwo3oXIiJ1rdmExdDsBNrERunpeSIi9aDZhEXrmGhOz0nSILeISD1oNmEB\ncFaPFNYXHaBo3+FIlyIi0qw0q7A4fsvyd9ardyEiUpeaVVj0S+9IRkJbXlhe7ZvWiohINTSrsIiK\nMi4bnsm7+bsoLD0U6XJERJqNZhUWAFcMz8Qd/rqkINKliIg0G80uLLKS2nFm92SeXbKNioqmeUdd\nEZHGptmFBcCVuVlsKznEwk0lkS5FRKRZaJZhMXHAaXRoE8Ozi7dFuhQRkWahWYZFm9hoLhncmZdX\n7WDfYd0rSkTkVIUNCzPLMrO5ZrbazPLM7LYTPr/DzNzMUoKfzcweMLN8M/vQzIZVWnaKma0PXlMq\ntQ83s5XBOg8Ez/0+JVfmZnH4WAX/WLHjVDclItLiVadnUQbc4e79gFHAzWbWD0JBAkwAtlZa/ktA\nz+A1FXgkWDYJuBMYCYwA7jSzxGCdR4AbK6038dR2CwZnxtOrUxyzdCpKROSUhQ0Ld9/h7kuD9/uB\nNUBG8PG9wPeBytOOJgHTPWQBkGBm6cAFwGvuXuLue4DXgInBZx3dfYGHHgg+HZh8qjtmZlyZm8Xy\nbaWs/3j/qW5ORKRFq9GYhZnlAEOBhWY2CSh09xUnLJYBVP7nfEHQdrL2giraq/r+qWa22MwWFxcX\nh6138tAMYqKMZ3XNhYjIKal2WJhZHPBX4HZCp6Z+DPy8nuqqkrs/7u657p6bmpoadvmUuNac2zeN\n55cWcKy8ogEqFBFpnqoVFmYWSygoZrj780B3oCuwwsw2A5nAUjM7DSgEsiqtnhm0naw9s4r2OnHF\n8Cx2HTjK3LVFdbVJEZEWpzqzoQx4Aljj7vcAuPtKd09z9xx3zyF06miYu+8EZgPXBrOiRgF73X0H\nMAeYYGaJwcD2BGBO8Nk+MxsVfNe1wIt1tYNje6eS2qE1sxbrVJSISG1Vp2cxGrgGGG9my4PXhSdZ\n/mVgI5AP/BG4CcDdS4BfA4uC16+CNoJl/hSsswF4pRb7UqWY6Ci+PCyDuR8VUbRfz7kQEakNC01A\nanpyc3N98eLF1Vo2v+gA593zNj++sA9Tz+lez5WJiDReZrbE3XNrul6zvIL7RD3S4hjeJZFZiwto\nquEoIhJJLSIsIHTr8vyiAyzdWhrpUkREmpwWExYXD+5Mh9Yx/HHexkiXIiLS5LSYsIhrHcP1o3N4\nNW8na3fui3Q5IiJNSosJC4Cvn9WVuNYxPPhmfqRLERFpUlpUWCS0a8WUM7vw8sodul+UiEgNtKiw\nALjhrG60jY1W70JEpAZaXFgktW/FNWd04e8fbie/6ECkyxERaRJaXFgA3Hh2N1rHRPHwXPUuRESq\no0WGRUpca742sgsvLC9k865PIl2OiEij1yLDAmDqmG7ERkfxkHoXIiJhtdiwSOvQhqtHZvP8skK2\nlRyMdDkiIo1aiw0LgG+N6U50lPHwW+pdiIicTIsOi04d23DV6Vk8t6SAgj3qXYiIfJEWHRYQ6l0A\nPPr2hghXIiLSeLX4sOic0JYrcrOYtaiAHXsPRbocEZFGqcWHBcBNY0O9i7vnfBThSkREGqfqPIM7\ny8zmmtlqM8szs9uC9rvNbK2ZfWhmfzOzhErr/MjM8s3sIzO7oFL7xKAt38x+WKm9q5ktDNqfMbNW\ndb2jJ5OZ2I5vnN2V55cWsmTLnob8ahGRJqE6PYsy4A537weMAm42s37Aa8AAdx8ErAN+BBB8dhXQ\nH5gIPGxm0WYWDTwEfAnoB3wlWBbgd8C97t4D2APcUFc7WF03j+tBp46t+cXsPCoq9DQ9EZHKwoaF\nu+9w96XB+/3AGiDD3f/p7mXBYguAzOD9JGCmux9x901APjAieOW7+0Z3PwrMBCaZmQHjgeeC9Z8C\nJtfN7lVf+9Yx/PjCvqws3MuzS7Y19NeLiDRqNRqzMLMcYCiw8ISPvg68ErzPACr/ti0I2r6oPRko\nrRQ8x9ur+v6pZrbYzBYXFxfXpPRquXRwZ3K7JPL7Vz9i76Fjdb59EZGmqtphYWZxwF+B2919X6X2\nnxA6VTWj7sv7V+7+uLvnuntuampqnW/fzPjFpf0pOXiU+19fX+fbFxFpqqoVFmYWSygoZrj785Xa\nrwMuBr7q7sdP9BcCWZVWzwzavqh9N5BgZjEntEfEgIx4vjIim6fe38w6PSBJRASo3mwoA54A1rj7\nPZXaJwLfBy5198qXP88GrjKz1mbWFegJfAAsAnoGM59aERoEnx2EzFzg8mD9KcCLp75rtffdCb2J\nax3DL/+ex2cZKCLSclWnZzEauAYYb2bLg9eFwB+ADsBrQdujAO6eB8wCVgOvAje7e3kwJnELMIfQ\nIPmsYFmAHwD/YWb5hMYwnqi7Xay5pPatuGNCL+bn72ZO3s5IliIi0ihYU/2Xc25uri9evLjetl9W\nXsHFD77L/sNlvHHHGNrERtfbd4mINBQzW+LuuTVdT1dwf4GY6CjuvKQ/haWHeOztjZEuR0QkohQW\nJ3FG92QuGpTOw2/l65kXItKiKSzC+PGFfYmJMu6YtYJyXdktIi2UwiKMjIS2/HryAD7YXMLDegSr\niLRQCotq+LehGUwa0pn73livGw2KSIuksKgGM+PXkweQHt+G22YuY99h3QpERFoWhUU1dWwTy/1X\nDWXH3sP8/IVVkS5HRKRBKSxqYHiXRG47tycvLN/O35YVRLocEZEGo7CooZvH9WBEThI/eyGPLbs/\niXQ5IiINQmFRQ9FRxr1XDcEMbpu5nGPlFZEuSUSk3iksaiEjoS2//fJAlm8r1a3MRaRFUFjU0sWD\nOnPF8Eweeiuftz4qinQ5IiL1SmFxCn5xaX/6ntaRm2YsZfm20kiXIyJSbxQWp6B96xie/PrpJMe1\n4utPLmJD8YFIlyQiUi8UFqcorUMb/vfrIzHg2ic+4ON9hyNdkohInVNY1IGclPY8ef0ISg8eZcq0\nD9h7SFd4i0jzorCoIwMz43nsmlw2FB/gxqcWc/hYeaRLEhGpM9V5BneWmc01s9VmlmdmtwXtSWb2\nmpmtD/6bGLSbmT1gZvlm9qGZDau0rSnB8uvNbEql9uFmtjJY54Hgud9Nzlk9U7jnyiEs2lLCrU8v\no0zXYIhIM1GdnkUZcIe79wNGATebWT/gh8Ab7t4TeCP4GeBLQM/gNRV4BELhAtwJjARGAHceD5hg\nmRsrrTfx1HctMi4Z3Jk7L+7HP1d/zM9eXEVTfWytiEhlYcPC3Xe4+9Lg/X5gDZABTAKeChZ7Cpgc\nvJ8ETPeQBUCCmaUDFwCvuXuJu+8BXgMmBp91dPcFHvrNOr3Stpqk60Z35aax3Xn6g2389pW1CgwR\nafJiarKwmeUAQ4GFQCd33xF8tBPoFLzPALZVWq0gaDtZe0EV7VV9/1RCvRWys7NrUnqD+94Fvdl3\n+BiPz9tIbLTx3Qm9aaJn10REqh8WZhYH/BW43d33Vf7F5+5uZvX+z2d3fxx4HCA3N7dR/3PdzPjV\npQMoK3cemruBVtHR3HZez0iXJSJSK9UKCzOLJRQUM9z9+aD5YzNLd/cdwamk4/e8KASyKq2eGbQV\nAmNPaH8raM+sYvkmLyrK+K9/G0hZhXPv6+uIiTZuHtcj0mWJiNRYdWZDGfAEsMbd76n00Wzg+Iym\nKcCLldqvDWZFjQL2Bqer5gATzCwxGNieAMwJPttnZqOC77q20raavKgo43eXDWLSkM7cPecj/jhv\nY6RLEhGpser0LEYD1wArzWx50PZj4C5glpndAGwBrgw+exm4EMgHDgLXA7h7iZn9GlgULPcrdy8J\n3t8EPAm0BV4JXs1GdJTxP1cMpqzc+c+X1xAbbVw3umukyxIRqbawYeHu7wJfNDJ7bhXLO3DzF2xr\nGjCtivbFwIBwtTRlMdFR3HfVEMoqKvjF31cTEx3F10Z1iXRZIiLVoiu4G1BsdBQPfmUY5/ZJ46cv\nrOKJdzdFuiQRkWpRWDSwVjFRPPy1YXxpwGn8+h+r+c+XVlNR0agndomIKCwioXVMNH+4ehjXnZnD\nH9/ZxG3PLOdIme4lJSKNV40uypO6Ex1l3HlJP9Lj2/DbV9ZSvP8wj12TS3zb2EiXJiLyOepZRJCZ\n8c0x3bn/qiEs2bKHKx99nx17D0W6LBGRz1FYNAKThmTw5PUjKCw9xJcffo91H++PdEkiIv9CYdFI\njO6RwqxvnkF5hXPZI+/x9rriSJckIvIphUUj0q9zR/5282gyEtpy3Z8/4KG5+bpjrYg0CgqLRiYj\noS3P33QmlwwK3R7kW/+3hP2H9ZhWEYkshUUj1K5VDPdfNYSfXdyP19cUMfmh+eQXHYh0WSLSgiks\nGikz44azuvJ/N4yk9OAxJj80nzl5OyNdloi0UAqLRu6M7sn849az6J4Wxzf/dwn/PecjynXFt4g0\nMIVFE5Ae35Znpo7iqtOz+MPcfK587H027/ok0mWJSAuisGgi2sRGc9dlg7j/qiGs/3g/Fz7wDjMW\nbtFsKRFpEAqLJmbSkAzm/Ps5DMtO5Cd/W8XXn1xE0b7DkS5LRJo5hUUTlB7flulfH8EvLunHext2\nc8F983h55Y5IlyUizZjCoomKigo9be+lW88mK6kdN81Yyu0zl1F68GikSxORZqg6z+CeZmZFZraq\nUtsQM1tgZsvNbLGZjQjazcweMLN8M/vQzIZVWmeKma0PXlMqtQ83s5XBOg8Ez+GWauqRFsdfv30m\nt5/Xk79/uIPz7nmbf3y4XWMZIlKnqtOzeBKYeELb74FfuvsQ4OfBzwBfAnoGr6nAIwBmlgTcCYwE\nRgB3mllisM4jwI2V1jvxuySM2Ogobj+vF3+/5SzS49tyy1+WceP0xWwv1R1sRaRuhA0Ld58HlJzY\nDHQM3scD24P3k4DpHrIASDCzdOAC4DV3L3H3PcBrwMTgs47uviB4dvd0YPIp71UL1a9zR/5205n8\n9KK+vJu/iwn3zuN/39+sJ/GJyCmr7ZjF7cDdZrYN+G/gR0F7BrCt0nIFQdvJ2guqaK+SmU0NTnst\nLi7WXVmrEhMdxTfO7sY/bx/D0OwEfvZiHlc89j7rddtzETkFtQ2LbwP/7u5ZwL8DT9RdSV/M3R93\n91x3z01NTW2Ir2yyspPbMf3rI/ifKwazofgAFz7wDv/zz484fEyPbxWRmqttWEwBng/eP0toHAKg\nEMiqtFxm0Hay9swq2qUOmBmXDc/k9f8Yw0UD03nwzXwuuG8e76xXr0xEaqa2YbEdGBO8Hw+sD97P\nBq4NZkWNAva6+w5gDjDBzBKDge0JwJzgs31mNiqYBXUt8GJtd0aqlhLXmvuuGsqMb4wkyoxrnviA\nW59eRtF+XcwnItUTE24BM3saGAukmFkBoVlNNwL3m1kMcJjQzCeAl4ELgXzgIHA9gLuXmNmvgUXB\ncr9y9+OD5jcRmnHVFngleEk9GN0jhVduO5tH3trAI29tYO5HRfxgYh+uHpFNVJRmLIvIF7OmOh8/\nNzfXFy9eHOkymqyNxQf46QureG/DboZkJfDzS/oxLDsx/Ioi0qSZ2RJ3z63perqCu4XqlhrHjG+M\n5L7/N4TC0kN8+eH3uHnGUrbs1t1sReTzwp6GkubLzJg8NIPz+3Xij+9s5LG3N/LP1Tu5ZlQO3xnf\ng8T2rSJdoog0EjoNJZ8q2neYe19fxzOLttG+dQzfGd+Da8/IoU1sdKRLE5E6otNQcsrSOrbht18e\nxKu3n0Nul0T+6+W1nPs/b/PckgI9nU+khVNYyOf06tSBP18/ghnfGElS+1Z899kVTLxvHq+u2qkb\nFIq0UAoL+UKje6Qw+5bRPPzVYZS7863/W8Lkh99jfv6uSJcmIg1MYSEnZWZcODCdf95+Dr+/fBC7\n9h/hq39ayFf/tIDl20ojXZ6INBANcEuNHCkrZ8aCrTw0N5/dnxzl/H6duGNCL/qc1jH8yiIScbUd\n4FZYSK0cOFLGn9/dxOPvbOTAkTIuHdyZfz+vFzkp7SNdmoichMJCIqL04FEem7eRJ+dv5mh5BVfm\nZvKd8T3pnNA20qWJSBUUFhJRRfsP8/DcDfxl4VYw+OrIbL49pjtpHdtEujQRqURhIY1CwZ6DPPDG\nev66tJDoKOPqEdl8c0w30uPV0xBpDBQW0qhs2f0JD8/dwF+XFhBlxpWnZ/LtsT3I0OkpkYhSWEij\ntK3kIA+/tYHnloSeqnv58ExuGtuDrKR2Ea5MpGVSWEijVlh6iEff2sAzi7ZR7s6kIZ25aWx3eqR1\niHRpIi2KwkKahB17D/HHeZv4ywdbOFJWwcT+p3HzuB4MyIiPdGkiLYLCQpqU3QeO8Of5m3nq/c3s\nP1zGmF6p3DyuByO6JkW6NJFmrd7uOmtm08ysyMxWndD+HTNba2Z5Zvb7Su0/MrN8M/vIzC6o1D4x\naMs3sx9Wau9qZguD9mfMTA9RaAGS41rz3Qt6M/+H4/neBb1ZVbiXKx97nysefY9/5u3UXW5FGpmw\nPQszOwc4AEx39wFB2zjgJ8BF7n7EzNLcvcjM+gFPAyOAzsDrQK9gU+uA84ECQs/i/oq7rzazWcDz\n7j7TzB4FVrj7I+EKV8+ieTl0tJyZi7byp3c2UVh6iJzkdtxwVlcuH55F21Z6noZIXam3noW7zwNK\nTmj+NnCXux8JlikK2icBM939iLtvAvIJBccIIN/dN7r7UWAmMMnMDBgPPBes/xQwuaY7IU1f21bR\nXD+6K29/bywPfmUo8W1j+dmLeZxx1xv895yPKNp/ONIlirRotb3rbC/g7OD00dtmdnrQngFsq7Rc\nQdD2Re3JQKm7l53QXiUzm2pmi81scXFxcS1Ll8YsJjqKSwZ35oWbR/Pst85gRE4SD72Vz1l3zeW7\nz64gb/veSJco0iLV9hncMUASMAo4HZhlZt3qrKov4O6PA49D6DRUfX+fRI6ZcXpOEqfnJLFp1ydM\ne3cTzy0p4LklBYzsmsT1o3M4v99pREdZpEsVaRFqGxYFhMYZHPjAzCqAFKAQyKq0XGbQxhe07wYS\nzCwm6F1UXl4EgK4p7fn15AF8d0Jvnlm8lafe28K3/m8pGQltmXJmF/5fbjbx7WIjXaZIs1bb01Av\nAOMAzKwX0ArYBcwGrjKz1mbWFegJfEBoQLtnMPOpFXAVMDsIm7nA5cF2pwAv1nZnpHmLbxfL1HO6\n8/b3xvLo14aRmdiW/3p5LaN++wY//ttKFm0uoUKzqETqRdiehZk9DYwFUsysALgTmAZMC6bTHgWm\nBL/484LZTauBMuBmdy8PtnMLMAeIBqa5e17wFT8AZprZb4BlwBN1uH/SDMVERzFxQDoTB6STt30v\nT87fzPNLC/jLwq1kJLTlksGdmTSkM31O60BoDoWInCpdlCfNwidHynht9ce8uLyQeet3UV7h9OoU\nx6QhGVw8KJ0uyXookwjoCm6RT+0+cISXV+1k9vJCFm3eA0DPtDjG903jvL6dGJqVQEy0Hj8vLZPC\nQqQKBXsO8s+8j3lj7ccs3FhCWYWT0C6Wcb3TGN8njTG9U+nYRoPj0nIoLETC2Hf4GO+s28Ubaz5m\n7kdF7Dl4jNho45yeqVw0KJ3z+nVScEizV9uwqO3UWZEmp2ObWC4alM5Fg9Ipr3CWbd3DnLydvPTh\nDt5YW0Sr6CjG9E7l4kHpnNu3E3Gt9ddD5Dj1LKTFq6hwlheU8tKHO3h55Q527D1Mq5goxvVO5d+G\nZjCuTxqtY3R/KmkedBpKpA5UVDjLtu3h7yt28NLKHRTvP0LHNjFcODCdyUMzGJGTRJSuGpcmTGEh\nUsfKyit4b8NuXlheyKurdnLwaDmd49tw6ZAMLh3cmb7puo5Dmh6FhUg9Ong0dB3HC8s+u44jM7Et\n5/frxPn9OjEiJ0nTcaVJUFiINJBdB47w+uqPeW31x7yTv4ujZRXEt41lfJ80zu/XiXN6pWpwXBot\nhYVIBBw8Wsa8dbt4bfXHvLn2Y/YcPEar6ChGdkvi3D5pnNu3E1lJ7SJdpsinFBYiEVZWXsGSLXt4\nY20Rr6/5mI3FnwDQq1Mc5/btxLl90hianajbqktEKSxEGplNuz7hjTUf8+baIj7YFLp6PLl9KyYO\nOI2LBqUzsmuygkManMJCpBHbe+gY89YV82reTt5cU8ShY+WkxIWC48KBCg5pOAoLkSbi0NFy5n5U\nxEsrd1QKjtac3y+Ns3umcmb3ZBLatYp0mdJMKSxEmqCDR8t466NiXvpwB/PWFbP/SBlmMCgjnrN6\npnB2z1SGZSfSKkbTcqVuKCxEmriy8gpWFJTyzvpdvLt+F8u2lVJe4bRrFc0Z3ZIZ2yd0p9yMhLaR\nLlWaMIWFSDOz7/AxFmzYzTvrd/HWuiK2lRwCoHenDoztk8r43mkM75KoiwGlRuotLMxsGnAxUOTu\nA0747A7gv4FUd99loXsf3A9cCBwErnP3pcGyU4CfBqv+xt2fCtqHA08CbYGXgdu8GgmmsJCWxN3Z\nUPwJc9cWMfejz2ZXdWgTw7jeaUwccBpjeqXSXhcDShj1eYvyJ4E/ANNP+MIsYAKwtVLzl4CewWsk\n8Agw0swOi3BtAAAOg0lEQVSSCD27OxdwYImZzXb3PcEyNwILCYXFROCVmu6ISHNmZvRIi6NHWhw3\nntON/YePMT9/F2+uLeL1NUXMXrGd1jFRnNMrlYn9T+O8vp2Ib6dnc0jdCRsW7j7PzHKq+Ohe4PvA\ni5XaJgHTg57BAjNLMLN0YCzwmruXAJjZa8BEM3sL6OjuC4L26cBkFBYiJ9WhTSwTB6QzcUA6ZeUV\nLN6yh1dX7WRO3k5eW/0xMVHGGd2TmdCvE+P6pJGZqKvI5dTUqs9qZpOAQndfccJdNzOAbZV+Lgja\nTtZeUEX7F33vVGAqQHZ2dm1KF2l2YqKjGNUtmVHdkrnzkn58WLCXV4Lg+NmLefBiXugZ5H3SGNs7\njdycRGI1ziE1VOOwMLN2wI8JnYJqUO7+OPA4hMYsGvr7RRo7M2NwVgKDsxL4wcTebNz12TjHtPmb\neGzeRjq0juHsXimM7ZXGOb1SOS2+TaTLliagNj2L7kBX4HivIhNYamYjgEIgq9KymUFbIaFTUZXb\n3wraM6tYXkROkZnRPTWO7qlxfOPsbhw4Usa763d9Gh4vr9wJhO5ddU7PVM7ulcrIrkm0idVTAeXz\nahwW7r4SSDv+s5ltBnKD2VCzgVvMbCahAe697r7DzOYA/2VmicFqE4AfuXuJme0zs1GEBrivBR48\ntV0SkarEtY5h4oDTmDjgNNydtTv3M29dMfPWFzP9/S386d1NtI6JYkTXJEb3SGFE1yQGZsTrlJUA\n1QgLM3uaUK8gxcwKgDvd/YkvWPxlQtNm8wlNnb0eIAiFXwOLguV+dXywG7iJz6bOvoIGt0XqnZnR\nN70jfdM78s0x3Tl0tJwFm3bzzrpdzFtfzF2vrAWgbWw0w7okcHpOEiO6JjE0K5G2rdTzaIl0UZ6I\nfE7x/iMs3lzCwk0lfLCphDU79+EOsdHG0OxExvRKZUyvVPqld9QzyZsYXcEtIvVm76FjLN2yhwWb\ndjM/fxerCvcBkBLXinN6pnJOr1TO7plCclzrCFcq4dTnRXki0sLFt41lXJ80xvUJDVcW7z/CO+uL\neXtdMW+tK+b5ZYWYhW5FcnpOErk5iZyek0Rn3ceq2VDPQkROSUWFs2r7Xt7+qJgPNpewdMsePjla\nDkDn+Dbk5iRxek4iw7ok0rtTB93LKsLUsxCRiIiKMgZlJjAoMwEI3T137c79LNpcwuIte1iwcTez\nV2wHQgPmAzPjGZqdwNCsRIZlJ5DWUdd5NAXqWYhIvXJ3CvYcYunWPSzbWsqybaWs3r6XY+Wh3z0Z\nCW0Z3iWRkd2SGNk1me6p7TnhzhBSh9SzEJFGyczISmpHVlI7Jg0J3c3n8LFy8rbvY1kQIO9X6n2k\nxLVmZLckRnVNYmS3ZHqmxSk8GgGFhYg0uDax0QzvksjwLqHrdN2dTbs+YeGmEhZu3M3CTSW89OEO\nAJLat2Jk1yRGdUtmZLckeqV10HTdCFBYiEjEmRndUuPolhrHV0Zk4+5sKznEgo27WbBpNws3lvDK\nqtDtSRLbxTIiCI/Tc5Lom96RaIVHvVNYiEijY2ZkJ7cjO7kdV54eut3ctpKDLAh6HQs27mZO3sdA\n6DYmQ7NDV5nndklkSHYC7VrpV1td0xEVkSbh+LjHFbmh8CjYc5AlW/aEZl1t3sO9r6/DHaKjjAGd\nOzI0O5HBWfEMykyga3J7nbo6RZoNJSLNwt5Dx1i6dQ+Lg/BYWbiXg8H1Hh3axDAoM57BmaHbtw/N\nTiCtQ8ucsqvZUCLSosW3jWVc7zTG9Q5dZV5e4eQXHWDFtlKWF5TyYUEpj8/bSFlF6B/IXZLbMbxL\nIrldQhcNdk+NU+/jJNSzEJEW4/iU3aXB6aslW/aw+5OjQChshndJ/PRWJQMz4pvlsz10I0ERkRpy\ndzbvPhgKjs17WLSlhI3FnwDQKjqKgZnx5OaEeh+5XRJJbN8qwhWfOoWFiEgdKPnkKEu2hMY+Fm0u\nYWXhZ1ebd01pz5CsBAZnxjMkO5G+6R1oHdO0eh8KCxGRenD4WDkfFuxl0eYSlm8rZfm2Uor3HwFC\nvY++nTsyNCshNICe1fhnXiksREQagLuzc99hlm8NDZwv31pa5cyrQZkJweyreNLjG8+t2uttNpSZ\nTQMuBorcfUDQdjdwCXAU2ABc7+6lwWc/Am4AyoFb3X1O0D4RuB+IBv7k7ncF7V2BmUAysAS4xt2P\n1nRHREQagpmRHt+W9IFt+dLAdKDSzKuCUlZsK2VFQSl/rDTz6rSObRiancCw7ESGZicwoAkOnoft\nWZjZOcABYHqlsJgAvOnuZWb2OwB3/4GZ9QOeBkYAnYHXgV7BptYB5wMFhJ7F/RV3X21ms4Dn3X2m\nmT0KrHD3R8IVrp6FiDRmh4+Vs3rHPlZsKw3utruHbSWHgNDjafulhy4cHJART//OHemRFkdsAzzr\no956Fu4+z8xyTmj7Z6UfFwCXB+8nATPd/QiwyczyCQUHQL67bwyKnQlMMrM1wHjg6mCZp4BfAGHD\nQkSkMWsTG82w7ESGZSdy/ehQW9H+0OmrpVtLWbZ1D88s2saT720GoFVMFH1O60D/zh3p3zkUIP06\nd2w0A+h1cVHe14FngvcZhMLjuIKgDWDbCe0jCZ16KnX3siqWFxFpVtI6tGFC/9OY0P80IHT6amPx\nAfK27yNv+17ytu/j5ZU7efqD0K/LVjFRDMqIZ3iX0JMGh3dJJCVCzzk/pbAws58AZcCMuikn7PdN\nBaYCZGdnN8RXiojUm+goo2enDvTs1IHJQ0P/Tj7+sKhVhXtZunUPS7bs4c/zN/PYvI0A5CS3Y1iX\nRAZnhsY++qV3pG2r+u991DoszOw6QgPf5/pnAx+FQFalxTKDNr6gfTeQYGYxQe+i8vKf4+6PA49D\naMyitrWLiDRWlR8WdXwAPXTl+d7g+o89zFu3i+eXhn5VRhn0TOvAgIx4BmZ0ZGBmPP3S4+s8QGoV\nFsHMpu8DY9z9YKWPZgN/MbN7CA1w9wQ+AAzoGcx8KgSuAq52dzezuYTGPGYCU4AXa7szIiLNUehh\nUUkM75LE1HM+m767smAvqwr3srJwL2+vK+KvSwuAUIB0T41jYEY8/TPiGRCMf3RoE1vrGqozdfZp\nYCyQYmYFwJ3Aj4DWwGvB4w4XuPu33D0vmN20mtDpqZvdvTzYzi3AHEJTZ6e5e17wFT8AZprZb4Bl\nwBO13hsRkRbg0+m78W0/Hf/4lwDZvo+8wr3M37CL55d9drKma0r72n+nLsoTEWm+ivYfDg2gBz2Q\nx689XVdwi4jIydX2Oov6vwJERESaPIWFiIiEpbAQEZGwFBYiIhKWwkJERMJSWIiISFgKCxERCUth\nISIiYTXZi/LMrBjYEuk66lEKsCvSRTQyOiZV03Gpmo5L1Xq7e4earlQXz7OICHdPjXQN9cnMFtfm\nKsvmTMekajouVdNxqZqZ1erWFzoNJSIiYSksREQkLIVF4/V4pAtohHRMqqbjUjUdl6rV6rg02QFu\nERFpOOpZiIhIWAqLCDKziWb2kZnlm9kPq/j8HDNbamZlZnZ5JGqMhGocl/8ws9Vm9qGZvWFmXSJR\nZ0OrxnH5lpmtNLPlZvaumfWLRJ0NLdxxqbTcZWbmZtbsZ0hV48/KdWZWHPxZWW5m3wi7UXfXKwIv\nQo+X3QB0A1oBK4B+JyyTAwwCpgOXR7rmRnRcxgHtgvffBp6JdN2N5Lh0rPT+UuDVSNfdGI5LsFwH\nYB6wAMiNdN2RPibAdcAfarJd9SwiZwSQ7+4b3f0oMBOYVHkBd9/s7h8CFZEoMEKqc1zmuvvB4McF\nQGYD1xgJ1Tku+yr92B5oCQOSYY9L4NfA74DDDVlchFT3mNSIwiJyMoBtlX4uCNpaupoelxuAV+q1\nosahWsfFzG42sw3A74FbG6i2SAp7XMxsGJDl7i81ZGERVN2/Q5cFp3KfM7OscBtVWEiTZWZfA3KB\nuyNdS2Ph7g+5e3fgB8BPI11PpJlZFHAPcEeka2lk/g7kuPsg4DXgqXArKCwipxConOaZQVtLV63j\nYmbnAT8BLnX3Iw1UWyTV9M/LTGByvVbUOIQ7Lh2AAcBbZrYZGAXMbuaD3GH/rLj77kp/b/4EDA+3\nUYVF5CwCeppZVzNrBVwFzI5wTY1B2ONiZkOBxwgFRVEEaoyE6hyXnpV+vAhY34D1RcpJj4u773X3\nFHfPcfccQmNcl7p7re6P1ERU589KeqUfLwXWhNtok72RYFPn7mVmdgswh9DshWnunmdmvwIWu/ts\nMzsd+BuQCFxiZr909/4RLLveVee4EDrtFAc8a2YAW9390ogV3QCqeVxuCXpcx4A9wJTIVdwwqnlc\nWpRqHpNbzexSoAwoITQ76qR0BbeIiISl01AiIhKWwkJERMJSWIiISFgKCxERCUthISIiYSksRE5g\nZglmdlPwfqyZ/aMevuM6M/tDXW9XpL4oLEQ+LwG4qSYrmFl0PdUi0igoLEQ+7y6gu5ktJ7gAMLjZ\n2lozm2HBlYBmttnMfmdmS4ErzKy7mb1qZkvM7B0z6xMsd4WZrTKzFWY2r9L3dA6WX29mv2/wvRSp\nAV3BLfJ5PwQGuPsQMxsLvAj0B7YD84HRwLvBsrvdfRiAmb0BfMvd15vZSOBhYDzwc+ACdy80s4RK\n3zMEGAocAT4yswfdvfLdQkUaDYWFSHgfuHsBQNDbyOGzsHgmaI8DzuSzW5AAtA7+Ox940sxmAc9X\n2u4b7r43WH810IV/vbW0SKOhsBAJr/Jdbcv51783nwT/jQJK3X3IiSu7+7eCnsZFwBIzO36Hz5Nt\nV6RR0ZiFyOftJ3Rr62oLnlK3ycyuALCQwcH77u6+0N1/DhTzr7ePFmkSFBYiJ3D33cB8M1tFzR6s\n9FXgBjNbAeTx2aMs7zazlcH23iP0TGSRJkV3nRURkbDUsxARkbAUFiIiEpbCQkREwlJYiIhIWAoL\nEREJS2EhIiJhKSxERCQshYWIiIT1/wG5YKgv8HFjRwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f97492d9d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_count[pos_count.thresh > 0.01].plot(x='thresh', y='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12806.0"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1366796678015114"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history['loss'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bidirectional-lstm-mean_averaged_window-loss_1.1229-f1_micro_0.7580-thresh_0.4.csv\n"
     ]
    }
   ],
   "source": [
    "sub_filename = 'bidirectional-lstm-mean_averaged_window-loss_{:.4f}-f1_micro_{:.4f}-thresh_{}.csv'.format(hist.history['loss'][-1], hist.history['f1_micro'][-1], thresh)\n",
    "print sub_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sub_df.astype(int).reset_index().rename(\n",
    "    columns={'index': 'id'}\n",
    ").sort_values('id').to_csv(\n",
    "    sub_filename, \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     160.00000\n",
       "mean       69.68125\n",
       "std       154.89779\n",
       "min         0.00000\n",
       "25%         4.00000\n",
       "50%        16.50000\n",
       "75%        59.25000\n",
       "max      1390.00000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activism                                    0.0\n",
       "afghanistan                               173.0\n",
       "aid                                        89.0\n",
       "algerianhostagecrisis                      19.0\n",
       "alqaida                                   177.0\n",
       "alshabaab                                  40.0\n",
       "antiwar                                     0.0\n",
       "arabandmiddleeastprotests                 434.0\n",
       "armstrade                                 107.0\n",
       "australianguncontrol                        0.0\n",
       "australiansecurityandcounterterrorism      42.0\n",
       "bastilledaytruckattack                     15.0\n",
       "belgium                                    24.0\n",
       "berlinchristmasmarketattack                10.0\n",
       "bigdata                                     1.0\n",
       "biometrics                                  0.0\n",
       "bokoharam                                  41.0\n",
       "bostonmarathonbombing                      52.0\n",
       "britisharmy                                15.0\n",
       "brusselsattacks                            34.0\n",
       "cameroon                                    2.0\n",
       "carers                                      2.0\n",
       "charliehebdoattack                         74.0\n",
       "chemicalweapons                            20.0\n",
       "clusterbombs                                0.0\n",
       "cobra                                       9.0\n",
       "conflictanddevelopment                     78.0\n",
       "controversy                                 3.0\n",
       "criminaljustice                            31.0\n",
       "cybercrime                                 90.0\n",
       "                                          ...  \n",
       "somalia                                    72.0\n",
       "southafrica                                39.0\n",
       "southchinasea                               1.0\n",
       "stopandsearch                               1.0\n",
       "surveillance                              131.0\n",
       "sydneysiege                                18.0\n",
       "syria                                    1532.0\n",
       "taliban                                    53.0\n",
       "terrorism                                 231.0\n",
       "thailand                                   25.0\n",
       "torture                                    22.0\n",
       "traincrashes                                3.0\n",
       "transport                                  91.0\n",
       "tunisiaattack2015                          31.0\n",
       "turkey                                    218.0\n",
       "turkeycoupattempt                          25.0\n",
       "ukcrime                                   402.0\n",
       "uksecurity                                492.0\n",
       "uksupremecourt                              4.0\n",
       "undercoverpoliceandpolicing                 2.0\n",
       "unitednations                             296.0\n",
       "usguncontrol                              227.0\n",
       "values                                      0.0\n",
       "warcrimes                                  41.0\n",
       "warreporting                               11.0\n",
       "weaponstechnology                           8.0\n",
       "womeninbusiness                             0.0\n",
       "woolwichattack                             92.0\n",
       "worldmigration                             31.0\n",
       "zikavirus                                   4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activism                                    0.0\n",
       "afghanistan                               147.0\n",
       "aid                                       127.0\n",
       "algerianhostagecrisis                      34.0\n",
       "alqaida                                   246.0\n",
       "alshabaab                                  46.0\n",
       "antiwar                                     0.0\n",
       "arabandmiddleeastprotests                 376.0\n",
       "armstrade                                  78.0\n",
       "australianguncontrol                        0.0\n",
       "australiansecurityandcounterterrorism      64.0\n",
       "bastilledaytruckattack                      9.0\n",
       "belgium                                    12.0\n",
       "berlinchristmasmarketattack                12.0\n",
       "bigdata                                     3.0\n",
       "biometrics                                  0.0\n",
       "bokoharam                                  65.0\n",
       "bostonmarathonbombing                      77.0\n",
       "britisharmy                                12.0\n",
       "brusselsattacks                            41.0\n",
       "cameroon                                    4.0\n",
       "carers                                      1.0\n",
       "charliehebdoattack                         51.0\n",
       "chemicalweapons                            20.0\n",
       "clusterbombs                                0.0\n",
       "cobra                                       9.0\n",
       "conflictanddevelopment                     97.0\n",
       "controversy                                 7.0\n",
       "criminaljustice                            16.0\n",
       "cybercrime                                103.0\n",
       "                                          ...  \n",
       "somalia                                    85.0\n",
       "southafrica                                51.0\n",
       "southchinasea                               5.0\n",
       "stopandsearch                               3.0\n",
       "surveillance                              112.0\n",
       "sydneysiege                                40.0\n",
       "syria                                    1749.0\n",
       "taliban                                    66.0\n",
       "terrorism                                 190.0\n",
       "thailand                                   28.0\n",
       "torture                                    29.0\n",
       "traincrashes                                3.0\n",
       "transport                                  75.0\n",
       "tunisiaattack2015                          36.0\n",
       "turkey                                    271.0\n",
       "turkeycoupattempt                          25.0\n",
       "ukcrime                                   335.0\n",
       "uksecurity                                409.0\n",
       "uksupremecourt                              5.0\n",
       "undercoverpoliceandpolicing                 2.0\n",
       "unitednations                             268.0\n",
       "usguncontrol                              169.0\n",
       "values                                      0.0\n",
       "warcrimes                                  40.0\n",
       "warreporting                               17.0\n",
       "weaponstechnology                           7.0\n",
       "womeninbusiness                             0.0\n",
       "woolwichattack                             81.0\n",
       "worldmigration                             13.0\n",
       "zikavirus                                   3.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
