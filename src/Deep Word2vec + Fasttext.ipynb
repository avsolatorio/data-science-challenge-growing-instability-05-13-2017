{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from growing_instability_lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub = pd.read_csv('../data/sampleSubmission.csv')\n",
    "topics = sorted(set(sample_sub.columns.difference(['id'])))\n",
    "\n",
    "topic2actual = {}\n",
    "for i in sample_sub.columns:\n",
    "    if 'id' == i:\n",
    "        continue\n",
    "    topic2actual[i] = segment(i)\n",
    "    \n",
    "target_columns = sorted(topics)\n",
    "len(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.58 s, sys: 1.47 s, total: 10 s\n",
      "Wall time: 10 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wvec_trainingX = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', 'wvec_trainingX')\n",
    "fvec_trainingX = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', 'fvec_trainingX')\n",
    "word2idx_trainingX = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', 'word2idx_trainingX')\n",
    "_word2idx = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', '_word2idx')\n",
    "trainingY = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', 'trainingY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 500\n",
    "\n",
    "top_tokens = Counter()\n",
    "for i in word2idx_trainingX:\n",
    "    top_tokens.update(set(i[:maxlen]))\n",
    "\n",
    "top_tokens = pd.DataFrame(top_tokens.most_common(), columns=['token', 'freq'])\n",
    "top_doc_tokens = top_tokens[top_tokens.freq > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_token2ind = {}\n",
    "for i, j in enumerate(top_doc_tokens.token):\n",
    "    top_token2ind[j] = i + 1  # Add 1 to start with 1 since 0 is special character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29 s, sys: 144 ms, total: 29.2 s\n",
      "Wall time: 29.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word2ind = top_token2ind\n",
    "\n",
    "ind2class = dict(enumerate(topics))\n",
    "class2ind = {j: i for i, j in ind2class.items()}\n",
    "\n",
    "num_samples = trainingY.shape[0]\n",
    "\n",
    "training_X = word2idx_trainingX.head(num_samples)\n",
    "\n",
    "training_Y = pd.DataFrame(zip(*np.where(trainingY.head(num_samples) == 1)), columns=['iloc', 'topics'])\n",
    "training_WV = wvec_trainingX.head(num_samples)\n",
    "training_FS = fvec_trainingX.head(num_samples)\n",
    "\n",
    "training_Y = training_Y.groupby('iloc')['topics'].apply(list)\n",
    "training_Y.index = trainingY.head(num_samples).index\n",
    "\n",
    "# indices = sorted(training_Y.index.copy())\n",
    "indices = sorted(training_Y.index[training_Y.index.str.contains('^201[0-9]')])\n",
    "# np.random.shuffle(indices)\n",
    "indices = pd.Index(indices)\n",
    "\n",
    "training_X = training_X.ix[indices]\n",
    "training_WV = training_WV.ix[indices]\n",
    "training_FS = training_FS.ix[indices]\n",
    "training_Y = training_Y.ix[indices]\n",
    "\n",
    "# Transform index to top index\n",
    "training_X = training_X.map(lambda x: [top_token2ind.get(i, 0) for i in x])\n",
    "\n",
    "dataset = zip(training_X, training_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wv_sc = StandardScaler()\n",
    "fs_sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "def build_target(y, size):\n",
    "    e = np.zeros(size)\n",
    "    e[y] = 1\n",
    "    return e\n",
    "\n",
    "def build_input_output_data(X, WV, FS, Y, maxlen):\n",
    "\n",
    "    x = sequence.pad_sequences(X, maxlen=maxlen)\n",
    "    y = np.vstack(Y.map(lambda x: build_target(x, len(topics))))\n",
    "    wv = np.vstack(WV)\n",
    "    fs = np.vstack(FS)\n",
    "    \n",
    "    return x, wv, fs, y\n",
    "\n",
    "\n",
    "test_ix = training_Y.index.str.contains('^201[0-4]')\n",
    "val_ix = training_Y.index.str.contains('^2014[b]')\n",
    "\n",
    "\n",
    "x_train, wv_train, fs_train, y_train = build_input_output_data(\n",
    "    training_X.ix[test_ix],\n",
    "    training_WV.ix[test_ix],\n",
    "    training_FS.ix[test_ix],\n",
    "    training_Y.ix[test_ix],\n",
    "    maxlen=maxlen\n",
    ")\n",
    "\n",
    "\n",
    "x_val, wv_val, fs_val, y_val = build_input_output_data(\n",
    "    training_X.ix[val_ix],\n",
    "    training_WV.ix[val_ix],\n",
    "    training_FS.ix[val_ix],\n",
    "    training_Y.ix[val_ix],\n",
    "    maxlen=maxlen\n",
    ")\n",
    "\n",
    "wv_train = wv_sc.fit_transform(wv_train)\n",
    "fs_train = fs_sc.fit_transform(fs_train)\n",
    "\n",
    "wv_val = wv_sc.transform(wv_val)\n",
    "fs_val = fs_sc.transform(fs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((94731,), (9424,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_Y.shape, training_Y.ix[training_Y.index.str.contains('^2014[b]')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Setup model\n",
    "# model_lstm = keras.models.Sequential()\n",
    "# model_lstm.add(keras.layers.Embedding(len(word2ind) + 1, 256))\n",
    "# # model_lstm.add(keras.layers.LSTM(32, return_sequences=False, input_shape=(None, len(word2ind) + 1)))\n",
    "# # model_lstm.add(keras.layers.Dropout(0.2))\n",
    "# model_lstm.add(keras.layers.LSTM(16, return_sequences=False))\n",
    "# model_lstm.add(keras.layers.Dense(128))\n",
    "# model_lstm.add(keras.layers.Activation('relu'))\n",
    "# model_lstm.add(keras.layers.Dropout(0.2))\n",
    "# model_lstm.add(keras.layers.Dense(len(class2ind)))\n",
    "# model_lstm.add(keras.layers.Activation('sigmoid'))\n",
    "# model_lstm.compile(\n",
    "#     loss='binary_crossentropy',\n",
    "#     optimizer='adam',\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# # for i in range(6):\n",
    "# #     model_lstm.fit_generator(id_lstm_gen, steps_per_epoch=len(dataset), epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense, Dropout, Convolution1D, MaxPooling1D, Flatten\n",
    "from keras.models import Model\n",
    "\n",
    "num_filters = 10\n",
    "sz = 3\n",
    "\n",
    "wv_input = Input(shape=(300,), name='wv_input')\n",
    "fs_input = Input(shape=(300,), name='fs_input')\n",
    "\n",
    "wv_x = Dense(128, activation='relu')(wv_input)\n",
    "wv_x = Dropout(0.3)(wv_x)\n",
    "wv_x = Dense(512, activation='relu')(wv_x)\n",
    "wv_x = Dropout(0.3)(wv_x)\n",
    "\n",
    "fs_x = Dense(128, activation='relu')(fs_input)\n",
    "fs_x = Dropout(0.3)(fs_x)\n",
    "fs_x = Dense(512, activation='relu')(fs_x)\n",
    "fs_x = Dropout(0.3)(fs_x)\n",
    "\n",
    "x_mult = keras.layers.dot([wv_x, fs_x], 1)\n",
    "x = keras.layers.concatenate([wv_x, fs_x, x_mult])\n",
    "\n",
    "# We stack a deep densely-connected network on top\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "# And finally we add the main logistic regression layer\n",
    "main_output = Dense(len(class2ind), activation='sigmoid', name='main_output')(x)\n",
    "\n",
    "model = Model(inputs=[wv_input, fs_input], outputs=[main_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as K\n",
    "\n",
    "\n",
    "def f1_micro(y_true, y_pred):\n",
    "    TP = K.metrics.true_positives(y_true, K.round(y_pred))\n",
    "    FP = K.metrics.false_positives(y_true, K.round(y_pred))\n",
    "    FN = K.metrics.false_negatives(y_true, K.round(y_pred))\n",
    "    \n",
    "    p = K.reduce_sum(TP) / (K.reduce_sum(TP) + K.reduce_sum(FP))\n",
    "    r = K.reduce_sum(TP) / (K.reduce_sum(TP) + K.reduce_sum(FN))\n",
    "    \n",
    "    return (2.0 * p * r) / (p + r)\n",
    "\n",
    "\n",
    "import keras.backend as KB\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "\n",
    "    # Count positive samples.\n",
    "    c1 = KB.sum(KB.round(KB.clip(y_true * y_pred, 0, 1)))\n",
    "    c2 = KB.sum(KB.round(KB.clip(y_pred, 0, 1)))\n",
    "    c3 = KB.sum(KB.round(KB.clip(y_true, 0, 1)))\n",
    "\n",
    "    # If there are no true samples, fix the F1 score at 0.\n",
    "    if c3 == 0:\n",
    "        return 0\n",
    "\n",
    "    # How many selected items are relevant?\n",
    "    precision = c1 / c2\n",
    "\n",
    "    # How many relevant items are selected?\n",
    "    recall = c1 / c3\n",
    "\n",
    "    # Calculate f1_score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "wv_input (InputLayer)            (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "fs_input (InputLayer)            (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_54 (Dense)                 (None, 128)           38528                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_56 (Dense)                 (None, 128)           38528                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)             (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)             (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_55 (Dense)                 (None, 512)           66048                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_57 (Dense)                 (None, 512)           66048                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)             (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)             (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_4 (Dot)                      (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)      (None, 1025)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_58 (Dense)                 (None, 128)           131328                                       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)             (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_59 (Dense)                 (None, 256)           33024                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)             (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_60 (Dense)                 (None, 128)           32896                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)             (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 160)           20640                                        \n",
      "====================================================================================================\n",
      "Total params: 427,040\n",
      "Trainable params: 427,040\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss={'main_output': 'categorical_crossentropy'},\n",
    "              loss_weights={'main_output': 1.}, metrics=['accuracy', f1_micro])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.callbacks import EarlyStopping\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "# model.fit(X, y, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import keras.backend as K\n",
    "# K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.train_on_batch(\n",
    "#     {'main_input': x_train[:10], 'wv_input': np.vstack(training_WV)[:10], 'fs_input': np.vstack(training_FS)[:10]},\n",
    "#     {'main_output': y_train[:10], 'aux_output': y_train[:10]}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/1\n",
      "94731/94731 [==============================] - 0s - loss: 2.1763 - acc: 0.6440 - f1_micro: 0.5268 - val_loss: 1.8363 - val_acc: 0.7068 - val_f1_micro: 0.5271\n",
      "CPU times: user 880 ms, sys: 200 ms, total: 1.08 s\n",
      "Wall time: 880 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# And trained it via:\n",
    "batch_size = 1200\n",
    "model.fit(\n",
    "    {'wv_input': wv_train, 'fs_input': fs_train},\n",
    "    {'main_output': y_train},\n",
    "    epochs=1, batch_size=batch_size,   # 500\n",
    "    validation_split=0.2,\n",
    "    validation_data=(\n",
    "        {'wv_input': wv_val, 'fs_input': fs_val},\n",
    "        {'main_output': y_val}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1779 - acc: 0.6421 - f1_micro: 0.5274 - val_loss: 1.8383 - val_acc: 0.7060 - val_f1_micro: 0.5277\n",
      "Epoch 2/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1739 - acc: 0.6435 - f1_micro: 0.5280 - val_loss: 1.8355 - val_acc: 0.7039 - val_f1_micro: 0.5283\n",
      "Epoch 3/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1788 - acc: 0.6415 - f1_micro: 0.5286 - val_loss: 1.8380 - val_acc: 0.7032 - val_f1_micro: 0.5289\n",
      "Epoch 4/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1703 - acc: 0.6437 - f1_micro: 0.5292 - val_loss: 1.8263 - val_acc: 0.7080 - val_f1_micro: 0.5296\n",
      "Epoch 5/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1739 - acc: 0.6430 - f1_micro: 0.5299 - val_loss: 1.8282 - val_acc: 0.7064 - val_f1_micro: 0.5302\n",
      "Epoch 6/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1748 - acc: 0.6442 - f1_micro: 0.5305 - val_loss: 1.8335 - val_acc: 0.7026 - val_f1_micro: 0.5308\n",
      "Epoch 7/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1723 - acc: 0.6429 - f1_micro: 0.5311 - val_loss: 1.8253 - val_acc: 0.7067 - val_f1_micro: 0.5314\n",
      "Epoch 8/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1705 - acc: 0.6423 - f1_micro: 0.5317 - val_loss: 1.8224 - val_acc: 0.7064 - val_f1_micro: 0.5320\n",
      "Epoch 9/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1658 - acc: 0.6418 - f1_micro: 0.5323 - val_loss: 1.8226 - val_acc: 0.7033 - val_f1_micro: 0.5325\n",
      "Epoch 10/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1611 - acc: 0.6414 - f1_micro: 0.5328 - val_loss: 1.8196 - val_acc: 0.7049 - val_f1_micro: 0.5331\n",
      "Epoch 11/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1582 - acc: 0.6427 - f1_micro: 0.5334 - val_loss: 1.8199 - val_acc: 0.7112 - val_f1_micro: 0.5337\n",
      "Epoch 12/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1540 - acc: 0.6422 - f1_micro: 0.5339 - val_loss: 1.8083 - val_acc: 0.7122 - val_f1_micro: 0.5341\n",
      "Epoch 13/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1568 - acc: 0.6448 - f1_micro: 0.5344 - val_loss: 1.8109 - val_acc: 0.7054 - val_f1_micro: 0.5347\n",
      "Epoch 14/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1580 - acc: 0.6431 - f1_micro: 0.5349 - val_loss: 1.8121 - val_acc: 0.7106 - val_f1_micro: 0.5352\n",
      "Epoch 15/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1552 - acc: 0.6448 - f1_micro: 0.5354 - val_loss: 1.8090 - val_acc: 0.6987 - val_f1_micro: 0.5357\n",
      "Epoch 16/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1559 - acc: 0.6446 - f1_micro: 0.5359 - val_loss: 1.8061 - val_acc: 0.7016 - val_f1_micro: 0.5362\n",
      "Epoch 17/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1482 - acc: 0.6453 - f1_micro: 0.5364 - val_loss: 1.8044 - val_acc: 0.7035 - val_f1_micro: 0.5367\n",
      "Epoch 18/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1530 - acc: 0.6437 - f1_micro: 0.5369 - val_loss: 1.8059 - val_acc: 0.7070 - val_f1_micro: 0.5372\n",
      "Epoch 19/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1516 - acc: 0.6450 - f1_micro: 0.5374 - val_loss: 1.7997 - val_acc: 0.7032 - val_f1_micro: 0.5377\n",
      "Epoch 20/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1516 - acc: 0.6431 - f1_micro: 0.5379 - val_loss: 1.8053 - val_acc: 0.7070 - val_f1_micro: 0.5382\n",
      "Epoch 21/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1533 - acc: 0.6436 - f1_micro: 0.5384 - val_loss: 1.7903 - val_acc: 0.7081 - val_f1_micro: 0.5386\n",
      "Epoch 22/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1490 - acc: 0.6450 - f1_micro: 0.5389 - val_loss: 1.8005 - val_acc: 0.7098 - val_f1_micro: 0.5391\n",
      "Epoch 23/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1360 - acc: 0.6458 - f1_micro: 0.5394 - val_loss: 1.7861 - val_acc: 0.7091 - val_f1_micro: 0.5396\n",
      "Epoch 24/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1458 - acc: 0.6459 - f1_micro: 0.5399 - val_loss: 1.7888 - val_acc: 0.7096 - val_f1_micro: 0.5401\n",
      "Epoch 25/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1433 - acc: 0.6435 - f1_micro: 0.5403 - val_loss: 1.7900 - val_acc: 0.7093 - val_f1_micro: 0.5405\n",
      "Epoch 26/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1397 - acc: 0.6454 - f1_micro: 0.5408 - val_loss: 1.7889 - val_acc: 0.7096 - val_f1_micro: 0.5410\n",
      "Epoch 27/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1364 - acc: 0.6450 - f1_micro: 0.5412 - val_loss: 1.7953 - val_acc: 0.7063 - val_f1_micro: 0.5415\n",
      "Epoch 28/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1381 - acc: 0.6485 - f1_micro: 0.5417 - val_loss: 1.7775 - val_acc: 0.7086 - val_f1_micro: 0.5420\n",
      "Epoch 29/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1325 - acc: 0.6455 - f1_micro: 0.5422 - val_loss: 1.7869 - val_acc: 0.7137 - val_f1_micro: 0.5424\n",
      "Epoch 30/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1365 - acc: 0.6456 - f1_micro: 0.5427 - val_loss: 1.7825 - val_acc: 0.7085 - val_f1_micro: 0.5429\n",
      "Epoch 31/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1300 - acc: 0.6475 - f1_micro: 0.5431 - val_loss: 1.7851 - val_acc: 0.7152 - val_f1_micro: 0.5433\n",
      "Epoch 32/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1355 - acc: 0.6474 - f1_micro: 0.5436 - val_loss: 1.7769 - val_acc: 0.7070 - val_f1_micro: 0.5438\n",
      "Epoch 33/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1290 - acc: 0.6467 - f1_micro: 0.5440 - val_loss: 1.7831 - val_acc: 0.7111 - val_f1_micro: 0.5442\n",
      "Epoch 34/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1305 - acc: 0.6470 - f1_micro: 0.5444 - val_loss: 1.7811 - val_acc: 0.7050 - val_f1_micro: 0.5446\n",
      "Epoch 35/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1288 - acc: 0.6475 - f1_micro: 0.5448 - val_loss: 1.7760 - val_acc: 0.7088 - val_f1_micro: 0.5450\n",
      "Epoch 36/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1290 - acc: 0.6449 - f1_micro: 0.5452 - val_loss: 1.7770 - val_acc: 0.7098 - val_f1_micro: 0.5454\n",
      "Epoch 37/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1259 - acc: 0.6471 - f1_micro: 0.5456 - val_loss: 1.7774 - val_acc: 0.7124 - val_f1_micro: 0.5458\n",
      "Epoch 38/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1198 - acc: 0.6479 - f1_micro: 0.5460 - val_loss: 1.7677 - val_acc: 0.7122 - val_f1_micro: 0.5462\n",
      "Epoch 39/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1231 - acc: 0.6480 - f1_micro: 0.5464 - val_loss: 1.7734 - val_acc: 0.7078 - val_f1_micro: 0.5466\n",
      "Epoch 40/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1276 - acc: 0.6480 - f1_micro: 0.5468 - val_loss: 1.7674 - val_acc: 0.7175 - val_f1_micro: 0.5470\n",
      "Epoch 41/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1214 - acc: 0.6488 - f1_micro: 0.5471 - val_loss: 1.7657 - val_acc: 0.7086 - val_f1_micro: 0.5473\n",
      "Epoch 42/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1238 - acc: 0.6475 - f1_micro: 0.5475 - val_loss: 1.7618 - val_acc: 0.7097 - val_f1_micro: 0.5477\n",
      "Epoch 43/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1244 - acc: 0.6477 - f1_micro: 0.5478 - val_loss: 1.7676 - val_acc: 0.7078 - val_f1_micro: 0.5480\n",
      "Epoch 44/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1220 - acc: 0.6492 - f1_micro: 0.5482 - val_loss: 1.7625 - val_acc: 0.7111 - val_f1_micro: 0.5484\n",
      "Epoch 45/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1100 - acc: 0.6493 - f1_micro: 0.5485 - val_loss: 1.7545 - val_acc: 0.7153 - val_f1_micro: 0.5487\n",
      "Epoch 46/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1172 - acc: 0.6492 - f1_micro: 0.5489 - val_loss: 1.7566 - val_acc: 0.7148 - val_f1_micro: 0.5491\n",
      "Epoch 47/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1145 - acc: 0.6508 - f1_micro: 0.5493 - val_loss: 1.7577 - val_acc: 0.7136 - val_f1_micro: 0.5494\n",
      "Epoch 48/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1140 - acc: 0.6496 - f1_micro: 0.5496 - val_loss: 1.7541 - val_acc: 0.7083 - val_f1_micro: 0.5498\n",
      "Epoch 49/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1116 - acc: 0.6499 - f1_micro: 0.5500 - val_loss: 1.7545 - val_acc: 0.7048 - val_f1_micro: 0.5501\n",
      "Epoch 50/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1077 - acc: 0.6496 - f1_micro: 0.5503 - val_loss: 1.7501 - val_acc: 0.7173 - val_f1_micro: 0.5505\n",
      "Epoch 51/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1152 - acc: 0.6472 - f1_micro: 0.5506 - val_loss: 1.7533 - val_acc: 0.7120 - val_f1_micro: 0.5508\n",
      "Epoch 52/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1050 - acc: 0.6484 - f1_micro: 0.5510 - val_loss: 1.7542 - val_acc: 0.7115 - val_f1_micro: 0.5512\n",
      "Epoch 53/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1044 - acc: 0.6482 - f1_micro: 0.5513 - val_loss: 1.7423 - val_acc: 0.7195 - val_f1_micro: 0.5515\n",
      "Epoch 54/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1097 - acc: 0.6497 - f1_micro: 0.5517 - val_loss: 1.7473 - val_acc: 0.7167 - val_f1_micro: 0.5519\n",
      "Epoch 55/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1108 - acc: 0.6487 - f1_micro: 0.5520 - val_loss: 1.7541 - val_acc: 0.7211 - val_f1_micro: 0.5522\n",
      "Epoch 56/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1046 - acc: 0.6495 - f1_micro: 0.5523 - val_loss: 1.7480 - val_acc: 0.7084 - val_f1_micro: 0.5525\n",
      "Epoch 57/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1047 - acc: 0.6494 - f1_micro: 0.5526 - val_loss: 1.7402 - val_acc: 0.7114 - val_f1_micro: 0.5528\n",
      "Epoch 58/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1038 - acc: 0.6487 - f1_micro: 0.5529 - val_loss: 1.7349 - val_acc: 0.7139 - val_f1_micro: 0.5531\n",
      "Epoch 59/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0990 - acc: 0.6510 - f1_micro: 0.5532 - val_loss: 1.7449 - val_acc: 0.7159 - val_f1_micro: 0.5534\n",
      "Epoch 60/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0949 - acc: 0.6506 - f1_micro: 0.5536 - val_loss: 1.7368 - val_acc: 0.7193 - val_f1_micro: 0.5537\n",
      "Epoch 61/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0963 - acc: 0.6506 - f1_micro: 0.5539 - val_loss: 1.7376 - val_acc: 0.7208 - val_f1_micro: 0.5541\n",
      "Epoch 62/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.1025 - acc: 0.6482 - f1_micro: 0.5542 - val_loss: 1.7389 - val_acc: 0.7103 - val_f1_micro: 0.5544\n",
      "Epoch 63/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0941 - acc: 0.6497 - f1_micro: 0.5546 - val_loss: 1.7388 - val_acc: 0.7162 - val_f1_micro: 0.5547\n",
      "Epoch 64/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0978 - acc: 0.6500 - f1_micro: 0.5549 - val_loss: 1.7326 - val_acc: 0.7151 - val_f1_micro: 0.5551\n",
      "Epoch 65/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0963 - acc: 0.6519 - f1_micro: 0.5552 - val_loss: 1.7302 - val_acc: 0.7211 - val_f1_micro: 0.5554\n",
      "Epoch 66/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0919 - acc: 0.6523 - f1_micro: 0.5555 - val_loss: 1.7293 - val_acc: 0.7204 - val_f1_micro: 0.5557\n",
      "Epoch 67/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0950 - acc: 0.6497 - f1_micro: 0.5559 - val_loss: 1.7324 - val_acc: 0.7176 - val_f1_micro: 0.5560\n",
      "Epoch 68/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0878 - acc: 0.6505 - f1_micro: 0.5561 - val_loss: 1.7274 - val_acc: 0.7125 - val_f1_micro: 0.5563\n",
      "Epoch 69/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0938 - acc: 0.6511 - f1_micro: 0.5564 - val_loss: 1.7277 - val_acc: 0.7172 - val_f1_micro: 0.5566\n",
      "Epoch 70/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0960 - acc: 0.6513 - f1_micro: 0.5567 - val_loss: 1.7313 - val_acc: 0.7194 - val_f1_micro: 0.5569\n",
      "Epoch 71/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0954 - acc: 0.6507 - f1_micro: 0.5570 - val_loss: 1.7308 - val_acc: 0.7187 - val_f1_micro: 0.5572\n",
      "Epoch 72/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0935 - acc: 0.6516 - f1_micro: 0.5573 - val_loss: 1.7258 - val_acc: 0.7182 - val_f1_micro: 0.5575\n",
      "Epoch 73/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0890 - acc: 0.6516 - f1_micro: 0.5576 - val_loss: 1.7256 - val_acc: 0.7185 - val_f1_micro: 0.5578\n",
      "Epoch 74/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0860 - acc: 0.6520 - f1_micro: 0.5580 - val_loss: 1.7212 - val_acc: 0.7255 - val_f1_micro: 0.5581\n",
      "Epoch 75/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0813 - acc: 0.6540 - f1_micro: 0.5583 - val_loss: 1.7209 - val_acc: 0.7208 - val_f1_micro: 0.5584\n",
      "Epoch 76/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0859 - acc: 0.6516 - f1_micro: 0.5586 - val_loss: 1.7249 - val_acc: 0.7227 - val_f1_micro: 0.5587\n",
      "Epoch 77/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0897 - acc: 0.6522 - f1_micro: 0.5588 - val_loss: 1.7226 - val_acc: 0.7177 - val_f1_micro: 0.5590\n",
      "Epoch 78/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0871 - acc: 0.6501 - f1_micro: 0.5591 - val_loss: 1.7216 - val_acc: 0.7209 - val_f1_micro: 0.5593\n",
      "Epoch 79/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0811 - acc: 0.6530 - f1_micro: 0.5594 - val_loss: 1.7115 - val_acc: 0.7094 - val_f1_micro: 0.5595\n",
      "Epoch 80/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0791 - acc: 0.6508 - f1_micro: 0.5597 - val_loss: 1.7188 - val_acc: 0.7173 - val_f1_micro: 0.5598\n",
      "Epoch 81/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0824 - acc: 0.6507 - f1_micro: 0.5599 - val_loss: 1.7195 - val_acc: 0.7200 - val_f1_micro: 0.5601\n",
      "Epoch 82/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0834 - acc: 0.6533 - f1_micro: 0.5602 - val_loss: 1.7145 - val_acc: 0.7141 - val_f1_micro: 0.5604\n",
      "Epoch 83/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0809 - acc: 0.6517 - f1_micro: 0.5605 - val_loss: 1.7105 - val_acc: 0.7189 - val_f1_micro: 0.5607\n",
      "Epoch 84/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0769 - acc: 0.6528 - f1_micro: 0.5608 - val_loss: 1.7122 - val_acc: 0.7228 - val_f1_micro: 0.5609\n",
      "Epoch 85/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0800 - acc: 0.6514 - f1_micro: 0.5611 - val_loss: 1.7099 - val_acc: 0.7193 - val_f1_micro: 0.5612\n",
      "Epoch 86/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0770 - acc: 0.6530 - f1_micro: 0.5613 - val_loss: 1.7094 - val_acc: 0.7163 - val_f1_micro: 0.5615\n",
      "Epoch 87/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0799 - acc: 0.6514 - f1_micro: 0.5616 - val_loss: 1.7135 - val_acc: 0.7232 - val_f1_micro: 0.5617\n",
      "Epoch 88/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0815 - acc: 0.6536 - f1_micro: 0.5619 - val_loss: 1.7084 - val_acc: 0.7198 - val_f1_micro: 0.5620\n",
      "Epoch 89/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0761 - acc: 0.6520 - f1_micro: 0.5621 - val_loss: 1.7060 - val_acc: 0.7198 - val_f1_micro: 0.5623\n",
      "Epoch 90/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0705 - acc: 0.6532 - f1_micro: 0.5624 - val_loss: 1.7054 - val_acc: 0.7221 - val_f1_micro: 0.5626\n",
      "Epoch 91/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0731 - acc: 0.6537 - f1_micro: 0.5627 - val_loss: 1.7077 - val_acc: 0.7240 - val_f1_micro: 0.5628\n",
      "Epoch 92/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0736 - acc: 0.6539 - f1_micro: 0.5629 - val_loss: 1.7017 - val_acc: 0.7159 - val_f1_micro: 0.5631\n",
      "Epoch 93/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0770 - acc: 0.6505 - f1_micro: 0.5632 - val_loss: 1.7023 - val_acc: 0.7212 - val_f1_micro: 0.5634\n",
      "Epoch 94/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0832 - acc: 0.6528 - f1_micro: 0.5635 - val_loss: 1.7072 - val_acc: 0.7176 - val_f1_micro: 0.5636\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94731/94731 [==============================] - 0s - loss: 2.0746 - acc: 0.6528 - f1_micro: 0.5637 - val_loss: 1.7070 - val_acc: 0.7149 - val_f1_micro: 0.5639\n",
      "Epoch 96/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0758 - acc: 0.6520 - f1_micro: 0.5640 - val_loss: 1.7026 - val_acc: 0.7169 - val_f1_micro: 0.5641\n",
      "Epoch 97/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0749 - acc: 0.6521 - f1_micro: 0.5642 - val_loss: 1.7042 - val_acc: 0.7228 - val_f1_micro: 0.5644\n",
      "Epoch 98/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0680 - acc: 0.6525 - f1_micro: 0.5645 - val_loss: 1.7044 - val_acc: 0.7192 - val_f1_micro: 0.5646\n",
      "Epoch 99/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0765 - acc: 0.6521 - f1_micro: 0.5648 - val_loss: 1.7041 - val_acc: 0.7147 - val_f1_micro: 0.5649\n",
      "Epoch 100/100\n",
      "94731/94731 [==============================] - 0s - loss: 2.0726 - acc: 0.6531 - f1_micro: 0.5650 - val_loss: 1.7050 - val_acc: 0.7228 - val_f1_micro: 0.5651\n",
      "CPU times: user 1min 34s, sys: 15.5 s, total: 1min 49s\n",
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# And trained it via:\n",
    "batch_size = 1200\n",
    "model.fit(\n",
    "    {'wv_input': wv_train, 'fs_input': fs_train},\n",
    "    {'main_output': y_train},\n",
    "    epochs=100, batch_size=batch_size,   # 500\n",
    "    validation_split=0.2,\n",
    "    validation_data=(\n",
    "        {'wv_input': wv_val, 'fs_input': fs_val},\n",
    "        {'main_output': y_val}\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 4.8078 - main_output_loss: 3.5175 - aux_output_loss: 6.4518 - main_output_acc: 0.4771 - main_output_f1_micro: 0.1114 - aux_output_acc: 0.0226 - aux_output_f1_micro: 0.0604 - val_loss: 4.4161 - val_main_output_loss: 3.0819 - val_aux_output_loss: 6.6709 - val_main_output_acc: 0.5578 - val_main_output_f1_micro: 0.1320 - val_aux_output_acc: 0.0427 - val_aux_output_f1_micro: 0.0637\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 4.4622 - main_output_loss: 3.1799 - aux_output_loss: 6.4113 - main_output_acc: 0.5187 - main_output_f1_micro: 0.1504 - aux_output_acc: 0.0562 - aux_output_f1_micro: 0.0661 - val_loss: 4.1918 - val_main_output_loss: 2.8589 - val_aux_output_loss: 6.6642 - val_main_output_acc: 0.5865 - val_main_output_f1_micro: 0.1678 - val_aux_output_acc: 0.0423 - val_aux_output_f1_micro: 0.0682\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 4.2921 - main_output_loss: 3.0142 - aux_output_loss: 6.3896 - main_output_acc: 0.5387 - main_output_f1_micro: 0.1835 - aux_output_acc: 0.0629 - aux_output_f1_micro: 0.0698 - val_loss: 4.0473 - val_main_output_loss: 2.7185 - val_aux_output_loss: 6.6437 - val_main_output_acc: 0.5935 - val_main_output_f1_micro: 0.1984 - val_aux_output_acc: 0.0585 - val_aux_output_f1_micro: 0.0714\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 4.1816 - main_output_loss: 2.9071 - aux_output_loss: 6.3722 - main_output_acc: 0.5530 - main_output_f1_micro: 0.2120 - aux_output_acc: 0.0704 - aux_output_f1_micro: 0.0727 - val_loss: 3.9736 - val_main_output_loss: 2.6488 - val_aux_output_loss: 6.6239 - val_main_output_acc: 0.6115 - val_main_output_f1_micro: 0.2250 - val_aux_output_acc: 0.0665 - val_aux_output_f1_micro: 0.0740\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 4.1058 - main_output_loss: 2.8346 - aux_output_loss: 6.3561 - main_output_acc: 0.5615 - main_output_f1_micro: 0.2367 - aux_output_acc: 0.0755 - aux_output_f1_micro: 0.0751 - val_loss: 3.9000 - val_main_output_loss: 2.5800 - val_aux_output_loss: 6.5998 - val_main_output_acc: 0.6056 - val_main_output_f1_micro: 0.2481 - val_aux_output_acc: 0.0726 - val_aux_output_f1_micro: 0.0762\n",
      "\n",
      "Done with epoch: 5\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 4.0374 - main_output_loss: 2.7697 - aux_output_loss: 6.3384 - main_output_acc: 0.5677 - main_output_f1_micro: 0.2586 - aux_output_acc: 0.0791 - aux_output_f1_micro: 0.0772 - val_loss: 3.8390 - val_main_output_loss: 2.5241 - val_aux_output_loss: 6.5743 - val_main_output_acc: 0.6108 - val_main_output_f1_micro: 0.2686 - val_aux_output_acc: 0.0741 - val_aux_output_f1_micro: 0.0781\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 3.9853 - main_output_loss: 2.7224 - aux_output_loss: 6.3144 - main_output_acc: 0.5746 - main_output_f1_micro: 0.2779 - aux_output_acc: 0.0810 - aux_output_f1_micro: 0.0790 - val_loss: 3.7775 - val_main_output_loss: 2.4719 - val_aux_output_loss: 6.5278 - val_main_output_acc: 0.6223 - val_main_output_f1_micro: 0.2869 - val_aux_output_acc: 0.0763 - val_aux_output_f1_micro: 0.0798\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 3.9232 - main_output_loss: 2.6681 - aux_output_loss: 6.2756 - main_output_acc: 0.5806 - main_output_f1_micro: 0.2953 - aux_output_acc: 0.0823 - aux_output_f1_micro: 0.0807 - val_loss: 3.7284 - val_main_output_loss: 2.4274 - val_aux_output_loss: 6.5052 - val_main_output_acc: 0.6272 - val_main_output_f1_micro: 0.3033 - val_aux_output_acc: 0.0780 - val_aux_output_f1_micro: 0.0815\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 3.8746 - main_output_loss: 2.6281 - aux_output_loss: 6.2326 - main_output_acc: 0.5856 - main_output_f1_micro: 0.3108 - aux_output_acc: 0.0826 - aux_output_f1_micro: 0.0823 - val_loss: 3.6628 - val_main_output_loss: 2.3812 - val_aux_output_loss: 6.4080 - val_main_output_acc: 0.6267 - val_main_output_f1_micro: 0.3182 - val_aux_output_acc: 0.0794 - val_aux_output_f1_micro: 0.0832\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 3.8167 - main_output_loss: 2.5887 - aux_output_loss: 6.1402 - main_output_acc: 0.5904 - main_output_f1_micro: 0.3251 - aux_output_acc: 0.0829 - aux_output_f1_micro: 0.0840 - val_loss: 3.6081 - val_main_output_loss: 2.3424 - val_aux_output_loss: 6.3283 - val_main_output_acc: 0.6348 - val_main_output_f1_micro: 0.3319 - val_aux_output_acc: 0.0794 - val_aux_output_f1_micro: 0.0849\n",
      "\n",
      "Done with epoch: 10\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 3.7645 - main_output_loss: 2.5492 - aux_output_loss: 6.0767 - main_output_acc: 0.5958 - main_output_f1_micro: 0.3383 - aux_output_acc: 0.0830 - aux_output_f1_micro: 0.0858 - val_loss: 3.5425 - val_main_output_loss: 2.2961 - val_aux_output_loss: 6.2319 - val_main_output_acc: 0.6356 - val_main_output_f1_micro: 0.3444 - val_aux_output_acc: 0.0791 - val_aux_output_f1_micro: 0.0866\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 3.7013 - main_output_loss: 2.5086 - aux_output_loss: 5.9637 - main_output_acc: 0.5999 - main_output_f1_micro: 0.3502 - aux_output_acc: 0.0856 - aux_output_f1_micro: 0.0875 - val_loss: 3.4732 - val_main_output_loss: 2.2522 - val_aux_output_loss: 6.1047 - val_main_output_acc: 0.6441 - val_main_output_f1_micro: 0.3558 - val_aux_output_acc: 0.0874 - val_aux_output_f1_micro: 0.0883\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 3.6296 - main_output_loss: 2.4643 - aux_output_loss: 5.8266 - main_output_acc: 0.6076 - main_output_f1_micro: 0.3612 - aux_output_acc: 0.1017 - aux_output_f1_micro: 0.0891 - val_loss: 3.4313 - val_main_output_loss: 2.2099 - val_aux_output_loss: 6.1072 - val_main_output_acc: 0.6538 - val_main_output_f1_micro: 0.3665 - val_aux_output_acc: 0.1002 - val_aux_output_f1_micro: 0.0898\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 3.5783 - main_output_loss: 2.4334 - aux_output_loss: 5.7246 - main_output_acc: 0.6108 - main_output_f1_micro: 0.3715 - aux_output_acc: 0.1298 - aux_output_f1_micro: 0.0904 - val_loss: 3.3294 - val_main_output_loss: 2.1656 - val_aux_output_loss: 5.8191 - val_main_output_acc: 0.6522 - val_main_output_f1_micro: 0.3765 - val_aux_output_acc: 0.1287 - val_aux_output_f1_micro: 0.0909\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 3.4890 - main_output_loss: 2.3854 - aux_output_loss: 5.5183 - main_output_acc: 0.6149 - main_output_f1_micro: 0.3811 - aux_output_acc: 0.1613 - aux_output_f1_micro: 0.0912 - val_loss: 3.2447 - val_main_output_loss: 2.1182 - val_aux_output_loss: 5.6329 - val_main_output_acc: 0.6562 - val_main_output_f1_micro: 0.3857 - val_aux_output_acc: 0.1548 - val_aux_output_f1_micro: 0.0915\n",
      "\n",
      "Done with epoch: 15\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 3.4014 - main_output_loss: 2.3373 - aux_output_loss: 5.3204 - main_output_acc: 0.6252 - main_output_f1_micro: 0.3900 - aux_output_acc: 0.1950 - aux_output_f1_micro: 0.0917 - val_loss: 3.1622 - val_main_output_loss: 2.0761 - val_aux_output_loss: 5.4306 - val_main_output_acc: 0.6698 - val_main_output_f1_micro: 0.3944 - val_aux_output_acc: 0.1781 - val_aux_output_f1_micro: 0.0919\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 3.3180 - main_output_loss: 2.3002 - aux_output_loss: 5.0893 - main_output_acc: 0.6292 - main_output_f1_micro: 0.3986 - aux_output_acc: 0.2334 - aux_output_f1_micro: 0.0920 - val_loss: 3.0776 - val_main_output_loss: 2.0372 - val_aux_output_loss: 5.2016 - val_main_output_acc: 0.6750 - val_main_output_f1_micro: 0.4028 - val_aux_output_acc: 0.2117 - val_aux_output_f1_micro: 0.0921\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 3.2272 - main_output_loss: 2.2633 - aux_output_loss: 4.8195 - main_output_acc: 0.6344 - main_output_f1_micro: 0.4067 - aux_output_acc: 0.2832 - aux_output_f1_micro: 0.0923 - val_loss: 2.9790 - val_main_output_loss: 1.9972 - val_aux_output_loss: 4.9090 - val_main_output_acc: 0.6836 - val_main_output_f1_micro: 0.4105 - val_aux_output_acc: 0.2816 - val_aux_output_f1_micro: 0.0924\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 3.1336 - main_output_loss: 2.2233 - aux_output_loss: 4.5514 - main_output_acc: 0.6409 - main_output_f1_micro: 0.4142 - aux_output_acc: 0.3370 - aux_output_f1_micro: 0.0926 - val_loss: 2.8695 - val_main_output_loss: 1.9341 - val_aux_output_loss: 4.6772 - val_main_output_acc: 0.6906 - val_main_output_f1_micro: 0.4179 - val_aux_output_acc: 0.3304 - val_aux_output_f1_micro: 0.0927\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 3.0397 - main_output_loss: 2.1772 - aux_output_loss: 4.3127 - main_output_acc: 0.6483 - main_output_f1_micro: 0.4214 - aux_output_acc: 0.3840 - aux_output_f1_micro: 0.0929 - val_loss: 2.7929 - val_main_output_loss: 1.9035 - val_aux_output_loss: 4.4468 - val_main_output_acc: 0.7043 - val_main_output_f1_micro: 0.4249 - val_aux_output_acc: 0.3764 - val_aux_output_f1_micro: 0.0930\n",
      "\n",
      "Done with epoch: 20\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.9632 - main_output_loss: 2.1417 - aux_output_loss: 4.1077 - main_output_acc: 0.6551 - main_output_f1_micro: 0.4282 - aux_output_acc: 0.4210 - aux_output_f1_micro: 0.0932 - val_loss: 2.7141 - val_main_output_loss: 1.8661 - val_aux_output_loss: 4.2399 - val_main_output_acc: 0.7020 - val_main_output_f1_micro: 0.4315 - val_aux_output_acc: 0.4219 - val_aux_output_f1_micro: 0.0933\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.8907 - main_output_loss: 2.1063 - aux_output_loss: 3.9221 - main_output_acc: 0.6594 - main_output_f1_micro: 0.4347 - aux_output_acc: 0.4526 - aux_output_f1_micro: 0.0934 - val_loss: 2.6462 - val_main_output_loss: 1.8345 - val_aux_output_loss: 4.0587 - val_main_output_acc: 0.7061 - val_main_output_f1_micro: 0.4379 - val_aux_output_acc: 0.4483 - val_aux_output_f1_micro: 0.0936\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.8249 - main_output_loss: 2.0756 - aux_output_loss: 3.7462 - main_output_acc: 0.6640 - main_output_f1_micro: 0.4410 - aux_output_acc: 0.4817 - aux_output_f1_micro: 0.0937 - val_loss: 2.5923 - val_main_output_loss: 1.8131 - val_aux_output_loss: 3.8958 - val_main_output_acc: 0.7104 - val_main_output_f1_micro: 0.4441 - val_aux_output_acc: 0.4722 - val_aux_output_f1_micro: 0.0938\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.7557 - main_output_loss: 2.0389 - aux_output_loss: 3.5838 - main_output_acc: 0.6709 - main_output_f1_micro: 0.4470 - aux_output_acc: 0.5080 - aux_output_f1_micro: 0.0939 - val_loss: 2.5182 - val_main_output_loss: 1.7681 - val_aux_output_loss: 3.7506 - val_main_output_acc: 0.7258 - val_main_output_f1_micro: 0.4499 - val_aux_output_acc: 0.5025 - val_aux_output_f1_micro: 0.0941\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.6928 - main_output_loss: 2.0047 - aux_output_loss: 3.4404 - main_output_acc: 0.6747 - main_output_f1_micro: 0.4527 - aux_output_acc: 0.5317 - aux_output_f1_micro: 0.0942 - val_loss: 2.4572 - val_main_output_loss: 1.7326 - val_aux_output_loss: 3.6227 - val_main_output_acc: 0.7298 - val_main_output_f1_micro: 0.4555 - val_aux_output_acc: 0.5204 - val_aux_output_f1_micro: 0.0943\n",
      "\n",
      "Done with epoch: 25\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.6352 - main_output_loss: 1.9727 - aux_output_loss: 3.3127 - main_output_acc: 0.6820 - main_output_f1_micro: 0.4583 - aux_output_acc: 0.5514 - aux_output_f1_micro: 0.0944 - val_loss: 2.4032 - val_main_output_loss: 1.7057 - val_aux_output_loss: 3.4873 - val_main_output_acc: 0.7298 - val_main_output_f1_micro: 0.4610 - val_aux_output_acc: 0.5401 - val_aux_output_f1_micro: 0.0945\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.5851 - main_output_loss: 1.9448 - aux_output_loss: 3.2015 - main_output_acc: 0.6847 - main_output_f1_micro: 0.4636 - aux_output_acc: 0.5676 - aux_output_f1_micro: 0.0946 - val_loss: 2.3583 - val_main_output_loss: 1.6795 - val_aux_output_loss: 3.3937 - val_main_output_acc: 0.7363 - val_main_output_f1_micro: 0.4663 - val_aux_output_acc: 0.5560 - val_aux_output_f1_micro: 0.0947\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.5321 - main_output_loss: 1.9122 - aux_output_loss: 3.0995 - main_output_acc: 0.6915 - main_output_f1_micro: 0.4689 - aux_output_acc: 0.5831 - aux_output_f1_micro: 0.0948 - val_loss: 2.3052 - val_main_output_loss: 1.6459 - val_aux_output_loss: 3.2966 - val_main_output_acc: 0.7428 - val_main_output_f1_micro: 0.4715 - val_aux_output_acc: 0.5730 - val_aux_output_f1_micro: 0.0949\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.4891 - main_output_loss: 1.8872 - aux_output_loss: 3.0095 - main_output_acc: 0.6944 - main_output_f1_micro: 0.4740 - aux_output_acc: 0.5971 - aux_output_f1_micro: 0.0950 - val_loss: 2.2571 - val_main_output_loss: 1.6170 - val_aux_output_loss: 3.2004 - val_main_output_acc: 0.7381 - val_main_output_f1_micro: 0.4765 - val_aux_output_acc: 0.5843 - val_aux_output_f1_micro: 0.0951\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.4486 - main_output_loss: 1.8637 - aux_output_loss: 2.9245 - main_output_acc: 0.6998 - main_output_f1_micro: 0.4790 - aux_output_acc: 0.6101 - aux_output_f1_micro: 0.0952 - val_loss: 2.2314 - val_main_output_loss: 1.6071 - val_aux_output_loss: 3.1214 - val_main_output_acc: 0.7472 - val_main_output_f1_micro: 0.4815 - val_aux_output_acc: 0.5977 - val_aux_output_f1_micro: 0.0952\n",
      "\n",
      "Done with epoch: 30\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.4090 - main_output_loss: 1.8395 - aux_output_loss: 2.8474 - main_output_acc: 0.7042 - main_output_f1_micro: 0.4839 - aux_output_acc: 0.6202 - aux_output_f1_micro: 0.0953 - val_loss: 2.1865 - val_main_output_loss: 1.5794 - val_aux_output_loss: 3.0354 - val_main_output_acc: 0.7522 - val_main_output_f1_micro: 0.4863 - val_aux_output_acc: 0.6125 - val_aux_output_f1_micro: 0.0954\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.3710 - main_output_loss: 1.8149 - aux_output_loss: 2.7808 - main_output_acc: 0.7082 - main_output_f1_micro: 0.4887 - aux_output_acc: 0.6304 - aux_output_f1_micro: 0.0955 - val_loss: 2.1559 - val_main_output_loss: 1.5603 - val_aux_output_loss: 2.9781 - val_main_output_acc: 0.7534 - val_main_output_f1_micro: 0.4911 - val_aux_output_acc: 0.6194 - val_aux_output_f1_micro: 0.0956\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.3382 - main_output_loss: 1.7953 - aux_output_loss: 2.7147 - main_output_acc: 0.7112 - main_output_f1_micro: 0.4934 - aux_output_acc: 0.6386 - aux_output_f1_micro: 0.0956 - val_loss: 2.1292 - val_main_output_loss: 1.5471 - val_aux_output_loss: 2.9109 - val_main_output_acc: 0.7582 - val_main_output_f1_micro: 0.4958 - val_aux_output_acc: 0.6299 - val_aux_output_f1_micro: 0.0957\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.3092 - main_output_loss: 1.7778 - aux_output_loss: 2.6570 - main_output_acc: 0.7143 - main_output_f1_micro: 0.4981 - aux_output_acc: 0.6470 - aux_output_f1_micro: 0.0958 - val_loss: 2.0928 - val_main_output_loss: 1.5228 - val_aux_output_loss: 2.8501 - val_main_output_acc: 0.7619 - val_main_output_f1_micro: 0.5004 - val_aux_output_acc: 0.6366 - val_aux_output_f1_micro: 0.0958\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94731/94731 [==============================] - 52s - loss: 2.2740 - main_output_loss: 1.7540 - aux_output_loss: 2.6000 - main_output_acc: 0.7173 - main_output_f1_micro: 0.5026 - aux_output_acc: 0.6542 - aux_output_f1_micro: 0.0959 - val_loss: 2.0584 - val_main_output_loss: 1.5023 - val_aux_output_loss: 2.7809 - val_main_output_acc: 0.7649 - val_main_output_f1_micro: 0.5049 - val_aux_output_acc: 0.6478 - val_aux_output_f1_micro: 0.0960\n",
      "\n",
      "Done with epoch: 35\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.2435 - main_output_loss: 1.7353 - aux_output_loss: 2.5413 - main_output_acc: 0.7192 - main_output_f1_micro: 0.5071 - aux_output_acc: 0.6623 - aux_output_f1_micro: 0.0960 - val_loss: 2.0364 - val_main_output_loss: 1.4907 - val_aux_output_loss: 2.7285 - val_main_output_acc: 0.7641 - val_main_output_f1_micro: 0.5093 - val_aux_output_acc: 0.6587 - val_aux_output_f1_micro: 0.0961\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.2152 - main_output_loss: 1.7164 - aux_output_loss: 2.4940 - main_output_acc: 0.7240 - main_output_f1_micro: 0.5115 - aux_output_acc: 0.6692 - aux_output_f1_micro: 0.0962 - val_loss: 1.9969 - val_main_output_loss: 1.4615 - val_aux_output_loss: 2.6771 - val_main_output_acc: 0.7678 - val_main_output_f1_micro: 0.5137 - val_aux_output_acc: 0.6640 - val_aux_output_f1_micro: 0.0962\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.1860 - main_output_loss: 1.6967 - aux_output_loss: 2.4465 - main_output_acc: 0.7276 - main_output_f1_micro: 0.5158 - aux_output_acc: 0.6748 - aux_output_f1_micro: 0.0963 - val_loss: 1.9792 - val_main_output_loss: 1.4545 - val_aux_output_loss: 2.6235 - val_main_output_acc: 0.7676 - val_main_output_f1_micro: 0.5179 - val_aux_output_acc: 0.6699 - val_aux_output_f1_micro: 0.0963\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.1625 - main_output_loss: 1.6825 - aux_output_loss: 2.4000 - main_output_acc: 0.7292 - main_output_f1_micro: 0.5200 - aux_output_acc: 0.6817 - aux_output_f1_micro: 0.0964 - val_loss: 1.9612 - val_main_output_loss: 1.4449 - val_aux_output_loss: 2.5813 - val_main_output_acc: 0.7728 - val_main_output_f1_micro: 0.5221 - val_aux_output_acc: 0.6781 - val_aux_output_f1_micro: 0.0965\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.1416 - main_output_loss: 1.6698 - aux_output_loss: 2.3590 - main_output_acc: 0.7344 - main_output_f1_micro: 0.5242 - aux_output_acc: 0.6882 - aux_output_f1_micro: 0.0965 - val_loss: 1.9458 - val_main_output_loss: 1.4367 - val_aux_output_loss: 2.5456 - val_main_output_acc: 0.7707 - val_main_output_f1_micro: 0.5263 - val_aux_output_acc: 0.6828 - val_aux_output_f1_micro: 0.0966\n",
      "\n",
      "Done with epoch: 40\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.1179 - main_output_loss: 1.6544 - aux_output_loss: 2.3173 - main_output_acc: 0.7326 - main_output_f1_micro: 0.5283 - aux_output_acc: 0.6932 - aux_output_f1_micro: 0.0966 - val_loss: 1.9196 - val_main_output_loss: 1.4191 - val_aux_output_loss: 2.5022 - val_main_output_acc: 0.7763 - val_main_output_f1_micro: 0.5303 - val_aux_output_acc: 0.6894 - val_aux_output_f1_micro: 0.0967\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.0930 - main_output_loss: 1.6370 - aux_output_loss: 2.2799 - main_output_acc: 0.7378 - main_output_f1_micro: 0.5323 - aux_output_acc: 0.6980 - aux_output_f1_micro: 0.0967 - val_loss: 1.8950 - val_main_output_loss: 1.4056 - val_aux_output_loss: 2.4471 - val_main_output_acc: 0.7743 - val_main_output_f1_micro: 0.5342 - val_aux_output_acc: 0.6932 - val_aux_output_f1_micro: 0.0968\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.0795 - main_output_loss: 1.6297 - aux_output_loss: 2.2491 - main_output_acc: 0.7386 - main_output_f1_micro: 0.5362 - aux_output_acc: 0.7012 - aux_output_f1_micro: 0.0969 - val_loss: 1.8804 - val_main_output_loss: 1.3954 - val_aux_output_loss: 2.4251 - val_main_output_acc: 0.7808 - val_main_output_f1_micro: 0.5381 - val_aux_output_acc: 0.7036 - val_aux_output_f1_micro: 0.0969\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.0547 - main_output_loss: 1.6124 - aux_output_loss: 2.2116 - main_output_acc: 0.7426 - main_output_f1_micro: 0.5400 - aux_output_acc: 0.7069 - aux_output_f1_micro: 0.0970 - val_loss: 1.8553 - val_main_output_loss: 1.3798 - val_aux_output_loss: 2.3779 - val_main_output_acc: 0.7847 - val_main_output_f1_micro: 0.5419 - val_aux_output_acc: 0.7085 - val_aux_output_f1_micro: 0.0971\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.0361 - main_output_loss: 1.6011 - aux_output_loss: 2.1753 - main_output_acc: 0.7414 - main_output_f1_micro: 0.5439 - aux_output_acc: 0.7101 - aux_output_f1_micro: 0.0971 - val_loss: 1.8457 - val_main_output_loss: 1.3763 - val_aux_output_loss: 2.3471 - val_main_output_acc: 0.7855 - val_main_output_f1_micro: 0.5458 - val_aux_output_acc: 0.7133 - val_aux_output_f1_micro: 0.0972\n",
      "\n",
      "Done with epoch: 45\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.0209 - main_output_loss: 1.5910 - aux_output_loss: 2.1494 - main_output_acc: 0.7431 - main_output_f1_micro: 0.5477 - aux_output_acc: 0.7128 - aux_output_f1_micro: 0.0973 - val_loss: 1.8257 - val_main_output_loss: 1.3615 - val_aux_output_loss: 2.3213 - val_main_output_acc: 0.7831 - val_main_output_f1_micro: 0.5495 - val_aux_output_acc: 0.7132 - val_aux_output_f1_micro: 0.0974\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.0024 - main_output_loss: 1.5790 - aux_output_loss: 2.1168 - main_output_acc: 0.7456 - main_output_f1_micro: 0.5514 - aux_output_acc: 0.7195 - aux_output_f1_micro: 0.0974 - val_loss: 1.8126 - val_main_output_loss: 1.3551 - val_aux_output_loss: 2.2874 - val_main_output_acc: 0.7836 - val_main_output_f1_micro: 0.5532 - val_aux_output_acc: 0.7197 - val_aux_output_f1_micro: 0.0975\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.9835 - main_output_loss: 1.5660 - aux_output_loss: 2.0876 - main_output_acc: 0.7469 - main_output_f1_micro: 0.5549 - aux_output_acc: 0.7224 - aux_output_f1_micro: 0.0975 - val_loss: 1.7947 - val_main_output_loss: 1.3436 - val_aux_output_loss: 2.2553 - val_main_output_acc: 0.7857 - val_main_output_f1_micro: 0.5567 - val_aux_output_acc: 0.7250 - val_aux_output_f1_micro: 0.0976\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.9690 - main_output_loss: 1.5571 - aux_output_loss: 2.0593 - main_output_acc: 0.7480 - main_output_f1_micro: 0.5585 - aux_output_acc: 0.7249 - aux_output_f1_micro: 0.0977 - val_loss: 1.7755 - val_main_output_loss: 1.3299 - val_aux_output_loss: 2.2276 - val_main_output_acc: 0.7906 - val_main_output_f1_micro: 0.5602 - val_aux_output_acc: 0.7255 - val_aux_output_f1_micro: 0.0977\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.9542 - main_output_loss: 1.5475 - aux_output_loss: 2.0334 - main_output_acc: 0.7484 - main_output_f1_micro: 0.5620 - aux_output_acc: 0.7295 - aux_output_f1_micro: 0.0978 - val_loss: 1.7592 - val_main_output_loss: 1.3206 - val_aux_output_loss: 2.1929 - val_main_output_acc: 0.7805 - val_main_output_f1_micro: 0.5637 - val_aux_output_acc: 0.7262 - val_aux_output_f1_micro: 0.0979\n",
      "\n",
      "Done with epoch: 50\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.9405 - main_output_loss: 1.5389 - aux_output_loss: 2.0079 - main_output_acc: 0.7488 - main_output_f1_micro: 0.5655 - aux_output_acc: 0.7327 - aux_output_f1_micro: 0.0980 - val_loss: 1.7519 - val_main_output_loss: 1.3174 - val_aux_output_loss: 2.1723 - val_main_output_acc: 0.7793 - val_main_output_f1_micro: 0.5672 - val_aux_output_acc: 0.7277 - val_aux_output_f1_micro: 0.0980\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.9278 - main_output_loss: 1.5309 - aux_output_loss: 1.9843 - main_output_acc: 0.7502 - main_output_f1_micro: 0.5689 - aux_output_acc: 0.7350 - aux_output_f1_micro: 0.0981 - val_loss: 1.7341 - val_main_output_loss: 1.3040 - val_aux_output_loss: 2.1509 - val_main_output_acc: 0.7894 - val_main_output_f1_micro: 0.5706 - val_aux_output_acc: 0.7371 - val_aux_output_f1_micro: 0.0982\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.9081 - main_output_loss: 1.5157 - aux_output_loss: 1.9617 - main_output_acc: 0.7539 - main_output_f1_micro: 0.5723 - aux_output_acc: 0.7376 - aux_output_f1_micro: 0.0983 - val_loss: 1.7195 - val_main_output_loss: 1.2941 - val_aux_output_loss: 2.1270 - val_main_output_acc: 0.7860 - val_main_output_f1_micro: 0.5740 - val_aux_output_acc: 0.7323 - val_aux_output_f1_micro: 0.0983\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.8993 - main_output_loss: 1.5117 - aux_output_loss: 1.9379 - main_output_acc: 0.7541 - main_output_f1_micro: 0.5756 - aux_output_acc: 0.7401 - aux_output_f1_micro: 0.0984 - val_loss: 1.7099 - val_main_output_loss: 1.2899 - val_aux_output_loss: 2.0999 - val_main_output_acc: 0.7842 - val_main_output_f1_micro: 0.5772 - val_aux_output_acc: 0.7344 - val_aux_output_f1_micro: 0.0985\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.8891 - main_output_loss: 1.5053 - aux_output_loss: 1.9189 - main_output_acc: 0.7547 - main_output_f1_micro: 0.5789 - aux_output_acc: 0.7423 - aux_output_f1_micro: 0.0985 - val_loss: 1.6988 - val_main_output_loss: 1.2837 - val_aux_output_loss: 2.0757 - val_main_output_acc: 0.7850 - val_main_output_f1_micro: 0.5805 - val_aux_output_acc: 0.7401 - val_aux_output_f1_micro: 0.0986\n",
      "\n",
      "Done with epoch: 55\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.8716 - main_output_loss: 1.4921 - aux_output_loss: 1.8975 - main_output_acc: 0.7567 - main_output_f1_micro: 0.5822 - aux_output_acc: 0.7453 - aux_output_f1_micro: 0.0987 - val_loss: 1.6873 - val_main_output_loss: 1.2767 - val_aux_output_loss: 2.0531 - val_main_output_acc: 0.7902 - val_main_output_f1_micro: 0.5838 - val_aux_output_acc: 0.7468 - val_aux_output_f1_micro: 0.0987\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.8576 - main_output_loss: 1.4825 - aux_output_loss: 1.8756 - main_output_acc: 0.7564 - main_output_f1_micro: 0.5854 - aux_output_acc: 0.7480 - aux_output_f1_micro: 0.0988 - val_loss: 1.6773 - val_main_output_loss: 1.2699 - val_aux_output_loss: 2.0369 - val_main_output_acc: 0.7899 - val_main_output_f1_micro: 0.5870 - val_aux_output_acc: 0.7432 - val_aux_output_f1_micro: 0.0989\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.8492 - main_output_loss: 1.4778 - aux_output_loss: 1.8572 - main_output_acc: 0.7569 - main_output_f1_micro: 0.5886 - aux_output_acc: 0.7501 - aux_output_f1_micro: 0.0990 - val_loss: 1.6676 - val_main_output_loss: 1.2652 - val_aux_output_loss: 2.0119 - val_main_output_acc: 0.7810 - val_main_output_f1_micro: 0.5902 - val_aux_output_acc: 0.7475 - val_aux_output_f1_micro: 0.0991\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.8377 - main_output_loss: 1.4699 - aux_output_loss: 1.8390 - main_output_acc: 0.7582 - main_output_f1_micro: 0.5917 - aux_output_acc: 0.7521 - aux_output_f1_micro: 0.0992 - val_loss: 1.6625 - val_main_output_loss: 1.2648 - val_aux_output_loss: 1.9885 - val_main_output_acc: 0.7893 - val_main_output_f1_micro: 0.5933 - val_aux_output_acc: 0.7524 - val_aux_output_f1_micro: 0.0992\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.8252 - main_output_loss: 1.4610 - aux_output_loss: 1.8210 - main_output_acc: 0.7569 - main_output_f1_micro: 0.5948 - aux_output_acc: 0.7540 - aux_output_f1_micro: 0.0993 - val_loss: 1.6522 - val_main_output_loss: 1.2585 - val_aux_output_loss: 1.9682 - val_main_output_acc: 0.7880 - val_main_output_f1_micro: 0.5964 - val_aux_output_acc: 0.7514 - val_aux_output_f1_micro: 0.0994\n",
      "\n",
      "Done with epoch: 60\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.8176 - main_output_loss: 1.4568 - aux_output_loss: 1.8041 - main_output_acc: 0.7609 - main_output_f1_micro: 0.5979 - aux_output_acc: 0.7560 - aux_output_f1_micro: 0.0995 - val_loss: 1.6349 - val_main_output_loss: 1.2434 - val_aux_output_loss: 1.9578 - val_main_output_acc: 0.7868 - val_main_output_f1_micro: 0.5994 - val_aux_output_acc: 0.7515 - val_aux_output_f1_micro: 0.0995\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.8042 - main_output_loss: 1.4465 - aux_output_loss: 1.7885 - main_output_acc: 0.7612 - main_output_f1_micro: 0.6009 - aux_output_acc: 0.7559 - aux_output_f1_micro: 0.0996 - val_loss: 1.6349 - val_main_output_loss: 1.2477 - val_aux_output_loss: 1.9359 - val_main_output_acc: 0.7899 - val_main_output_f1_micro: 0.6023 - val_aux_output_acc: 0.7591 - val_aux_output_f1_micro: 0.0997\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.8003 - main_output_loss: 1.4454 - aux_output_loss: 1.7743 - main_output_acc: 0.7609 - main_output_f1_micro: 0.6038 - aux_output_acc: 0.7588 - aux_output_f1_micro: 0.0998 - val_loss: 1.6183 - val_main_output_loss: 1.2343 - val_aux_output_loss: 1.9196 - val_main_output_acc: 0.7927 - val_main_output_f1_micro: 0.6053 - val_aux_output_acc: 0.7589 - val_aux_output_f1_micro: 0.0999\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.7883 - main_output_loss: 1.4369 - aux_output_loss: 1.7570 - main_output_acc: 0.7637 - main_output_f1_micro: 0.6067 - aux_output_acc: 0.7585 - aux_output_f1_micro: 0.1000 - val_loss: 1.6107 - val_main_output_loss: 1.2317 - val_aux_output_loss: 1.8950 - val_main_output_acc: 0.7973 - val_main_output_f1_micro: 0.6081 - val_aux_output_acc: 0.7625 - val_aux_output_f1_micro: 0.1000\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.7794 - main_output_loss: 1.4307 - aux_output_loss: 1.7434 - main_output_acc: 0.7635 - main_output_f1_micro: 0.6095 - aux_output_acc: 0.7609 - aux_output_f1_micro: 0.1001 - val_loss: 1.6026 - val_main_output_loss: 1.2268 - val_aux_output_loss: 1.8789 - val_main_output_acc: 0.7937 - val_main_output_f1_micro: 0.6108 - val_aux_output_acc: 0.7636 - val_aux_output_f1_micro: 0.1002\n",
      "\n",
      "Done with epoch: 65\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.7702 - main_output_loss: 1.4245 - aux_output_loss: 1.7283 - main_output_acc: 0.7635 - main_output_f1_micro: 0.6122 - aux_output_acc: 0.7615 - aux_output_f1_micro: 0.1003 - val_loss: 1.5956 - val_main_output_loss: 1.2223 - val_aux_output_loss: 1.8666 - val_main_output_acc: 0.7956 - val_main_output_f1_micro: 0.6136 - val_aux_output_acc: 0.7611 - val_aux_output_f1_micro: 0.1004\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.7587 - main_output_loss: 1.4158 - aux_output_loss: 1.7140 - main_output_acc: 0.7640 - main_output_f1_micro: 0.6150 - aux_output_acc: 0.7620 - aux_output_f1_micro: 0.1004 - val_loss: 1.5741 - val_main_output_loss: 1.2050 - val_aux_output_loss: 1.8457 - val_main_output_acc: 0.7915 - val_main_output_f1_micro: 0.6164 - val_aux_output_acc: 0.7647 - val_aux_output_f1_micro: 0.1005\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.7511 - main_output_loss: 1.4111 - aux_output_loss: 1.6997 - main_output_acc: 0.7648 - main_output_f1_micro: 0.6177 - aux_output_acc: 0.7662 - aux_output_f1_micro: 0.1006 - val_loss: 1.5765 - val_main_output_loss: 1.2098 - val_aux_output_loss: 1.8336 - val_main_output_acc: 0.7916 - val_main_output_f1_micro: 0.6191 - val_aux_output_acc: 0.7683 - val_aux_output_f1_micro: 0.1007\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94731/94731 [==============================] - 52s - loss: 1.7431 - main_output_loss: 1.4059 - aux_output_loss: 1.6863 - main_output_acc: 0.7658 - main_output_f1_micro: 0.6204 - aux_output_acc: 0.7666 - aux_output_f1_micro: 0.1008 - val_loss: 1.5676 - val_main_output_loss: 1.2041 - val_aux_output_loss: 1.8177 - val_main_output_acc: 0.7945 - val_main_output_f1_micro: 0.6217 - val_aux_output_acc: 0.7685 - val_aux_output_f1_micro: 0.1009\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.7366 - main_output_loss: 1.4013 - aux_output_loss: 1.6766 - main_output_acc: 0.7668 - main_output_f1_micro: 0.6231 - aux_output_acc: 0.7667 - aux_output_f1_micro: 0.1010 - val_loss: 1.5580 - val_main_output_loss: 1.1965 - val_aux_output_loss: 1.8072 - val_main_output_acc: 0.7924 - val_main_output_f1_micro: 0.6244 - val_aux_output_acc: 0.7707 - val_aux_output_f1_micro: 0.1011\n",
      "\n",
      "Done with epoch: 70\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.7275 - main_output_loss: 1.3951 - aux_output_loss: 1.6619 - main_output_acc: 0.7670 - main_output_f1_micro: 0.6257 - aux_output_acc: 0.7688 - aux_output_f1_micro: 0.1012 - val_loss: 1.5606 - val_main_output_loss: 1.2025 - val_aux_output_loss: 1.7904 - val_main_output_acc: 0.7938 - val_main_output_f1_micro: 0.6269 - val_aux_output_acc: 0.7703 - val_aux_output_f1_micro: 0.1013\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.7247 - main_output_loss: 1.3948 - aux_output_loss: 1.6495 - main_output_acc: 0.7662 - main_output_f1_micro: 0.6282 - aux_output_acc: 0.7708 - aux_output_f1_micro: 0.1014 - val_loss: 1.5461 - val_main_output_loss: 1.1901 - val_aux_output_loss: 1.7798 - val_main_output_acc: 0.7942 - val_main_output_f1_micro: 0.6295 - val_aux_output_acc: 0.7735 - val_aux_output_f1_micro: 0.1015\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.7114 - main_output_loss: 1.3832 - aux_output_loss: 1.6407 - main_output_acc: 0.7684 - main_output_f1_micro: 0.6307 - aux_output_acc: 0.7722 - aux_output_f1_micro: 0.1016 - val_loss: 1.5344 - val_main_output_loss: 1.1826 - val_aux_output_loss: 1.7593 - val_main_output_acc: 0.7920 - val_main_output_f1_micro: 0.6320 - val_aux_output_acc: 0.7726 - val_aux_output_f1_micro: 0.1016\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.7095 - main_output_loss: 1.3837 - aux_output_loss: 1.6288 - main_output_acc: 0.7688 - main_output_f1_micro: 0.6333 - aux_output_acc: 0.7720 - aux_output_f1_micro: 0.1018 - val_loss: 1.5307 - val_main_output_loss: 1.1813 - val_aux_output_loss: 1.7470 - val_main_output_acc: 0.7971 - val_main_output_f1_micro: 0.6345 - val_aux_output_acc: 0.7696 - val_aux_output_f1_micro: 0.1019\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.7016 - main_output_loss: 1.3783 - aux_output_loss: 1.6163 - main_output_acc: 0.7695 - main_output_f1_micro: 0.6357 - aux_output_acc: 0.7733 - aux_output_f1_micro: 0.1020 - val_loss: 1.5274 - val_main_output_loss: 1.1802 - val_aux_output_loss: 1.7362 - val_main_output_acc: 0.7972 - val_main_output_f1_micro: 0.6370 - val_aux_output_acc: 0.7731 - val_aux_output_f1_micro: 0.1020\n",
      "\n",
      "Done with epoch: 75\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6946 - main_output_loss: 1.3733 - aux_output_loss: 1.6067 - main_output_acc: 0.7685 - main_output_f1_micro: 0.6382 - aux_output_acc: 0.7746 - aux_output_f1_micro: 0.1022 - val_loss: 1.5216 - val_main_output_loss: 1.1757 - val_aux_output_loss: 1.7299 - val_main_output_acc: 0.7956 - val_main_output_f1_micro: 0.6394 - val_aux_output_acc: 0.7754 - val_aux_output_f1_micro: 0.1023\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6825 - main_output_loss: 1.3629 - aux_output_loss: 1.5980 - main_output_acc: 0.7685 - main_output_f1_micro: 0.6406 - aux_output_acc: 0.7753 - aux_output_f1_micro: 0.1024 - val_loss: 1.5173 - val_main_output_loss: 1.1745 - val_aux_output_loss: 1.7143 - val_main_output_acc: 0.8015 - val_main_output_f1_micro: 0.6417 - val_aux_output_acc: 0.7762 - val_aux_output_f1_micro: 0.1025\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6782 - main_output_loss: 1.3613 - aux_output_loss: 1.5845 - main_output_acc: 0.7705 - main_output_f1_micro: 0.6429 - aux_output_acc: 0.7754 - aux_output_f1_micro: 0.1026 - val_loss: 1.5063 - val_main_output_loss: 1.1655 - val_aux_output_loss: 1.7039 - val_main_output_acc: 0.8013 - val_main_output_f1_micro: 0.6441 - val_aux_output_acc: 0.7823 - val_aux_output_f1_micro: 0.1027\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6763 - main_output_loss: 1.3610 - aux_output_loss: 1.5764 - main_output_acc: 0.7699 - main_output_f1_micro: 0.6453 - aux_output_acc: 0.7762 - aux_output_f1_micro: 0.1028 - val_loss: 1.5047 - val_main_output_loss: 1.1661 - val_aux_output_loss: 1.6931 - val_main_output_acc: 0.7964 - val_main_output_f1_micro: 0.6464 - val_aux_output_acc: 0.7773 - val_aux_output_f1_micro: 0.1030\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6666 - main_output_loss: 1.3535 - aux_output_loss: 1.5657 - main_output_acc: 0.7701 - main_output_f1_micro: 0.6476 - aux_output_acc: 0.7776 - aux_output_f1_micro: 0.1031 - val_loss: 1.4976 - val_main_output_loss: 1.1610 - val_aux_output_loss: 1.6828 - val_main_output_acc: 0.7918 - val_main_output_f1_micro: 0.6488 - val_aux_output_acc: 0.7843 - val_aux_output_f1_micro: 0.1032\n",
      "\n",
      "Done with epoch: 80\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6643 - main_output_loss: 1.3525 - aux_output_loss: 1.5590 - main_output_acc: 0.7706 - main_output_f1_micro: 0.6499 - aux_output_acc: 0.7775 - aux_output_f1_micro: 0.1033 - val_loss: 1.4979 - val_main_output_loss: 1.1626 - val_aux_output_loss: 1.6763 - val_main_output_acc: 0.7989 - val_main_output_f1_micro: 0.6510 - val_aux_output_acc: 0.7825 - val_aux_output_f1_micro: 0.1034\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6546 - main_output_loss: 1.3453 - aux_output_loss: 1.5466 - main_output_acc: 0.7713 - main_output_f1_micro: 0.6522 - aux_output_acc: 0.7806 - aux_output_f1_micro: 0.1035 - val_loss: 1.4865 - val_main_output_loss: 1.1547 - val_aux_output_loss: 1.6587 - val_main_output_acc: 0.8044 - val_main_output_f1_micro: 0.6533 - val_aux_output_acc: 0.7847 - val_aux_output_f1_micro: 0.1036\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6478 - main_output_loss: 1.3402 - aux_output_loss: 1.5378 - main_output_acc: 0.7732 - main_output_f1_micro: 0.6544 - aux_output_acc: 0.7814 - aux_output_f1_micro: 0.1037 - val_loss: 1.4808 - val_main_output_loss: 1.1519 - val_aux_output_loss: 1.6447 - val_main_output_acc: 0.7962 - val_main_output_f1_micro: 0.6555 - val_aux_output_acc: 0.7843 - val_aux_output_f1_micro: 0.1039\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6429 - main_output_loss: 1.3371 - aux_output_loss: 1.5291 - main_output_acc: 0.7714 - main_output_f1_micro: 0.6566 - aux_output_acc: 0.7807 - aux_output_f1_micro: 0.1040 - val_loss: 1.4782 - val_main_output_loss: 1.1504 - val_aux_output_loss: 1.6392 - val_main_output_acc: 0.8039 - val_main_output_f1_micro: 0.6577 - val_aux_output_acc: 0.7822 - val_aux_output_f1_micro: 0.1041\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6415 - main_output_loss: 1.3366 - aux_output_loss: 1.5246 - main_output_acc: 0.7727 - main_output_f1_micro: 0.6588 - aux_output_acc: 0.7801 - aux_output_f1_micro: 0.1042 - val_loss: 1.4781 - val_main_output_loss: 1.1522 - val_aux_output_loss: 1.6293 - val_main_output_acc: 0.8000 - val_main_output_f1_micro: 0.6598 - val_aux_output_acc: 0.7847 - val_aux_output_f1_micro: 0.1043\n",
      "\n",
      "Done with epoch: 85\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6361 - main_output_loss: 1.3329 - aux_output_loss: 1.5162 - main_output_acc: 0.7732 - main_output_f1_micro: 0.6609 - aux_output_acc: 0.7815 - aux_output_f1_micro: 0.1045 - val_loss: 1.4749 - val_main_output_loss: 1.1498 - val_aux_output_loss: 1.6253 - val_main_output_acc: 0.7951 - val_main_output_f1_micro: 0.6620 - val_aux_output_acc: 0.7901 - val_aux_output_f1_micro: 0.1046\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6273 - main_output_loss: 1.3262 - aux_output_loss: 1.5059 - main_output_acc: 0.7701 - main_output_f1_micro: 0.6630 - aux_output_acc: 0.7810 - aux_output_f1_micro: 0.1047 - val_loss: 1.4623 - val_main_output_loss: 1.1396 - val_aux_output_loss: 1.6133 - val_main_output_acc: 0.7911 - val_main_output_f1_micro: 0.6641 - val_aux_output_acc: 0.7872 - val_aux_output_f1_micro: 0.1048\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6260 - main_output_loss: 1.3265 - aux_output_loss: 1.4972 - main_output_acc: 0.7734 - main_output_f1_micro: 0.6651 - aux_output_acc: 0.7825 - aux_output_f1_micro: 0.1049 - val_loss: 1.4612 - val_main_output_loss: 1.1416 - val_aux_output_loss: 1.5981 - val_main_output_acc: 0.7945 - val_main_output_f1_micro: 0.6661 - val_aux_output_acc: 0.7893 - val_aux_output_f1_micro: 0.1051\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6175 - main_output_loss: 1.3191 - aux_output_loss: 1.4923 - main_output_acc: 0.7735 - main_output_f1_micro: 0.6671 - aux_output_acc: 0.7836 - aux_output_f1_micro: 0.1052 - val_loss: 1.4602 - val_main_output_loss: 1.1405 - val_aux_output_loss: 1.5984 - val_main_output_acc: 0.7956 - val_main_output_f1_micro: 0.6682 - val_aux_output_acc: 0.7888 - val_aux_output_f1_micro: 0.1053\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6122 - main_output_loss: 1.3158 - aux_output_loss: 1.4818 - main_output_acc: 0.7729 - main_output_f1_micro: 0.6692 - aux_output_acc: 0.7834 - aux_output_f1_micro: 0.1054 - val_loss: 1.4512 - val_main_output_loss: 1.1332 - val_aux_output_loss: 1.5899 - val_main_output_acc: 0.8077 - val_main_output_f1_micro: 0.6702 - val_aux_output_acc: 0.7863 - val_aux_output_f1_micro: 0.1055\n",
      "\n",
      "Done with epoch: 90\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6090 - main_output_loss: 1.3138 - aux_output_loss: 1.4763 - main_output_acc: 0.7736 - main_output_f1_micro: 0.6712 - aux_output_acc: 0.7841 - aux_output_f1_micro: 0.1056 - val_loss: 1.4482 - val_main_output_loss: 1.1317 - val_aux_output_loss: 1.5827 - val_main_output_acc: 0.7983 - val_main_output_f1_micro: 0.6721 - val_aux_output_acc: 0.7894 - val_aux_output_f1_micro: 0.1058\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6044 - main_output_loss: 1.3104 - aux_output_loss: 1.4704 - main_output_acc: 0.7764 - main_output_f1_micro: 0.6731 - aux_output_acc: 0.7841 - aux_output_f1_micro: 0.1059 - val_loss: 1.4464 - val_main_output_loss: 1.1324 - val_aux_output_loss: 1.5700 - val_main_output_acc: 0.7972 - val_main_output_f1_micro: 0.6741 - val_aux_output_acc: 0.7968 - val_aux_output_f1_micro: 0.1060\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6013 - main_output_loss: 1.3087 - aux_output_loss: 1.4631 - main_output_acc: 0.7747 - main_output_f1_micro: 0.6751 - aux_output_acc: 0.7849 - aux_output_f1_micro: 0.1062 - val_loss: 1.4389 - val_main_output_loss: 1.1256 - val_aux_output_loss: 1.5667 - val_main_output_acc: 0.7906 - val_main_output_f1_micro: 0.6760 - val_aux_output_acc: 0.7875 - val_aux_output_f1_micro: 0.1063\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.5976 - main_output_loss: 1.3064 - aux_output_loss: 1.4560 - main_output_acc: 0.7735 - main_output_f1_micro: 0.6770 - aux_output_acc: 0.7836 - aux_output_f1_micro: 0.1064 - val_loss: 1.4425 - val_main_output_loss: 1.1318 - val_aux_output_loss: 1.5533 - val_main_output_acc: 0.7932 - val_main_output_f1_micro: 0.6780 - val_aux_output_acc: 0.7900 - val_aux_output_f1_micro: 0.1065\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.5887 - main_output_loss: 1.2989 - aux_output_loss: 1.4490 - main_output_acc: 0.7739 - main_output_f1_micro: 0.6789 - aux_output_acc: 0.7864 - aux_output_f1_micro: 0.1067 - val_loss: 1.4344 - val_main_output_loss: 1.1241 - val_aux_output_loss: 1.5513 - val_main_output_acc: 0.8054 - val_main_output_f1_micro: 0.6798 - val_aux_output_acc: 0.7923 - val_aux_output_f1_micro: 0.1068\n",
      "\n",
      "Done with epoch: 95\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.5893 - main_output_loss: 1.3008 - aux_output_loss: 1.4425 - main_output_acc: 0.7756 - main_output_f1_micro: 0.6808 - aux_output_acc: 0.7853 - aux_output_f1_micro: 0.1069 - val_loss: 1.4272 - val_main_output_loss: 1.1199 - val_aux_output_loss: 1.5369 - val_main_output_acc: 0.7994 - val_main_output_f1_micro: 0.6817 - val_aux_output_acc: 0.7894 - val_aux_output_f1_micro: 0.1071\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.5866 - main_output_loss: 1.2991 - aux_output_loss: 1.4378 - main_output_acc: 0.7761 - main_output_f1_micro: 0.6826 - aux_output_acc: 0.7862 - aux_output_f1_micro: 0.1072 - val_loss: 1.4255 - val_main_output_loss: 1.1193 - val_aux_output_loss: 1.5309 - val_main_output_acc: 0.7999 - val_main_output_f1_micro: 0.6835 - val_aux_output_acc: 0.7935 - val_aux_output_f1_micro: 0.1073\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.5792 - main_output_loss: 1.2932 - aux_output_loss: 1.4304 - main_output_acc: 0.7761 - main_output_f1_micro: 0.6845 - aux_output_acc: 0.7870 - aux_output_f1_micro: 0.1075 - val_loss: 1.4155 - val_main_output_loss: 1.1104 - val_aux_output_loss: 1.5255 - val_main_output_acc: 0.7958 - val_main_output_f1_micro: 0.6854 - val_aux_output_acc: 0.7893 - val_aux_output_f1_micro: 0.1076\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.5741 - main_output_loss: 1.2892 - aux_output_loss: 1.4245 - main_output_acc: 0.7752 - main_output_f1_micro: 0.6863 - aux_output_acc: 0.7871 - aux_output_f1_micro: 0.1077 - val_loss: 1.4189 - val_main_output_loss: 1.1143 - val_aux_output_loss: 1.5229 - val_main_output_acc: 0.8024 - val_main_output_f1_micro: 0.6871 - val_aux_output_acc: 0.7928 - val_aux_output_f1_micro: 0.1079\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.5703 - main_output_loss: 1.2866 - aux_output_loss: 1.4184 - main_output_acc: 0.7738 - main_output_f1_micro: 0.6880 - aux_output_acc: 0.7856 - aux_output_f1_micro: 0.1080 - val_loss: 1.4146 - val_main_output_loss: 1.1102 - val_aux_output_loss: 1.5218 - val_main_output_acc: 0.8017 - val_main_output_f1_micro: 0.6889 - val_aux_output_acc: 0.7924 - val_aux_output_f1_micro: 0.1082\n",
      "\n",
      "Done with epoch: 100\n",
      "\n",
      "CPU times: user 1h 43min 17s, sys: 9min 19s, total: 1h 52min 37s\n",
      "Wall time: 1h 27min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_name = 'models/lstm-word2vec-fasttext_2012-2014-data_cat-crossentropy-2014-b-val-sc_wv_fs-trimmed_tokens.model'\n",
    "epochs = 5\n",
    "for i in xrange(0, 100 // epochs):\n",
    "    hist = model.fit(\n",
    "        {'main_input': x_train, 'wv_input': wv_train, 'fs_input': fs_train},\n",
    "        {'main_output': y_train, 'aux_output': y_train},\n",
    "        epochs=epochs, batch_size=batch_size,   # 500\n",
    "        validation_split=0.2,\n",
    "        validation_data=(\n",
    "            {'main_input': x_val, 'wv_input': wv_val, 'fs_input': fs_val},\n",
    "            {'main_output': y_val, 'aux_output': y_val}\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.save(model_name.format(i))\n",
    "    print\n",
    "    print('Done with epoch: {}'.format((i + 1) * epochs))\n",
    "    with open('lstm-word2vec-fasttext.epoch.csv', 'a') as fl:\n",
    "        fl.write(model_name + '\\n')\n",
    "        fl.write('Epoch {}\\n'.format((i + 1) * epochs))\n",
    "        fl.write('{}\\n'.format(datetime.now()))\n",
    "        fl.write('\\n'.join(['{}: {}'.format(k, v[0]) for k, v in hist.history.items()]))\n",
    "        fl.write('\\n\\n')\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.6427 - main_output_loss: 1.3490 - aux_output_loss: 1.4686 - main_output_acc: 0.7712 - main_output_f1_micro: 0.6905 - aux_output_acc: 0.7839 - aux_output_f1_micro: 0.1085 - val_loss: 1.4372 - val_main_output_loss: 1.1302 - val_aux_output_loss: 1.5348 - val_main_output_acc: 0.7941 - val_main_output_f1_micro: 0.6913 - val_aux_output_acc: 0.7884 - val_aux_output_f1_micro: 0.1086\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5833 - main_output_loss: 1.2980 - aux_output_loss: 1.4265 - main_output_acc: 0.7738 - main_output_f1_micro: 0.6921 - aux_output_acc: 0.7855 - aux_output_f1_micro: 0.1088 - val_loss: 1.4210 - val_main_output_loss: 1.1179 - val_aux_output_loss: 1.5153 - val_main_output_acc: 0.7967 - val_main_output_f1_micro: 0.6930 - val_aux_output_acc: 0.7949 - val_aux_output_f1_micro: 0.1090\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5656 - main_output_loss: 1.2841 - aux_output_loss: 1.4076 - main_output_acc: 0.7752 - main_output_f1_micro: 0.6938 - aux_output_acc: 0.7870 - aux_output_f1_micro: 0.1091 - val_loss: 1.4123 - val_main_output_loss: 1.1124 - val_aux_output_loss: 1.4995 - val_main_output_acc: 0.7930 - val_main_output_f1_micro: 0.6946 - val_aux_output_acc: 0.7916 - val_aux_output_f1_micro: 0.1093\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5551 - main_output_loss: 1.2755 - aux_output_loss: 1.3983 - main_output_acc: 0.7779 - main_output_f1_micro: 0.6955 - aux_output_acc: 0.7867 - aux_output_f1_micro: 0.1094 - val_loss: 1.4043 - val_main_output_loss: 1.1070 - val_aux_output_loss: 1.4866 - val_main_output_acc: 0.7988 - val_main_output_f1_micro: 0.6963 - val_aux_output_acc: 0.7918 - val_aux_output_f1_micro: 0.1096\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5504 - main_output_loss: 1.2725 - aux_output_loss: 1.3899 - main_output_acc: 0.7771 - main_output_f1_micro: 0.6971 - aux_output_acc: 0.7872 - aux_output_f1_micro: 0.1097 - val_loss: 1.4002 - val_main_output_loss: 1.1043 - val_aux_output_loss: 1.4796 - val_main_output_acc: 0.8088 - val_main_output_f1_micro: 0.6980 - val_aux_output_acc: 0.7916 - val_aux_output_f1_micro: 0.1099\n",
      "\n",
      "Done with epoch: 100\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5459 - main_output_loss: 1.2693 - aux_output_loss: 1.3833 - main_output_acc: 0.7773 - main_output_f1_micro: 0.6988 - aux_output_acc: 0.7896 - aux_output_f1_micro: 0.1100 - val_loss: 1.3938 - val_main_output_loss: 1.0999 - val_aux_output_loss: 1.4694 - val_main_output_acc: 0.8001 - val_main_output_f1_micro: 0.6996 - val_aux_output_acc: 0.7926 - val_aux_output_f1_micro: 0.1102\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5393 - main_output_loss: 1.2640 - aux_output_loss: 1.3764 - main_output_acc: 0.7776 - main_output_f1_micro: 0.7004 - aux_output_acc: 0.7896 - aux_output_f1_micro: 0.1103 - val_loss: 1.3912 - val_main_output_loss: 1.0979 - val_aux_output_loss: 1.4664 - val_main_output_acc: 0.7940 - val_main_output_f1_micro: 0.7012 - val_aux_output_acc: 0.7917 - val_aux_output_f1_micro: 0.1105\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5369 - main_output_loss: 1.2627 - aux_output_loss: 1.3708 - main_output_acc: 0.7815 - main_output_f1_micro: 0.7020 - aux_output_acc: 0.7890 - aux_output_f1_micro: 0.1106 - val_loss: 1.3821 - val_main_output_loss: 1.0902 - val_aux_output_loss: 1.4594 - val_main_output_acc: 0.8066 - val_main_output_f1_micro: 0.7028 - val_aux_output_acc: 0.7940 - val_aux_output_f1_micro: 0.1108\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5302 - main_output_loss: 1.2571 - aux_output_loss: 1.3656 - main_output_acc: 0.7796 - main_output_f1_micro: 0.7036 - aux_output_acc: 0.7897 - aux_output_f1_micro: 0.1109 - val_loss: 1.3878 - val_main_output_loss: 1.0954 - val_aux_output_loss: 1.4620 - val_main_output_acc: 0.7964 - val_main_output_f1_micro: 0.7044 - val_aux_output_acc: 0.7954 - val_aux_output_f1_micro: 0.1111\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5282 - main_output_loss: 1.2561 - aux_output_loss: 1.3605 - main_output_acc: 0.7775 - main_output_f1_micro: 0.7052 - aux_output_acc: 0.7913 - aux_output_f1_micro: 0.1112 - val_loss: 1.3855 - val_main_output_loss: 1.0954 - val_aux_output_loss: 1.4505 - val_main_output_acc: 0.7928 - val_main_output_f1_micro: 0.7059 - val_aux_output_acc: 0.7964 - val_aux_output_f1_micro: 0.1114\n",
      "\n",
      "Done with epoch: 105\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5262 - main_output_loss: 1.2551 - aux_output_loss: 1.3553 - main_output_acc: 0.7791 - main_output_f1_micro: 0.7067 - aux_output_acc: 0.7902 - aux_output_f1_micro: 0.1115 - val_loss: 1.3707 - val_main_output_loss: 1.0832 - val_aux_output_loss: 1.4377 - val_main_output_acc: 0.8034 - val_main_output_f1_micro: 0.7075 - val_aux_output_acc: 0.7948 - val_aux_output_f1_micro: 0.1117\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5205 - main_output_loss: 1.2508 - aux_output_loss: 1.3484 - main_output_acc: 0.7803 - main_output_f1_micro: 0.7083 - aux_output_acc: 0.7910 - aux_output_f1_micro: 0.1118 - val_loss: 1.3696 - val_main_output_loss: 1.0827 - val_aux_output_loss: 1.4348 - val_main_output_acc: 0.8018 - val_main_output_f1_micro: 0.7090 - val_aux_output_acc: 0.7929 - val_aux_output_f1_micro: 0.1120\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5220 - main_output_loss: 1.2527 - aux_output_loss: 1.3466 - main_output_acc: 0.7793 - main_output_f1_micro: 0.7098 - aux_output_acc: 0.7904 - aux_output_f1_micro: 0.1122 - val_loss: 1.3695 - val_main_output_loss: 1.0827 - val_aux_output_loss: 1.4341 - val_main_output_acc: 0.7963 - val_main_output_f1_micro: 0.7105 - val_aux_output_acc: 0.7926 - val_aux_output_f1_micro: 0.1123\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5216 - main_output_loss: 1.2530 - aux_output_loss: 1.3431 - main_output_acc: 0.7800 - main_output_f1_micro: 0.7113 - aux_output_acc: 0.7914 - aux_output_f1_micro: 0.1125 - val_loss: 1.3708 - val_main_output_loss: 1.0860 - val_aux_output_loss: 1.4240 - val_main_output_acc: 0.8011 - val_main_output_f1_micro: 0.7120 - val_aux_output_acc: 0.7966 - val_aux_output_f1_micro: 0.1126\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5163 - main_output_loss: 1.2486 - aux_output_loss: 1.3386 - main_output_acc: 0.7807 - main_output_f1_micro: 0.7128 - aux_output_acc: 0.7916 - aux_output_f1_micro: 0.1128 - val_loss: 1.3660 - val_main_output_loss: 1.0814 - val_aux_output_loss: 1.4232 - val_main_output_acc: 0.7929 - val_main_output_f1_micro: 0.7135 - val_aux_output_acc: 0.7930 - val_aux_output_f1_micro: 0.1130\n",
      "\n",
      "Done with epoch: 110\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5152 - main_output_loss: 1.2484 - aux_output_loss: 1.3341 - main_output_acc: 0.7792 - main_output_f1_micro: 0.7142 - aux_output_acc: 0.7911 - aux_output_f1_micro: 0.1131 - val_loss: 1.3651 - val_main_output_loss: 1.0816 - val_aux_output_loss: 1.4173 - val_main_output_acc: 0.7956 - val_main_output_f1_micro: 0.7149 - val_aux_output_acc: 0.7927 - val_aux_output_f1_micro: 0.1133\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5089 - main_output_loss: 1.2427 - aux_output_loss: 1.3309 - main_output_acc: 0.7803 - main_output_f1_micro: 0.7156 - aux_output_acc: 0.7912 - aux_output_f1_micro: 0.1135 - val_loss: 1.3627 - val_main_output_loss: 1.0794 - val_aux_output_loss: 1.4167 - val_main_output_acc: 0.7989 - val_main_output_f1_micro: 0.7164 - val_aux_output_acc: 0.7968 - val_aux_output_f1_micro: 0.1136\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5082 - main_output_loss: 1.2431 - aux_output_loss: 1.3254 - main_output_acc: 0.7813 - main_output_f1_micro: 0.7171 - aux_output_acc: 0.7917 - aux_output_f1_micro: 0.1138 - val_loss: 1.3610 - val_main_output_loss: 1.0787 - val_aux_output_loss: 1.4114 - val_main_output_acc: 0.8054 - val_main_output_f1_micro: 0.7178 - val_aux_output_acc: 0.7916 - val_aux_output_f1_micro: 0.1139\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5043 - main_output_loss: 1.2400 - aux_output_loss: 1.3214 - main_output_acc: 0.7788 - main_output_f1_micro: 0.7185 - aux_output_acc: 0.7905 - aux_output_f1_micro: 0.1141 - val_loss: 1.3573 - val_main_output_loss: 1.0764 - val_aux_output_loss: 1.4045 - val_main_output_acc: 0.8025 - val_main_output_f1_micro: 0.7192 - val_aux_output_acc: 0.7962 - val_aux_output_f1_micro: 0.1143\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5045 - main_output_loss: 1.2409 - aux_output_loss: 1.3181 - main_output_acc: 0.7785 - main_output_f1_micro: 0.7199 - aux_output_acc: 0.7919 - aux_output_f1_micro: 0.1145 - val_loss: 1.3638 - val_main_output_loss: 1.0828 - val_aux_output_loss: 1.4050 - val_main_output_acc: 0.7982 - val_main_output_f1_micro: 0.7205 - val_aux_output_acc: 0.7963 - val_aux_output_f1_micro: 0.1146\n",
      "\n",
      "Done with epoch: 115\n",
      "\n",
      "CPU times: user 20min 20s, sys: 1min 53s, total: 22min 14s\n",
      "Wall time: 17min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# i = 100\n",
    "# batch_size = 600\n",
    "batch_size = 1200\n",
    "for j in xrange(i, i + (20 // epochs)):\n",
    "    hist = model.fit(\n",
    "        {'main_input': x_train, 'wv_input': wv_train, 'fs_input': fs_train},\n",
    "        {'main_output': y_train, 'aux_output': y_train},\n",
    "        epochs=epochs, batch_size=batch_size,   # 500\n",
    "        validation_split=0.2,\n",
    "        validation_data=(\n",
    "            {'main_input': x_val, 'wv_input': wv_val, 'fs_input': fs_val},\n",
    "            {'main_output': y_val, 'aux_output': y_val}\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.save(model_name.format(i))\n",
    "    print\n",
    "    print('Done with epoch: {}'.format((j + 1) * epochs))\n",
    "    with open('lstm-word2vec-fasttext.epoch.csv', 'a') as fl:\n",
    "        fl.write(model_name + '\\n')\n",
    "        fl.write('Epoch {}\\n'.format((j + 1) * epochs))\n",
    "        fl.write('{}\\n'.format(datetime.now()))\n",
    "        fl.write('\\n'.join(['{}: {}'.format(k, v[0]) for k, v in hist.history.items()]))\n",
    "        fl.write('\\n\\n')\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = keras.models.load_model(\n",
    "#     'models/lstm-word2vec-fasttext_2010-2014-data_categorical-crossentropy-2014-b-val-standard_scaled_wv_fs.model',\n",
    "#     custom_objects={'f1_micro': f1_micro}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = model.predict({'wv_input': wv_train[:100], 'fs_input': fs_train[:100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd3fcc49610>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd35e915e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "ix = 29\n",
    "pd.Series(g[ix]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([ 1, 98]),), (array([ 1, 98]),))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh = 0.5\n",
    "np.where(y_train[ix] == 1), np.where(g[ix] > thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wvmodel = Word2Vec.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fsmodel = fasttext.load_model('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.fasttext.model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_fasttext(tokens, stopwords=[]):\n",
    "    global fsmodel\n",
    "    # This requires fsmodel to be present in the namespace.\n",
    "    fs_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    ).map(lambda x: np.array([fsmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return fs_feature_vec\n",
    "\n",
    "\n",
    "def transform_unsupervised_sentiment_neuron(tokens, stopwords=[]):\n",
    "    # This requires fsmodel to be present in the namespace.\n",
    "    \n",
    "    usn_feature_vec = usnmodel.transform(tokens)\n",
    "\n",
    "    # usn_feature_vec = tokens.map(\n",
    "    #     lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    # ).map(lambda x: np.array([usnmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return usn_feature_vec\n",
    "\n",
    "\n",
    "def transform_word2vec(tokens, stopwords=[]):\n",
    "    global wvmodel\n",
    "    # This requires wvmodel to be present in the namespace.\n",
    "    wv_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords and w in wvmodel.wv.vocab)]\n",
    "    ).map(lambda x: np.array([wvmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return wv_feature_vec\n",
    "\n",
    "\n",
    "def parallel_generate_word_vectors(samp, transformer, stopwords, batch, num_proc):\n",
    "    with Parallel(n_jobs=num_proc) as parallel:\n",
    "        dataset = []\n",
    "        is_break = False\n",
    "        i = 0\n",
    "\n",
    "        while not is_break:\n",
    "            payload = []\n",
    "\n",
    "            for j in xrange(num_proc):\n",
    "                t_df = samp[(i + j) * batch: (i + 1 + j) * batch]\n",
    "\n",
    "                if t_df.empty:\n",
    "                    is_break = True\n",
    "                    continue\n",
    "\n",
    "                payload.append(\n",
    "                    delayed(transformer)(\n",
    "                        t_df, stopwords\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            print('Current batch in main thread: {}'.format((i + j) * batch))\n",
    "\n",
    "            if payload:\n",
    "                results = parallel(payload)\n",
    "                dataset.extend(results)\n",
    "                i += num_proc\n",
    "\n",
    "    return pd.concat(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_classes(pred, scale_param=0.75, min_thresh=0.05, thresh = 0.5):\n",
    "#     mx = pred.mean() + 3 * pred.std()\n",
    "    return np.where(pred > thresh)[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2idx_transform(word, _word2idx):\n",
    "    return _word2idx.get(word, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features_for(df, min_batch=2000, stopwords=[], num_proc=7):\n",
    "    df_tokens = transform_text(df)\n",
    "    \n",
    "    batch = min(df_tokens.shape[0] / num_proc, min_batch)\n",
    "\n",
    "    print('Computing fs features...')\n",
    "    fvec = parallel_generate_word_vectors(df_tokens, transform_fasttext, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Computing wv features...')\n",
    "    wvec = parallel_generate_word_vectors(df_tokens, transform_word2vec, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Mapping word indices...')\n",
    "    word_indices = df_tokens.map(lambda x: [word2idx_transform(i, _word2idx) for i in x.split()])\n",
    "    \n",
    "    return word_indices, wvec, fvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/TestData.json') as fl:\n",
    "    data = json.load(fl)\n",
    "    test_df = pd.DataFrame(data['TestData']).T\n",
    "    del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fs features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Computing wv features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Mapping word indices...\n",
      "CPU times: user 45.4 s, sys: 1.4 s, total: 46.8 s\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_word_indices,test_wvec, test_fvec = extract_features_for(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert(np.all(test_wvec[test_wvec.isnull()].index == test_fvec[test_fvec.isnull()].index))\n",
    "test_null_index = test_wvec[test_wvec.isnull()].index.union(test_fvec[test_fvec.isnull()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'TestData_02543', u'TestData_05012', u'TestData_05830'], dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_null_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.46 s, sys: 344 ms, total: 1.8 s\n",
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "valid_test_index = test_word_indices.index.difference(test_null_index)\n",
    "x_test = test_word_indices.ix[valid_test_index].map(lambda x: [top_token2ind.get(i, 0) for i in x])\n",
    "\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "wv_test = np.vstack(test_wvec.ix[valid_test_index])\n",
    "fs_test = np.vstack(test_fvec.ix[valid_test_index])\n",
    "\n",
    "\n",
    "wv_test = wv_sc.transform(wv_test)\n",
    "fs_test = fs_sc.transform(fs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# batch_size = 500\n",
    "test_probas = model.predict({'wv_input': wv_test, 'fs_input': fs_test}, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_test_probas = test_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.74815157e-29,   2.11267219e-11,   1.34445944e-11, ...,\n",
       "          1.61652150e-10,   1.19902983e-19,   5.00701499e-30],\n",
       "       [  6.51111238e-19,   6.03693752e-06,   9.45944703e-06, ...,\n",
       "          2.79082599e-07,   1.09168514e-08,   4.14589044e-18],\n",
       "       [  2.99217006e-26,   2.92211788e-09,   2.60005173e-09, ...,\n",
       "          1.68579870e-08,   1.02189038e-11,   1.02200788e-25],\n",
       "       ..., \n",
       "       [  2.64666045e-12,   8.47350527e-03,   1.80977553e-01, ...,\n",
       "          2.36585450e-07,   8.62547848e-03,   1.32497637e-12],\n",
       "       [  8.47511775e-15,   1.70108990e-03,   6.92925882e-04, ...,\n",
       "          7.45428849e-07,   7.65395555e-07,   1.52762206e-14],\n",
       "       [  9.11000706e-15,   7.51551241e-04,   2.85331416e-03, ...,\n",
       "          2.08217841e-07,   1.20753214e-07,   1.57505014e-14]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_test_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_df.ix[test_df.index.difference(test_null_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2542, 5011, 5829]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_index = [int(s.split('_')[1]) - 1 for s in test_null_index]  # Subtract 1 since test index starts at 1 while enumerate starts at 0\n",
    "skip_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7578, 160), (7581, 3))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_test_probas.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56 ms, sys: 8 ms, total: 64 ms\n",
      "Wall time: 595 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# valid_test_feature_vec found below!\n",
    "test_values = np.zeros([main_test_probas.shape[0], len(topics)])\n",
    "for ix, pred in enumerate(main_test_probas):\n",
    "    for v in get_classes(pred, thresh=0.3):\n",
    "        test_values[ix][v] = 1\n",
    "\n",
    "test_sub_df = pd.DataFrame(\n",
    "    test_values,\n",
    "    index=test_df.ix[test_df.index.difference(test_null_index)].index,\n",
    "    columns=topics\n",
    ")\n",
    "\n",
    "null_test_df = pd.DataFrame(\n",
    "    np.zeros((len(test_null_index), len(topics))),\n",
    "    index=test_null_index,\n",
    "    columns=topics\n",
    ")\n",
    "\n",
    "test_sub_df = test_sub_df.append(null_test_df)\n",
    "test_sub_df = test_sub_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 9627 (0.5), 14297 (0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11677.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94731/94731 [==============================] - 51s - loss: 1.5045 - main_output_loss: 1.2409 - aux_output_loss: 1.3181 - main_output_acc: 0.7785 - main_output_f1_micro: 0.7199 - aux_output_acc: 0.7919 - aux_output_f1_micro: 0.1145 - val_loss: 1.3638 - val_main_output_loss: 1.0828 - val_aux_output_loss: 1.4050 - val_main_output_acc: 0.7982 - val_main_output_f1_micro: 0.7205 - val_aux_output_acc: 0.7963 - val_aux_output_f1_micro: 0.1146\n"
     ]
    }
   ],
   "source": [
    "print '94731/94731 [==============================] - 51s - loss: 1.5045 - main_output_loss: 1.2409 - aux_output_loss: 1.3181 - main_output_acc: 0.7785 - main_output_f1_micro: 0.7199 - aux_output_acc: 0.7919 - aux_output_f1_micro: 0.1145 - val_loss: 1.3638 - val_main_output_loss: 1.0828 - val_aux_output_loss: 1.4050 - val_main_output_acc: 0.7982 - val_main_output_f1_micro: 0.7205 - val_aux_output_acc: 0.7963 - val_aux_output_f1_micro: 0.1146'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_sub_df.astype(int).reset_index().rename(\n",
    "    columns={'index': 'id'}\n",
    ").sort_values('id').to_csv(\n",
    "    'lstm_300-word2vec_300-fasttext_300-maxlen_500-dense_128_256_128-cat_cross-epoch_115-batch_size_1200-val_main_output_f1_micro_0.7205-main_output_f1_micro_0.7199-main_output_loss_1.2409-data_2012_2014-val_data_2014-thresh_0.3-with_sc_wv_fs.csv', \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7581, 160)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TestData_04490\tThe World Health Organisation has convened an ...\t[]\t28-01-2016\n",
    "TestData_04550\tSpraying pesticides will fail to deal with the...\t[]\t02-02-2016\n",
    "TestData_05683\tViolent protests at Trump rally in California ...\t[]\t03-06-2016\n",
    "TestData_05869\tLast weekend, we saw the darkest side of human...\t[]\t17-06-2016\n",
    "TestData_06148\tAs dusk falls over Copacabana beach, Ubira San...\t[]\t16-07-2016\n",
    "TestData_06291\tIt is 3pm and yet another patient is brought t...\t[]\t27-07-2016\n",
    "TestData_06610\tHuddled around their hives, beekeepers around ...\t[]\t04-09-2016\n",
    "TestData_06708\tA United Nations high-level panel on access to...\t[]\t14-09-2016\n",
    "TestData_07263\tWHO: Zika virus is no longer a world threat Th...\t[]\t19-11-2016\n",
    "TestData_07478\t1 World Health Organisation declares a public ...\t[]\t18-12-2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "guncrime    1.0\n",
       "Name: TestData_05683, dtype: float64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = 5682\n",
    "test_sub_df.iloc[ix][test_sub_df.iloc[ix] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36 ms, sys: 0 ns, total: 36 ms\n",
      "Wall time: 32.6 ms\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# adjust_index = 0\n",
    "# # valid_test_feature_vec found below!\n",
    "# test_values = np.zeros([test_df.shape[0], len(topics)])\n",
    "# for ix, pred in enumerate(main_test_probas):\n",
    "#     if ix in skip_index:\n",
    "#         test_values[ix] = np.nan\n",
    "#         # Increment adjust index so that we have the correct index for other samples\n",
    "#         adjust_index += 1\n",
    "#         continue\n",
    "\n",
    "#     for v in get_classes(pred, thresh=0.05):\n",
    "#         test_values[ix + adjust_index][v] = 1\n",
    "\n",
    "# test_sub_df = pd.DataFrame(test_values, columns=sorted(topics), index=test_df.index)\n",
    "\n",
    "# q = test_sub_df.sum(axis=1)\n",
    "# assert(len(q[q.isnull()].index.difference(test_null_index)) == 0)\n",
    "\n",
    "# test_sub_df = test_sub_df.fillna(0)\n",
    "\n",
    "# # for i in test_feature_vec[test_feature_vec.isnull()].index:\n",
    "# #     test_sub_df.ix[i] = np.zeros(len(topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestData_02543    0.0\n",
       "TestData_05012    0.0\n",
       "TestData_05830    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.ix[test_null_index].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11656.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sub_df.astype(int).reset_index().rename(\n",
    "    columns={'index': 'id'}\n",
    ").sort_values('id').to_csv(\n",
    "    'lstm_300-word2vec_300-fasttext_300-maxlen_500-dense_64_64_64-cat_cross-epoch_210-batch_size_750-val_main_output_f1_micro_0.5760-main_output_f1_micro_0.5751-main_output_loss_0.9143-data_2010_2013-val_data_2014-thresh_0.05.csv', \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: zikavirus, dtype: float64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = test_sub_df['zikavirus']\n",
    "e[e==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14328"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_submission = pd.read_csv('basic_nn_submission_0.649_accuracy_multi_class.csv')\n",
    "top_submission.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9280"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_index_lstm_sub = pd.read_csv('lstm.2014b_training_700_maxlen_64cell_100epochs_0.0025_threshold.csv')\n",
    "wrong_index_lstm_sub.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34952"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_sub = pd.read_csv('basic_nn_submission_full_training_data_0.9958_validation_accuracy_binary_crossentropy.csv')\n",
    "some_sub.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2197, 160)\n",
      "(3957, 160)\n",
      "(12, 160)\n",
      "(1503, 160)\n"
     ]
    }
   ],
   "source": [
    "print top_submission.set_index('id')[top_submission.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print wrong_index_lstm_sub.set_index('id')[wrong_index_lstm_sub.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print some_sub.set_index('id')[some_sub.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print test_sub_df[test_sub_df.sum(axis=1) == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestData_00011     0\n",
       "TestData_00012     0\n",
       "TestData_00015     0\n",
       "TestData_00027     3\n",
       "TestData_00029     0\n",
       "TestData_00038     1\n",
       "TestData_00042     5\n",
       "TestData_00053     4\n",
       "TestData_00056     1\n",
       "TestData_00060     1\n",
       "TestData_00066     0\n",
       "TestData_00085     0\n",
       "TestData_00087     1\n",
       "TestData_00090     0\n",
       "TestData_00092     0\n",
       "TestData_00107     3\n",
       "TestData_00111     0\n",
       "TestData_00114     0\n",
       "TestData_00115     1\n",
       "TestData_00118     0\n",
       "TestData_00119     0\n",
       "TestData_00121     0\n",
       "TestData_00123     0\n",
       "TestData_00125     0\n",
       "TestData_00127     0\n",
       "TestData_00128     1\n",
       "TestData_00139     1\n",
       "TestData_00140     1\n",
       "TestData_00144     0\n",
       "TestData_00147     2\n",
       "                  ..\n",
       "TestData_07445     0\n",
       "TestData_07456     3\n",
       "TestData_07461     1\n",
       "TestData_07462     4\n",
       "TestData_07465     0\n",
       "TestData_07468     0\n",
       "TestData_07471     1\n",
       "TestData_07475     0\n",
       "TestData_07486    10\n",
       "TestData_07495     1\n",
       "TestData_07509     0\n",
       "TestData_07514     3\n",
       "TestData_07515     1\n",
       "TestData_07523     0\n",
       "TestData_07533     2\n",
       "TestData_07534     2\n",
       "TestData_07542     1\n",
       "TestData_07544     2\n",
       "TestData_07545     0\n",
       "TestData_07552     2\n",
       "TestData_07556     5\n",
       "TestData_07563     1\n",
       "TestData_07565     0\n",
       "TestData_07566     0\n",
       "TestData_07569     0\n",
       "TestData_07571     3\n",
       "TestData_07572     1\n",
       "TestData_07579     6\n",
       "TestData_07580     2\n",
       "TestData_07581     3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_submission.set_index('id').ix[q[q == 0].index].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1222,)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.sum(axis=1)\n",
    "q[q==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7581.000000\n",
       "mean        2.160929\n",
       "std         1.739411\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         2.000000\n",
       "75%         3.000000\n",
       "max        13.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = trainingY.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    236286.000000\n",
       "mean          1.392787\n",
       "std           0.762577\n",
       "min           1.000000\n",
       "25%           1.000000\n",
       "50%           1.000000\n",
       "75%           2.000000\n",
       "max          15.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bodyText</th>\n",
       "      <th>topics</th>\n",
       "      <th>webPublicationDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TestData_03241</th>\n",
       "      <td>A special British police unit was put on stand...</td>\n",
       "      <td>[]</td>\n",
       "      <td>15-11-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_04088</th>\n",
       "      <td>The youngest convict in a fatal gang-rape in N...</td>\n",
       "      <td>[]</td>\n",
       "      <td>20-12-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_06306</th>\n",
       "      <td>Former New York City mayor Rudy Giuliani has s...</td>\n",
       "      <td>[]</td>\n",
       "      <td>28-07-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_06083</th>\n",
       "      <td>John Cantlie, the British journalist who has b...</td>\n",
       "      <td>[]</td>\n",
       "      <td>13-07-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_05896</th>\n",
       "      <td>Lawyers for the companies that manufactured an...</td>\n",
       "      <td>[]</td>\n",
       "      <td>20-06-2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         bodyText topics  \\\n",
       "TestData_03241  A special British police unit was put on stand...     []   \n",
       "TestData_04088  The youngest convict in a fatal gang-rape in N...     []   \n",
       "TestData_06306  Former New York City mayor Rudy Giuliani has s...     []   \n",
       "TestData_06083  John Cantlie, the British journalist who has b...     []   \n",
       "TestData_05896  Lawyers for the companies that manufactured an...     []   \n",
       "\n",
       "               webPublicationDate  \n",
       "TestData_03241         15-11-2015  \n",
       "TestData_04088         20-12-2015  \n",
       "TestData_06306         28-07-2016  \n",
       "TestData_06083         13-07-2016  \n",
       "TestData_05896         20-06-2016  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ix = 'TestData_04088'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "humanrights    1.0\n",
       "india          1.0\n",
       "Name: TestData_04088, dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ukcrime    1\n",
       "Name: TestData_04088, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = top_submission.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "humanrights    1\n",
       "india          1\n",
       "protest        1\n",
       "ukcrime        1\n",
       "Name: TestData_04088, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = some_sub.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "humanrights    1\n",
       "Name: TestData_02924, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = wrong_index_lstm_sub.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Counter-terrorism policy\n",
    " \n",
    "Foreign policy\n",
    " \n",
    "Defence policy\n",
    " \n",
    "Islamic State\n",
    " \n",
    "Syria\n",
    " \n",
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = trainingY.sum()\n",
    "unseen_topics = s[s.isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activism',\n",
       " 'bastilledaytruckattack',\n",
       " 'berlinchristmasmarketattack',\n",
       " 'brusselsattacks',\n",
       " 'charliehebdoattack',\n",
       " 'francetrainattack',\n",
       " 'munichshooting',\n",
       " 'orlandoterrorattack',\n",
       " 'parisattacks',\n",
       " 'peaceandreconciliation',\n",
       " 'sanbernardinoshooting',\n",
       " 'tunisiaattack2015',\n",
       " 'turkeycoupattempt',\n",
       " 'zikavirus'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(topics).intersection(unseen_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activism\n",
      "afghanistan\n",
      "aid\n",
      "algerianhostagecrisis\n",
      "alqaida\n",
      "alshabaab\n",
      "antiwar\n",
      "arabandmiddleeastprotests\n",
      "armstrade\n",
      "australianguncontrol\n",
      "australiansecurityandcounterterrorism\n",
      "bastilledaytruckattack\n",
      "belgium\n",
      "berlinchristmasmarketattack\n",
      "bigdata\n",
      "biometrics\n",
      "bokoharam\n",
      "bostonmarathonbombing\n",
      "britisharmy\n",
      "brusselsattacks\n",
      "cameroon\n",
      "carers\n",
      "charliehebdoattack\n",
      "chemicalweapons\n",
      "clusterbombs\n",
      "cobra\n",
      "conflictanddevelopment\n",
      "controversy\n",
      "criminaljustice\n",
      "cybercrime\n",
      "cyberwar\n",
      "darknet\n",
      "dataprotection\n",
      "debate\n",
      "defence\n",
      "deflation\n",
      "drones\n",
      "drugs\n",
      "drugspolicy\n",
      "drugstrade\n",
      "earthquakes\n",
      "ebola\n",
      "economy\n",
      "egypt\n",
      "encryption\n",
      "energy\n",
      "espionage\n",
      "ethics\n",
      "europeanarrestwarrant\n",
      "europeancourtofhumanrights\n",
      "events\n",
      "extradition\n",
      "famine\n",
      "farright\n",
      "firefighters\n",
      "forensicscience\n",
      "france\n",
      "francetrainattack\n",
      "freedomofspeech\n",
      "genevaconventions\n",
      "germany\n",
      "guncrime\n",
      "hacking\n",
      "hashtags\n",
      "helicoptercrashes\n",
      "humanitarianresponse\n",
      "humanrights\n",
      "humanrightsact\n",
      "humantrafficking\n",
      "immigration\n",
      "india\n",
      "indonesia\n",
      "internallydisplacedpeople\n",
      "internationalcourtofjustice\n",
      "internationalcriminaljustice\n",
      "internetsafety\n",
      "iraq\n",
      "isis\n",
      "israel\n",
      "jordan\n",
      "jubilee\n",
      "judiciary\n",
      "july7\n",
      "justiceandsecurity\n",
      "kenya\n",
      "knifecrime\n",
      "lebanon\n",
      "libya\n",
      "localgovernment\n",
      "logistics\n",
      "london\n",
      "londonriots\n",
      "malaysia\n",
      "mali\n",
      "malware\n",
      "metropolitanpolice\n",
      "middleeastpeacetalks\n",
      "migration\n",
      "military\n",
      "ministryofdefence\n",
      "morocco\n",
      "mrsa\n",
      "mumbaiterrorattacks\n",
      "munichshooting\n",
      "naturaldisasters\n",
      "nigeria\n",
      "nuclearweapons\n",
      "occupy\n",
      "organisedcrime\n",
      "orlandoterrorattack\n",
      "osamabinladen\n",
      "paris\n",
      "parisattacks\n",
      "peaceandreconciliation\n",
      "philippines\n",
      "piracy\n",
      "planecrashes\n",
      "police\n",
      "protest\n",
      "refugees\n",
      "religion\n",
      "retirementage\n",
      "rio20earthsummit\n",
      "royalairforce\n",
      "royalnavy\n",
      "russia\n",
      "sanbernardinoshooting\n",
      "saudiarabia\n",
      "september11\n",
      "slavery\n",
      "somalia\n",
      "southafrica\n",
      "southchinasea\n",
      "stopandsearch\n",
      "surveillance\n",
      "sydneysiege\n",
      "syria\n",
      "taliban\n",
      "terrorism\n",
      "thailand\n",
      "torture\n",
      "traincrashes\n",
      "transport\n",
      "tunisiaattack2015\n",
      "turkey\n",
      "turkeycoupattempt\n",
      "ukcrime\n",
      "uksecurity\n",
      "uksupremecourt\n",
      "undercoverpoliceandpolicing\n",
      "unitednations\n",
      "usguncontrol\n",
      "values\n",
      "warcrimes\n",
      "warreporting\n",
      "weaponstechnology\n",
      "womeninbusiness\n",
      "woolwichattack\n",
      "worldmigration\n",
      "zikavirus\n"
     ]
    }
   ],
   "source": [
    "for i in topics:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsolatorio/ml-ai/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3445929"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(wvmodel['zika'], np.vstack(test_wvec.dropna())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsolatorio/ml-ai/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.38107796869050226"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(fsmodel['zika'], np.vstack(test_fvec.dropna())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              The World Health Organisation has convened an ...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           28-01-2016\n",
       "Name: TestData_04490, dtype: object"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[4488 + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              The United Nations security council has called...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           17-09-2016\n",
       "Name: TestData_06730, dtype: object"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[6727 + 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              We are deeply concerned that the counter-terro...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           02-02-2015\n",
       "Name: TestData_00360, dtype: object"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[359]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drugstrade    1.0\n",
       "Name: TestData_04490, dtype: float64"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.iloc[4488 + 1]\n",
    "q[q > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
