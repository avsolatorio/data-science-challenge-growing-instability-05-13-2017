{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from growing_instability_lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub = pd.read_csv('../data/sampleSubmission.csv')\n",
    "topics = sorted(set(sample_sub.columns.difference(['id'])))\n",
    "\n",
    "topic2actual = {}\n",
    "for i in sample_sub.columns:\n",
    "    if 'id' == i:\n",
    "        continue\n",
    "    topic2actual[i] = segment(i)\n",
    "    \n",
    "target_columns = sorted(topics)\n",
    "len(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.74 s, sys: 2.25 s, total: 11 s\n",
      "Wall time: 13.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wvec_trainingX = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', 'wvec_trainingX')\n",
    "fvec_trainingX = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', 'fvec_trainingX')\n",
    "word2idx_trainingX = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', 'word2idx_trainingX')\n",
    "_word2idx = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', '_word2idx')\n",
    "trainingY = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', 'trainingY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.8 s, sys: 72 ms, total: 19.9 s\n",
      "Wall time: 19.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word2ind = _word2idx.to_dict()\n",
    "\n",
    "ind2word = {i: j + 1 for i, j in word2ind.items()}  # Remove the increment if data is fixed.\n",
    "word2ind = {j: i for i, j in ind2word.items()}\n",
    "\n",
    "ind2class = dict(enumerate(topics))\n",
    "class2ind = {j: i for i, j in ind2class.items()}\n",
    "\n",
    "num_samples = trainingY.shape[0]\n",
    "\n",
    "training_X = word2idx_trainingX.head(num_samples)\n",
    "\n",
    "training_Y = pd.DataFrame(zip(*np.where(trainingY.head(num_samples) == 1)), columns=['iloc', 'topics'])\n",
    "training_WV = wvec_trainingX.head(num_samples)\n",
    "training_FS = fvec_trainingX.head(num_samples)\n",
    "\n",
    "training_Y = training_Y.groupby('iloc')['topics'].apply(list)\n",
    "training_Y.index = trainingY.head(num_samples).index\n",
    "\n",
    "# indices = sorted(training_Y.index.copy())\n",
    "indices = sorted(training_Y.index[training_Y.index.str.contains('^201[0-9]')])\n",
    "# np.random.shuffle(indices)\n",
    "indices = pd.Index(indices)\n",
    "\n",
    "training_X = training_X.ix[indices]\n",
    "training_WV = training_WV.ix[indices]\n",
    "training_FS = training_FS.ix[indices]\n",
    "training_Y = training_Y.ix[indices]\n",
    "\n",
    "dataset = zip(training_X, training_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def generate_lstm_batch_dataset(dataset, word2ind, class2ind, max_len, batch_size=1000, shuffle=True):\n",
    "#     if shuffle:\n",
    "#         np.random.shuffle(dataset)\n",
    "\n",
    "#     num_docs = len(dataset)\n",
    "#     num_words = len(word2ind) + 1\n",
    "#     num_class = len(class2ind)\n",
    "\n",
    "#     for s in xrange(0, num_docs, batch_size):\n",
    "#         x_batch = np.zeros([batch_size, max_len, num_words])\n",
    "#         y_batch = np.zeros([batch_size, num_class])\n",
    "\n",
    "#         for ix, (features, target) in enumerate(dataset[s:s + batch_size]):\n",
    "#             # print features\n",
    "#             for idx, feat in enumerate(features):\n",
    "#                 if idx >= max_len:\n",
    "#                     break\n",
    "\n",
    "#                 # print feat, ind2word[feat]\n",
    "#                 x_batch[ix, idx, feat] = 1\n",
    "\n",
    "#             if not isinstance(target, list):\n",
    "#                 target = [target]\n",
    "                \n",
    "#             for tg in target:\n",
    "#                 y_batch[ix, tg] = 1\n",
    "\n",
    "#         yield x_batch[:ix + 1, :, :], y_batch[:ix + 1, :]\n",
    "\n",
    "\n",
    "# def infinite_lstm_dataset_generator(dataset, word2ind, class2ind, max_len, batch_size=100):\n",
    "#     while 1:\n",
    "#         for b in generate_lstm_batch_dataset(dataset, word2ind, class2ind, max_len, batch_size):\n",
    "#             yield b\n",
    "\n",
    "# # lens = []\n",
    "# # for i in dataset:\n",
    "# #     lens.append(len(i[0]))\n",
    "# # pd.Series(lens).quantile(0.999)\n",
    "# # Use the above to estimate the acceptable timeseries dimension.\n",
    "# LSTM_TIMESERIES = 100\n",
    "# id_lstm_gen = infinite_lstm_dataset_generator(dataset, word2ind, class2ind, max_len=LSTM_TIMESERIES, batch_size=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wv_sc = StandardScaler()\n",
    "fs_sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "def build_target(y, size):\n",
    "    e = np.zeros(size)\n",
    "    e[y] = 1\n",
    "    return e\n",
    "\n",
    "def build_input_output_data(X, WV, FS, Y, maxlen):\n",
    "\n",
    "    x = sequence.pad_sequences(X, maxlen=maxlen)\n",
    "    y = np.vstack(Y.map(lambda x: build_target(x, len(topics))))\n",
    "    wv = np.vstack(WV)\n",
    "    fs = np.vstack(FS)\n",
    "    \n",
    "    return x, wv, fs, y\n",
    "\n",
    "\n",
    "test_ix = training_Y.index.str.contains('^201[0-4]')\n",
    "val_ix = training_Y.index.str.contains('^2014[b]')\n",
    "\n",
    "\n",
    "maxlen = 500\n",
    "\n",
    "\n",
    "x_train, wv_train, fs_train, y_train = build_input_output_data(\n",
    "    training_X.ix[test_ix],\n",
    "    training_WV.ix[test_ix],\n",
    "    training_FS.ix[test_ix],\n",
    "    training_Y.ix[test_ix],\n",
    "    maxlen=maxlen\n",
    ")\n",
    "\n",
    "\n",
    "x_val, wv_val, fs_val, y_val = build_input_output_data(\n",
    "    training_X.ix[val_ix],\n",
    "    training_WV.ix[val_ix],\n",
    "    training_FS.ix[val_ix],\n",
    "    training_Y.ix[val_ix],\n",
    "    maxlen=maxlen\n",
    ")\n",
    "\n",
    "wv_train = wv_sc.fit_transform(wv_train)\n",
    "fs_train = fs_sc.fit_transform(fs_train)\n",
    "\n",
    "wv_val = wv_sc.transform(wv_val)\n",
    "fs_val = fs_sc.transform(fs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((94731,), (9424,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_Y.shape, training_Y.ix[training_Y.index.str.contains('^2014[b]')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Setup model\n",
    "# model_lstm = keras.models.Sequential()\n",
    "# model_lstm.add(keras.layers.Embedding(len(word2ind) + 1, 256))\n",
    "# # model_lstm.add(keras.layers.LSTM(32, return_sequences=False, input_shape=(None, len(word2ind) + 1)))\n",
    "# # model_lstm.add(keras.layers.Dropout(0.2))\n",
    "# model_lstm.add(keras.layers.LSTM(16, return_sequences=False))\n",
    "# model_lstm.add(keras.layers.Dense(128))\n",
    "# model_lstm.add(keras.layers.Activation('relu'))\n",
    "# model_lstm.add(keras.layers.Dropout(0.2))\n",
    "# model_lstm.add(keras.layers.Dense(len(class2ind)))\n",
    "# model_lstm.add(keras.layers.Activation('sigmoid'))\n",
    "# model_lstm.compile(\n",
    "#     loss='binary_crossentropy',\n",
    "#     optimizer='adam',\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# # for i in range(6):\n",
    "# #     model_lstm.fit_generator(id_lstm_gen, steps_per_epoch=len(dataset), epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "# Headline input: meant to receive sequences of 100 integers, between 1 and 10000.\n",
    "# Note that we can name any layer by passing it a \"name\" argument.\n",
    "main_input = Input(shape=(maxlen,), dtype='int32', name='main_input')\n",
    "\n",
    "# This embedding layer will encode the input sequence\n",
    "# into a sequence of dense 512-dimensional vectors.\n",
    "x = Embedding(output_dim=300, input_dim=len(word2ind) + 1, input_length=maxlen)(main_input)\n",
    "\n",
    "# A LSTM will transform the vector sequence into a single vector,\n",
    "# containing information about the entire sequence\n",
    "lstm_out = LSTM(32)(x)\n",
    "\n",
    "auxiliary_output = Dense(len(class2ind), activation='sigmoid', name='aux_output')(lstm_out)\n",
    "\n",
    "\n",
    "wv_input = Input(shape=(300,), name='wv_input')\n",
    "fs_input = Input(shape=(300,), name='fs_input')\n",
    "\n",
    "x = keras.layers.concatenate([lstm_out, wv_input, fs_input])\n",
    "\n",
    "# We stack a deep densely-connected network on top\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "# And finally we add the main logistic regression layer\n",
    "main_output = Dense(len(class2ind), activation='sigmoid', name='main_output')(x)\n",
    "\n",
    "model = Model(inputs=[main_input, wv_input, fs_input], outputs=[main_output, auxiliary_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as K\n",
    "\n",
    "\n",
    "def f1_micro(y_true, y_pred):\n",
    "    TP = K.metrics.true_positives(y_true, K.round(y_pred))\n",
    "    FP = K.metrics.false_positives(y_true, K.round(y_pred))\n",
    "    FN = K.metrics.false_negatives(y_true, K.round(y_pred))\n",
    "    \n",
    "    p = K.reduce_sum(TP) / (K.reduce_sum(TP) + K.reduce_sum(FP))\n",
    "    r = K.reduce_sum(TP) / (K.reduce_sum(TP) + K.reduce_sum(FN))\n",
    "    \n",
    "    return (2.0 * p * r) / (p + r)\n",
    "\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "\n",
    "    # Count positive samples.\n",
    "    c1 = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    c2 = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    c3 = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "\n",
    "    # If there are no true samples, fix the F1 score at 0.\n",
    "    if c3 == 0:\n",
    "        return 0\n",
    "\n",
    "    # How many selected items are relevant?\n",
    "    precision = c1 / c2\n",
    "\n",
    "    # How many relevant items are selected?\n",
    "    recall = c1 / c3\n",
    "\n",
    "    # Calculate f1_score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input (InputLayer)          (None, 500)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 500, 300)      105478200                                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 32)            42624                                        \n",
      "____________________________________________________________________________________________________\n",
      "wv_input (InputLayer)            (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "fs_input (InputLayer)            (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 632)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 128)           81024                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 256)           33024                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 128)           32896                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 160)           20640                                        \n",
      "____________________________________________________________________________________________________\n",
      "aux_output (Dense)               (None, 160)           5280                                         \n",
      "====================================================================================================\n",
      "Total params: 105,693,688\n",
      "Trainable params: 105,693,688\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss={'main_output': 'categorical_crossentropy', 'aux_output': 'categorical_crossentropy'},\n",
    "              loss_weights={'main_output': 1., 'aux_output': 0.2}, metrics=['accuracy', f1_micro])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.callbacks import EarlyStopping\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "# model.fit(X, y, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import keras.backend as K\n",
    "# K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.train_on_batch(\n",
    "#     {'main_input': x_train[:10], 'wv_input': np.vstack(training_WV)[:10], 'fs_input': np.vstack(training_FS)[:10]},\n",
    "#     {'main_output': y_train[:10], 'aux_output': y_train[:10]}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/1\n",
      "94731/94731 [==============================] - 101s - loss: 6.5440 - main_output_loss: 5.1776 - aux_output_loss: 6.8321 - main_output_acc: 0.2264 - main_output_f1_micro: 0.0686 - aux_output_acc: 0.0424 - aux_output_f1_micro: 0.0486 - val_loss: 4.7639 - val_main_output_loss: 3.4273 - val_aux_output_loss: 6.6827 - val_main_output_acc: 0.5110 - val_main_output_f1_micro: 0.1113 - val_aux_output_acc: 0.0780 - val_aux_output_f1_micro: 0.0606\n",
      "CPU times: user 2min 7s, sys: 10.4 s, total: 2min 17s\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# And trained it via:\n",
    "batch_size = 600\n",
    "model.fit(\n",
    "    {'main_input': x_train, 'wv_input': wv_train, 'fs_input': fs_train},\n",
    "    {'main_output': y_train, 'aux_output': y_train},\n",
    "    epochs=1, batch_size=batch_size,   # 500\n",
    "    validation_split=0.2,\n",
    "    validation_data=(\n",
    "        {'main_input': x_val, 'wv_input': wv_val, 'fs_input': fs_val},\n",
    "        {'main_output': y_val, 'aux_output': y_val}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 100s - loss: 4.6525 - main_output_loss: 3.3686 - aux_output_loss: 6.4196 - main_output_acc: 0.4914 - main_output_f1_micro: 0.1447 - aux_output_acc: 0.0826 - aux_output_f1_micro: 0.0657 - val_loss: 4.2857 - val_main_output_loss: 2.9544 - val_aux_output_loss: 6.6566 - val_main_output_acc: 0.5682 - val_main_output_f1_micro: 0.1748 - val_aux_output_acc: 0.0780 - val_aux_output_f1_micro: 0.0696\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 101s - loss: 4.3476 - main_output_loss: 3.0708 - aux_output_loss: 6.3843 - main_output_acc: 0.5326 - main_output_f1_micro: 0.2000 - aux_output_acc: 0.0826 - aux_output_f1_micro: 0.0721 - val_loss: 4.1080 - val_main_output_loss: 2.7788 - val_aux_output_loss: 6.6457 - val_main_output_acc: 0.6054 - val_main_output_f1_micro: 0.2233 - val_aux_output_acc: 0.0780 - val_aux_output_f1_micro: 0.0744\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 101s - loss: 4.1887 - main_output_loss: 2.9165 - aux_output_loss: 6.3608 - main_output_acc: 0.5548 - main_output_f1_micro: 0.2434 - aux_output_acc: 0.0826 - aux_output_f1_micro: 0.0762 - val_loss: 3.9520 - val_main_output_loss: 2.6309 - val_aux_output_loss: 6.6056 - val_main_output_acc: 0.6093 - val_main_output_f1_micro: 0.2618 - val_aux_output_acc: 0.0780 - val_aux_output_f1_micro: 0.0779\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 100s - loss: 4.0901 - main_output_loss: 2.8232 - aux_output_loss: 6.3343 - main_output_acc: 0.5619 - main_output_f1_micro: 0.2780 - aux_output_acc: 0.0826 - aux_output_f1_micro: 0.0794 - val_loss: 3.8753 - val_main_output_loss: 2.5615 - val_aux_output_loss: 6.5693 - val_main_output_acc: 0.6196 - val_main_output_f1_micro: 0.2930 - val_aux_output_acc: 0.0780 - val_aux_output_f1_micro: 0.0807\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 100s - loss: 4.0025 - main_output_loss: 2.7441 - aux_output_loss: 6.2919 - main_output_acc: 0.5718 - main_output_f1_micro: 0.3064 - aux_output_acc: 0.0826 - aux_output_f1_micro: 0.0820 - val_loss: 3.7802 - val_main_output_loss: 2.4885 - val_aux_output_loss: 6.4589 - val_main_output_acc: 0.6211 - val_main_output_f1_micro: 0.3191 - val_aux_output_acc: 0.0780 - val_aux_output_f1_micro: 0.0832\n",
      "\n",
      "Done with epoch: 5\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 100s - loss: 3.9152 - main_output_loss: 2.6737 - aux_output_loss: 6.2075 - main_output_acc: 0.5814 - main_output_f1_micro: 0.3306 - aux_output_acc: 0.0826 - aux_output_f1_micro: 0.0844 - val_loss: 3.6971 - val_main_output_loss: 2.4080 - val_aux_output_loss: 6.4457 - val_main_output_acc: 0.6279 - val_main_output_f1_micro: 0.3415 - val_aux_output_acc: 0.0780 - val_aux_output_f1_micro: 0.0857\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 101s - loss: 3.8309 - main_output_loss: 2.6163 - aux_output_loss: 6.0730 - main_output_acc: 0.5886 - main_output_f1_micro: 0.3514 - aux_output_acc: 0.0846 - aux_output_f1_micro: 0.0871 - val_loss: 3.5913 - val_main_output_loss: 2.3420 - val_aux_output_loss: 6.2465 - val_main_output_acc: 0.6372 - val_main_output_f1_micro: 0.3609 - val_aux_output_acc: 0.0824 - val_aux_output_f1_micro: 0.0885\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 101s - loss: 3.7493 - main_output_loss: 2.5666 - aux_output_loss: 5.9134 - main_output_acc: 0.5914 - main_output_f1_micro: 0.3696 - aux_output_acc: 0.1080 - aux_output_f1_micro: 0.0899 - val_loss: 3.5103 - val_main_output_loss: 2.2959 - val_aux_output_loss: 6.0718 - val_main_output_acc: 0.6434 - val_main_output_f1_micro: 0.3779 - val_aux_output_acc: 0.1083 - val_aux_output_f1_micro: 0.0913\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 100s - loss: 3.6501 - main_output_loss: 2.5071 - aux_output_loss: 5.7150 - main_output_acc: 0.5999 - main_output_f1_micro: 0.3855 - aux_output_acc: 0.1439 - aux_output_f1_micro: 0.0924 - val_loss: 3.4041 - val_main_output_loss: 2.2310 - val_aux_output_loss: 5.8658 - val_main_output_acc: 0.6436 - val_main_output_f1_micro: 0.3929 - val_aux_output_acc: 0.1333 - val_aux_output_f1_micro: 0.0933\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 101s - loss: 3.5674 - main_output_loss: 2.4612 - aux_output_loss: 5.5313 - main_output_acc: 0.6074 - main_output_f1_micro: 0.3999 - aux_output_acc: 0.1737 - aux_output_f1_micro: 0.0940 - val_loss: 3.3334 - val_main_output_loss: 2.1847 - val_aux_output_loss: 5.7436 - val_main_output_acc: 0.6569 - val_main_output_f1_micro: 0.4065 - val_aux_output_acc: 0.1486 - val_aux_output_f1_micro: 0.0946\n",
      "\n",
      "Done with epoch: 10\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 101s - loss: 3.4845 - main_output_loss: 2.4136 - aux_output_loss: 5.3545 - main_output_acc: 0.6144 - main_output_f1_micro: 0.4127 - aux_output_acc: 0.2008 - aux_output_f1_micro: 0.0951 - val_loss: 3.2185 - val_main_output_loss: 2.1097 - val_aux_output_loss: 5.5438 - val_main_output_acc: 0.6681 - val_main_output_f1_micro: 0.4188 - val_aux_output_acc: 0.1813 - val_aux_output_f1_micro: 0.0954\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 101s - loss: 3.3913 - main_output_loss: 2.3581 - aux_output_loss: 5.1662 - main_output_acc: 0.6220 - main_output_f1_micro: 0.4245 - aux_output_acc: 0.2332 - aux_output_f1_micro: 0.0957 - val_loss: 3.1273 - val_main_output_loss: 2.0627 - val_aux_output_loss: 5.3227 - val_main_output_acc: 0.6741 - val_main_output_f1_micro: 0.4301 - val_aux_output_acc: 0.2220 - val_aux_output_f1_micro: 0.0960\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 101s - loss: 3.2973 - main_output_loss: 2.3152 - aux_output_loss: 4.9108 - main_output_acc: 0.6287 - main_output_f1_micro: 0.4354 - aux_output_acc: 0.2794 - aux_output_f1_micro: 0.0963 - val_loss: 3.0213 - val_main_output_loss: 2.0272 - val_aux_output_loss: 4.9703 - val_main_output_acc: 0.6876 - val_main_output_f1_micro: 0.4405 - val_aux_output_acc: 0.2808 - val_aux_output_f1_micro: 0.0965\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 101s - loss: 3.1686 - main_output_loss: 2.2719 - aux_output_loss: 4.4836 - main_output_acc: 0.6396 - main_output_f1_micro: 0.4454 - aux_output_acc: 0.3563 - aux_output_f1_micro: 0.0969 - val_loss: 2.8716 - val_main_output_loss: 1.9573 - val_aux_output_loss: 4.5712 - val_main_output_acc: 0.6878 - val_main_output_f1_micro: 0.4502 - val_aux_output_acc: 0.3549 - val_aux_output_f1_micro: 0.0973\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 101s - loss: 3.0359 - main_output_loss: 2.2129 - aux_output_loss: 4.1150 - main_output_acc: 0.6474 - main_output_f1_micro: 0.4547 - aux_output_acc: 0.4140 - aux_output_f1_micro: 0.0978 - val_loss: 2.7443 - val_main_output_loss: 1.8932 - val_aux_output_loss: 4.2557 - val_main_output_acc: 0.7018 - val_main_output_f1_micro: 0.4591 - val_aux_output_acc: 0.4040 - val_aux_output_f1_micro: 0.0982\n",
      "\n",
      "Done with epoch: 15\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 100s - loss: 2.9224 - main_output_loss: 2.1547 - aux_output_loss: 3.8387 - main_output_acc: 0.6569 - main_output_f1_micro: 0.4634 - aux_output_acc: 0.4605 - aux_output_f1_micro: 0.0986 - val_loss: 2.6428 - val_main_output_loss: 1.8468 - val_aux_output_loss: 3.9802 - val_main_output_acc: 0.7162 - val_main_output_f1_micro: 0.4676 - val_aux_output_acc: 0.4430 - val_aux_output_f1_micro: 0.0989\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 100s - loss: 2.8233 - main_output_loss: 2.1025 - aux_output_loss: 3.6040 - main_output_acc: 0.6666 - main_output_f1_micro: 0.4717 - aux_output_acc: 0.5012 - aux_output_f1_micro: 0.0992 - val_loss: 2.5323 - val_main_output_loss: 1.7846 - val_aux_output_loss: 3.7383 - val_main_output_acc: 0.7198 - val_main_output_f1_micro: 0.4756 - val_aux_output_acc: 0.4944 - val_aux_output_f1_micro: 0.0995\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 100s - loss: 2.7295 - main_output_loss: 2.0499 - aux_output_loss: 3.3979 - main_output_acc: 0.6751 - main_output_f1_micro: 0.4794 - aux_output_acc: 0.5395 - aux_output_f1_micro: 0.0998 - val_loss: 2.4514 - val_main_output_loss: 1.7460 - val_aux_output_loss: 3.5272 - val_main_output_acc: 0.7315 - val_main_output_f1_micro: 0.4831 - val_aux_output_acc: 0.5400 - val_aux_output_f1_micro: 0.1001\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 100s - loss: 2.6481 - main_output_loss: 2.0050 - aux_output_loss: 3.2151 - main_output_acc: 0.6820 - main_output_f1_micro: 0.4869 - aux_output_acc: 0.5689 - aux_output_f1_micro: 0.1003 - val_loss: 2.3667 - val_main_output_loss: 1.6970 - val_aux_output_loss: 3.3485 - val_main_output_acc: 0.7371 - val_main_output_f1_micro: 0.4906 - val_aux_output_acc: 0.5708 - val_aux_output_f1_micro: 0.1006\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 100s - loss: 2.5669 - main_output_loss: 1.9569 - aux_output_loss: 3.0499 - main_output_acc: 0.6908 - main_output_f1_micro: 0.4941 - aux_output_acc: 0.5964 - aux_output_f1_micro: 0.1008 - val_loss: 2.3049 - val_main_output_loss: 1.6679 - val_aux_output_loss: 3.1851 - val_main_output_acc: 0.7426 - val_main_output_f1_micro: 0.4977 - val_aux_output_acc: 0.6020 - val_aux_output_f1_micro: 0.1011\n",
      "\n",
      "Done with epoch: 20\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 100s - loss: 2.4925 - main_output_loss: 1.9134 - aux_output_loss: 2.8951 - main_output_acc: 0.6983 - main_output_f1_micro: 0.5011 - aux_output_acc: 0.6206 - aux_output_f1_micro: 0.1014 - val_loss: 2.2255 - val_main_output_loss: 1.6207 - val_aux_output_loss: 3.0240 - val_main_output_acc: 0.7465 - val_main_output_f1_micro: 0.5045 - val_aux_output_acc: 0.6286 - val_aux_output_f1_micro: 0.1016\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 100s - loss: 2.4251 - main_output_loss: 1.8731 - aux_output_loss: 2.7602 - main_output_acc: 0.7056 - main_output_f1_micro: 0.5078 - aux_output_acc: 0.6408 - aux_output_f1_micro: 0.1019 - val_loss: 2.1476 - val_main_output_loss: 1.5724 - val_aux_output_loss: 2.8759 - val_main_output_acc: 0.7425 - val_main_output_f1_micro: 0.5112 - val_aux_output_acc: 0.6435 - val_aux_output_f1_micro: 0.1022\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 100s - loss: 2.3646 - main_output_loss: 1.8368 - aux_output_loss: 2.6390 - main_output_acc: 0.7109 - main_output_f1_micro: 0.5144 - aux_output_acc: 0.6592 - aux_output_f1_micro: 0.1025 - val_loss: 2.1058 - val_main_output_loss: 1.5541 - val_aux_output_loss: 2.7583 - val_main_output_acc: 0.7554 - val_main_output_f1_micro: 0.5176 - val_aux_output_acc: 0.6682 - val_aux_output_f1_micro: 0.1028\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 100s - loss: 2.3100 - main_output_loss: 1.8035 - aux_output_loss: 2.5321 - main_output_acc: 0.7168 - main_output_f1_micro: 0.5208 - aux_output_acc: 0.6745 - aux_output_f1_micro: 0.1032 - val_loss: 2.0447 - val_main_output_loss: 1.5165 - val_aux_output_loss: 2.6411 - val_main_output_acc: 0.7564 - val_main_output_f1_micro: 0.5239 - val_aux_output_acc: 0.6777 - val_aux_output_f1_micro: 0.1035\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 100s - loss: 2.2590 - main_output_loss: 1.7715 - aux_output_loss: 2.4376 - main_output_acc: 0.7211 - main_output_f1_micro: 0.5270 - aux_output_acc: 0.6876 - aux_output_f1_micro: 0.1038 - val_loss: 2.0034 - val_main_output_loss: 1.4900 - val_aux_output_loss: 2.5667 - val_main_output_acc: 0.7554 - val_main_output_f1_micro: 0.5301 - val_aux_output_acc: 0.6940 - val_aux_output_f1_micro: 0.1041\n",
      "\n",
      "Done with epoch: 25\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 100s - loss: 2.2104 - main_output_loss: 1.7401 - aux_output_loss: 2.3514 - main_output_acc: 0.7256 - main_output_f1_micro: 0.5331 - aux_output_acc: 0.6990 - aux_output_f1_micro: 0.1045 - val_loss: 1.9551 - val_main_output_loss: 1.4606 - val_aux_output_loss: 2.4726 - val_main_output_acc: 0.7611 - val_main_output_f1_micro: 0.5361 - val_aux_output_acc: 0.7007 - val_aux_output_f1_micro: 0.1048\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 99s - loss: 2.1647 - main_output_loss: 1.7097 - aux_output_loss: 2.2748 - main_output_acc: 0.7294 - main_output_f1_micro: 0.5391 - aux_output_acc: 0.7106 - aux_output_f1_micro: 0.1051 - val_loss: 1.9132 - val_main_output_loss: 1.4342 - val_aux_output_loss: 2.3951 - val_main_output_acc: 0.7617 - val_main_output_f1_micro: 0.5420 - val_aux_output_acc: 0.7132 - val_aux_output_f1_micro: 0.1054\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 99s - loss: 2.1293 - main_output_loss: 1.6882 - aux_output_loss: 2.2057 - main_output_acc: 0.7337 - main_output_f1_micro: 0.5448 - aux_output_acc: 0.7193 - aux_output_f1_micro: 0.1057 - val_loss: 1.8807 - val_main_output_loss: 1.4156 - val_aux_output_loss: 2.3255 - val_main_output_acc: 0.7737 - val_main_output_f1_micro: 0.5476 - val_aux_output_acc: 0.7243 - val_aux_output_f1_micro: 0.1060\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 99s - loss: 2.0904 - main_output_loss: 1.6614 - aux_output_loss: 2.1453 - main_output_acc: 0.7365 - main_output_f1_micro: 0.5505 - aux_output_acc: 0.7251 - aux_output_f1_micro: 0.1063 - val_loss: 1.8464 - val_main_output_loss: 1.3963 - val_aux_output_loss: 2.2509 - val_main_output_acc: 0.7679 - val_main_output_f1_micro: 0.5533 - val_aux_output_acc: 0.7277 - val_aux_output_f1_micro: 0.1067\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 99s - loss: 2.0547 - main_output_loss: 1.6376 - aux_output_loss: 2.0855 - main_output_acc: 0.7391 - main_output_f1_micro: 0.5561 - aux_output_acc: 0.7338 - aux_output_f1_micro: 0.1070 - val_loss: 1.8191 - val_main_output_loss: 1.3810 - val_aux_output_loss: 2.1907 - val_main_output_acc: 0.7725 - val_main_output_f1_micro: 0.5590 - val_aux_output_acc: 0.7344 - val_aux_output_f1_micro: 0.1073\n",
      "\n",
      "Done with epoch: 30\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 99s - loss: 2.0261 - main_output_loss: 1.6198 - aux_output_loss: 2.0315 - main_output_acc: 0.7418 - main_output_f1_micro: 0.5617 - aux_output_acc: 0.7400 - aux_output_f1_micro: 0.1076 - val_loss: 1.7898 - val_main_output_loss: 1.3621 - val_aux_output_loss: 2.1386 - val_main_output_acc: 0.7747 - val_main_output_f1_micro: 0.5645 - val_aux_output_acc: 0.7389 - val_aux_output_f1_micro: 0.1079\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 99s - loss: 1.9928 - main_output_loss: 1.5963 - aux_output_loss: 1.9829 - main_output_acc: 0.7442 - main_output_f1_micro: 0.5672 - aux_output_acc: 0.7461 - aux_output_f1_micro: 0.1082 - val_loss: 1.7733 - val_main_output_loss: 1.3537 - val_aux_output_loss: 2.0979 - val_main_output_acc: 0.7817 - val_main_output_f1_micro: 0.5699 - val_aux_output_acc: 0.7464 - val_aux_output_f1_micro: 0.1085\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 99s - loss: 1.9707 - main_output_loss: 1.5830 - aux_output_loss: 1.9385 - main_output_acc: 0.7488 - main_output_f1_micro: 0.5726 - aux_output_acc: 0.7510 - aux_output_f1_micro: 0.1088 - val_loss: 1.7436 - val_main_output_loss: 1.3348 - val_aux_output_loss: 2.0441 - val_main_output_acc: 0.7708 - val_main_output_f1_micro: 0.5752 - val_aux_output_acc: 0.7550 - val_aux_output_f1_micro: 0.1092\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 99s - loss: 1.9394 - main_output_loss: 1.5606 - aux_output_loss: 1.8942 - main_output_acc: 0.7497 - main_output_f1_micro: 0.5778 - aux_output_acc: 0.7552 - aux_output_f1_micro: 0.1095 - val_loss: 1.7250 - val_main_output_loss: 1.3238 - val_aux_output_loss: 2.0060 - val_main_output_acc: 0.7820 - val_main_output_f1_micro: 0.5804 - val_aux_output_acc: 0.7530 - val_aux_output_f1_micro: 0.1098\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94731/94731 [==============================] - 99s - loss: 1.9189 - main_output_loss: 1.5471 - aux_output_loss: 1.8592 - main_output_acc: 0.7518 - main_output_f1_micro: 0.5829 - aux_output_acc: 0.7592 - aux_output_f1_micro: 0.1101 - val_loss: 1.7000 - val_main_output_loss: 1.3082 - val_aux_output_loss: 1.9590 - val_main_output_acc: 0.7840 - val_main_output_f1_micro: 0.5854 - val_aux_output_acc: 0.7596 - val_aux_output_f1_micro: 0.1104\n",
      "\n",
      "Done with epoch: 35\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 99s - loss: 1.8936 - main_output_loss: 1.5298 - aux_output_loss: 1.8192 - main_output_acc: 0.7523 - main_output_f1_micro: 0.5879 - aux_output_acc: 0.7623 - aux_output_f1_micro: 0.1107 - val_loss: 1.6774 - val_main_output_loss: 1.2923 - val_aux_output_loss: 1.9254 - val_main_output_acc: 0.7747 - val_main_output_f1_micro: 0.5904 - val_aux_output_acc: 0.7588 - val_aux_output_f1_micro: 0.1110\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 99s - loss: 1.8704 - main_output_loss: 1.5137 - aux_output_loss: 1.7836 - main_output_acc: 0.7555 - main_output_f1_micro: 0.5929 - aux_output_acc: 0.7635 - aux_output_f1_micro: 0.1113 - val_loss: 1.6639 - val_main_output_loss: 1.2847 - val_aux_output_loss: 1.8958 - val_main_output_acc: 0.7715 - val_main_output_f1_micro: 0.5953 - val_aux_output_acc: 0.7626 - val_aux_output_f1_micro: 0.1116\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 99s - loss: 1.8573 - main_output_loss: 1.5066 - aux_output_loss: 1.7537 - main_output_acc: 0.7572 - main_output_f1_micro: 0.5977 - aux_output_acc: 0.7668 - aux_output_f1_micro: 0.1120 - val_loss: 1.6440 - val_main_output_loss: 1.2725 - val_aux_output_loss: 1.8575 - val_main_output_acc: 0.7808 - val_main_output_f1_micro: 0.6001 - val_aux_output_acc: 0.7714 - val_aux_output_f1_micro: 0.1123\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 99s - loss: 1.8324 - main_output_loss: 1.4878 - aux_output_loss: 1.7228 - main_output_acc: 0.7585 - main_output_f1_micro: 0.6025 - aux_output_acc: 0.7690 - aux_output_f1_micro: 0.1126 - val_loss: 1.6280 - val_main_output_loss: 1.2613 - val_aux_output_loss: 1.8337 - val_main_output_acc: 0.7882 - val_main_output_f1_micro: 0.6048 - val_aux_output_acc: 0.7671 - val_aux_output_f1_micro: 0.1129\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 99s - loss: 1.8143 - main_output_loss: 1.4749 - aux_output_loss: 1.6971 - main_output_acc: 0.7597 - main_output_f1_micro: 0.6072 - aux_output_acc: 0.7727 - aux_output_f1_micro: 0.1132 - val_loss: 1.6110 - val_main_output_loss: 1.2493 - val_aux_output_loss: 1.8088 - val_main_output_acc: 0.7770 - val_main_output_f1_micro: 0.6095 - val_aux_output_acc: 0.7727 - val_aux_output_f1_micro: 0.1136\n",
      "\n",
      "Done with epoch: 40\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 99s - loss: 1.7977 - main_output_loss: 1.4635 - aux_output_loss: 1.6711 - main_output_acc: 0.7614 - main_output_f1_micro: 0.6117 - aux_output_acc: 0.7740 - aux_output_f1_micro: 0.1139 - val_loss: 1.5998 - val_main_output_loss: 1.2442 - val_aux_output_loss: 1.7782 - val_main_output_acc: 0.7791 - val_main_output_f1_micro: 0.6140 - val_aux_output_acc: 0.7689 - val_aux_output_f1_micro: 0.1142\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 99s - loss: 1.7812 - main_output_loss: 1.4522 - aux_output_loss: 1.6449 - main_output_acc: 0.7617 - main_output_f1_micro: 0.6162 - aux_output_acc: 0.7760 - aux_output_f1_micro: 0.1146 - val_loss: 1.5890 - val_main_output_loss: 1.2401 - val_aux_output_loss: 1.7445 - val_main_output_acc: 0.7812 - val_main_output_f1_micro: 0.6184 - val_aux_output_acc: 0.7763 - val_aux_output_f1_micro: 0.1149\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 99s - loss: 1.7672 - main_output_loss: 1.4430 - aux_output_loss: 1.6211 - main_output_acc: 0.7612 - main_output_f1_micro: 0.6206 - aux_output_acc: 0.7781 - aux_output_f1_micro: 0.1153 - val_loss: 1.5749 - val_main_output_loss: 1.2303 - val_aux_output_loss: 1.7230 - val_main_output_acc: 0.7861 - val_main_output_f1_micro: 0.6228 - val_aux_output_acc: 0.7807 - val_aux_output_f1_micro: 0.1156\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 99s - loss: 1.7556 - main_output_loss: 1.4350 - aux_output_loss: 1.6031 - main_output_acc: 0.7626 - main_output_f1_micro: 0.6249 - aux_output_acc: 0.7788 - aux_output_f1_micro: 0.1159 - val_loss: 1.5551 - val_main_output_loss: 1.2159 - val_aux_output_loss: 1.6960 - val_main_output_acc: 0.7834 - val_main_output_f1_micro: 0.6271 - val_aux_output_acc: 0.7827 - val_aux_output_f1_micro: 0.1162\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 99s - loss: 1.7369 - main_output_loss: 1.4207 - aux_output_loss: 1.5812 - main_output_acc: 0.7642 - main_output_f1_micro: 0.6292 - aux_output_acc: 0.7806 - aux_output_f1_micro: 0.1166 - val_loss: 1.5381 - val_main_output_loss: 1.2026 - val_aux_output_loss: 1.6775 - val_main_output_acc: 0.7833 - val_main_output_f1_micro: 0.6313 - val_aux_output_acc: 0.7811 - val_aux_output_f1_micro: 0.1169\n",
      "\n",
      "Done with epoch: 45\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 99s - loss: 1.7225 - main_output_loss: 1.4103 - aux_output_loss: 1.5610 - main_output_acc: 0.7655 - main_output_f1_micro: 0.6334 - aux_output_acc: 0.7811 - aux_output_f1_micro: 0.1172 - val_loss: 1.5259 - val_main_output_loss: 1.1952 - val_aux_output_loss: 1.6535 - val_main_output_acc: 0.7906 - val_main_output_f1_micro: 0.6354 - val_aux_output_acc: 0.7879 - val_aux_output_f1_micro: 0.1175\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 99s - loss: 1.7135 - main_output_loss: 1.4046 - aux_output_loss: 1.5443 - main_output_acc: 0.7654 - main_output_f1_micro: 0.6374 - aux_output_acc: 0.7840 - aux_output_f1_micro: 0.1179 - val_loss: 1.5180 - val_main_output_loss: 1.1907 - val_aux_output_loss: 1.6367 - val_main_output_acc: 0.7889 - val_main_output_f1_micro: 0.6394 - val_aux_output_acc: 0.7896 - val_aux_output_f1_micro: 0.1182\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 99s - loss: 1.7034 - main_output_loss: 1.3983 - aux_output_loss: 1.5253 - main_output_acc: 0.7668 - main_output_f1_micro: 0.6414 - aux_output_acc: 0.7840 - aux_output_f1_micro: 0.1186 - val_loss: 1.5128 - val_main_output_loss: 1.1886 - val_aux_output_loss: 1.6212 - val_main_output_acc: 0.7833 - val_main_output_f1_micro: 0.6433 - val_aux_output_acc: 0.7912 - val_aux_output_f1_micro: 0.1189\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 99s - loss: 1.6862 - main_output_loss: 1.3840 - aux_output_loss: 1.5112 - main_output_acc: 0.7680 - main_output_f1_micro: 0.6452 - aux_output_acc: 0.7856 - aux_output_f1_micro: 0.1193 - val_loss: 1.4980 - val_main_output_loss: 1.1793 - val_aux_output_loss: 1.5935 - val_main_output_acc: 0.7954 - val_main_output_f1_micro: 0.6472 - val_aux_output_acc: 0.7963 - val_aux_output_f1_micro: 0.1196\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 99s - loss: 1.6766 - main_output_loss: 1.3781 - aux_output_loss: 1.4928 - main_output_acc: 0.7704 - main_output_f1_micro: 0.6490 - aux_output_acc: 0.7862 - aux_output_f1_micro: 0.1200 - val_loss: 1.4894 - val_main_output_loss: 1.1742 - val_aux_output_loss: 1.5762 - val_main_output_acc: 0.7938 - val_main_output_f1_micro: 0.6509 - val_aux_output_acc: 0.7926 - val_aux_output_f1_micro: 0.1204\n",
      "\n",
      "Done with epoch: 50\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 99s - loss: 1.6672 - main_output_loss: 1.3717 - aux_output_loss: 1.4776 - main_output_acc: 0.7693 - main_output_f1_micro: 0.6528 - aux_output_acc: 0.7870 - aux_output_f1_micro: 0.1207 - val_loss: 1.4826 - val_main_output_loss: 1.1704 - val_aux_output_loss: 1.5614 - val_main_output_acc: 0.7899 - val_main_output_f1_micro: 0.6546 - val_aux_output_acc: 0.7910 - val_aux_output_f1_micro: 0.1210\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 99s - loss: 1.6553 - main_output_loss: 1.3625 - aux_output_loss: 1.4642 - main_output_acc: 0.7689 - main_output_f1_micro: 0.6564 - aux_output_acc: 0.7879 - aux_output_f1_micro: 0.1214 - val_loss: 1.4691 - val_main_output_loss: 1.1583 - val_aux_output_loss: 1.5540 - val_main_output_acc: 0.7886 - val_main_output_f1_micro: 0.6582 - val_aux_output_acc: 0.7884 - val_aux_output_f1_micro: 0.1218\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 99s - loss: 1.6487 - main_output_loss: 1.3582 - aux_output_loss: 1.4523 - main_output_acc: 0.7722 - main_output_f1_micro: 0.6600 - aux_output_acc: 0.7882 - aux_output_f1_micro: 0.1222 - val_loss: 1.4516 - val_main_output_loss: 1.1434 - val_aux_output_loss: 1.5408 - val_main_output_acc: 0.7981 - val_main_output_f1_micro: 0.6617 - val_aux_output_acc: 0.7953 - val_aux_output_f1_micro: 0.1225\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 99s - loss: 1.6370 - main_output_loss: 1.3491 - aux_output_loss: 1.4392 - main_output_acc: 0.7732 - main_output_f1_micro: 0.6635 - aux_output_acc: 0.7891 - aux_output_f1_micro: 0.1229 - val_loss: 1.4526 - val_main_output_loss: 1.1496 - val_aux_output_loss: 1.5147 - val_main_output_acc: 0.8026 - val_main_output_f1_micro: 0.6652 - val_aux_output_acc: 0.8031 - val_aux_output_f1_micro: 0.1233\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 99s - loss: 1.6283 - main_output_loss: 1.3431 - aux_output_loss: 1.4260 - main_output_acc: 0.7736 - main_output_f1_micro: 0.6669 - aux_output_acc: 0.7912 - aux_output_f1_micro: 0.1237 - val_loss: 1.4462 - val_main_output_loss: 1.1452 - val_aux_output_loss: 1.5052 - val_main_output_acc: 0.7951 - val_main_output_f1_micro: 0.6686 - val_aux_output_acc: 0.7981 - val_aux_output_f1_micro: 0.1241\n",
      "\n",
      "Done with epoch: 55\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 99s - loss: 1.6192 - main_output_loss: 1.3363 - aux_output_loss: 1.4148 - main_output_acc: 0.7736 - main_output_f1_micro: 0.6703 - aux_output_acc: 0.7919 - aux_output_f1_micro: 0.1245 - val_loss: 1.4375 - val_main_output_loss: 1.1371 - val_aux_output_loss: 1.5023 - val_main_output_acc: 0.7801 - val_main_output_f1_micro: 0.6719 - val_aux_output_acc: 0.7957 - val_aux_output_f1_micro: 0.1249\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 99s - loss: 1.6190 - main_output_loss: 1.3377 - aux_output_loss: 1.4062 - main_output_acc: 0.7725 - main_output_f1_micro: 0.6735 - aux_output_acc: 0.7918 - aux_output_f1_micro: 0.1253 - val_loss: 1.4304 - val_main_output_loss: 1.1337 - val_aux_output_loss: 1.4834 - val_main_output_acc: 0.7884 - val_main_output_f1_micro: 0.6751 - val_aux_output_acc: 0.8021 - val_aux_output_f1_micro: 0.1257\n",
      "Epoch 3/5\n",
      "21000/94731 [=====>........................] - ETA: 75s - loss: 1.5946 - main_output_loss: 1.3167 - aux_output_loss: 1.3898 - main_output_acc: 0.7762 - main_output_f1_micro: 0.6756 - aux_output_acc: 0.7934 - aux_output_f1_micro: 0.1258"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_name = 'models/lstm-word2vec-fasttext_2010-2014-data_categorical-crossentropy-2014-b-val-standard_scaled_wv_fs.model'\n",
    "epochs = 5\n",
    "for i in xrange(0, 100 // epochs):\n",
    "    hist = model.fit(\n",
    "        {'main_input': x_train, 'wv_input': wv_train, 'fs_input': fs_train},\n",
    "        {'main_output': y_train, 'aux_output': y_train},\n",
    "        epochs=epochs, batch_size=batch_size,   # 500\n",
    "        validation_split=0.2,\n",
    "        validation_data=(\n",
    "            {'main_input': x_val, 'wv_input': wv_val, 'fs_input': fs_val},\n",
    "            {'main_output': y_val, 'aux_output': y_val}\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.save(model_name.format(i))\n",
    "    print\n",
    "    print('Done with epoch: {}'.format((i + 1) * epochs))\n",
    "    with open('lstm-word2vec-fasttext.epoch.csv', 'a') as fl:\n",
    "        fl.write(model_name + '\\n')\n",
    "        fl.write('Epoch {}\\n'.format((i + 1) * epochs))\n",
    "        fl.write('{}\\n'.format(datetime.now()))\n",
    "        fl.write('\\n'.join(['{}: {}'.format(k, v[0]) for k, v in hist.history.items()]))\n",
    "        fl.write('\\n\\n')\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for j in xrange(i, i + (100 // epochs)):\n",
    "    hist = model.fit(\n",
    "        {'main_input': x_train, 'wv_input': wv_train, 'fs_input': fs_train},\n",
    "        {'main_output': y_train, 'aux_output': y_train},\n",
    "        epochs=epochs, batch_size=batch_size,   # 500\n",
    "        validation_split=0.2,\n",
    "        validation_data=(\n",
    "            {'main_input': x_val, 'wv_input': wv_val, 'fs_input': fs_val},\n",
    "            {'main_output': y_val, 'aux_output': y_val}\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.save(model_name.format(i))\n",
    "    print\n",
    "    print('Done with epoch: {}'.format((j + 1) * epochs))\n",
    "    with open('lstm-word2vec-fasttext.epoch.csv', 'a') as fl:\n",
    "        fl.write(model_name + '\\n')\n",
    "        fl.write('Epoch {}\\n'.format((j + 1) * epochs))\n",
    "        fl.write('{}\\n'.format(datetime.now()))\n",
    "        fl.write('\\n'.join(['{}: {}'.format(k, v[0]) for k, v in hist.history.items()]))\n",
    "        fl.write('\\n\\n')\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\n",
    "    'models/lstm-word2vec-fasttext_2010-2014-data_categorical-crossentropy-2014-b-val-standard_scaled_wv_fs.model',\n",
    "    custom_objects={'f1_micro': f1_micro}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = model.predict({'main_input': x_train[:100], 'wv_input': wv_train[:100], 'fs_input': fs_train[:100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1e470b96d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB4Bt6P8A/ZZsN+7NPBwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1e47115d90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "ix = 29\n",
    "pd.Series(g[0][ix]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1e47000650>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1d6bc02950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(g[1][ix]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([ 1, 98]),), (array([ 1, 98]),), (array([], dtype=int64),))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh = 0.5\n",
    "np.where(y_train[ix] == 1), np.where(g[0][ix] > thresh), np.where(g[1][ix] > thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wvmodel = Word2Vec.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fsmodel = fasttext.load_model('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.fasttext.model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_fasttext(tokens, stopwords=[]):\n",
    "    global fsmodel\n",
    "    # This requires fsmodel to be present in the namespace.\n",
    "    fs_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    ).map(lambda x: np.array([fsmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return fs_feature_vec\n",
    "\n",
    "\n",
    "def transform_unsupervised_sentiment_neuron(tokens, stopwords=[]):\n",
    "    # This requires fsmodel to be present in the namespace.\n",
    "    \n",
    "    usn_feature_vec = usnmodel.transform(tokens)\n",
    "\n",
    "    # usn_feature_vec = tokens.map(\n",
    "    #     lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    # ).map(lambda x: np.array([usnmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return usn_feature_vec\n",
    "\n",
    "\n",
    "def transform_word2vec(tokens, stopwords=[]):\n",
    "    global wvmodel\n",
    "    # This requires wvmodel to be present in the namespace.\n",
    "    wv_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords and w in wvmodel.wv.vocab)]\n",
    "    ).map(lambda x: np.array([wvmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return wv_feature_vec\n",
    "\n",
    "\n",
    "def parallel_generate_word_vectors(samp, transformer, stopwords, batch, num_proc):\n",
    "    with Parallel(n_jobs=num_proc) as parallel:\n",
    "        dataset = []\n",
    "        is_break = False\n",
    "        i = 0\n",
    "\n",
    "        while not is_break:\n",
    "            payload = []\n",
    "\n",
    "            for j in xrange(num_proc):\n",
    "                t_df = samp[(i + j) * batch: (i + 1 + j) * batch]\n",
    "\n",
    "                if t_df.empty:\n",
    "                    is_break = True\n",
    "                    continue\n",
    "\n",
    "                payload.append(\n",
    "                    delayed(transformer)(\n",
    "                        t_df, stopwords\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            print('Current batch in main thread: {}'.format((i + j) * batch))\n",
    "\n",
    "            if payload:\n",
    "                results = parallel(payload)\n",
    "                dataset.extend(results)\n",
    "                i += num_proc\n",
    "\n",
    "    return pd.concat(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_classes(pred, scale_param=0.75, min_thresh=0.05, thresh = 0.5):\n",
    "#     mx = pred.mean() + 3 * pred.std()\n",
    "    return np.where(pred > thresh)[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2idx_transform(word, _word2idx):\n",
    "    return _word2idx.get(word, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features_for(df, min_batch=2000, stopwords=[], num_proc=7):\n",
    "    df_tokens = transform_text(df)\n",
    "    \n",
    "    batch = min(df_tokens.shape[0] / num_proc, min_batch)\n",
    "\n",
    "    print('Computing fs features...')\n",
    "    fvec = parallel_generate_word_vectors(df_tokens, transform_fasttext, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Computing wv features...')\n",
    "    wvec = parallel_generate_word_vectors(df_tokens, transform_word2vec, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Mapping word indices...')\n",
    "    word_indices = df_tokens.map(lambda x: [word2idx_transform(i, _word2idx) for i in x.split()])\n",
    "    \n",
    "    return word_indices, wvec, fvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/TestData.json') as fl:\n",
    "    data = json.load(fl)\n",
    "    test_df = pd.DataFrame(data['TestData']).T\n",
    "    del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fs features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Computing wv features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Mapping word indices...\n",
      "CPU times: user 42.2 s, sys: 1.35 s, total: 43.6 s\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_word_indices,test_wvec, test_fvec = extract_features_for(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert(np.all(test_wvec[test_wvec.isnull()].index == test_fvec[test_fvec.isnull()].index))\n",
    "test_null_index = test_wvec[test_wvec.isnull()].index.union(test_fvec[test_fvec.isnull()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'TestData_02543', u'TestData_05012', u'TestData_05830'], dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_null_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 320 ms, sys: 8 ms, total: 328 ms\n",
      "Wall time: 325 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "maxlen = 500\n",
    "\n",
    "valid_test_index = test_word_indices.index.difference(test_null_index)\n",
    "x_test = sequence.pad_sequences(test_word_indices.ix[valid_test_index], maxlen=maxlen)\n",
    "wv_test = np.vstack(test_wvec.ix[valid_test_index])\n",
    "fs_test = np.vstack(test_fvec.ix[valid_test_index])\n",
    "\n",
    "wv_test = wv_sc.transform(wv_test)\n",
    "fs_test = fs_sc.transform(fs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "test_probas = model.predict({'main_input': x_test, 'wv_input': wv_test, 'fs_input': fs_test}, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_test_probas, aux_test_probas = test_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   6.55482543e-11,   2.40463197e-20, ...,\n",
       "          2.59207180e-15,   5.18131315e-21,   0.00000000e+00],\n",
       "       [  3.50870202e-28,   3.69621139e-11,   6.43091275e-11, ...,\n",
       "          2.57583854e-14,   7.85017176e-15,   7.34451819e-29],\n",
       "       [  0.00000000e+00,   5.73172568e-24,   2.40125536e-23, ...,\n",
       "          2.81079201e-15,   7.77269308e-31,   0.00000000e+00],\n",
       "       ..., \n",
       "       [  7.15643372e-19,   8.12338025e-04,   7.16986835e-01, ...,\n",
       "          5.10852341e-12,   1.46519290e-06,   1.33264858e-19],\n",
       "       [  8.52415053e-28,   3.58516263e-05,   4.24800507e-11, ...,\n",
       "          9.22245891e-11,   1.50055023e-12,   1.36613106e-27],\n",
       "       [  4.15145364e-29,   1.10339286e-04,   2.94213205e-05, ...,\n",
       "          8.72289183e-15,   8.62857556e-14,   7.09845416e-30]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_test_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_df.ix[test_df.index.difference(test_null_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2542, 5011, 5829]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_index = [int(s.split('_')[1]) - 1 for s in test_null_index]  # Subtract 1 since test index starts at 1 while enumerate starts at 0\n",
    "skip_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7578, 160), (7581, 3))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_test_probas.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24 ms, sys: 12 ms, total: 36 ms\n",
      "Wall time: 31.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# valid_test_feature_vec found below!\n",
    "test_values = np.zeros([main_test_probas.shape[0], len(topics)])\n",
    "for ix, pred in enumerate(main_test_probas):\n",
    "    for v in get_classes(pred, thresh=0.5):\n",
    "        test_values[ix][v] = 1\n",
    "\n",
    "test_sub_df = pd.DataFrame(\n",
    "    test_values,\n",
    "    index=test_df.ix[test_df.index.difference(test_null_index)].index,\n",
    "    columns=topics\n",
    ")\n",
    "\n",
    "null_test_df = pd.DataFrame(\n",
    "    np.zeros((len(test_null_index), len(topics))),\n",
    "    index=test_null_index,\n",
    "    columns=topics\n",
    ")\n",
    "\n",
    "test_sub_df = test_sub_df.append(null_test_df)\n",
    "test_sub_df = test_sub_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_sub_df.astype(int).reset_index().rename(\n",
    "    columns={'index': 'id'}\n",
    ").sort_values('id').to_csv(\n",
    "    'lstm_300-word2vec_300-fasttext_300-maxlen_500-dense_128_256_128-cat_cross-epoch_100-batch_size_500-val_main_output_f1_micro_0.7619-main_output_f1_micro_0.7611-main_output_loss_1.1978-data_2010_2014-val_data_2014-thresh_0.5-with_sc_wv_fs.csv', \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7581, 160)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36 ms, sys: 0 ns, total: 36 ms\n",
      "Wall time: 32.6 ms\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# adjust_index = 0\n",
    "# # valid_test_feature_vec found below!\n",
    "# test_values = np.zeros([test_df.shape[0], len(topics)])\n",
    "# for ix, pred in enumerate(main_test_probas):\n",
    "#     if ix in skip_index:\n",
    "#         test_values[ix] = np.nan\n",
    "#         # Increment adjust index so that we have the correct index for other samples\n",
    "#         adjust_index += 1\n",
    "#         continue\n",
    "\n",
    "#     for v in get_classes(pred, thresh=0.05):\n",
    "#         test_values[ix + adjust_index][v] = 1\n",
    "\n",
    "# test_sub_df = pd.DataFrame(test_values, columns=sorted(topics), index=test_df.index)\n",
    "\n",
    "# q = test_sub_df.sum(axis=1)\n",
    "# assert(len(q[q.isnull()].index.difference(test_null_index)) == 0)\n",
    "\n",
    "# test_sub_df = test_sub_df.fillna(0)\n",
    "\n",
    "# # for i in test_feature_vec[test_feature_vec.isnull()].index:\n",
    "# #     test_sub_df.ix[i] = np.zeros(len(topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestData_02543    0.0\n",
       "TestData_05012    0.0\n",
       "TestData_05830    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.ix[test_null_index].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11656.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sub_df.astype(int).reset_index().rename(\n",
    "    columns={'index': 'id'}\n",
    ").sort_values('id').to_csv(\n",
    "    'lstm_300-word2vec_300-fasttext_300-maxlen_500-dense_64_64_64-cat_cross-epoch_210-batch_size_750-val_main_output_f1_micro_0.5760-main_output_f1_micro_0.5751-main_output_loss_0.9143-data_2010_2013-val_data_2014-thresh_0.05.csv', \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: zikavirus, dtype: float64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = test_sub_df['zikavirus']\n",
    "e[e==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14328"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_submission = pd.read_csv('basic_nn_submission_0.649_accuracy_multi_class.csv')\n",
    "top_submission.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9280"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_index_lstm_sub = pd.read_csv('lstm.2014b_training_700_maxlen_64cell_100epochs_0.0025_threshold.csv')\n",
    "wrong_index_lstm_sub.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34952"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_sub = pd.read_csv('basic_nn_submission_full_training_data_0.9958_validation_accuracy_binary_crossentropy.csv')\n",
    "some_sub.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2197, 160)\n",
      "(3957, 160)\n",
      "(12, 160)\n",
      "(1503, 160)\n"
     ]
    }
   ],
   "source": [
    "print top_submission.set_index('id')[top_submission.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print wrong_index_lstm_sub.set_index('id')[wrong_index_lstm_sub.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print some_sub.set_index('id')[some_sub.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print test_sub_df[test_sub_df.sum(axis=1) == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestData_00011     0\n",
       "TestData_00012     0\n",
       "TestData_00015     0\n",
       "TestData_00027     3\n",
       "TestData_00029     0\n",
       "TestData_00038     1\n",
       "TestData_00042     5\n",
       "TestData_00053     4\n",
       "TestData_00056     1\n",
       "TestData_00060     1\n",
       "TestData_00066     0\n",
       "TestData_00085     0\n",
       "TestData_00087     1\n",
       "TestData_00090     0\n",
       "TestData_00092     0\n",
       "TestData_00107     3\n",
       "TestData_00111     0\n",
       "TestData_00114     0\n",
       "TestData_00115     1\n",
       "TestData_00118     0\n",
       "TestData_00119     0\n",
       "TestData_00121     0\n",
       "TestData_00123     0\n",
       "TestData_00125     0\n",
       "TestData_00127     0\n",
       "TestData_00128     1\n",
       "TestData_00139     1\n",
       "TestData_00140     1\n",
       "TestData_00144     0\n",
       "TestData_00147     2\n",
       "                  ..\n",
       "TestData_07445     0\n",
       "TestData_07456     3\n",
       "TestData_07461     1\n",
       "TestData_07462     4\n",
       "TestData_07465     0\n",
       "TestData_07468     0\n",
       "TestData_07471     1\n",
       "TestData_07475     0\n",
       "TestData_07486    10\n",
       "TestData_07495     1\n",
       "TestData_07509     0\n",
       "TestData_07514     3\n",
       "TestData_07515     1\n",
       "TestData_07523     0\n",
       "TestData_07533     2\n",
       "TestData_07534     2\n",
       "TestData_07542     1\n",
       "TestData_07544     2\n",
       "TestData_07545     0\n",
       "TestData_07552     2\n",
       "TestData_07556     5\n",
       "TestData_07563     1\n",
       "TestData_07565     0\n",
       "TestData_07566     0\n",
       "TestData_07569     0\n",
       "TestData_07571     3\n",
       "TestData_07572     1\n",
       "TestData_07579     6\n",
       "TestData_07580     2\n",
       "TestData_07581     3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_submission.set_index('id').ix[q[q == 0].index].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1222,)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.sum(axis=1)\n",
    "q[q==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7581.000000\n",
       "mean        2.160929\n",
       "std         1.739411\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         2.000000\n",
       "75%         3.000000\n",
       "max        13.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = trainingY.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    236286.000000\n",
       "mean          1.392787\n",
       "std           0.762577\n",
       "min           1.000000\n",
       "25%           1.000000\n",
       "50%           1.000000\n",
       "75%           2.000000\n",
       "max          15.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bodyText</th>\n",
       "      <th>topics</th>\n",
       "      <th>webPublicationDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TestData_03241</th>\n",
       "      <td>A special British police unit was put on stand...</td>\n",
       "      <td>[]</td>\n",
       "      <td>15-11-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_04088</th>\n",
       "      <td>The youngest convict in a fatal gang-rape in N...</td>\n",
       "      <td>[]</td>\n",
       "      <td>20-12-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_06306</th>\n",
       "      <td>Former New York City mayor Rudy Giuliani has s...</td>\n",
       "      <td>[]</td>\n",
       "      <td>28-07-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_06083</th>\n",
       "      <td>John Cantlie, the British journalist who has b...</td>\n",
       "      <td>[]</td>\n",
       "      <td>13-07-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_05896</th>\n",
       "      <td>Lawyers for the companies that manufactured an...</td>\n",
       "      <td>[]</td>\n",
       "      <td>20-06-2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         bodyText topics  \\\n",
       "TestData_03241  A special British police unit was put on stand...     []   \n",
       "TestData_04088  The youngest convict in a fatal gang-rape in N...     []   \n",
       "TestData_06306  Former New York City mayor Rudy Giuliani has s...     []   \n",
       "TestData_06083  John Cantlie, the British journalist who has b...     []   \n",
       "TestData_05896  Lawyers for the companies that manufactured an...     []   \n",
       "\n",
       "               webPublicationDate  \n",
       "TestData_03241         15-11-2015  \n",
       "TestData_04088         20-12-2015  \n",
       "TestData_06306         28-07-2016  \n",
       "TestData_06083         13-07-2016  \n",
       "TestData_05896         20-06-2016  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ix = 'TestData_04088'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "humanrights    1.0\n",
       "india          1.0\n",
       "Name: TestData_04088, dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ukcrime    1\n",
       "Name: TestData_04088, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = top_submission.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "humanrights    1\n",
       "india          1\n",
       "protest        1\n",
       "ukcrime        1\n",
       "Name: TestData_04088, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = some_sub.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "humanrights    1\n",
       "Name: TestData_02924, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = wrong_index_lstm_sub.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Counter-terrorism policy\n",
    " \n",
    "Foreign policy\n",
    " \n",
    "Defence policy\n",
    " \n",
    "Islamic State\n",
    " \n",
    "Syria\n",
    " \n",
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = trainingY.sum()\n",
    "unseen_topics = s[s.isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activism',\n",
       " 'bastilledaytruckattack',\n",
       " 'berlinchristmasmarketattack',\n",
       " 'brusselsattacks',\n",
       " 'charliehebdoattack',\n",
       " 'francetrainattack',\n",
       " 'munichshooting',\n",
       " 'orlandoterrorattack',\n",
       " 'parisattacks',\n",
       " 'peaceandreconciliation',\n",
       " 'sanbernardinoshooting',\n",
       " 'tunisiaattack2015',\n",
       " 'turkeycoupattempt',\n",
       " 'zikavirus'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(topics).intersection(unseen_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activism\n",
      "afghanistan\n",
      "aid\n",
      "algerianhostagecrisis\n",
      "alqaida\n",
      "alshabaab\n",
      "antiwar\n",
      "arabandmiddleeastprotests\n",
      "armstrade\n",
      "australianguncontrol\n",
      "australiansecurityandcounterterrorism\n",
      "bastilledaytruckattack\n",
      "belgium\n",
      "berlinchristmasmarketattack\n",
      "bigdata\n",
      "biometrics\n",
      "bokoharam\n",
      "bostonmarathonbombing\n",
      "britisharmy\n",
      "brusselsattacks\n",
      "cameroon\n",
      "carers\n",
      "charliehebdoattack\n",
      "chemicalweapons\n",
      "clusterbombs\n",
      "cobra\n",
      "conflictanddevelopment\n",
      "controversy\n",
      "criminaljustice\n",
      "cybercrime\n",
      "cyberwar\n",
      "darknet\n",
      "dataprotection\n",
      "debate\n",
      "defence\n",
      "deflation\n",
      "drones\n",
      "drugs\n",
      "drugspolicy\n",
      "drugstrade\n",
      "earthquakes\n",
      "ebola\n",
      "economy\n",
      "egypt\n",
      "encryption\n",
      "energy\n",
      "espionage\n",
      "ethics\n",
      "europeanarrestwarrant\n",
      "europeancourtofhumanrights\n",
      "events\n",
      "extradition\n",
      "famine\n",
      "farright\n",
      "firefighters\n",
      "forensicscience\n",
      "france\n",
      "francetrainattack\n",
      "freedomofspeech\n",
      "genevaconventions\n",
      "germany\n",
      "guncrime\n",
      "hacking\n",
      "hashtags\n",
      "helicoptercrashes\n",
      "humanitarianresponse\n",
      "humanrights\n",
      "humanrightsact\n",
      "humantrafficking\n",
      "immigration\n",
      "india\n",
      "indonesia\n",
      "internallydisplacedpeople\n",
      "internationalcourtofjustice\n",
      "internationalcriminaljustice\n",
      "internetsafety\n",
      "iraq\n",
      "isis\n",
      "israel\n",
      "jordan\n",
      "jubilee\n",
      "judiciary\n",
      "july7\n",
      "justiceandsecurity\n",
      "kenya\n",
      "knifecrime\n",
      "lebanon\n",
      "libya\n",
      "localgovernment\n",
      "logistics\n",
      "london\n",
      "londonriots\n",
      "malaysia\n",
      "mali\n",
      "malware\n",
      "metropolitanpolice\n",
      "middleeastpeacetalks\n",
      "migration\n",
      "military\n",
      "ministryofdefence\n",
      "morocco\n",
      "mrsa\n",
      "mumbaiterrorattacks\n",
      "munichshooting\n",
      "naturaldisasters\n",
      "nigeria\n",
      "nuclearweapons\n",
      "occupy\n",
      "organisedcrime\n",
      "orlandoterrorattack\n",
      "osamabinladen\n",
      "paris\n",
      "parisattacks\n",
      "peaceandreconciliation\n",
      "philippines\n",
      "piracy\n",
      "planecrashes\n",
      "police\n",
      "protest\n",
      "refugees\n",
      "religion\n",
      "retirementage\n",
      "rio20earthsummit\n",
      "royalairforce\n",
      "royalnavy\n",
      "russia\n",
      "sanbernardinoshooting\n",
      "saudiarabia\n",
      "september11\n",
      "slavery\n",
      "somalia\n",
      "southafrica\n",
      "southchinasea\n",
      "stopandsearch\n",
      "surveillance\n",
      "sydneysiege\n",
      "syria\n",
      "taliban\n",
      "terrorism\n",
      "thailand\n",
      "torture\n",
      "traincrashes\n",
      "transport\n",
      "tunisiaattack2015\n",
      "turkey\n",
      "turkeycoupattempt\n",
      "ukcrime\n",
      "uksecurity\n",
      "uksupremecourt\n",
      "undercoverpoliceandpolicing\n",
      "unitednations\n",
      "usguncontrol\n",
      "values\n",
      "warcrimes\n",
      "warreporting\n",
      "weaponstechnology\n",
      "womeninbusiness\n",
      "woolwichattack\n",
      "worldmigration\n",
      "zikavirus\n"
     ]
    }
   ],
   "source": [
    "for i in topics:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsolatorio/ml-ai/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3445929"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(wvmodel['zika'], np.vstack(test_wvec.dropna())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsolatorio/ml-ai/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.38107796869050226"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(fsmodel['zika'], np.vstack(test_fvec.dropna())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              The World Health Organisation has convened an ...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           28-01-2016\n",
       "Name: TestData_04490, dtype: object"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[4488 + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              The United Nations security council has called...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           17-09-2016\n",
       "Name: TestData_06730, dtype: object"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[6727 + 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              We are deeply concerned that the counter-terro...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           02-02-2015\n",
       "Name: TestData_00360, dtype: object"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[359]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drugstrade    1.0\n",
       "Name: TestData_04490, dtype: float64"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.iloc[4488 + 1]\n",
    "q[q > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
