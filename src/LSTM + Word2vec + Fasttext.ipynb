{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from growing_instability_lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub = pd.read_csv('../data/sampleSubmission.csv')\n",
    "topics = sorted(set(sample_sub.columns.difference(['id'])))\n",
    "\n",
    "topic2actual = {}\n",
    "for i in sample_sub.columns:\n",
    "    if 'id' == i:\n",
    "        continue\n",
    "    topic2actual[i] = segment(i)\n",
    "    \n",
    "target_columns = sorted(topics)\n",
    "len(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.73 s, sys: 1.31 s, total: 10 s\n",
      "Wall time: 10 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wvec_trainingX = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', 'wvec_trainingX')\n",
    "fvec_trainingX = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', 'fvec_trainingX')\n",
    "word2idx_trainingX = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', 'word2idx_trainingX')\n",
    "_word2idx = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', '_word2idx')\n",
    "trainingY = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', 'trainingY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Notes:\n",
    "\n",
    "1. Implement sample weight based on temporal data. Ideally, we penalize more misclassification in more recent news than older ones.\n",
    "[sample_weight](https://keras.io/models/sequential/)\n",
    "```\n",
    "sample_weight: Numpy array of weights for the training samples, used for scaling the loss function (during training only). You can either pass a flat (1D) Numpy array with the same length as the input samples\n",
    "(1:1 mapping between weights and samples), or in the case of temporal data, you can pass a 2D array with shape (samples, sequence_length), to apply a different weight to every timestep of every sample. In this case you should make sure to specify sample_weight_mode=\"temporal\" in compile().\n",
    "```\n",
    "2. Try training data more recent that 2012, say, start with 2013.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.1 s, sys: 72 ms, total: 20.2 s\n",
      "Wall time: 20 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word2ind = _word2idx.to_dict()\n",
    "\n",
    "ind2word = {i: j + 1 for i, j in word2ind.items()}  # Remove the increment if data is fixed.\n",
    "word2ind = {j: i for i, j in ind2word.items()}\n",
    "\n",
    "ind2class = dict(enumerate(topics))\n",
    "class2ind = {j: i for i, j in ind2class.items()}\n",
    "\n",
    "num_samples = trainingY.shape[0]\n",
    "\n",
    "training_X = word2idx_trainingX.head(num_samples)\n",
    "\n",
    "training_Y = pd.DataFrame(zip(*np.where(trainingY.head(num_samples) == 1)), columns=['iloc', 'topics'])\n",
    "training_WV = wvec_trainingX.head(num_samples)\n",
    "training_FS = fvec_trainingX.head(num_samples)\n",
    "\n",
    "training_Y = training_Y.groupby('iloc')['topics'].apply(list)\n",
    "training_Y.index = trainingY.head(num_samples).index\n",
    "\n",
    "# indices = sorted(training_Y.index.copy())\n",
    "indices = sorted(training_Y.index[training_Y.index.str.contains('^201[2-4]')])\n",
    "# np.random.shuffle(indices)\n",
    "indices = pd.Index(indices)\n",
    "\n",
    "training_X = training_X.ix[indices]\n",
    "training_WV = training_WV.ix[indices]\n",
    "training_FS = training_FS.ix[indices]\n",
    "training_Y = training_Y.ix[indices]\n",
    "\n",
    "dataset = zip(training_X, training_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def generate_lstm_batch_dataset(dataset, word2ind, class2ind, max_len, batch_size=1000, shuffle=True):\n",
    "#     if shuffle:\n",
    "#         np.random.shuffle(dataset)\n",
    "\n",
    "#     num_docs = len(dataset)\n",
    "#     num_words = len(word2ind) + 1\n",
    "#     num_class = len(class2ind)\n",
    "\n",
    "#     for s in xrange(0, num_docs, batch_size):\n",
    "#         x_batch = np.zeros([batch_size, max_len, num_words])\n",
    "#         y_batch = np.zeros([batch_size, num_class])\n",
    "\n",
    "#         for ix, (features, target) in enumerate(dataset[s:s + batch_size]):\n",
    "#             # print features\n",
    "#             for idx, feat in enumerate(features):\n",
    "#                 if idx >= max_len:\n",
    "#                     break\n",
    "\n",
    "#                 # print feat, ind2word[feat]\n",
    "#                 x_batch[ix, idx, feat] = 1\n",
    "\n",
    "#             if not isinstance(target, list):\n",
    "#                 target = [target]\n",
    "                \n",
    "#             for tg in target:\n",
    "#                 y_batch[ix, tg] = 1\n",
    "\n",
    "#         yield x_batch[:ix + 1, :, :], y_batch[:ix + 1, :]\n",
    "\n",
    "\n",
    "# def infinite_lstm_dataset_generator(dataset, word2ind, class2ind, max_len, batch_size=100):\n",
    "#     while 1:\n",
    "#         for b in generate_lstm_batch_dataset(dataset, word2ind, class2ind, max_len, batch_size):\n",
    "#             yield b\n",
    "\n",
    "# # lens = []\n",
    "# # for i in dataset:\n",
    "# #     lens.append(len(i[0]))\n",
    "# # pd.Series(lens).quantile(0.999)\n",
    "# # Use the above to estimate the acceptable timeseries dimension.\n",
    "# LSTM_TIMESERIES = 100\n",
    "# id_lstm_gen = infinite_lstm_dataset_generator(dataset, word2ind, class2ind, max_len=LSTM_TIMESERIES, batch_size=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wv_sc = StandardScaler()\n",
    "fs_sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "def build_target(y, size):\n",
    "    e = np.zeros(size)\n",
    "    e[y] = 1\n",
    "    return e\n",
    "\n",
    "def build_input_output_data(X, WV, FS, Y, maxlen):\n",
    "\n",
    "    x = sequence.pad_sequences(X, maxlen=maxlen)\n",
    "    y = np.vstack(Y.map(lambda x: build_target(x, len(topics))))\n",
    "    wv = np.vstack(WV)\n",
    "    fs = np.vstack(FS)\n",
    "    \n",
    "    return x, wv, fs, y\n",
    "\n",
    "\n",
    "test_ix = training_Y.index.str.contains('^201[0-4]')\n",
    "val_ix = training_Y.index.str.contains('^2014[b]')\n",
    "\n",
    "\n",
    "maxlen = 500\n",
    "\n",
    "\n",
    "x_train, wv_train, fs_train, y_train = build_input_output_data(\n",
    "    training_X.ix[test_ix],\n",
    "    training_WV.ix[test_ix],\n",
    "    training_FS.ix[test_ix],\n",
    "    training_Y.ix[test_ix],\n",
    "    maxlen=maxlen\n",
    ")\n",
    "\n",
    "\n",
    "x_val, wv_val, fs_val, y_val = build_input_output_data(\n",
    "    training_X.ix[val_ix],\n",
    "    training_WV.ix[val_ix],\n",
    "    training_FS.ix[val_ix],\n",
    "    training_Y.ix[val_ix],\n",
    "    maxlen=maxlen\n",
    ")\n",
    "\n",
    "wv_train = wv_sc.fit_transform(wv_train)\n",
    "fs_train = fs_sc.fit_transform(fs_train)\n",
    "\n",
    "wv_val = wv_sc.transform(wv_val)\n",
    "fs_val = fs_sc.transform(fs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((56877,), (9424,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_Y.shape, training_Y.ix[training_Y.index.str.contains('^2014[b]')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Setup model\n",
    "# model_lstm = keras.models.Sequential()\n",
    "# model_lstm.add(keras.layers.Embedding(len(word2ind) + 1, 256))\n",
    "# # model_lstm.add(keras.layers.LSTM(32, return_sequences=False, input_shape=(None, len(word2ind) + 1)))\n",
    "# # model_lstm.add(keras.layers.Dropout(0.2))\n",
    "# model_lstm.add(keras.layers.LSTM(16, return_sequences=False))\n",
    "# model_lstm.add(keras.layers.Dense(128))\n",
    "# model_lstm.add(keras.layers.Activation('relu'))\n",
    "# model_lstm.add(keras.layers.Dropout(0.2))\n",
    "# model_lstm.add(keras.layers.Dense(len(class2ind)))\n",
    "# model_lstm.add(keras.layers.Activation('sigmoid'))\n",
    "# model_lstm.compile(\n",
    "#     loss='binary_crossentropy',\n",
    "#     optimizer='adam',\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# # for i in range(6):\n",
    "# #     model_lstm.fit_generator(id_lstm_gen, steps_per_epoch=len(dataset), epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "# Headline input: meant to receive sequences of 100 integers, between 1 and 10000.\n",
    "# Note that we can name any layer by passing it a \"name\" argument.\n",
    "main_input = Input(shape=(maxlen,), dtype='int32', name='main_input')\n",
    "\n",
    "# This embedding layer will encode the input sequence\n",
    "# into a sequence of dense 512-dimensional vectors.\n",
    "x = Embedding(output_dim=300, input_dim=len(word2ind) + 1, input_length=maxlen)(main_input)\n",
    "\n",
    "# A LSTM will transform the vector sequence into a single vector,\n",
    "# containing information about the entire sequence\n",
    "lstm_out = LSTM(32)(x)\n",
    "\n",
    "auxiliary_output = Dense(len(class2ind), activation='sigmoid', name='aux_output')(lstm_out)\n",
    "\n",
    "\n",
    "wv_input = Input(shape=(300,), name='wv_input')\n",
    "fs_input = Input(shape=(300,), name='fs_input')\n",
    "\n",
    "x = keras.layers.concatenate([lstm_out, wv_input, fs_input])\n",
    "\n",
    "# We stack a deep densely-connected network on top\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "# And finally we add the main logistic regression layer\n",
    "main_output = Dense(len(class2ind), activation='sigmoid', name='main_output')(x)\n",
    "\n",
    "model = Model(inputs=[main_input, wv_input, fs_input], outputs=[main_output, auxiliary_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as K\n",
    "\n",
    "\n",
    "def f1_micro(y_true, y_pred):\n",
    "    TP = K.metrics.true_positives(y_true, K.round(y_pred))\n",
    "    FP = K.metrics.false_positives(y_true, K.round(y_pred))\n",
    "    FN = K.metrics.false_negatives(y_true, K.round(y_pred))\n",
    "    \n",
    "    p = K.reduce_sum(TP) / (K.reduce_sum(TP) + K.reduce_sum(FP))\n",
    "    r = K.reduce_sum(TP) / (K.reduce_sum(TP) + K.reduce_sum(FN))\n",
    "    \n",
    "    return (2.0 * p * r) / (p + r)\n",
    "\n",
    "\n",
    "import keras.backend as KB\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "\n",
    "    # Count positive samples.\n",
    "    c1 = KB.sum(KB.round(KB.clip(y_true * y_pred, 0, 1)))\n",
    "    c2 = KB.sum(K.round(KB.clip(y_pred, 0, 1)))\n",
    "    c3 = KB.sum(K.round(KB.clip(y_true, 0, 1)))\n",
    "\n",
    "    # If there are no true samples, fix the F1 score at 0.\n",
    "    if c3 == 0:\n",
    "        return 0\n",
    "\n",
    "    # How many selected items are relevant?\n",
    "    precision = c1 / c2\n",
    "\n",
    "    # How many relevant items are selected?\n",
    "    recall = c1 / c3\n",
    "\n",
    "    # Calculate f1_score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input (InputLayer)          (None, 500)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 500, 300)      105478200                                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 32)            42624                                        \n",
      "____________________________________________________________________________________________________\n",
      "wv_input (InputLayer)            (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "fs_input (InputLayer)            (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 632)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 128)           81024                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 256)           33024                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 128)           32896                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 160)           20640                                        \n",
      "____________________________________________________________________________________________________\n",
      "aux_output (Dense)               (None, 160)           5280                                         \n",
      "====================================================================================================\n",
      "Total params: 105,693,688\n",
      "Trainable params: 105,693,688\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss={'main_output': 'categorical_crossentropy', 'aux_output': 'categorical_crossentropy'},\n",
    "              loss_weights={'main_output': 1., 'aux_output': 0.2}, metrics=['accuracy', f1_micro])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.callbacks import EarlyStopping\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "# model.fit(X, y, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import keras.backend as K\n",
    "# K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.train_on_batch(\n",
    "#     {'main_input': x_train[:10], 'wv_input': np.vstack(training_WV)[:10], 'fs_input': np.vstack(training_FS)[:10]},\n",
    "#     {'main_output': y_train[:10], 'aux_output': y_train[:10]}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 5.01 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# And trained it via:\n",
    "batch_size = 700\n",
    "model.fit(\n",
    "    {'main_input': x_train, 'wv_input': wv_train, 'fs_input': fs_train},\n",
    "    {'main_output': y_train, 'aux_output': y_train},\n",
    "    epochs=1, batch_size=batch_size,   # 500\n",
    "    validation_split=0.2,\n",
    "    validation_data=(\n",
    "        {'main_input': x_val, 'wv_input': wv_val, 'fs_input': fs_val},\n",
    "        {'main_output': y_val, 'aux_output': y_val}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 54s - loss: 5.2118 - main_output_loss: 3.9216 - aux_output_loss: 6.4508 - main_output_acc: 0.3954 - main_output_f1_micro: 0.0964 - aux_output_acc: 0.0505 - aux_output_f1_micro: 0.0566 - val_loss: 4.4711 - val_main_output_loss: 3.1595 - val_aux_output_loss: 6.5580 - val_main_output_acc: 0.5260 - val_main_output_f1_micro: 0.1166 - val_aux_output_acc: 0.0423 - val_aux_output_f1_micro: 0.0602\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 54s - loss: 4.6088 - main_output_loss: 3.3304 - aux_output_loss: 6.3919 - main_output_acc: 0.4880 - main_output_f1_micro: 0.1348 - aux_output_acc: 0.0505 - aux_output_f1_micro: 0.0630 - val_loss: 4.1412 - val_main_output_loss: 2.8350 - val_aux_output_loss: 6.5310 - val_main_output_acc: 0.5757 - val_main_output_f1_micro: 0.1521 - val_aux_output_acc: 0.0423 - val_aux_output_f1_micro: 0.0654\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 54s - loss: 4.3826 - main_output_loss: 3.1100 - aux_output_loss: 6.3630 - main_output_acc: 0.5213 - main_output_f1_micro: 0.1680 - aux_output_acc: 0.0505 - aux_output_f1_micro: 0.0674 - val_loss: 4.0103 - val_main_output_loss: 2.7072 - val_aux_output_loss: 6.5155 - val_main_output_acc: 0.5750 - val_main_output_f1_micro: 0.1830 - val_aux_output_acc: 0.0423 - val_aux_output_f1_micro: 0.0691\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 54s - loss: 4.2421 - main_output_loss: 2.9739 - aux_output_loss: 6.3410 - main_output_acc: 0.5374 - main_output_f1_micro: 0.1968 - aux_output_acc: 0.0584 - aux_output_f1_micro: 0.0706 - val_loss: 3.9290 - val_main_output_loss: 2.6312 - val_aux_output_loss: 6.4889 - val_main_output_acc: 0.6002 - val_main_output_f1_micro: 0.2099 - val_aux_output_acc: 0.0780 - val_aux_output_f1_micro: 0.0720\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 54s - loss: 4.1318 - main_output_loss: 2.8689 - aux_output_loss: 6.3149 - main_output_acc: 0.5506 - main_output_f1_micro: 0.2220 - aux_output_acc: 0.0877 - aux_output_f1_micro: 0.0732 - val_loss: 3.8395 - val_main_output_loss: 2.5497 - val_aux_output_loss: 6.4491 - val_main_output_acc: 0.6071 - val_main_output_f1_micro: 0.2338 - val_aux_output_acc: 0.0780 - val_aux_output_f1_micro: 0.0744\n",
      "\n",
      "Done with epoch: 5\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 54s - loss: 4.0476 - main_output_loss: 2.7944 - aux_output_loss: 6.2658 - main_output_acc: 0.5594 - main_output_f1_micro: 0.2445 - aux_output_acc: 0.0876 - aux_output_f1_micro: 0.0755 - val_loss: 3.7397 - val_main_output_loss: 2.4672 - val_aux_output_loss: 6.3627 - val_main_output_acc: 0.6214 - val_main_output_f1_micro: 0.2549 - val_aux_output_acc: 0.0777 - val_aux_output_f1_micro: 0.0766\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 54s - loss: 3.9594 - main_output_loss: 2.7230 - aux_output_loss: 6.1822 - main_output_acc: 0.5714 - main_output_f1_micro: 0.2645 - aux_output_acc: 0.0876 - aux_output_f1_micro: 0.0777 - val_loss: 3.6650 - val_main_output_loss: 2.4119 - val_aux_output_loss: 6.2656 - val_main_output_acc: 0.6179 - val_main_output_f1_micro: 0.2738 - val_aux_output_acc: 0.0777 - val_aux_output_f1_micro: 0.0789\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 54s - loss: 3.8861 - main_output_loss: 2.6686 - aux_output_loss: 6.0876 - main_output_acc: 0.5771 - main_output_f1_micro: 0.2825 - aux_output_acc: 0.0876 - aux_output_f1_micro: 0.0801 - val_loss: 3.5900 - val_main_output_loss: 2.3480 - val_aux_output_loss: 6.2100 - val_main_output_acc: 0.6238 - val_main_output_f1_micro: 0.2909 - val_aux_output_acc: 0.0779 - val_aux_output_f1_micro: 0.0813\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 54s - loss: 3.7951 - main_output_loss: 2.5996 - aux_output_loss: 5.9777 - main_output_acc: 0.5878 - main_output_f1_micro: 0.2988 - aux_output_acc: 0.0882 - aux_output_f1_micro: 0.0824 - val_loss: 3.5240 - val_main_output_loss: 2.3094 - val_aux_output_loss: 6.0729 - val_main_output_acc: 0.6373 - val_main_output_f1_micro: 0.3065 - val_aux_output_acc: 0.0788 - val_aux_output_f1_micro: 0.0836\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 54s - loss: 3.7359 - main_output_loss: 2.5588 - aux_output_loss: 5.8856 - main_output_acc: 0.5939 - main_output_f1_micro: 0.3138 - aux_output_acc: 0.0918 - aux_output_f1_micro: 0.0847 - val_loss: 3.4378 - val_main_output_loss: 2.2438 - val_aux_output_loss: 5.9704 - val_main_output_acc: 0.6434 - val_main_output_f1_micro: 0.3208 - val_aux_output_acc: 0.0827 - val_aux_output_f1_micro: 0.0858\n",
      "\n",
      "Done with epoch: 10\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 55s - loss: 3.6570 - main_output_loss: 2.5001 - aux_output_loss: 5.7846 - main_output_acc: 0.6016 - main_output_f1_micro: 0.3274 - aux_output_acc: 0.1019 - aux_output_f1_micro: 0.0869 - val_loss: 3.3622 - val_main_output_loss: 2.1893 - val_aux_output_loss: 5.8643 - val_main_output_acc: 0.6555 - val_main_output_f1_micro: 0.3339 - val_aux_output_acc: 0.0958 - val_aux_output_f1_micro: 0.0880\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 54s - loss: 3.5879 - main_output_loss: 2.4496 - aux_output_loss: 5.6911 - main_output_acc: 0.6065 - main_output_f1_micro: 0.3400 - aux_output_acc: 0.1109 - aux_output_f1_micro: 0.0890 - val_loss: 3.2984 - val_main_output_loss: 2.1418 - val_aux_output_loss: 5.7828 - val_main_output_acc: 0.6529 - val_main_output_f1_micro: 0.3461 - val_aux_output_acc: 0.1022 - val_aux_output_f1_micro: 0.0900\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 54s - loss: 3.5301 - main_output_loss: 2.4090 - aux_output_loss: 5.6052 - main_output_acc: 0.6100 - main_output_f1_micro: 0.3519 - aux_output_acc: 0.1196 - aux_output_f1_micro: 0.0908 - val_loss: 3.2121 - val_main_output_loss: 2.0751 - val_aux_output_loss: 5.6849 - val_main_output_acc: 0.6666 - val_main_output_f1_micro: 0.3575 - val_aux_output_acc: 0.1122 - val_aux_output_f1_micro: 0.0916\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 54s - loss: 3.4532 - main_output_loss: 2.3534 - aux_output_loss: 5.4991 - main_output_acc: 0.6182 - main_output_f1_micro: 0.3627 - aux_output_acc: 0.1315 - aux_output_f1_micro: 0.0923 - val_loss: 3.1662 - val_main_output_loss: 2.0401 - val_aux_output_loss: 5.6306 - val_main_output_acc: 0.6778 - val_main_output_f1_micro: 0.3678 - val_aux_output_acc: 0.1198 - val_aux_output_f1_micro: 0.0929\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 54s - loss: 3.3937 - main_output_loss: 2.3145 - aux_output_loss: 5.3958 - main_output_acc: 0.6237 - main_output_f1_micro: 0.3728 - aux_output_acc: 0.1541 - aux_output_f1_micro: 0.0935 - val_loss: 3.0905 - val_main_output_loss: 1.9907 - val_aux_output_loss: 5.4993 - val_main_output_acc: 0.6729 - val_main_output_f1_micro: 0.3777 - val_aux_output_acc: 0.1521 - val_aux_output_f1_micro: 0.0940\n",
      "\n",
      "Done with epoch: 15\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 54s - loss: 3.3400 - main_output_loss: 2.2825 - aux_output_loss: 5.2877 - main_output_acc: 0.6289 - main_output_f1_micro: 0.3824 - aux_output_acc: 0.1804 - aux_output_f1_micro: 0.0945 - val_loss: 3.0519 - val_main_output_loss: 1.9723 - val_aux_output_loss: 5.3980 - val_main_output_acc: 0.6805 - val_main_output_f1_micro: 0.3871 - val_aux_output_acc: 0.1752 - val_aux_output_f1_micro: 0.0949\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 54s - loss: 3.2711 - main_output_loss: 2.2385 - aux_output_loss: 5.1631 - main_output_acc: 0.6369 - main_output_f1_micro: 0.3914 - aux_output_acc: 0.2085 - aux_output_f1_micro: 0.0953 - val_loss: 2.9996 - val_main_output_loss: 1.9489 - val_aux_output_loss: 5.2536 - val_main_output_acc: 0.6907 - val_main_output_f1_micro: 0.3958 - val_aux_output_acc: 0.2108 - val_aux_output_f1_micro: 0.0957\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 54s - loss: 3.2128 - main_output_loss: 2.2059 - aux_output_loss: 5.0345 - main_output_acc: 0.6402 - main_output_f1_micro: 0.4000 - aux_output_acc: 0.2362 - aux_output_f1_micro: 0.0960 - val_loss: 2.9241 - val_main_output_loss: 1.8979 - val_aux_output_loss: 5.1315 - val_main_output_acc: 0.6983 - val_main_output_f1_micro: 0.4041 - val_aux_output_acc: 0.2373 - val_aux_output_f1_micro: 0.0964\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 54s - loss: 3.1506 - main_output_loss: 2.1699 - aux_output_loss: 4.9034 - main_output_acc: 0.6480 - main_output_f1_micro: 0.4080 - aux_output_acc: 0.2592 - aux_output_f1_micro: 0.0967 - val_loss: 2.8511 - val_main_output_loss: 1.8475 - val_aux_output_loss: 5.0183 - val_main_output_acc: 0.6963 - val_main_output_f1_micro: 0.4118 - val_aux_output_acc: 0.2504 - val_aux_output_f1_micro: 0.0969\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 54s - loss: 3.0919 - main_output_loss: 2.1370 - aux_output_loss: 4.7748 - main_output_acc: 0.6520 - main_output_f1_micro: 0.4156 - aux_output_acc: 0.2859 - aux_output_f1_micro: 0.0972 - val_loss: 2.8028 - val_main_output_loss: 1.8273 - val_aux_output_loss: 4.8775 - val_main_output_acc: 0.6994 - val_main_output_f1_micro: 0.4192 - val_aux_output_acc: 0.2858 - val_aux_output_f1_micro: 0.0974\n",
      "\n",
      "Done with epoch: 20\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 54s - loss: 3.0379 - main_output_loss: 2.1093 - aux_output_loss: 4.6433 - main_output_acc: 0.6554 - main_output_f1_micro: 0.4227 - aux_output_acc: 0.3097 - aux_output_f1_micro: 0.0977 - val_loss: 2.7438 - val_main_output_loss: 1.7945 - val_aux_output_loss: 4.7464 - val_main_output_acc: 0.7099 - val_main_output_f1_micro: 0.4263 - val_aux_output_acc: 0.3027 - val_aux_output_f1_micro: 0.0979\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.9837 - main_output_loss: 2.0801 - aux_output_loss: 4.5178 - main_output_acc: 0.6608 - main_output_f1_micro: 0.4298 - aux_output_acc: 0.3344 - aux_output_f1_micro: 0.0981 - val_loss: 2.7003 - val_main_output_loss: 1.7740 - val_aux_output_loss: 4.6317 - val_main_output_acc: 0.7088 - val_main_output_f1_micro: 0.4333 - val_aux_output_acc: 0.3339 - val_aux_output_f1_micro: 0.0983\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.9283 - main_output_loss: 2.0502 - aux_output_loss: 4.3903 - main_output_acc: 0.6672 - main_output_f1_micro: 0.4366 - aux_output_acc: 0.3557 - aux_output_f1_micro: 0.0985 - val_loss: 2.6407 - val_main_output_loss: 1.7410 - val_aux_output_loss: 4.4983 - val_main_output_acc: 0.7204 - val_main_output_f1_micro: 0.4398 - val_aux_output_acc: 0.3544 - val_aux_output_f1_micro: 0.0986\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.8781 - main_output_loss: 2.0228 - aux_output_loss: 4.2767 - main_output_acc: 0.6707 - main_output_f1_micro: 0.4429 - aux_output_acc: 0.3769 - aux_output_f1_micro: 0.0988 - val_loss: 2.5961 - val_main_output_loss: 1.7167 - val_aux_output_loss: 4.3969 - val_main_output_acc: 0.7191 - val_main_output_f1_micro: 0.4460 - val_aux_output_acc: 0.3765 - val_aux_output_f1_micro: 0.0989\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.8337 - main_output_loss: 1.9995 - aux_output_loss: 4.1713 - main_output_acc: 0.6760 - main_output_f1_micro: 0.4490 - aux_output_acc: 0.3926 - aux_output_f1_micro: 0.0991 - val_loss: 2.5489 - val_main_output_loss: 1.6961 - val_aux_output_loss: 4.2644 - val_main_output_acc: 0.7290 - val_main_output_f1_micro: 0.4520 - val_aux_output_acc: 0.3985 - val_aux_output_f1_micro: 0.0992\n",
      "\n",
      "Done with epoch: 25\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.7769 - main_output_loss: 1.9669 - aux_output_loss: 4.0501 - main_output_acc: 0.6796 - main_output_f1_micro: 0.4549 - aux_output_acc: 0.4170 - aux_output_f1_micro: 0.0993 - val_loss: 2.4960 - val_main_output_loss: 1.6632 - val_aux_output_loss: 4.1639 - val_main_output_acc: 0.7297 - val_main_output_f1_micro: 0.4577 - val_aux_output_acc: 0.4194 - val_aux_output_f1_micro: 0.0994\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.7371 - main_output_loss: 1.9476 - aux_output_loss: 3.9471 - main_output_acc: 0.6832 - main_output_f1_micro: 0.4605 - aux_output_acc: 0.4343 - aux_output_f1_micro: 0.0996 - val_loss: 2.4515 - val_main_output_loss: 1.6409 - val_aux_output_loss: 4.0531 - val_main_output_acc: 0.7462 - val_main_output_f1_micro: 0.4634 - val_aux_output_acc: 0.4310 - val_aux_output_f1_micro: 0.0997\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.6900 - main_output_loss: 1.9216 - aux_output_loss: 3.8422 - main_output_acc: 0.6886 - main_output_f1_micro: 0.4662 - aux_output_acc: 0.4533 - aux_output_f1_micro: 0.0998 - val_loss: 2.4074 - val_main_output_loss: 1.6172 - val_aux_output_loss: 3.9512 - val_main_output_acc: 0.7427 - val_main_output_f1_micro: 0.4689 - val_aux_output_acc: 0.4499 - val_aux_output_f1_micro: 0.0999\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.6470 - main_output_loss: 1.8988 - aux_output_loss: 3.7411 - main_output_acc: 0.6902 - main_output_f1_micro: 0.4716 - aux_output_acc: 0.4676 - aux_output_f1_micro: 0.1000 - val_loss: 2.3759 - val_main_output_loss: 1.6071 - val_aux_output_loss: 3.8441 - val_main_output_acc: 0.7452 - val_main_output_f1_micro: 0.4743 - val_aux_output_acc: 0.4711 - val_aux_output_f1_micro: 0.1000\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.5995 - main_output_loss: 1.8715 - aux_output_loss: 3.6399 - main_output_acc: 0.6958 - main_output_f1_micro: 0.4769 - aux_output_acc: 0.4846 - aux_output_f1_micro: 0.1001 - val_loss: 2.3243 - val_main_output_loss: 1.5727 - val_aux_output_loss: 3.7578 - val_main_output_acc: 0.7498 - val_main_output_f1_micro: 0.4795 - val_aux_output_acc: 0.4757 - val_aux_output_f1_micro: 0.1002\n",
      "\n",
      "Done with epoch: 30\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.5607 - main_output_loss: 1.8516 - aux_output_loss: 3.5457 - main_output_acc: 0.6991 - main_output_f1_micro: 0.4821 - aux_output_acc: 0.4986 - aux_output_f1_micro: 0.1003 - val_loss: 2.2923 - val_main_output_loss: 1.5636 - val_aux_output_loss: 3.6437 - val_main_output_acc: 0.7454 - val_main_output_f1_micro: 0.4846 - val_aux_output_acc: 0.5035 - val_aux_output_f1_micro: 0.1004\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.5239 - main_output_loss: 1.8332 - aux_output_loss: 3.4534 - main_output_acc: 0.7023 - main_output_f1_micro: 0.4871 - aux_output_acc: 0.5163 - aux_output_f1_micro: 0.1005 - val_loss: 2.2398 - val_main_output_loss: 1.5334 - val_aux_output_loss: 3.5321 - val_main_output_acc: 0.7375 - val_main_output_f1_micro: 0.4896 - val_aux_output_acc: 0.5158 - val_aux_output_f1_micro: 0.1005\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.4882 - main_output_loss: 1.8122 - aux_output_loss: 3.3799 - main_output_acc: 0.7051 - main_output_f1_micro: 0.4921 - aux_output_acc: 0.5265 - aux_output_f1_micro: 0.1006 - val_loss: 2.2180 - val_main_output_loss: 1.5271 - val_aux_output_loss: 3.4542 - val_main_output_acc: 0.7504 - val_main_output_f1_micro: 0.4945 - val_aux_output_acc: 0.5251 - val_aux_output_f1_micro: 0.1007\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.4474 - main_output_loss: 1.7900 - aux_output_loss: 3.2870 - main_output_acc: 0.7100 - main_output_f1_micro: 0.4969 - aux_output_acc: 0.5414 - aux_output_f1_micro: 0.1008 - val_loss: 2.1817 - val_main_output_loss: 1.5084 - val_aux_output_loss: 3.3668 - val_main_output_acc: 0.7572 - val_main_output_f1_micro: 0.4994 - val_aux_output_acc: 0.5398 - val_aux_output_f1_micro: 0.1008\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56877/56877 [==============================] - 54s - loss: 2.4201 - main_output_loss: 1.7781 - aux_output_loss: 3.2101 - main_output_acc: 0.7107 - main_output_f1_micro: 0.5018 - aux_output_acc: 0.5532 - aux_output_f1_micro: 0.1009 - val_loss: 2.1514 - val_main_output_loss: 1.4922 - val_aux_output_loss: 3.2963 - val_main_output_acc: 0.7571 - val_main_output_f1_micro: 0.5041 - val_aux_output_acc: 0.5457 - val_aux_output_f1_micro: 0.1010\n",
      "\n",
      "Done with epoch: 35\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.3810 - main_output_loss: 1.7538 - aux_output_loss: 3.1363 - main_output_acc: 0.7167 - main_output_f1_micro: 0.5064 - aux_output_acc: 0.5650 - aux_output_f1_micro: 0.1010 - val_loss: 2.1175 - val_main_output_loss: 1.4740 - val_aux_output_loss: 3.2177 - val_main_output_acc: 0.7616 - val_main_output_f1_micro: 0.5087 - val_aux_output_acc: 0.5666 - val_aux_output_f1_micro: 0.1011\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.3590 - main_output_loss: 1.7448 - aux_output_loss: 3.0711 - main_output_acc: 0.7140 - main_output_f1_micro: 0.5109 - aux_output_acc: 0.5753 - aux_output_f1_micro: 0.1011 - val_loss: 2.0935 - val_main_output_loss: 1.4640 - val_aux_output_loss: 3.1474 - val_main_output_acc: 0.7699 - val_main_output_f1_micro: 0.5132 - val_aux_output_acc: 0.5723 - val_aux_output_f1_micro: 0.1012\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.3272 - main_output_loss: 1.7266 - aux_output_loss: 3.0031 - main_output_acc: 0.7179 - main_output_f1_micro: 0.5153 - aux_output_acc: 0.5848 - aux_output_f1_micro: 0.1013 - val_loss: 2.0605 - val_main_output_loss: 1.4456 - val_aux_output_loss: 3.0746 - val_main_output_acc: 0.7674 - val_main_output_f1_micro: 0.5175 - val_aux_output_acc: 0.5871 - val_aux_output_f1_micro: 0.1013\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.2951 - main_output_loss: 1.7073 - aux_output_loss: 2.9386 - main_output_acc: 0.7257 - main_output_f1_micro: 0.5197 - aux_output_acc: 0.5958 - aux_output_f1_micro: 0.1014 - val_loss: 2.0300 - val_main_output_loss: 1.4257 - val_aux_output_loss: 3.0216 - val_main_output_acc: 0.7714 - val_main_output_f1_micro: 0.5218 - val_aux_output_acc: 0.5903 - val_aux_output_f1_micro: 0.1014\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.2726 - main_output_loss: 1.6964 - aux_output_loss: 2.8809 - main_output_acc: 0.7268 - main_output_f1_micro: 0.5239 - aux_output_acc: 0.6049 - aux_output_f1_micro: 0.1015 - val_loss: 2.0089 - val_main_output_loss: 1.4189 - val_aux_output_loss: 2.9501 - val_main_output_acc: 0.7750 - val_main_output_f1_micro: 0.5260 - val_aux_output_acc: 0.6028 - val_aux_output_f1_micro: 0.1015\n",
      "\n",
      "Done with epoch: 40\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.2490 - main_output_loss: 1.6851 - aux_output_loss: 2.8197 - main_output_acc: 0.7279 - main_output_f1_micro: 0.5280 - aux_output_acc: 0.6144 - aux_output_f1_micro: 0.1016 - val_loss: 1.9885 - val_main_output_loss: 1.4123 - val_aux_output_loss: 2.8810 - val_main_output_acc: 0.7708 - val_main_output_f1_micro: 0.5301 - val_aux_output_acc: 0.6153 - val_aux_output_f1_micro: 0.1016\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.2138 - main_output_loss: 1.6626 - aux_output_loss: 2.7559 - main_output_acc: 0.7291 - main_output_f1_micro: 0.5321 - aux_output_acc: 0.6221 - aux_output_f1_micro: 0.1017 - val_loss: 1.9535 - val_main_output_loss: 1.3913 - val_aux_output_loss: 2.8113 - val_main_output_acc: 0.7735 - val_main_output_f1_micro: 0.5342 - val_aux_output_acc: 0.6187 - val_aux_output_f1_micro: 0.1018\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.1906 - main_output_loss: 1.6514 - aux_output_loss: 2.6959 - main_output_acc: 0.7329 - main_output_f1_micro: 0.5362 - aux_output_acc: 0.6322 - aux_output_f1_micro: 0.1019 - val_loss: 1.9318 - val_main_output_loss: 1.3807 - val_aux_output_loss: 2.7557 - val_main_output_acc: 0.7783 - val_main_output_f1_micro: 0.5381 - val_aux_output_acc: 0.6312 - val_aux_output_f1_micro: 0.1019\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.1599 - main_output_loss: 1.6319 - aux_output_loss: 2.6403 - main_output_acc: 0.7366 - main_output_f1_micro: 0.5401 - aux_output_acc: 0.6399 - aux_output_f1_micro: 0.1020 - val_loss: 1.9139 - val_main_output_loss: 1.3711 - val_aux_output_loss: 2.7140 - val_main_output_acc: 0.7698 - val_main_output_f1_micro: 0.5420 - val_aux_output_acc: 0.6348 - val_aux_output_f1_micro: 0.1021\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.1383 - main_output_loss: 1.6203 - aux_output_loss: 2.5903 - main_output_acc: 0.7367 - main_output_f1_micro: 0.5439 - aux_output_acc: 0.6477 - aux_output_f1_micro: 0.1021 - val_loss: 1.8924 - val_main_output_loss: 1.3597 - val_aux_output_loss: 2.6636 - val_main_output_acc: 0.7813 - val_main_output_f1_micro: 0.5458 - val_aux_output_acc: 0.6404 - val_aux_output_f1_micro: 0.1022\n",
      "\n",
      "Done with epoch: 45\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.1155 - main_output_loss: 1.6075 - aux_output_loss: 2.5402 - main_output_acc: 0.7401 - main_output_f1_micro: 0.5477 - aux_output_acc: 0.6529 - aux_output_f1_micro: 0.1023 - val_loss: 1.8726 - val_main_output_loss: 1.3510 - val_aux_output_loss: 2.6078 - val_main_output_acc: 0.7793 - val_main_output_f1_micro: 0.5495 - val_aux_output_acc: 0.6499 - val_aux_output_f1_micro: 0.1023\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.0968 - main_output_loss: 1.5989 - aux_output_loss: 2.4895 - main_output_acc: 0.7419 - main_output_f1_micro: 0.5514 - aux_output_acc: 0.6608 - aux_output_f1_micro: 0.1024 - val_loss: 1.8576 - val_main_output_loss: 1.3447 - val_aux_output_loss: 2.5641 - val_main_output_acc: 0.7830 - val_main_output_f1_micro: 0.5533 - val_aux_output_acc: 0.6595 - val_aux_output_f1_micro: 0.1025\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.0724 - main_output_loss: 1.5838 - aux_output_loss: 2.4429 - main_output_acc: 0.7419 - main_output_f1_micro: 0.5552 - aux_output_acc: 0.6708 - aux_output_f1_micro: 0.1025 - val_loss: 1.8229 - val_main_output_loss: 1.3211 - val_aux_output_loss: 2.5087 - val_main_output_acc: 0.7826 - val_main_output_f1_micro: 0.5570 - val_aux_output_acc: 0.6652 - val_aux_output_f1_micro: 0.1026\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.0545 - main_output_loss: 1.5745 - aux_output_loss: 2.4002 - main_output_acc: 0.7453 - main_output_f1_micro: 0.5588 - aux_output_acc: 0.6765 - aux_output_f1_micro: 0.1027 - val_loss: 1.8056 - val_main_output_loss: 1.3133 - val_aux_output_loss: 2.4618 - val_main_output_acc: 0.7825 - val_main_output_f1_micro: 0.5606 - val_aux_output_acc: 0.6717 - val_aux_output_f1_micro: 0.1028\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.0365 - main_output_loss: 1.5651 - aux_output_loss: 2.3568 - main_output_acc: 0.7462 - main_output_f1_micro: 0.5623 - aux_output_acc: 0.6816 - aux_output_f1_micro: 0.1029 - val_loss: 1.7922 - val_main_output_loss: 1.3070 - val_aux_output_loss: 2.4259 - val_main_output_acc: 0.7816 - val_main_output_f1_micro: 0.5641 - val_aux_output_acc: 0.6786 - val_aux_output_f1_micro: 0.1030\n",
      "\n",
      "Done with epoch: 50\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.0147 - main_output_loss: 1.5515 - aux_output_loss: 2.3161 - main_output_acc: 0.7507 - main_output_f1_micro: 0.5659 - aux_output_acc: 0.6892 - aux_output_f1_micro: 0.1031 - val_loss: 1.7716 - val_main_output_loss: 1.2954 - val_aux_output_loss: 2.3809 - val_main_output_acc: 0.7887 - val_main_output_f1_micro: 0.5677 - val_aux_output_acc: 0.6872 - val_aux_output_f1_micro: 0.1032\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.9892 - main_output_loss: 1.5347 - aux_output_loss: 2.2726 - main_output_acc: 0.7502 - main_output_f1_micro: 0.5694 - aux_output_acc: 0.6944 - aux_output_f1_micro: 0.1033 - val_loss: 1.7565 - val_main_output_loss: 1.2890 - val_aux_output_loss: 2.3375 - val_main_output_acc: 0.7746 - val_main_output_f1_micro: 0.5711 - val_aux_output_acc: 0.6896 - val_aux_output_f1_micro: 0.1034\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.9757 - main_output_loss: 1.5292 - aux_output_loss: 2.2328 - main_output_acc: 0.7538 - main_output_f1_micro: 0.5728 - aux_output_acc: 0.7013 - aux_output_f1_micro: 0.1035 - val_loss: 1.7306 - val_main_output_loss: 1.2723 - val_aux_output_loss: 2.2917 - val_main_output_acc: 0.7858 - val_main_output_f1_micro: 0.5745 - val_aux_output_acc: 0.6980 - val_aux_output_f1_micro: 0.1036\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.9598 - main_output_loss: 1.5207 - aux_output_loss: 2.1956 - main_output_acc: 0.7544 - main_output_f1_micro: 0.5762 - aux_output_acc: 0.7062 - aux_output_f1_micro: 0.1037 - val_loss: 1.7158 - val_main_output_loss: 1.2634 - val_aux_output_loss: 2.2619 - val_main_output_acc: 0.7956 - val_main_output_f1_micro: 0.5779 - val_aux_output_acc: 0.7129 - val_aux_output_f1_micro: 0.1038\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.9386 - main_output_loss: 1.5060 - aux_output_loss: 2.1628 - main_output_acc: 0.7556 - main_output_f1_micro: 0.5795 - aux_output_acc: 0.7124 - aux_output_f1_micro: 0.1040 - val_loss: 1.7130 - val_main_output_loss: 1.2667 - val_aux_output_loss: 2.2313 - val_main_output_acc: 0.7895 - val_main_output_f1_micro: 0.5812 - val_aux_output_acc: 0.7100 - val_aux_output_f1_micro: 0.1041\n",
      "\n",
      "Done with epoch: 55\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.9207 - main_output_loss: 1.4954 - aux_output_loss: 2.1264 - main_output_acc: 0.7566 - main_output_f1_micro: 0.5828 - aux_output_acc: 0.7165 - aux_output_f1_micro: 0.1042 - val_loss: 1.6861 - val_main_output_loss: 1.2479 - val_aux_output_loss: 2.1912 - val_main_output_acc: 0.7926 - val_main_output_f1_micro: 0.5845 - val_aux_output_acc: 0.7230 - val_aux_output_f1_micro: 0.1043\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.9007 - main_output_loss: 1.4826 - aux_output_loss: 2.0904 - main_output_acc: 0.7580 - main_output_f1_micro: 0.5861 - aux_output_acc: 0.7228 - aux_output_f1_micro: 0.1044 - val_loss: 1.6809 - val_main_output_loss: 1.2473 - val_aux_output_loss: 2.1679 - val_main_output_acc: 0.7973 - val_main_output_f1_micro: 0.5878 - val_aux_output_acc: 0.7213 - val_aux_output_f1_micro: 0.1046\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.8934 - main_output_loss: 1.4815 - aux_output_loss: 2.0592 - main_output_acc: 0.7580 - main_output_f1_micro: 0.5894 - aux_output_acc: 0.7257 - aux_output_f1_micro: 0.1047 - val_loss: 1.6715 - val_main_output_loss: 1.2442 - val_aux_output_loss: 2.1364 - val_main_output_acc: 0.7913 - val_main_output_f1_micro: 0.5910 - val_aux_output_acc: 0.7262 - val_aux_output_f1_micro: 0.1048\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.8786 - main_output_loss: 1.4732 - aux_output_loss: 2.0270 - main_output_acc: 0.7599 - main_output_f1_micro: 0.5926 - aux_output_acc: 0.7298 - aux_output_f1_micro: 0.1050 - val_loss: 1.6551 - val_main_output_loss: 1.2351 - val_aux_output_loss: 2.0997 - val_main_output_acc: 0.7935 - val_main_output_f1_micro: 0.5942 - val_aux_output_acc: 0.7258 - val_aux_output_f1_micro: 0.1051\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.8597 - main_output_loss: 1.4606 - aux_output_loss: 1.9957 - main_output_acc: 0.7605 - main_output_f1_micro: 0.5957 - aux_output_acc: 0.7337 - aux_output_f1_micro: 0.1053 - val_loss: 1.6395 - val_main_output_loss: 1.2254 - val_aux_output_loss: 2.0708 - val_main_output_acc: 0.7826 - val_main_output_f1_micro: 0.5973 - val_aux_output_acc: 0.7289 - val_aux_output_f1_micro: 0.1054\n",
      "\n",
      "Done with epoch: 60\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.8449 - main_output_loss: 1.4516 - aux_output_loss: 1.9664 - main_output_acc: 0.7603 - main_output_f1_micro: 0.5988 - aux_output_acc: 0.7379 - aux_output_f1_micro: 0.1056 - val_loss: 1.6340 - val_main_output_loss: 1.2246 - val_aux_output_loss: 2.0469 - val_main_output_acc: 0.7829 - val_main_output_f1_micro: 0.6004 - val_aux_output_acc: 0.7378 - val_aux_output_f1_micro: 0.1058\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.8381 - main_output_loss: 1.4499 - aux_output_loss: 1.9407 - main_output_acc: 0.7618 - main_output_f1_micro: 0.6019 - aux_output_acc: 0.7414 - aux_output_f1_micro: 0.1059 - val_loss: 1.6271 - val_main_output_loss: 1.2229 - val_aux_output_loss: 2.0207 - val_main_output_acc: 0.7869 - val_main_output_f1_micro: 0.6034 - val_aux_output_acc: 0.7361 - val_aux_output_f1_micro: 0.1061\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.8203 - main_output_loss: 1.4372 - aux_output_loss: 1.9156 - main_output_acc: 0.7647 - main_output_f1_micro: 0.6050 - aux_output_acc: 0.7441 - aux_output_f1_micro: 0.1062 - val_loss: 1.6053 - val_main_output_loss: 1.2059 - val_aux_output_loss: 1.9967 - val_main_output_acc: 0.7919 - val_main_output_f1_micro: 0.6065 - val_aux_output_acc: 0.7400 - val_aux_output_f1_micro: 0.1064\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.8145 - main_output_loss: 1.4363 - aux_output_loss: 1.8911 - main_output_acc: 0.7660 - main_output_f1_micro: 0.6079 - aux_output_acc: 0.7465 - aux_output_f1_micro: 0.1066 - val_loss: 1.5987 - val_main_output_loss: 1.2049 - val_aux_output_loss: 1.9686 - val_main_output_acc: 0.7921 - val_main_output_f1_micro: 0.6094 - val_aux_output_acc: 0.7443 - val_aux_output_f1_micro: 0.1068\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.7974 - main_output_loss: 1.4246 - aux_output_loss: 1.8642 - main_output_acc: 0.7628 - main_output_f1_micro: 0.6108 - aux_output_acc: 0.7498 - aux_output_f1_micro: 0.1070 - val_loss: 1.5834 - val_main_output_loss: 1.1951 - val_aux_output_loss: 1.9415 - val_main_output_acc: 0.7959 - val_main_output_f1_micro: 0.6123 - val_aux_output_acc: 0.7463 - val_aux_output_f1_micro: 0.1072\n",
      "\n",
      "Done with epoch: 65\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.7860 - main_output_loss: 1.4174 - aux_output_loss: 1.8427 - main_output_acc: 0.7648 - main_output_f1_micro: 0.6137 - aux_output_acc: 0.7541 - aux_output_f1_micro: 0.1074 - val_loss: 1.5803 - val_main_output_loss: 1.1956 - val_aux_output_loss: 1.9234 - val_main_output_acc: 0.7934 - val_main_output_f1_micro: 0.6151 - val_aux_output_acc: 0.7540 - val_aux_output_f1_micro: 0.1076\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.7767 - main_output_loss: 1.4129 - aux_output_loss: 1.8187 - main_output_acc: 0.7660 - main_output_f1_micro: 0.6166 - aux_output_acc: 0.7560 - aux_output_f1_micro: 0.1079 - val_loss: 1.5710 - val_main_output_loss: 1.1917 - val_aux_output_loss: 1.8962 - val_main_output_acc: 0.7926 - val_main_output_f1_micro: 0.6180 - val_aux_output_acc: 0.7546 - val_aux_output_f1_micro: 0.1081\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.7605 - main_output_loss: 1.4011 - aux_output_loss: 1.7971 - main_output_acc: 0.7678 - main_output_f1_micro: 0.6194 - aux_output_acc: 0.7584 - aux_output_f1_micro: 0.1083 - val_loss: 1.5544 - val_main_output_loss: 1.1809 - val_aux_output_loss: 1.8675 - val_main_output_acc: 0.7998 - val_main_output_f1_micro: 0.6208 - val_aux_output_acc: 0.7592 - val_aux_output_f1_micro: 0.1085\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56877/56877 [==============================] - 76s - loss: 1.7577 - main_output_loss: 1.4024 - aux_output_loss: 1.7764 - main_output_acc: 0.7700 - main_output_f1_micro: 0.6221 - aux_output_acc: 0.7593 - aux_output_f1_micro: 0.1087 - val_loss: 1.5486 - val_main_output_loss: 1.1782 - val_aux_output_loss: 1.8520 - val_main_output_acc: 0.7963 - val_main_output_f1_micro: 0.6235 - val_aux_output_acc: 0.7546 - val_aux_output_f1_micro: 0.1089\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.7429 - main_output_loss: 1.3917 - aux_output_loss: 1.7561 - main_output_acc: 0.7709 - main_output_f1_micro: 0.6248 - aux_output_acc: 0.7618 - aux_output_f1_micro: 0.1091 - val_loss: 1.5413 - val_main_output_loss: 1.1744 - val_aux_output_loss: 1.8347 - val_main_output_acc: 0.7902 - val_main_output_f1_micro: 0.6262 - val_aux_output_acc: 0.7626 - val_aux_output_f1_micro: 0.1094\n",
      "\n",
      "Done with epoch: 70\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.7346 - main_output_loss: 1.3872 - aux_output_loss: 1.7367 - main_output_acc: 0.7706 - main_output_f1_micro: 0.6275 - aux_output_acc: 0.7647 - aux_output_f1_micro: 0.1096 - val_loss: 1.5279 - val_main_output_loss: 1.1659 - val_aux_output_loss: 1.8095 - val_main_output_acc: 0.7964 - val_main_output_f1_micro: 0.6289 - val_aux_output_acc: 0.7624 - val_aux_output_f1_micro: 0.1098\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.7296 - main_output_loss: 1.3861 - aux_output_loss: 1.7177 - main_output_acc: 0.7711 - main_output_f1_micro: 0.6302 - aux_output_acc: 0.7684 - aux_output_f1_micro: 0.1100 - val_loss: 1.5211 - val_main_output_loss: 1.1626 - val_aux_output_loss: 1.7928 - val_main_output_acc: 0.7945 - val_main_output_f1_micro: 0.6315 - val_aux_output_acc: 0.7617 - val_aux_output_f1_micro: 0.1102\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.7127 - main_output_loss: 1.3730 - aux_output_loss: 1.6985 - main_output_acc: 0.7708 - main_output_f1_micro: 0.6328 - aux_output_acc: 0.7683 - aux_output_f1_micro: 0.1105 - val_loss: 1.5149 - val_main_output_loss: 1.1607 - val_aux_output_loss: 1.7708 - val_main_output_acc: 0.7972 - val_main_output_f1_micro: 0.6341 - val_aux_output_acc: 0.7615 - val_aux_output_f1_micro: 0.1107\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.7023 - main_output_loss: 1.3664 - aux_output_loss: 1.6797 - main_output_acc: 0.7729 - main_output_f1_micro: 0.6354 - aux_output_acc: 0.7722 - aux_output_f1_micro: 0.1109 - val_loss: 1.5071 - val_main_output_loss: 1.1560 - val_aux_output_loss: 1.7558 - val_main_output_acc: 0.7930 - val_main_output_f1_micro: 0.6367 - val_aux_output_acc: 0.7670 - val_aux_output_f1_micro: 0.1111\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.6884 - main_output_loss: 1.3553 - aux_output_loss: 1.6659 - main_output_acc: 0.7720 - main_output_f1_micro: 0.6379 - aux_output_acc: 0.7726 - aux_output_f1_micro: 0.1113 - val_loss: 1.5019 - val_main_output_loss: 1.1535 - val_aux_output_loss: 1.7419 - val_main_output_acc: 0.7952 - val_main_output_f1_micro: 0.6392 - val_aux_output_acc: 0.7741 - val_aux_output_f1_micro: 0.1116\n",
      "\n",
      "Done with epoch: 75\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.6801 - main_output_loss: 1.3499 - aux_output_loss: 1.6511 - main_output_acc: 0.7763 - main_output_f1_micro: 0.6405 - aux_output_acc: 0.7744 - aux_output_f1_micro: 0.1118 - val_loss: 1.4951 - val_main_output_loss: 1.1497 - val_aux_output_loss: 1.7270 - val_main_output_acc: 0.7942 - val_main_output_f1_micro: 0.6417 - val_aux_output_acc: 0.7742 - val_aux_output_f1_micro: 0.1121\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.6840 - main_output_loss: 1.3569 - aux_output_loss: 1.6359 - main_output_acc: 0.7712 - main_output_f1_micro: 0.6430 - aux_output_acc: 0.7728 - aux_output_f1_micro: 0.1123 - val_loss: 1.4922 - val_main_output_loss: 1.1502 - val_aux_output_loss: 1.7100 - val_main_output_acc: 0.7822 - val_main_output_f1_micro: 0.6442 - val_aux_output_acc: 0.7727 - val_aux_output_f1_micro: 0.1126\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.6674 - main_output_loss: 1.3433 - aux_output_loss: 1.6205 - main_output_acc: 0.7755 - main_output_f1_micro: 0.6454 - aux_output_acc: 0.7758 - aux_output_f1_micro: 0.1129 - val_loss: 1.4845 - val_main_output_loss: 1.1447 - val_aux_output_loss: 1.6992 - val_main_output_acc: 0.7947 - val_main_output_f1_micro: 0.6466 - val_aux_output_acc: 0.7724 - val_aux_output_f1_micro: 0.1131\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.6636 - main_output_loss: 1.3424 - aux_output_loss: 1.6058 - main_output_acc: 0.7763 - main_output_f1_micro: 0.6478 - aux_output_acc: 0.7776 - aux_output_f1_micro: 0.1134 - val_loss: 1.4726 - val_main_output_loss: 1.1369 - val_aux_output_loss: 1.6783 - val_main_output_acc: 0.7918 - val_main_output_f1_micro: 0.6490 - val_aux_output_acc: 0.7763 - val_aux_output_f1_micro: 0.1137\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.6538 - main_output_loss: 1.3353 - aux_output_loss: 1.5924 - main_output_acc: 0.7735 - main_output_f1_micro: 0.6502 - aux_output_acc: 0.7789 - aux_output_f1_micro: 0.1139 - val_loss: 1.4678 - val_main_output_loss: 1.1352 - val_aux_output_loss: 1.6629 - val_main_output_acc: 0.7877 - val_main_output_f1_micro: 0.6514 - val_aux_output_acc: 0.7792 - val_aux_output_f1_micro: 0.1142\n",
      "\n",
      "Done with epoch: 80\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.6469 - main_output_loss: 1.3317 - aux_output_loss: 1.5758 - main_output_acc: 0.7756 - main_output_f1_micro: 0.6526 - aux_output_acc: 0.7808 - aux_output_f1_micro: 0.1144 - val_loss: 1.4604 - val_main_output_loss: 1.1302 - val_aux_output_loss: 1.6509 - val_main_output_acc: 0.7926 - val_main_output_f1_micro: 0.6538 - val_aux_output_acc: 0.7808 - val_aux_output_f1_micro: 0.1147\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.6405 - main_output_loss: 1.3280 - aux_output_loss: 1.5624 - main_output_acc: 0.7748 - main_output_f1_micro: 0.6549 - aux_output_acc: 0.7788 - aux_output_f1_micro: 0.1149 - val_loss: 1.4537 - val_main_output_loss: 1.1263 - val_aux_output_loss: 1.6370 - val_main_output_acc: 0.7895 - val_main_output_f1_micro: 0.6560 - val_aux_output_acc: 0.7853 - val_aux_output_f1_micro: 0.1152\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.6329 - main_output_loss: 1.3233 - aux_output_loss: 1.5481 - main_output_acc: 0.7740 - main_output_f1_micro: 0.6572 - aux_output_acc: 0.7825 - aux_output_f1_micro: 0.1155 - val_loss: 1.4512 - val_main_output_loss: 1.1250 - val_aux_output_loss: 1.6307 - val_main_output_acc: 0.7955 - val_main_output_f1_micro: 0.6583 - val_aux_output_acc: 0.7824 - val_aux_output_f1_micro: 0.1158\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.6184 - main_output_loss: 1.3109 - aux_output_loss: 1.5378 - main_output_acc: 0.7752 - main_output_f1_micro: 0.6594 - aux_output_acc: 0.7834 - aux_output_f1_micro: 0.1160 - val_loss: 1.4373 - val_main_output_loss: 1.1147 - val_aux_output_loss: 1.6131 - val_main_output_acc: 0.7915 - val_main_output_f1_micro: 0.6605 - val_aux_output_acc: 0.7820 - val_aux_output_f1_micro: 0.1163\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.6130 - main_output_loss: 1.3087 - aux_output_loss: 1.5215 - main_output_acc: 0.7746 - main_output_f1_micro: 0.6616 - aux_output_acc: 0.7839 - aux_output_f1_micro: 0.1165 - val_loss: 1.4313 - val_main_output_loss: 1.1122 - val_aux_output_loss: 1.5956 - val_main_output_acc: 0.7899 - val_main_output_f1_micro: 0.6627 - val_aux_output_acc: 0.7864 - val_aux_output_f1_micro: 0.1168\n",
      "\n",
      "Done with epoch: 85\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.6070 - main_output_loss: 1.3045 - aux_output_loss: 1.5124 - main_output_acc: 0.7732 - main_output_f1_micro: 0.6638 - aux_output_acc: 0.7851 - aux_output_f1_micro: 0.1171 - val_loss: 1.4296 - val_main_output_loss: 1.1127 - val_aux_output_loss: 1.5845 - val_main_output_acc: 0.7967 - val_main_output_f1_micro: 0.6649 - val_aux_output_acc: 0.7855 - val_aux_output_f1_micro: 0.1173\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.6053 - main_output_loss: 1.3051 - aux_output_loss: 1.5010 - main_output_acc: 0.7761 - main_output_f1_micro: 0.6660 - aux_output_acc: 0.7871 - aux_output_f1_micro: 0.1176 - val_loss: 1.4213 - val_main_output_loss: 1.1073 - val_aux_output_loss: 1.5697 - val_main_output_acc: 0.7932 - val_main_output_f1_micro: 0.6671 - val_aux_output_acc: 0.7855 - val_aux_output_f1_micro: 0.1179\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.5996 - main_output_loss: 1.3014 - aux_output_loss: 1.4911 - main_output_acc: 0.7772 - main_output_f1_micro: 0.6682 - aux_output_acc: 0.7885 - aux_output_f1_micro: 0.1182 - val_loss: 1.4131 - val_main_output_loss: 1.1005 - val_aux_output_loss: 1.5629 - val_main_output_acc: 0.7884 - val_main_output_f1_micro: 0.6693 - val_aux_output_acc: 0.7869 - val_aux_output_f1_micro: 0.1184\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.5926 - main_output_loss: 1.2964 - aux_output_loss: 1.4808 - main_output_acc: 0.7775 - main_output_f1_micro: 0.6703 - aux_output_acc: 0.7872 - aux_output_f1_micro: 0.1187 - val_loss: 1.4177 - val_main_output_loss: 1.1069 - val_aux_output_loss: 1.5543 - val_main_output_acc: 0.7968 - val_main_output_f1_micro: 0.6714 - val_aux_output_acc: 0.7844 - val_aux_output_f1_micro: 0.1190\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.5870 - main_output_loss: 1.2927 - aux_output_loss: 1.4711 - main_output_acc: 0.7789 - main_output_f1_micro: 0.6724 - aux_output_acc: 0.7891 - aux_output_f1_micro: 0.1192 - val_loss: 1.4138 - val_main_output_loss: 1.1048 - val_aux_output_loss: 1.5450 - val_main_output_acc: 0.8036 - val_main_output_f1_micro: 0.6735 - val_aux_output_acc: 0.7880 - val_aux_output_f1_micro: 0.1195\n",
      "\n",
      "Done with epoch: 90\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.5793 - main_output_loss: 1.2868 - aux_output_loss: 1.4623 - main_output_acc: 0.7801 - main_output_f1_micro: 0.6745 - aux_output_acc: 0.7902 - aux_output_f1_micro: 0.1198 - val_loss: 1.4006 - val_main_output_loss: 1.0931 - val_aux_output_loss: 1.5374 - val_main_output_acc: 0.8048 - val_main_output_f1_micro: 0.6755 - val_aux_output_acc: 0.7885 - val_aux_output_f1_micro: 0.1201\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.5749 - main_output_loss: 1.2845 - aux_output_loss: 1.4523 - main_output_acc: 0.7777 - main_output_f1_micro: 0.6765 - aux_output_acc: 0.7894 - aux_output_f1_micro: 0.1204 - val_loss: 1.3991 - val_main_output_loss: 1.0933 - val_aux_output_loss: 1.5287 - val_main_output_acc: 0.7991 - val_main_output_f1_micro: 0.6775 - val_aux_output_acc: 0.7950 - val_aux_output_f1_micro: 0.1208\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.5653 - main_output_loss: 1.2768 - aux_output_loss: 1.4423 - main_output_acc: 0.7802 - main_output_f1_micro: 0.6785 - aux_output_acc: 0.7921 - aux_output_f1_micro: 0.1211 - val_loss: 1.3877 - val_main_output_loss: 1.0851 - val_aux_output_loss: 1.5132 - val_main_output_acc: 0.7907 - val_main_output_f1_micro: 0.6795 - val_aux_output_acc: 0.7946 - val_aux_output_f1_micro: 0.1214\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.5695 - main_output_loss: 1.2829 - aux_output_loss: 1.4328 - main_output_acc: 0.7774 - main_output_f1_micro: 0.6805 - aux_output_acc: 0.7920 - aux_output_f1_micro: 0.1217 - val_loss: 1.3919 - val_main_output_loss: 1.0897 - val_aux_output_loss: 1.5105 - val_main_output_acc: 0.7906 - val_main_output_f1_micro: 0.6815 - val_aux_output_acc: 0.7915 - val_aux_output_f1_micro: 0.1220\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.5629 - main_output_loss: 1.2782 - aux_output_loss: 1.4236 - main_output_acc: 0.7783 - main_output_f1_micro: 0.6824 - aux_output_acc: 0.7933 - aux_output_f1_micro: 0.1223 - val_loss: 1.3928 - val_main_output_loss: 1.0933 - val_aux_output_loss: 1.4977 - val_main_output_acc: 0.7844 - val_main_output_f1_micro: 0.6834 - val_aux_output_acc: 0.7953 - val_aux_output_f1_micro: 0.1226\n",
      "\n",
      "Done with epoch: 95\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.5537 - main_output_loss: 1.2710 - aux_output_loss: 1.4138 - main_output_acc: 0.7817 - main_output_f1_micro: 0.6844 - aux_output_acc: 0.7946 - aux_output_f1_micro: 0.1229 - val_loss: 1.3793 - val_main_output_loss: 1.0822 - val_aux_output_loss: 1.4851 - val_main_output_acc: 0.7969 - val_main_output_f1_micro: 0.6853 - val_aux_output_acc: 0.7956 - val_aux_output_f1_micro: 0.1233\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.5482 - main_output_loss: 1.2670 - aux_output_loss: 1.4060 - main_output_acc: 0.7811 - main_output_f1_micro: 0.6863 - aux_output_acc: 0.7947 - aux_output_f1_micro: 0.1236 - val_loss: 1.3849 - val_main_output_loss: 1.0889 - val_aux_output_loss: 1.4799 - val_main_output_acc: 0.7939 - val_main_output_f1_micro: 0.6872 - val_aux_output_acc: 0.7922 - val_aux_output_f1_micro: 0.1238\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.5412 - main_output_loss: 1.2616 - aux_output_loss: 1.3981 - main_output_acc: 0.7810 - main_output_f1_micro: 0.6881 - aux_output_acc: 0.7947 - aux_output_f1_micro: 0.1241 - val_loss: 1.3801 - val_main_output_loss: 1.0851 - val_aux_output_loss: 1.4752 - val_main_output_acc: 0.7940 - val_main_output_f1_micro: 0.6891 - val_aux_output_acc: 0.7971 - val_aux_output_f1_micro: 0.1244\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.5424 - main_output_loss: 1.2634 - aux_output_loss: 1.3950 - main_output_acc: 0.7808 - main_output_f1_micro: 0.6900 - aux_output_acc: 0.7922 - aux_output_f1_micro: 0.1247 - val_loss: 1.3652 - val_main_output_loss: 1.0722 - val_aux_output_loss: 1.4651 - val_main_output_acc: 0.7955 - val_main_output_f1_micro: 0.6909 - val_aux_output_acc: 0.7987 - val_aux_output_f1_micro: 0.1250\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.5393 - main_output_loss: 1.2625 - aux_output_loss: 1.3838 - main_output_acc: 0.7823 - main_output_f1_micro: 0.6918 - aux_output_acc: 0.7961 - aux_output_f1_micro: 0.1253 - val_loss: 1.3725 - val_main_output_loss: 1.0813 - val_aux_output_loss: 1.4562 - val_main_output_acc: 0.8079 - val_main_output_f1_micro: 0.6927 - val_aux_output_acc: 0.7994 - val_aux_output_f1_micro: 0.1256\n",
      "\n",
      "Done with epoch: 100\n",
      "\n",
      "CPU times: user 1h 49min 4s, sys: 9min 34s, total: 1h 58min 38s\n",
      "Wall time: 1h 31min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_name = 'models/lstm-word2vec-fasttext_2012-2014-data_categorical-crossentropy-2014-b-val-sc_wv_fs.model'\n",
    "epochs = 5\n",
    "for i in xrange(0, 100 // epochs):\n",
    "    hist = model.fit(\n",
    "        {'main_input': x_train, 'wv_input': wv_train, 'fs_input': fs_train},\n",
    "        {'main_output': y_train, 'aux_output': y_train},\n",
    "        epochs=epochs, batch_size=batch_size,   # 500\n",
    "        validation_split=0.2,\n",
    "        validation_data=(\n",
    "            {'main_input': x_val, 'wv_input': wv_val, 'fs_input': fs_val},\n",
    "            {'main_output': y_val, 'aux_output': y_val}\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.save(model_name.format(i))\n",
    "    print\n",
    "    print('Done with epoch: {}'.format((i + 1) * epochs))\n",
    "    with open('lstm-word2vec-fasttext.epoch.csv', 'a') as fl:\n",
    "        fl.write(model_name + '\\n')\n",
    "        fl.write('Epoch {}\\n'.format((i + 1) * epochs))\n",
    "        fl.write('{}\\n'.format(datetime.now()))\n",
    "        fl.write('\\n'.join(['{}: {}'.format(k, v[0]) for k, v in hist.history.items()]))\n",
    "        fl.write('\\n\\n')\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 79s - loss: 1.5507 - main_output_loss: 1.2739 - aux_output_loss: 1.3838 - main_output_acc: 0.7813 - main_output_f1_micro: 0.6936 - aux_output_acc: 0.7948 - aux_output_f1_micro: 0.1259 - val_loss: 1.3893 - val_main_output_loss: 1.0967 - val_aux_output_loss: 1.4632 - val_main_output_acc: 0.7983 - val_main_output_f1_micro: 0.6945 - val_aux_output_acc: 0.7938 - val_aux_output_f1_micro: 0.1262\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.5634 - main_output_loss: 1.2855 - aux_output_loss: 1.3898 - main_output_acc: 0.7811 - main_output_f1_micro: 0.6953 - aux_output_acc: 0.7943 - aux_output_f1_micro: 0.1265 - val_loss: 1.3845 - val_main_output_loss: 1.0915 - val_aux_output_loss: 1.4651 - val_main_output_acc: 0.7865 - val_main_output_f1_micro: 0.6962 - val_aux_output_acc: 0.7951 - val_aux_output_f1_micro: 0.1269\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.5639 - main_output_loss: 1.2869 - aux_output_loss: 1.3846 - main_output_acc: 0.7815 - main_output_f1_micro: 0.6970 - aux_output_acc: 0.7951 - aux_output_f1_micro: 0.1272 - val_loss: 1.3851 - val_main_output_loss: 1.0951 - val_aux_output_loss: 1.4501 - val_main_output_acc: 0.8035 - val_main_output_f1_micro: 0.6979 - val_aux_output_acc: 0.7993 - val_aux_output_f1_micro: 0.1275\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.5567 - main_output_loss: 1.2818 - aux_output_loss: 1.3746 - main_output_acc: 0.7783 - main_output_f1_micro: 0.6987 - aux_output_acc: 0.7947 - aux_output_f1_micro: 0.1278 - val_loss: 1.3712 - val_main_output_loss: 1.0824 - val_aux_output_loss: 1.4443 - val_main_output_acc: 0.8001 - val_main_output_f1_micro: 0.6995 - val_aux_output_acc: 0.8003 - val_aux_output_f1_micro: 0.1281\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.5517 - main_output_loss: 1.2781 - aux_output_loss: 1.3679 - main_output_acc: 0.7810 - main_output_f1_micro: 0.7003 - aux_output_acc: 0.7953 - aux_output_f1_micro: 0.1285 - val_loss: 1.3722 - val_main_output_loss: 1.0847 - val_aux_output_loss: 1.4375 - val_main_output_acc: 0.8018 - val_main_output_f1_micro: 0.7012 - val_aux_output_acc: 0.7934 - val_aux_output_f1_micro: 0.1288\n",
      "\n",
      "Done with epoch: 100\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.5451 - main_output_loss: 1.2731 - aux_output_loss: 1.3599 - main_output_acc: 0.7842 - main_output_f1_micro: 0.7020 - aux_output_acc: 0.7964 - aux_output_f1_micro: 0.1291 - val_loss: 1.3697 - val_main_output_loss: 1.0842 - val_aux_output_loss: 1.4272 - val_main_output_acc: 0.8133 - val_main_output_f1_micro: 0.7028 - val_aux_output_acc: 0.7987 - val_aux_output_f1_micro: 0.1294\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.5380 - main_output_loss: 1.2681 - aux_output_loss: 1.3495 - main_output_acc: 0.7814 - main_output_f1_micro: 0.7036 - aux_output_acc: 0.7965 - aux_output_f1_micro: 0.1298 - val_loss: 1.3619 - val_main_output_loss: 1.0798 - val_aux_output_loss: 1.4105 - val_main_output_acc: 0.7946 - val_main_output_f1_micro: 0.7044 - val_aux_output_acc: 0.8020 - val_aux_output_f1_micro: 0.1301\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.5364 - main_output_loss: 1.2684 - aux_output_loss: 1.3403 - main_output_acc: 0.7820 - main_output_f1_micro: 0.7052 - aux_output_acc: 0.7971 - aux_output_f1_micro: 0.1305 - val_loss: 1.3662 - val_main_output_loss: 1.0841 - val_aux_output_loss: 1.4106 - val_main_output_acc: 0.7935 - val_main_output_f1_micro: 0.7060 - val_aux_output_acc: 0.8024 - val_aux_output_f1_micro: 0.1308\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.5242 - main_output_loss: 1.2575 - aux_output_loss: 1.3332 - main_output_acc: 0.7798 - main_output_f1_micro: 0.7068 - aux_output_acc: 0.7987 - aux_output_f1_micro: 0.1311 - val_loss: 1.3593 - val_main_output_loss: 1.0789 - val_aux_output_loss: 1.4024 - val_main_output_acc: 0.7980 - val_main_output_f1_micro: 0.7076 - val_aux_output_acc: 0.8036 - val_aux_output_f1_micro: 0.1315\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.5195 - main_output_loss: 1.2544 - aux_output_loss: 1.3255 - main_output_acc: 0.7825 - main_output_f1_micro: 0.7083 - aux_output_acc: 0.7989 - aux_output_f1_micro: 0.1318 - val_loss: 1.3476 - val_main_output_loss: 1.0688 - val_aux_output_loss: 1.3936 - val_main_output_acc: 0.8004 - val_main_output_f1_micro: 0.7091 - val_aux_output_acc: 0.8023 - val_aux_output_f1_micro: 0.1322\n",
      "\n",
      "Done with epoch: 105\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.5147 - main_output_loss: 1.2513 - aux_output_loss: 1.3173 - main_output_acc: 0.7835 - main_output_f1_micro: 0.7099 - aux_output_acc: 0.7984 - aux_output_f1_micro: 0.1325 - val_loss: 1.3450 - val_main_output_loss: 1.0685 - val_aux_output_loss: 1.3829 - val_main_output_acc: 0.7926 - val_main_output_f1_micro: 0.7107 - val_aux_output_acc: 0.8040 - val_aux_output_f1_micro: 0.1329\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.5060 - main_output_loss: 1.2440 - aux_output_loss: 1.3099 - main_output_acc: 0.7829 - main_output_f1_micro: 0.7115 - aux_output_acc: 0.7999 - aux_output_f1_micro: 0.1332 - val_loss: 1.3413 - val_main_output_loss: 1.0650 - val_aux_output_loss: 1.3811 - val_main_output_acc: 0.7985 - val_main_output_f1_micro: 0.7122 - val_aux_output_acc: 0.8088 - val_aux_output_f1_micro: 0.1336\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.5029 - main_output_loss: 1.2420 - aux_output_loss: 1.3044 - main_output_acc: 0.7840 - main_output_f1_micro: 0.7130 - aux_output_acc: 0.7991 - aux_output_f1_micro: 0.1339 - val_loss: 1.3351 - val_main_output_loss: 1.0602 - val_aux_output_loss: 1.3743 - val_main_output_acc: 0.7939 - val_main_output_f1_micro: 0.7138 - val_aux_output_acc: 0.8061 - val_aux_output_f1_micro: 0.1343\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.4934 - main_output_loss: 1.2366 - aux_output_loss: 1.2840 - main_output_acc: 0.7838 - main_output_f1_micro: 0.7175 - aux_output_acc: 0.7992 - aux_output_f1_micro: 0.1362 - val_loss: 1.3264 - val_main_output_loss: 1.0570 - val_aux_output_loss: 1.3473 - val_main_output_acc: 0.7922 - val_main_output_f1_micro: 0.7182 - val_aux_output_acc: 0.8059 - val_aux_output_f1_micro: 0.1365\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.4920 - main_output_loss: 1.2365 - aux_output_loss: 1.2775 - main_output_acc: 0.7838 - main_output_f1_micro: 0.7189 - aux_output_acc: 0.7998 - aux_output_f1_micro: 0.1369 - val_loss: 1.3284 - val_main_output_loss: 1.0603 - val_aux_output_loss: 1.3405 - val_main_output_acc: 0.7915 - val_main_output_f1_micro: 0.7196 - val_aux_output_acc: 0.8050 - val_aux_output_f1_micro: 0.1372\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.4805 - main_output_loss: 1.2263 - aux_output_loss: 1.2713 - main_output_acc: 0.7847 - main_output_f1_micro: 0.7204 - aux_output_acc: 0.8007 - aux_output_f1_micro: 0.1376 - val_loss: 1.3171 - val_main_output_loss: 1.0505 - val_aux_output_loss: 1.3334 - val_main_output_acc: 0.7984 - val_main_output_f1_micro: 0.7211 - val_aux_output_acc: 0.7987 - val_aux_output_f1_micro: 0.1380\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.4789 - main_output_loss: 1.2263 - aux_output_loss: 1.2630 - main_output_acc: 0.7830 - main_output_f1_micro: 0.7218 - aux_output_acc: 0.8013 - aux_output_f1_micro: 0.1384 - val_loss: 1.3180 - val_main_output_loss: 1.0521 - val_aux_output_loss: 1.3292 - val_main_output_acc: 0.7993 - val_main_output_f1_micro: 0.7225 - val_aux_output_acc: 0.8032 - val_aux_output_f1_micro: 0.1387\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.4734 - main_output_loss: 1.2215 - aux_output_loss: 1.2595 - main_output_acc: 0.7841 - main_output_f1_micro: 0.7232 - aux_output_acc: 0.8014 - aux_output_f1_micro: 0.1391 - val_loss: 1.3160 - val_main_output_loss: 1.0514 - val_aux_output_loss: 1.3228 - val_main_output_acc: 0.8085 - val_main_output_f1_micro: 0.7239 - val_aux_output_acc: 0.8081 - val_aux_output_f1_micro: 0.1395\n",
      "\n",
      "Done with epoch: 115\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.4726 - main_output_loss: 1.2219 - aux_output_loss: 1.2538 - main_output_acc: 0.7827 - main_output_f1_micro: 0.7246 - aux_output_acc: 0.8018 - aux_output_f1_micro: 0.1399 - val_loss: 1.3080 - val_main_output_loss: 1.0451 - val_aux_output_loss: 1.3145 - val_main_output_acc: 0.7983 - val_main_output_f1_micro: 0.7253 - val_aux_output_acc: 0.8020 - val_aux_output_f1_micro: 0.1402\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.4713 - main_output_loss: 1.2216 - aux_output_loss: 1.2481 - main_output_acc: 0.7855 - main_output_f1_micro: 0.7260 - aux_output_acc: 0.8022 - aux_output_f1_micro: 0.1406 - val_loss: 1.3080 - val_main_output_loss: 1.0459 - val_aux_output_loss: 1.3106 - val_main_output_acc: 0.7893 - val_main_output_f1_micro: 0.7267 - val_aux_output_acc: 0.8096 - val_aux_output_f1_micro: 0.1410\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.4600 - main_output_loss: 1.2113 - aux_output_loss: 1.2434 - main_output_acc: 0.7836 - main_output_f1_micro: 0.7274 - aux_output_acc: 0.8015 - aux_output_f1_micro: 0.1414 - val_loss: 1.3022 - val_main_output_loss: 1.0409 - val_aux_output_loss: 1.3062 - val_main_output_acc: 0.7955 - val_main_output_f1_micro: 0.7281 - val_aux_output_acc: 0.8034 - val_aux_output_f1_micro: 0.1418\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.4623 - main_output_loss: 1.2144 - aux_output_loss: 1.2399 - main_output_acc: 0.7861 - main_output_f1_micro: 0.7287 - aux_output_acc: 0.8027 - aux_output_f1_micro: 0.1422 - val_loss: 1.3089 - val_main_output_loss: 1.0483 - val_aux_output_loss: 1.3029 - val_main_output_acc: 0.7922 - val_main_output_f1_micro: 0.7294 - val_aux_output_acc: 0.8054 - val_aux_output_f1_micro: 0.1426\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.4566 - main_output_loss: 1.2102 - aux_output_loss: 1.2320 - main_output_acc: 0.7855 - main_output_f1_micro: 0.7301 - aux_output_acc: 0.8026 - aux_output_f1_micro: 0.1430 - val_loss: 1.2986 - val_main_output_loss: 1.0399 - val_aux_output_loss: 1.2930 - val_main_output_acc: 0.7944 - val_main_output_f1_micro: 0.7307 - val_aux_output_acc: 0.8063 - val_aux_output_f1_micro: 0.1434\n",
      "\n",
      "Done with epoch: 120\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.4539 - main_output_loss: 1.2084 - aux_output_loss: 1.2276 - main_output_acc: 0.7872 - main_output_f1_micro: 0.7314 - aux_output_acc: 0.8020 - aux_output_f1_micro: 0.1438 - val_loss: 1.2987 - val_main_output_loss: 1.0416 - val_aux_output_loss: 1.2857 - val_main_output_acc: 0.8023 - val_main_output_f1_micro: 0.7320 - val_aux_output_acc: 0.8060 - val_aux_output_f1_micro: 0.1442\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.4514 - main_output_loss: 1.2071 - aux_output_loss: 1.2217 - main_output_acc: 0.7858 - main_output_f1_micro: 0.7327 - aux_output_acc: 0.8021 - aux_output_f1_micro: 0.1446 - val_loss: 1.2952 - val_main_output_loss: 1.0375 - val_aux_output_loss: 1.2885 - val_main_output_acc: 0.7999 - val_main_output_f1_micro: 0.7333 - val_aux_output_acc: 0.8058 - val_aux_output_f1_micro: 0.1450\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.4483 - main_output_loss: 1.2044 - aux_output_loss: 1.2196 - main_output_acc: 0.7856 - main_output_f1_micro: 0.7340 - aux_output_acc: 0.8026 - aux_output_f1_micro: 0.1454 - val_loss: 1.2978 - val_main_output_loss: 1.0420 - val_aux_output_loss: 1.2792 - val_main_output_acc: 0.7978 - val_main_output_f1_micro: 0.7346 - val_aux_output_acc: 0.8022 - val_aux_output_f1_micro: 0.1458\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.4465 - main_output_loss: 1.2038 - aux_output_loss: 1.2132 - main_output_acc: 0.7869 - main_output_f1_micro: 0.7353 - aux_output_acc: 0.8046 - aux_output_f1_micro: 0.1462 - val_loss: 1.2895 - val_main_output_loss: 1.0332 - val_aux_output_loss: 1.2813 - val_main_output_acc: 0.7998 - val_main_output_f1_micro: 0.7359 - val_aux_output_acc: 0.8065 - val_aux_output_f1_micro: 0.1466\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.4434 - main_output_loss: 1.2011 - aux_output_loss: 1.2112 - main_output_acc: 0.7885 - main_output_f1_micro: 0.7365 - aux_output_acc: 0.8025 - aux_output_f1_micro: 0.1470 - val_loss: 1.2887 - val_main_output_loss: 1.0348 - val_aux_output_loss: 1.2694 - val_main_output_acc: 0.8013 - val_main_output_f1_micro: 0.7372 - val_aux_output_acc: 0.8096 - val_aux_output_f1_micro: 0.1475\n",
      "\n",
      "Done with epoch: 125\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.4380 - main_output_loss: 1.1965 - aux_output_loss: 1.2076 - main_output_acc: 0.7873 - main_output_f1_micro: 0.7378 - aux_output_acc: 0.8052 - aux_output_f1_micro: 0.1479 - val_loss: 1.2846 - val_main_output_loss: 1.0304 - val_aux_output_loss: 1.2709 - val_main_output_acc: 0.7915 - val_main_output_f1_micro: 0.7384 - val_aux_output_acc: 0.8098 - val_aux_output_f1_micro: 0.1483\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.4395 - main_output_loss: 1.1988 - aux_output_loss: 1.2037 - main_output_acc: 0.7892 - main_output_f1_micro: 0.7390 - aux_output_acc: 0.8032 - aux_output_f1_micro: 0.1486 - val_loss: 1.2908 - val_main_output_loss: 1.0374 - val_aux_output_loss: 1.2675 - val_main_output_acc: 0.7911 - val_main_output_f1_micro: 0.7396 - val_aux_output_acc: 0.8153 - val_aux_output_f1_micro: 0.1490\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.4335 - main_output_loss: 1.1938 - aux_output_loss: 1.1986 - main_output_acc: 0.7876 - main_output_f1_micro: 0.7402 - aux_output_acc: 0.8050 - aux_output_f1_micro: 0.1494 - val_loss: 1.2801 - val_main_output_loss: 1.0286 - val_aux_output_loss: 1.2578 - val_main_output_acc: 0.8023 - val_main_output_f1_micro: 0.7409 - val_aux_output_acc: 0.8068 - val_aux_output_f1_micro: 0.1498\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.4300 - main_output_loss: 1.1911 - aux_output_loss: 1.1944 - main_output_acc: 0.7865 - main_output_f1_micro: 0.7415 - aux_output_acc: 0.8048 - aux_output_f1_micro: 0.1502 - val_loss: 1.2803 - val_main_output_loss: 1.0286 - val_aux_output_loss: 1.2585 - val_main_output_acc: 0.7976 - val_main_output_f1_micro: 0.7421 - val_aux_output_acc: 0.8084 - val_aux_output_f1_micro: 0.1506\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.4282 - main_output_loss: 1.1903 - aux_output_loss: 1.1897 - main_output_acc: 0.7882 - main_output_f1_micro: 0.7427 - aux_output_acc: 0.8048 - aux_output_f1_micro: 0.1511 - val_loss: 1.2838 - val_main_output_loss: 1.0329 - val_aux_output_loss: 1.2546 - val_main_output_acc: 0.8020 - val_main_output_f1_micro: 0.7433 - val_aux_output_acc: 0.8142 - val_aux_output_f1_micro: 0.1515\n",
      "\n",
      "Done with epoch: 130\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.4298 - main_output_loss: 1.1924 - aux_output_loss: 1.1873 - main_output_acc: 0.7898 - main_output_f1_micro: 0.7439 - aux_output_acc: 0.8063 - aux_output_f1_micro: 0.1519 - val_loss: 1.2795 - val_main_output_loss: 1.0293 - val_aux_output_loss: 1.2508 - val_main_output_acc: 0.8002 - val_main_output_f1_micro: 0.7444 - val_aux_output_acc: 0.8107 - val_aux_output_f1_micro: 0.1522\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56877/56877 [==============================] - 71s - loss: 1.4237 - main_output_loss: 1.1870 - aux_output_loss: 1.1835 - main_output_acc: 0.7904 - main_output_f1_micro: 0.7450 - aux_output_acc: 0.8065 - aux_output_f1_micro: 0.1526 - val_loss: 1.2707 - val_main_output_loss: 1.0215 - val_aux_output_loss: 1.2461 - val_main_output_acc: 0.7949 - val_main_output_f1_micro: 0.7456 - val_aux_output_acc: 0.8046 - val_aux_output_f1_micro: 0.1531\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.4187 - main_output_loss: 1.1828 - aux_output_loss: 1.1791 - main_output_acc: 0.7886 - main_output_f1_micro: 0.7462 - aux_output_acc: 0.8034 - aux_output_f1_micro: 0.1535 - val_loss: 1.2741 - val_main_output_loss: 1.0257 - val_aux_output_loss: 1.2422 - val_main_output_acc: 0.7947 - val_main_output_f1_micro: 0.7468 - val_aux_output_acc: 0.8053 - val_aux_output_f1_micro: 0.1539\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.4248 - main_output_loss: 1.1897 - aux_output_loss: 1.1752 - main_output_acc: 0.7885 - main_output_f1_micro: 0.7473 - aux_output_acc: 0.8043 - aux_output_f1_micro: 0.1543 - val_loss: 1.2739 - val_main_output_loss: 1.0274 - val_aux_output_loss: 1.2327 - val_main_output_acc: 0.8083 - val_main_output_f1_micro: 0.7479 - val_aux_output_acc: 0.8071 - val_aux_output_f1_micro: 0.1547\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.4155 - main_output_loss: 1.1812 - aux_output_loss: 1.1713 - main_output_acc: 0.7925 - main_output_f1_micro: 0.7485 - aux_output_acc: 0.8037 - aux_output_f1_micro: 0.1551 - val_loss: 1.2680 - val_main_output_loss: 1.0214 - val_aux_output_loss: 1.2329 - val_main_output_acc: 0.8031 - val_main_output_f1_micro: 0.7490 - val_aux_output_acc: 0.8068 - val_aux_output_f1_micro: 0.1555\n",
      "\n",
      "Done with epoch: 135\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.4178 - main_output_loss: 1.1837 - aux_output_loss: 1.1705 - main_output_acc: 0.7902 - main_output_f1_micro: 0.7496 - aux_output_acc: 0.8041 - aux_output_f1_micro: 0.1559 - val_loss: 1.2717 - val_main_output_loss: 1.0252 - val_aux_output_loss: 1.2325 - val_main_output_acc: 0.8020 - val_main_output_f1_micro: 0.7501 - val_aux_output_acc: 0.8068 - val_aux_output_f1_micro: 0.1563\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.4104 - main_output_loss: 1.1771 - aux_output_loss: 1.1664 - main_output_acc: 0.7924 - main_output_f1_micro: 0.7507 - aux_output_acc: 0.8037 - aux_output_f1_micro: 0.1567 - val_loss: 1.2685 - val_main_output_loss: 1.0223 - val_aux_output_loss: 1.2309 - val_main_output_acc: 0.7994 - val_main_output_f1_micro: 0.7512 - val_aux_output_acc: 0.8080 - val_aux_output_f1_micro: 0.1571\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.4100 - main_output_loss: 1.1772 - aux_output_loss: 1.1638 - main_output_acc: 0.7927 - main_output_f1_micro: 0.7518 - aux_output_acc: 0.8055 - aux_output_f1_micro: 0.1575 - val_loss: 1.2616 - val_main_output_loss: 1.0165 - val_aux_output_loss: 1.2255 - val_main_output_acc: 0.8004 - val_main_output_f1_micro: 0.7523 - val_aux_output_acc: 0.8113 - val_aux_output_f1_micro: 0.1579\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.4075 - main_output_loss: 1.1753 - aux_output_loss: 1.1606 - main_output_acc: 0.7931 - main_output_f1_micro: 0.7529 - aux_output_acc: 0.8050 - aux_output_f1_micro: 0.1583 - val_loss: 1.2619 - val_main_output_loss: 1.0172 - val_aux_output_loss: 1.2231 - val_main_output_acc: 0.7963 - val_main_output_f1_micro: 0.7534 - val_aux_output_acc: 0.8080 - val_aux_output_f1_micro: 0.1587\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.4075 - main_output_loss: 1.1763 - aux_output_loss: 1.1560 - main_output_acc: 0.7914 - main_output_f1_micro: 0.7539 - aux_output_acc: 0.8064 - aux_output_f1_micro: 0.1591 - val_loss: 1.2678 - val_main_output_loss: 1.0230 - val_aux_output_loss: 1.2238 - val_main_output_acc: 0.8048 - val_main_output_f1_micro: 0.7545 - val_aux_output_acc: 0.8145 - val_aux_output_f1_micro: 0.1595\n",
      "\n",
      "Done with epoch: 140\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.4101 - main_output_loss: 1.1794 - aux_output_loss: 1.1534 - main_output_acc: 0.7905 - main_output_f1_micro: 0.7550 - aux_output_acc: 0.8040 - aux_output_f1_micro: 0.1598 - val_loss: 1.2609 - val_main_output_loss: 1.0181 - val_aux_output_loss: 1.2142 - val_main_output_acc: 0.7997 - val_main_output_f1_micro: 0.7555 - val_aux_output_acc: 0.8028 - val_aux_output_f1_micro: 0.1602\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.4062 - main_output_loss: 1.1754 - aux_output_loss: 1.1539 - main_output_acc: 0.7874 - main_output_f1_micro: 0.7560 - aux_output_acc: 0.8057 - aux_output_f1_micro: 0.1606 - val_loss: 1.2578 - val_main_output_loss: 1.0170 - val_aux_output_loss: 1.2042 - val_main_output_acc: 0.8032 - val_main_output_f1_micro: 0.7566 - val_aux_output_acc: 0.8088 - val_aux_output_f1_micro: 0.1610\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.4022 - main_output_loss: 1.1723 - aux_output_loss: 1.1497 - main_output_acc: 0.7893 - main_output_f1_micro: 0.7571 - aux_output_acc: 0.8059 - aux_output_f1_micro: 0.1614 - val_loss: 1.2556 - val_main_output_loss: 1.0142 - val_aux_output_loss: 1.2071 - val_main_output_acc: 0.7921 - val_main_output_f1_micro: 0.7576 - val_aux_output_acc: 0.8089 - val_aux_output_f1_micro: 0.1618\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.4046 - main_output_loss: 1.1758 - aux_output_loss: 1.1440 - main_output_acc: 0.7935 - main_output_f1_micro: 0.7581 - aux_output_acc: 0.8057 - aux_output_f1_micro: 0.1622 - val_loss: 1.2575 - val_main_output_loss: 1.0171 - val_aux_output_loss: 1.2020 - val_main_output_acc: 0.8002 - val_main_output_f1_micro: 0.7586 - val_aux_output_acc: 0.8093 - val_aux_output_f1_micro: 0.1626\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3893 - main_output_loss: 1.1611 - aux_output_loss: 1.1412 - main_output_acc: 0.7914 - main_output_f1_micro: 0.7591 - aux_output_acc: 0.8078 - aux_output_f1_micro: 0.1630 - val_loss: 1.2490 - val_main_output_loss: 1.0096 - val_aux_output_loss: 1.1969 - val_main_output_acc: 0.8024 - val_main_output_f1_micro: 0.7596 - val_aux_output_acc: 0.8135 - val_aux_output_f1_micro: 0.1634\n",
      "\n",
      "Done with epoch: 145\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.4024 - main_output_loss: 1.1745 - aux_output_loss: 1.1397 - main_output_acc: 0.7930 - main_output_f1_micro: 0.7601 - aux_output_acc: 0.8069 - aux_output_f1_micro: 0.1638 - val_loss: 1.2523 - val_main_output_loss: 1.0118 - val_aux_output_loss: 1.2027 - val_main_output_acc: 0.8085 - val_main_output_f1_micro: 0.7606 - val_aux_output_acc: 0.8079 - val_aux_output_f1_micro: 0.1642\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3991 - main_output_loss: 1.1718 - aux_output_loss: 1.1368 - main_output_acc: 0.7930 - main_output_f1_micro: 0.7611 - aux_output_acc: 0.8048 - aux_output_f1_micro: 0.1646 - val_loss: 1.2537 - val_main_output_loss: 1.0141 - val_aux_output_loss: 1.1981 - val_main_output_acc: 0.7959 - val_main_output_f1_micro: 0.7616 - val_aux_output_acc: 0.8054 - val_aux_output_f1_micro: 0.1650\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3932 - main_output_loss: 1.1663 - aux_output_loss: 1.1347 - main_output_acc: 0.7904 - main_output_f1_micro: 0.7621 - aux_output_acc: 0.8052 - aux_output_f1_micro: 0.1655 - val_loss: 1.2503 - val_main_output_loss: 1.0112 - val_aux_output_loss: 1.1956 - val_main_output_acc: 0.8062 - val_main_output_f1_micro: 0.7626 - val_aux_output_acc: 0.8097 - val_aux_output_f1_micro: 0.1659\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3909 - main_output_loss: 1.1644 - aux_output_loss: 1.1323 - main_output_acc: 0.7914 - main_output_f1_micro: 0.7631 - aux_output_acc: 0.8041 - aux_output_f1_micro: 0.1663 - val_loss: 1.2525 - val_main_output_loss: 1.0144 - val_aux_output_loss: 1.1907 - val_main_output_acc: 0.8123 - val_main_output_f1_micro: 0.7636 - val_aux_output_acc: 0.8086 - val_aux_output_f1_micro: 0.1666\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3861 - main_output_loss: 1.1602 - aux_output_loss: 1.1294 - main_output_acc: 0.7931 - main_output_f1_micro: 0.7641 - aux_output_acc: 0.8052 - aux_output_f1_micro: 0.1670 - val_loss: 1.2451 - val_main_output_loss: 1.0074 - val_aux_output_loss: 1.1888 - val_main_output_acc: 0.8060 - val_main_output_f1_micro: 0.7646 - val_aux_output_acc: 0.8063 - val_aux_output_f1_micro: 0.1675\n",
      "\n",
      "Done with epoch: 150\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3842 - main_output_loss: 1.1591 - aux_output_loss: 1.1256 - main_output_acc: 0.7945 - main_output_f1_micro: 0.7651 - aux_output_acc: 0.8062 - aux_output_f1_micro: 0.1679 - val_loss: 1.2433 - val_main_output_loss: 1.0063 - val_aux_output_loss: 1.1846 - val_main_output_acc: 0.8045 - val_main_output_f1_micro: 0.7655 - val_aux_output_acc: 0.8017 - val_aux_output_f1_micro: 0.1683\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3883 - main_output_loss: 1.1633 - aux_output_loss: 1.1253 - main_output_acc: 0.7931 - main_output_f1_micro: 0.7660 - aux_output_acc: 0.8043 - aux_output_f1_micro: 0.1687 - val_loss: 1.2464 - val_main_output_loss: 1.0094 - val_aux_output_loss: 1.1854 - val_main_output_acc: 0.7993 - val_main_output_f1_micro: 0.7665 - val_aux_output_acc: 0.8069 - val_aux_output_f1_micro: 0.1691\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3831 - main_output_loss: 1.1584 - aux_output_loss: 1.1233 - main_output_acc: 0.7910 - main_output_f1_micro: 0.7670 - aux_output_acc: 0.8041 - aux_output_f1_micro: 0.1696 - val_loss: 1.2424 - val_main_output_loss: 1.0051 - val_aux_output_loss: 1.1865 - val_main_output_acc: 0.8003 - val_main_output_f1_micro: 0.7674 - val_aux_output_acc: 0.8058 - val_aux_output_f1_micro: 0.1700\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3845 - main_output_loss: 1.1604 - aux_output_loss: 1.1206 - main_output_acc: 0.7940 - main_output_f1_micro: 0.7679 - aux_output_acc: 0.8049 - aux_output_f1_micro: 0.1704 - val_loss: 1.2355 - val_main_output_loss: 0.9994 - val_aux_output_loss: 1.1805 - val_main_output_acc: 0.7978 - val_main_output_f1_micro: 0.7684 - val_aux_output_acc: 0.8063 - val_aux_output_f1_micro: 0.1708\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3782 - main_output_loss: 1.1543 - aux_output_loss: 1.1192 - main_output_acc: 0.7924 - main_output_f1_micro: 0.7688 - aux_output_acc: 0.8065 - aux_output_f1_micro: 0.1712 - val_loss: 1.2374 - val_main_output_loss: 1.0022 - val_aux_output_loss: 1.1760 - val_main_output_acc: 0.7993 - val_main_output_f1_micro: 0.7693 - val_aux_output_acc: 0.8081 - val_aux_output_f1_micro: 0.1716\n",
      "\n",
      "Done with epoch: 155\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3748 - main_output_loss: 1.1520 - aux_output_loss: 1.1140 - main_output_acc: 0.7911 - main_output_f1_micro: 0.7697 - aux_output_acc: 0.8059 - aux_output_f1_micro: 0.1721 - val_loss: 1.2407 - val_main_output_loss: 1.0047 - val_aux_output_loss: 1.1800 - val_main_output_acc: 0.8037 - val_main_output_f1_micro: 0.7702 - val_aux_output_acc: 0.8046 - val_aux_output_f1_micro: 0.1725\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3749 - main_output_loss: 1.1524 - aux_output_loss: 1.1126 - main_output_acc: 0.7911 - main_output_f1_micro: 0.7706 - aux_output_acc: 0.8064 - aux_output_f1_micro: 0.1729 - val_loss: 1.2363 - val_main_output_loss: 1.0021 - val_aux_output_loss: 1.1709 - val_main_output_acc: 0.7951 - val_main_output_f1_micro: 0.7711 - val_aux_output_acc: 0.8096 - val_aux_output_f1_micro: 0.1733\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3703 - main_output_loss: 1.1483 - aux_output_loss: 1.1100 - main_output_acc: 0.7908 - main_output_f1_micro: 0.7715 - aux_output_acc: 0.8066 - aux_output_f1_micro: 0.1737 - val_loss: 1.2339 - val_main_output_loss: 1.0000 - val_aux_output_loss: 1.1698 - val_main_output_acc: 0.8071 - val_main_output_f1_micro: 0.7720 - val_aux_output_acc: 0.8045 - val_aux_output_f1_micro: 0.1741\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3766 - main_output_loss: 1.1550 - aux_output_loss: 1.1076 - main_output_acc: 0.7916 - main_output_f1_micro: 0.7724 - aux_output_acc: 0.8069 - aux_output_f1_micro: 0.1745 - val_loss: 1.2354 - val_main_output_loss: 1.0007 - val_aux_output_loss: 1.1734 - val_main_output_acc: 0.8016 - val_main_output_f1_micro: 0.7729 - val_aux_output_acc: 0.8045 - val_aux_output_f1_micro: 0.1749\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3715 - main_output_loss: 1.1498 - aux_output_loss: 1.1084 - main_output_acc: 0.7914 - main_output_f1_micro: 0.7733 - aux_output_acc: 0.8059 - aux_output_f1_micro: 0.1753 - val_loss: 1.2377 - val_main_output_loss: 1.0037 - val_aux_output_loss: 1.1703 - val_main_output_acc: 0.8006 - val_main_output_f1_micro: 0.7737 - val_aux_output_acc: 0.8078 - val_aux_output_f1_micro: 0.1758\n",
      "\n",
      "Done with epoch: 160\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3680 - main_output_loss: 1.1468 - aux_output_loss: 1.1055 - main_output_acc: 0.7949 - main_output_f1_micro: 0.7742 - aux_output_acc: 0.8075 - aux_output_f1_micro: 0.1762 - val_loss: 1.2317 - val_main_output_loss: 0.9989 - val_aux_output_loss: 1.1640 - val_main_output_acc: 0.7970 - val_main_output_f1_micro: 0.7746 - val_aux_output_acc: 0.8076 - val_aux_output_f1_micro: 0.1766\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3699 - main_output_loss: 1.1492 - aux_output_loss: 1.1038 - main_output_acc: 0.7939 - main_output_f1_micro: 0.7750 - aux_output_acc: 0.8068 - aux_output_f1_micro: 0.1770 - val_loss: 1.2276 - val_main_output_loss: 0.9954 - val_aux_output_loss: 1.1610 - val_main_output_acc: 0.8077 - val_main_output_f1_micro: 0.7755 - val_aux_output_acc: 0.8094 - val_aux_output_f1_micro: 0.1774\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3678 - main_output_loss: 1.1470 - aux_output_loss: 1.1037 - main_output_acc: 0.7977 - main_output_f1_micro: 0.7759 - aux_output_acc: 0.8083 - aux_output_f1_micro: 0.1778 - val_loss: 1.2290 - val_main_output_loss: 0.9968 - val_aux_output_loss: 1.1614 - val_main_output_acc: 0.8089 - val_main_output_f1_micro: 0.7763 - val_aux_output_acc: 0.8098 - val_aux_output_f1_micro: 0.1782\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3614 - main_output_loss: 1.1416 - aux_output_loss: 1.0990 - main_output_acc: 0.7937 - main_output_f1_micro: 0.7767 - aux_output_acc: 0.8073 - aux_output_f1_micro: 0.1786 - val_loss: 1.2234 - val_main_output_loss: 0.9926 - val_aux_output_loss: 1.1544 - val_main_output_acc: 0.7957 - val_main_output_f1_micro: 0.7772 - val_aux_output_acc: 0.8138 - val_aux_output_f1_micro: 0.1790\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3624 - main_output_loss: 1.1434 - aux_output_loss: 1.0948 - main_output_acc: 0.7937 - main_output_f1_micro: 0.7776 - aux_output_acc: 0.8068 - aux_output_f1_micro: 0.1794 - val_loss: 1.2238 - val_main_output_loss: 0.9932 - val_aux_output_loss: 1.1526 - val_main_output_acc: 0.8026 - val_main_output_f1_micro: 0.7780 - val_aux_output_acc: 0.8068 - val_aux_output_f1_micro: 0.1798\n",
      "\n",
      "Done with epoch: 165\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56877/56877 [==============================] - 71s - loss: 1.3632 - main_output_loss: 1.1443 - aux_output_loss: 1.0948 - main_output_acc: 0.7942 - main_output_f1_micro: 0.7784 - aux_output_acc: 0.8084 - aux_output_f1_micro: 0.1803 - val_loss: 1.2249 - val_main_output_loss: 0.9952 - val_aux_output_loss: 1.1486 - val_main_output_acc: 0.8127 - val_main_output_f1_micro: 0.7788 - val_aux_output_acc: 0.8095 - val_aux_output_f1_micro: 0.1807\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3548 - main_output_loss: 1.1366 - aux_output_loss: 1.0908 - main_output_acc: 0.7957 - main_output_f1_micro: 0.7792 - aux_output_acc: 0.8051 - aux_output_f1_micro: 0.1811 - val_loss: 1.2202 - val_main_output_loss: 0.9898 - val_aux_output_loss: 1.1519 - val_main_output_acc: 0.7994 - val_main_output_f1_micro: 0.7796 - val_aux_output_acc: 0.8097 - val_aux_output_f1_micro: 0.1815\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3520 - main_output_loss: 1.1340 - aux_output_loss: 1.0899 - main_output_acc: 0.7925 - main_output_f1_micro: 0.7801 - aux_output_acc: 0.8064 - aux_output_f1_micro: 0.1819 - val_loss: 1.2229 - val_main_output_loss: 0.9933 - val_aux_output_loss: 1.1480 - val_main_output_acc: 0.7974 - val_main_output_f1_micro: 0.7805 - val_aux_output_acc: 0.8061 - val_aux_output_f1_micro: 0.1823\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3603 - main_output_loss: 1.1425 - aux_output_loss: 1.0887 - main_output_acc: 0.7926 - main_output_f1_micro: 0.7809 - aux_output_acc: 0.8069 - aux_output_f1_micro: 0.1827 - val_loss: 1.2250 - val_main_output_loss: 0.9935 - val_aux_output_loss: 1.1574 - val_main_output_acc: 0.8023 - val_main_output_f1_micro: 0.7813 - val_aux_output_acc: 0.8059 - val_aux_output_f1_micro: 0.1831\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3587 - main_output_loss: 1.1411 - aux_output_loss: 1.0884 - main_output_acc: 0.7945 - main_output_f1_micro: 0.7817 - aux_output_acc: 0.8077 - aux_output_f1_micro: 0.1836 - val_loss: 1.2247 - val_main_output_loss: 0.9950 - val_aux_output_loss: 1.1487 - val_main_output_acc: 0.8055 - val_main_output_f1_micro: 0.7821 - val_aux_output_acc: 0.8087 - val_aux_output_f1_micro: 0.1840\n",
      "\n",
      "Done with epoch: 170\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3555 - main_output_loss: 1.1385 - aux_output_loss: 1.0847 - main_output_acc: 0.7930 - main_output_f1_micro: 0.7825 - aux_output_acc: 0.8050 - aux_output_f1_micro: 0.1844 - val_loss: 1.2203 - val_main_output_loss: 0.9923 - val_aux_output_loss: 1.1396 - val_main_output_acc: 0.8092 - val_main_output_f1_micro: 0.7829 - val_aux_output_acc: 0.8115 - val_aux_output_f1_micro: 0.1848\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3533 - main_output_loss: 1.1370 - aux_output_loss: 1.0816 - main_output_acc: 0.7950 - main_output_f1_micro: 0.7832 - aux_output_acc: 0.8094 - aux_output_f1_micro: 0.1852 - val_loss: 1.2179 - val_main_output_loss: 0.9905 - val_aux_output_loss: 1.1371 - val_main_output_acc: 0.8058 - val_main_output_f1_micro: 0.7836 - val_aux_output_acc: 0.8123 - val_aux_output_f1_micro: 0.1857\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3522 - main_output_loss: 1.1363 - aux_output_loss: 1.0793 - main_output_acc: 0.7966 - main_output_f1_micro: 0.7840 - aux_output_acc: 0.8066 - aux_output_f1_micro: 0.1861 - val_loss: 1.2166 - val_main_output_loss: 0.9888 - val_aux_output_loss: 1.1386 - val_main_output_acc: 0.8093 - val_main_output_f1_micro: 0.7844 - val_aux_output_acc: 0.8114 - val_aux_output_f1_micro: 0.1865\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3494 - main_output_loss: 1.1334 - aux_output_loss: 1.0800 - main_output_acc: 0.7943 - main_output_f1_micro: 0.7848 - aux_output_acc: 0.8071 - aux_output_f1_micro: 0.1870 - val_loss: 1.2207 - val_main_output_loss: 0.9931 - val_aux_output_loss: 1.1381 - val_main_output_acc: 0.8042 - val_main_output_f1_micro: 0.7852 - val_aux_output_acc: 0.8118 - val_aux_output_f1_micro: 0.1874\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3489 - main_output_loss: 1.1330 - aux_output_loss: 1.0792 - main_output_acc: 0.7946 - main_output_f1_micro: 0.7856 - aux_output_acc: 0.8093 - aux_output_f1_micro: 0.1878 - val_loss: 1.2176 - val_main_output_loss: 0.9906 - val_aux_output_loss: 1.1347 - val_main_output_acc: 0.8029 - val_main_output_f1_micro: 0.7859 - val_aux_output_acc: 0.8072 - val_aux_output_f1_micro: 0.1882\n",
      "\n",
      "Done with epoch: 175\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3485 - main_output_loss: 1.1334 - aux_output_loss: 1.0756 - main_output_acc: 0.7950 - main_output_f1_micro: 0.7863 - aux_output_acc: 0.8070 - aux_output_f1_micro: 0.1886 - val_loss: 1.2148 - val_main_output_loss: 0.9884 - val_aux_output_loss: 1.1319 - val_main_output_acc: 0.8081 - val_main_output_f1_micro: 0.7867 - val_aux_output_acc: 0.8060 - val_aux_output_f1_micro: 0.1890\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3434 - main_output_loss: 1.1285 - aux_output_loss: 1.0745 - main_output_acc: 0.7942 - main_output_f1_micro: 0.7871 - aux_output_acc: 0.8064 - aux_output_f1_micro: 0.1894 - val_loss: 1.2136 - val_main_output_loss: 0.9868 - val_aux_output_loss: 1.1337 - val_main_output_acc: 0.8042 - val_main_output_f1_micro: 0.7874 - val_aux_output_acc: 0.8142 - val_aux_output_f1_micro: 0.1898\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 70s - loss: 1.3500 - main_output_loss: 1.1346 - aux_output_loss: 1.0768 - main_output_acc: 0.7938 - main_output_f1_micro: 0.7878 - aux_output_acc: 0.8080 - aux_output_f1_micro: 0.1903 - val_loss: 1.2139 - val_main_output_loss: 0.9878 - val_aux_output_loss: 1.1305 - val_main_output_acc: 0.8046 - val_main_output_f1_micro: 0.7882 - val_aux_output_acc: 0.8135 - val_aux_output_f1_micro: 0.1907\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3448 - main_output_loss: 1.1304 - aux_output_loss: 1.0720 - main_output_acc: 0.7925 - main_output_f1_micro: 0.7885 - aux_output_acc: 0.8084 - aux_output_f1_micro: 0.1912 - val_loss: 1.2146 - val_main_output_loss: 0.9886 - val_aux_output_loss: 1.1303 - val_main_output_acc: 0.8008 - val_main_output_f1_micro: 0.7889 - val_aux_output_acc: 0.8034 - val_aux_output_f1_micro: 0.1916\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3455 - main_output_loss: 1.1314 - aux_output_loss: 1.0706 - main_output_acc: 0.7930 - main_output_f1_micro: 0.7893 - aux_output_acc: 0.8063 - aux_output_f1_micro: 0.1921 - val_loss: 1.2116 - val_main_output_loss: 0.9856 - val_aux_output_loss: 1.1302 - val_main_output_acc: 0.8040 - val_main_output_f1_micro: 0.7896 - val_aux_output_acc: 0.8184 - val_aux_output_f1_micro: 0.1925\n",
      "\n",
      "Done with epoch: 180\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3448 - main_output_loss: 1.1310 - aux_output_loss: 1.0693 - main_output_acc: 0.7934 - main_output_f1_micro: 0.7900 - aux_output_acc: 0.8087 - aux_output_f1_micro: 0.1929 - val_loss: 1.2108 - val_main_output_loss: 0.9854 - val_aux_output_loss: 1.1273 - val_main_output_acc: 0.8083 - val_main_output_f1_micro: 0.7904 - val_aux_output_acc: 0.8121 - val_aux_output_f1_micro: 0.1933\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 70s - loss: 1.3329 - main_output_loss: 1.1197 - aux_output_loss: 1.0657 - main_output_acc: 0.7929 - main_output_f1_micro: 0.7907 - aux_output_acc: 0.8071 - aux_output_f1_micro: 0.1937 - val_loss: 1.2083 - val_main_output_loss: 0.9829 - val_aux_output_loss: 1.1268 - val_main_output_acc: 0.8084 - val_main_output_f1_micro: 0.7911 - val_aux_output_acc: 0.8153 - val_aux_output_f1_micro: 0.1941\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3410 - main_output_loss: 1.1277 - aux_output_loss: 1.0662 - main_output_acc: 0.7981 - main_output_f1_micro: 0.7915 - aux_output_acc: 0.8064 - aux_output_f1_micro: 0.1946 - val_loss: 1.2098 - val_main_output_loss: 0.9852 - val_aux_output_loss: 1.1232 - val_main_output_acc: 0.8066 - val_main_output_f1_micro: 0.7918 - val_aux_output_acc: 0.8068 - val_aux_output_f1_micro: 0.1950\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3368 - main_output_loss: 1.1240 - aux_output_loss: 1.0640 - main_output_acc: 0.7941 - main_output_f1_micro: 0.7922 - aux_output_acc: 0.8063 - aux_output_f1_micro: 0.1954 - val_loss: 1.2063 - val_main_output_loss: 0.9821 - val_aux_output_loss: 1.1210 - val_main_output_acc: 0.8038 - val_main_output_f1_micro: 0.7925 - val_aux_output_acc: 0.8054 - val_aux_output_f1_micro: 0.1959\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3382 - main_output_loss: 1.1252 - aux_output_loss: 1.0649 - main_output_acc: 0.7960 - main_output_f1_micro: 0.7929 - aux_output_acc: 0.8066 - aux_output_f1_micro: 0.1963 - val_loss: 1.2054 - val_main_output_loss: 0.9818 - val_aux_output_loss: 1.1179 - val_main_output_acc: 0.8033 - val_main_output_f1_micro: 0.7932 - val_aux_output_acc: 0.8072 - val_aux_output_f1_micro: 0.1967\n",
      "\n",
      "Done with epoch: 185\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3357 - main_output_loss: 1.1233 - aux_output_loss: 1.0619 - main_output_acc: 0.7974 - main_output_f1_micro: 0.7936 - aux_output_acc: 0.8078 - aux_output_f1_micro: 0.1972 - val_loss: 1.2060 - val_main_output_loss: 0.9818 - val_aux_output_loss: 1.1210 - val_main_output_acc: 0.8104 - val_main_output_f1_micro: 0.7939 - val_aux_output_acc: 0.8071 - val_aux_output_f1_micro: 0.1976\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 71s - loss: 1.3346 - main_output_loss: 1.1224 - aux_output_loss: 1.0610 - main_output_acc: 0.7950 - main_output_f1_micro: 0.7943 - aux_output_acc: 0.8081 - aux_output_f1_micro: 0.1980 - val_loss: 1.2084 - val_main_output_loss: 0.9845 - val_aux_output_loss: 1.1194 - val_main_output_acc: 0.7981 - val_main_output_f1_micro: 0.7946 - val_aux_output_acc: 0.8061 - val_aux_output_f1_micro: 0.1985\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 70s - loss: 1.3341 - main_output_loss: 1.1220 - aux_output_loss: 1.0606 - main_output_acc: 0.7972 - main_output_f1_micro: 0.7949 - aux_output_acc: 0.8067 - aux_output_f1_micro: 0.1989 - val_loss: 1.2049 - val_main_output_loss: 0.9818 - val_aux_output_loss: 1.1155 - val_main_output_acc: 0.8109 - val_main_output_f1_micro: 0.7953 - val_aux_output_acc: 0.8131 - val_aux_output_f1_micro: 0.1993\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 70s - loss: 1.3334 - main_output_loss: 1.1219 - aux_output_loss: 1.0575 - main_output_acc: 0.7950 - main_output_f1_micro: 0.7956 - aux_output_acc: 0.8068 - aux_output_f1_micro: 0.1997 - val_loss: 1.2065 - val_main_output_loss: 0.9836 - val_aux_output_loss: 1.1149 - val_main_output_acc: 0.8121 - val_main_output_f1_micro: 0.7960 - val_aux_output_acc: 0.8049 - val_aux_output_f1_micro: 0.2001\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 70s - loss: 1.3318 - main_output_loss: 1.1206 - aux_output_loss: 1.0560 - main_output_acc: 0.7956 - main_output_f1_micro: 0.7963 - aux_output_acc: 0.8084 - aux_output_f1_micro: 0.2006 - val_loss: 1.2042 - val_main_output_loss: 0.9810 - val_aux_output_loss: 1.1156 - val_main_output_acc: 0.8115 - val_main_output_f1_micro: 0.7966 - val_aux_output_acc: 0.8113 - val_aux_output_f1_micro: 0.2010\n",
      "\n",
      "Done with epoch: 190\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 70s - loss: 1.3330 - main_output_loss: 1.1221 - aux_output_loss: 1.0544 - main_output_acc: 0.7989 - main_output_f1_micro: 0.7969 - aux_output_acc: 0.8069 - aux_output_f1_micro: 0.2015 - val_loss: 1.2031 - val_main_output_loss: 0.9797 - val_aux_output_loss: 1.1171 - val_main_output_acc: 0.8083 - val_main_output_f1_micro: 0.7973 - val_aux_output_acc: 0.8135 - val_aux_output_f1_micro: 0.2019\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 70s - loss: 1.3310 - main_output_loss: 1.1200 - aux_output_loss: 1.0550 - main_output_acc: 0.7933 - main_output_f1_micro: 0.7976 - aux_output_acc: 0.8067 - aux_output_f1_micro: 0.2023 - val_loss: 1.2053 - val_main_output_loss: 0.9829 - val_aux_output_loss: 1.1122 - val_main_output_acc: 0.8041 - val_main_output_f1_micro: 0.7979 - val_aux_output_acc: 0.8045 - val_aux_output_f1_micro: 0.2027\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 70s - loss: 1.3272 - main_output_loss: 1.1168 - aux_output_loss: 1.0522 - main_output_acc: 0.7944 - main_output_f1_micro: 0.7983 - aux_output_acc: 0.8086 - aux_output_f1_micro: 0.2031 - val_loss: 1.2061 - val_main_output_loss: 0.9840 - val_aux_output_loss: 1.1102 - val_main_output_acc: 0.8057 - val_main_output_f1_micro: 0.7986 - val_aux_output_acc: 0.8074 - val_aux_output_f1_micro: 0.2035\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 70s - loss: 1.3287 - main_output_loss: 1.1183 - aux_output_loss: 1.0520 - main_output_acc: 0.7973 - main_output_f1_micro: 0.7989 - aux_output_acc: 0.8060 - aux_output_f1_micro: 0.2039 - val_loss: 1.2015 - val_main_output_loss: 0.9796 - val_aux_output_loss: 1.1096 - val_main_output_acc: 0.8138 - val_main_output_f1_micro: 0.7992 - val_aux_output_acc: 0.8146 - val_aux_output_f1_micro: 0.2043\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 70s - loss: 1.3326 - main_output_loss: 1.1223 - aux_output_loss: 1.0519 - main_output_acc: 0.7972 - main_output_f1_micro: 0.7996 - aux_output_acc: 0.8082 - aux_output_f1_micro: 0.2047 - val_loss: 1.2024 - val_main_output_loss: 0.9809 - val_aux_output_loss: 1.1076 - val_main_output_acc: 0.8023 - val_main_output_f1_micro: 0.7999 - val_aux_output_acc: 0.8121 - val_aux_output_f1_micro: 0.2052\n",
      "\n",
      "Done with epoch: 195\n",
      "\n",
      "CPU times: user 2h 26min 44s, sys: 11min 15s, total: 2h 37min 59s\n",
      "Wall time: 2h 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for j in xrange(i, i + (100 // epochs)):\n",
    "    hist = model.fit(\n",
    "        {'main_input': x_train, 'wv_input': wv_train, 'fs_input': fs_train},\n",
    "        {'main_output': y_train, 'aux_output': y_train},\n",
    "        epochs=epochs, batch_size=batch_size,   # 500\n",
    "        validation_split=0.2,\n",
    "        validation_data=(\n",
    "            {'main_input': x_val, 'wv_input': wv_val, 'fs_input': fs_val},\n",
    "            {'main_output': y_val, 'aux_output': y_val}\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.save(model_name.format(i))\n",
    "    print\n",
    "    print('Done with epoch: {}'.format((j + 1) * epochs))\n",
    "    with open('lstm-word2vec-fasttext.epoch.csv', 'a') as fl:\n",
    "        fl.write(model_name + '\\n')\n",
    "        fl.write('Epoch {}\\n'.format((j + 1) * epochs))\n",
    "        fl.write('{}\\n'.format(datetime.now()))\n",
    "        fl.write('\\n'.join(['{}: {}'.format(k, v[0]) for k, v in hist.history.items()]))\n",
    "        fl.write('\\n\\n')\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = keras.models.load_model(\n",
    "#     'models/lstm-word2vec-fasttext_2010-2014-data_categorical-crossentropy-2014-b-val-standard_scaled_wv_fs.model',\n",
    "#     custom_objects={'f1_micro': f1_micro}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = model.predict({'main_input': x_train[:100], 'wv_input': wv_train[:100], 'fs_input': fs_train[:100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f806fa59710>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZHKXpAb9f9BdZCqg0iucAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f806fef6390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "ix = 29\n",
    "pd.Series(g[0][ix]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7ee46907d0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8070012450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(g[1][ix]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([136]),), (array([136]),), (array([136]),))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh = 0.5\n",
    "np.where(y_train[ix] == 1), np.where(g[0][ix] > thresh), np.where(g[1][ix] > thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wvmodel = Word2Vec.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fsmodel = fasttext.load_model('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.fasttext.model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_fasttext(tokens, stopwords=[]):\n",
    "    global fsmodel\n",
    "    # This requires fsmodel to be present in the namespace.\n",
    "    fs_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    ).map(lambda x: np.array([fsmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return fs_feature_vec\n",
    "\n",
    "\n",
    "def transform_unsupervised_sentiment_neuron(tokens, stopwords=[]):\n",
    "    # This requires fsmodel to be present in the namespace.\n",
    "    \n",
    "    usn_feature_vec = usnmodel.transform(tokens)\n",
    "\n",
    "    # usn_feature_vec = tokens.map(\n",
    "    #     lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    # ).map(lambda x: np.array([usnmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return usn_feature_vec\n",
    "\n",
    "\n",
    "def transform_word2vec(tokens, stopwords=[]):\n",
    "    global wvmodel\n",
    "    # This requires wvmodel to be present in the namespace.\n",
    "    wv_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords and w in wvmodel.wv.vocab)]\n",
    "    ).map(lambda x: np.array([wvmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return wv_feature_vec\n",
    "\n",
    "\n",
    "def parallel_generate_word_vectors(samp, transformer, stopwords, batch, num_proc):\n",
    "    with Parallel(n_jobs=num_proc) as parallel:\n",
    "        dataset = []\n",
    "        is_break = False\n",
    "        i = 0\n",
    "\n",
    "        while not is_break:\n",
    "            payload = []\n",
    "\n",
    "            for j in xrange(num_proc):\n",
    "                t_df = samp[(i + j) * batch: (i + 1 + j) * batch]\n",
    "\n",
    "                if t_df.empty:\n",
    "                    is_break = True\n",
    "                    continue\n",
    "\n",
    "                payload.append(\n",
    "                    delayed(transformer)(\n",
    "                        t_df, stopwords\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            print('Current batch in main thread: {}'.format((i + j) * batch))\n",
    "\n",
    "            if payload:\n",
    "                results = parallel(payload)\n",
    "                dataset.extend(results)\n",
    "                i += num_proc\n",
    "\n",
    "    return pd.concat(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_classes(pred, scale_param=0.75, min_thresh=0.05, thresh = 0.5):\n",
    "#     mx = pred.mean() + 3 * pred.std()\n",
    "    return np.where(pred > thresh)[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2idx_transform(word, _word2idx):\n",
    "    return _word2idx.get(word, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features_for(df, min_batch=2000, stopwords=[], num_proc=7):\n",
    "    df_tokens = transform_text(df)\n",
    "    \n",
    "    batch = min(df_tokens.shape[0] / num_proc, min_batch)\n",
    "\n",
    "    print('Computing fs features...')\n",
    "    fvec = parallel_generate_word_vectors(df_tokens, transform_fasttext, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Computing wv features...')\n",
    "    wvec = parallel_generate_word_vectors(df_tokens, transform_word2vec, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Mapping word indices...')\n",
    "    word_indices = df_tokens.map(lambda x: [word2idx_transform(i, _word2idx) for i in x.split()])\n",
    "    \n",
    "    return word_indices, wvec, fvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/TestData.json') as fl:\n",
    "    data = json.load(fl)\n",
    "    test_df = pd.DataFrame(data['TestData']).T\n",
    "    del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fs features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Computing wv features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Mapping word indices...\n",
      "CPU times: user 42.6 s, sys: 5.86 s, total: 48.5 s\n",
      "Wall time: 2min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_word_indices,test_wvec, test_fvec = extract_features_for(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert(np.all(test_wvec[test_wvec.isnull()].index == test_fvec[test_fvec.isnull()].index))\n",
    "test_null_index = test_wvec[test_wvec.isnull()].index.union(test_fvec[test_fvec.isnull()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'TestData_02543', u'TestData_05012', u'TestData_05830'], dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_null_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 296 ms, sys: 24 ms, total: 320 ms\n",
      "Wall time: 322 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "maxlen = 500\n",
    "\n",
    "valid_test_index = test_word_indices.index.difference(test_null_index)\n",
    "x_test = sequence.pad_sequences(test_word_indices.ix[valid_test_index], maxlen=maxlen)\n",
    "wv_test = np.vstack(test_wvec.ix[valid_test_index])\n",
    "fs_test = np.vstack(test_fvec.ix[valid_test_index])\n",
    "\n",
    "wv_test = wv_sc.transform(wv_test)\n",
    "fs_test = fs_sc.transform(fs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "test_probas = model.predict({'main_input': x_test, 'wv_input': wv_test, 'fs_input': fs_test}, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_test_probas, aux_test_probas = test_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.61576608e-27,   3.58520289e-08,   1.01937272e-16, ...,\n",
       "          1.94816299e-12,   5.47995730e-19,   1.47268390e-27],\n",
       "       [  2.25389925e-27,   6.82758503e-11,   3.20246542e-12, ...,\n",
       "          1.10186437e-12,   9.29205069e-17,   8.34213667e-29],\n",
       "       [  0.00000000e+00,   1.12812037e-21,   3.60383826e-19, ...,\n",
       "          7.97751012e-14,   1.09284648e-25,   0.00000000e+00],\n",
       "       ..., \n",
       "       [  6.69756556e-24,   1.85728350e-04,   7.84619451e-01, ...,\n",
       "          3.57485893e-15,   1.03940337e-07,   1.85798180e-24],\n",
       "       [  2.21757412e-29,   8.43061862e-05,   7.74505011e-08, ...,\n",
       "          1.55861830e-08,   2.81551885e-19,   4.40050805e-30],\n",
       "       [  0.00000000e+00,   1.88861898e-10,   1.34529872e-14, ...,\n",
       "          1.25917372e-18,   2.79991799e-31,   0.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_test_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_df.ix[test_df.index.difference(test_null_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2542, 5011, 5829]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_index = [int(s.split('_')[1]) - 1 for s in test_null_index]  # Subtract 1 since test index starts at 1 while enumerate starts at 0\n",
    "skip_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7578, 160), (7581, 3))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_test_probas.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24 ms, sys: 8 ms, total: 32 ms\n",
      "Wall time: 29.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# valid_test_feature_vec found below!\n",
    "test_values = np.zeros([main_test_probas.shape[0], len(topics)])\n",
    "for ix, pred in enumerate(main_test_probas):\n",
    "    for v in get_classes(pred, thresh=0.5):\n",
    "        test_values[ix][v] = 1\n",
    "\n",
    "test_sub_df = pd.DataFrame(\n",
    "    test_values,\n",
    "    index=test_df.ix[test_df.index.difference(test_null_index)].index,\n",
    "    columns=topics\n",
    ")\n",
    "\n",
    "null_test_df = pd.DataFrame(\n",
    "    np.zeros((len(test_null_index), len(topics))),\n",
    "    index=test_null_index,\n",
    "    columns=topics\n",
    ")\n",
    "\n",
    "test_sub_df = test_sub_df.append(null_test_df)\n",
    "test_sub_df = test_sub_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# init_test_sub_df = test_sub_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11656.0, 13075.0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init_test_sub_df.sum().sum(), \n",
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9891.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init_test_sub_df.sum().sum(), \n",
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12034.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init_test_sub_df.sum().sum(), \n",
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56877/56877 [==============================] - 70s - loss: 1.3326 - main_output_loss: 1.1223 - aux_output_loss: 1.0519 - main_output_acc: 0.7972 - main_output_f1_micro: 0.7996 - aux_output_acc: 0.8082 - aux_output_f1_micro: 0.2047 - val_loss: 1.2024 - val_main_output_loss: 0.9809 - val_aux_output_loss: 1.1076 - val_main_output_acc: 0.8023 - val_main_output_f1_micro: 0.7999 - val_aux_output_acc: 0.8121 - val_aux_output_f1_micro: 0.2052\n"
     ]
    }
   ],
   "source": [
    "print '56877/56877 [==============================] - 70s - loss: 1.3326 - main_output_loss: 1.1223 - aux_output_loss: 1.0519 - main_output_acc: 0.7972 - main_output_f1_micro: 0.7996 - aux_output_acc: 0.8082 - aux_output_f1_micro: 0.2047 - val_loss: 1.2024 - val_main_output_loss: 0.9809 - val_aux_output_loss: 1.1076 - val_main_output_acc: 0.8023 - val_main_output_f1_micro: 0.7999 - val_aux_output_acc: 0.8121 - val_aux_output_f1_micro: 0.2052'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_sub_df.astype(int).reset_index().rename(\n",
    "    columns={'index': 'id'}\n",
    ").sort_values('id').to_csv(\n",
    "    'lstm_300-word2vec_300-fasttext_300-maxlen_500-dense_128_256_128-cat_cross-epoch_200-batch_size_700-val_main_output_f1_micro_0.7999-main_output_f1_micro_0.7996-main_output_loss_1.1223-data_2012_2014-val_data_2014-thresh_0.5-with_sc_wv_fs.csv', \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7581, 160)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36 ms, sys: 0 ns, total: 36 ms\n",
      "Wall time: 32.6 ms\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# adjust_index = 0\n",
    "# # valid_test_feature_vec found below!\n",
    "# test_values = np.zeros([test_df.shape[0], len(topics)])\n",
    "# for ix, pred in enumerate(main_test_probas):\n",
    "#     if ix in skip_index:\n",
    "#         test_values[ix] = np.nan\n",
    "#         # Increment adjust index so that we have the correct index for other samples\n",
    "#         adjust_index += 1\n",
    "#         continue\n",
    "\n",
    "#     for v in get_classes(pred, thresh=0.05):\n",
    "#         test_values[ix + adjust_index][v] = 1\n",
    "\n",
    "# test_sub_df = pd.DataFrame(test_values, columns=sorted(topics), index=test_df.index)\n",
    "\n",
    "# q = test_sub_df.sum(axis=1)\n",
    "# assert(len(q[q.isnull()].index.difference(test_null_index)) == 0)\n",
    "\n",
    "# test_sub_df = test_sub_df.fillna(0)\n",
    "\n",
    "# # for i in test_feature_vec[test_feature_vec.isnull()].index:\n",
    "# #     test_sub_df.ix[i] = np.zeros(len(topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestData_02543    0.0\n",
       "TestData_05012    0.0\n",
       "TestData_05830    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.ix[test_null_index].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13075.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_sub_df.astype(int).reset_index().rename(\n",
    "#     columns={'index': 'id'}\n",
    "# ).sort_values('id').to_csv(\n",
    "#     'lstm_300-word2vec_300-fasttext_300-maxlen_500-dense_64_64_64-cat_cross-epoch_210-batch_size_750-val_main_output_f1_micro_0.5760-main_output_f1_micro_0.5751-main_output_loss_0.9143-data_2010_2013-val_data_2014-thresh_0.05.csv', \n",
    "#     index=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: zikavirus, dtype: float64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = test_sub_df['zikavirus']\n",
    "e[e==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14328"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_submission = pd.read_csv('basic_nn_submission_0.649_accuracy_multi_class.csv')\n",
    "top_submission.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9280"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_index_lstm_sub = pd.read_csv('lstm.2014b_training_700_maxlen_64cell_100epochs_0.0025_threshold.csv')\n",
    "wrong_index_lstm_sub.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34952"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_sub = pd.read_csv('basic_nn_submission_full_training_data_0.9958_validation_accuracy_binary_crossentropy.csv')\n",
    "some_sub.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2197, 160)\n",
      "(3957, 160)\n",
      "(12, 160)\n",
      "(959, 160)\n"
     ]
    }
   ],
   "source": [
    "print top_submission.set_index('id')[top_submission.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print wrong_index_lstm_sub.set_index('id')[wrong_index_lstm_sub.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print some_sub.set_index('id')[some_sub.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print test_sub_df[test_sub_df.sum(axis=1) == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestData_00011     0\n",
       "TestData_00012     0\n",
       "TestData_00015     0\n",
       "TestData_00027     3\n",
       "TestData_00029     0\n",
       "TestData_00038     1\n",
       "TestData_00042     5\n",
       "TestData_00053     4\n",
       "TestData_00056     1\n",
       "TestData_00060     1\n",
       "TestData_00066     0\n",
       "TestData_00085     0\n",
       "TestData_00087     1\n",
       "TestData_00090     0\n",
       "TestData_00092     0\n",
       "TestData_00107     3\n",
       "TestData_00111     0\n",
       "TestData_00114     0\n",
       "TestData_00115     1\n",
       "TestData_00118     0\n",
       "TestData_00119     0\n",
       "TestData_00121     0\n",
       "TestData_00123     0\n",
       "TestData_00125     0\n",
       "TestData_00127     0\n",
       "TestData_00128     1\n",
       "TestData_00139     1\n",
       "TestData_00140     1\n",
       "TestData_00144     0\n",
       "TestData_00147     2\n",
       "                  ..\n",
       "TestData_07445     0\n",
       "TestData_07456     3\n",
       "TestData_07461     1\n",
       "TestData_07462     4\n",
       "TestData_07465     0\n",
       "TestData_07468     0\n",
       "TestData_07471     1\n",
       "TestData_07475     0\n",
       "TestData_07486    10\n",
       "TestData_07495     1\n",
       "TestData_07509     0\n",
       "TestData_07514     3\n",
       "TestData_07515     1\n",
       "TestData_07523     0\n",
       "TestData_07533     2\n",
       "TestData_07534     2\n",
       "TestData_07542     1\n",
       "TestData_07544     2\n",
       "TestData_07545     0\n",
       "TestData_07552     2\n",
       "TestData_07556     5\n",
       "TestData_07563     1\n",
       "TestData_07565     0\n",
       "TestData_07566     0\n",
       "TestData_07569     0\n",
       "TestData_07571     3\n",
       "TestData_07572     1\n",
       "TestData_07579     6\n",
       "TestData_07580     2\n",
       "TestData_07581     3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_submission.set_index('id').ix[q[q == 0].index].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1712,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.sum(axis=1)\n",
    "q[q==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7581.000000\n",
       "mean        1.304709\n",
       "std         1.046046\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         1.000000\n",
       "75%         2.000000\n",
       "max         7.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = trainingY.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    236286.000000\n",
       "mean          1.392787\n",
       "std           0.762577\n",
       "min           1.000000\n",
       "25%           1.000000\n",
       "50%           1.000000\n",
       "75%           2.000000\n",
       "max          15.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bodyText</th>\n",
       "      <th>topics</th>\n",
       "      <th>webPublicationDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TestData_03241</th>\n",
       "      <td>A special British police unit was put on stand...</td>\n",
       "      <td>[]</td>\n",
       "      <td>15-11-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_04088</th>\n",
       "      <td>The youngest convict in a fatal gang-rape in N...</td>\n",
       "      <td>[]</td>\n",
       "      <td>20-12-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_06306</th>\n",
       "      <td>Former New York City mayor Rudy Giuliani has s...</td>\n",
       "      <td>[]</td>\n",
       "      <td>28-07-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_06083</th>\n",
       "      <td>John Cantlie, the British journalist who has b...</td>\n",
       "      <td>[]</td>\n",
       "      <td>13-07-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_05896</th>\n",
       "      <td>Lawyers for the companies that manufactured an...</td>\n",
       "      <td>[]</td>\n",
       "      <td>20-06-2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         bodyText topics  \\\n",
       "TestData_03241  A special British police unit was put on stand...     []   \n",
       "TestData_04088  The youngest convict in a fatal gang-rape in N...     []   \n",
       "TestData_06306  Former New York City mayor Rudy Giuliani has s...     []   \n",
       "TestData_06083  John Cantlie, the British journalist who has b...     []   \n",
       "TestData_05896  Lawyers for the companies that manufactured an...     []   \n",
       "\n",
       "               webPublicationDate  \n",
       "TestData_03241         15-11-2015  \n",
       "TestData_04088         20-12-2015  \n",
       "TestData_06306         28-07-2016  \n",
       "TestData_06083         13-07-2016  \n",
       "TestData_05896         20-06-2016  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ix = 'TestData_03241'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "london        1.0\n",
       "police        1.0\n",
       "terrorism     1.0\n",
       "uksecurity    1.0\n",
       "Name: TestData_03241, dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "london                1\n",
       "metropolitanpolice    1\n",
       "police                1\n",
       "uksecurity            1\n",
       "Name: TestData_03241, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = top_submission.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "immigration           1\n",
       "july7                 1\n",
       "london                1\n",
       "metropolitanpolice    1\n",
       "police                1\n",
       "terrorism             1\n",
       "ukcrime               1\n",
       "uksecurity            1\n",
       "Name: TestData_03241, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = some_sub.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "guncrime                       1\n",
       "knifecrime                     1\n",
       "london                         1\n",
       "metropolitanpolice             1\n",
       "occupy                         1\n",
       "police                         1\n",
       "protest                        1\n",
       "ukcrime                        1\n",
       "undercoverpoliceandpolicing    1\n",
       "Name: TestData_03241, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = wrong_index_lstm_sub.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Counter-terrorism policy\n",
    " \n",
    "Foreign policy\n",
    " \n",
    "Defence policy\n",
    " \n",
    "Islamic State\n",
    " \n",
    "Syria\n",
    " \n",
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = trainingY.sum()\n",
    "unseen_topics = s[s.isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activism',\n",
       " 'bastilledaytruckattack',\n",
       " 'berlinchristmasmarketattack',\n",
       " 'brusselsattacks',\n",
       " 'charliehebdoattack',\n",
       " 'francetrainattack',\n",
       " 'munichshooting',\n",
       " 'orlandoterrorattack',\n",
       " 'parisattacks',\n",
       " 'peaceandreconciliation',\n",
       " 'sanbernardinoshooting',\n",
       " 'tunisiaattack2015',\n",
       " 'turkeycoupattempt',\n",
       " 'zikavirus'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(topics).intersection(unseen_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activism\n",
      "afghanistan\n",
      "aid\n",
      "algerianhostagecrisis\n",
      "alqaida\n",
      "alshabaab\n",
      "antiwar\n",
      "arabandmiddleeastprotests\n",
      "armstrade\n",
      "australianguncontrol\n",
      "australiansecurityandcounterterrorism\n",
      "bastilledaytruckattack\n",
      "belgium\n",
      "berlinchristmasmarketattack\n",
      "bigdata\n",
      "biometrics\n",
      "bokoharam\n",
      "bostonmarathonbombing\n",
      "britisharmy\n",
      "brusselsattacks\n",
      "cameroon\n",
      "carers\n",
      "charliehebdoattack\n",
      "chemicalweapons\n",
      "clusterbombs\n",
      "cobra\n",
      "conflictanddevelopment\n",
      "controversy\n",
      "criminaljustice\n",
      "cybercrime\n",
      "cyberwar\n",
      "darknet\n",
      "dataprotection\n",
      "debate\n",
      "defence\n",
      "deflation\n",
      "drones\n",
      "drugs\n",
      "drugspolicy\n",
      "drugstrade\n",
      "earthquakes\n",
      "ebola\n",
      "economy\n",
      "egypt\n",
      "encryption\n",
      "energy\n",
      "espionage\n",
      "ethics\n",
      "europeanarrestwarrant\n",
      "europeancourtofhumanrights\n",
      "events\n",
      "extradition\n",
      "famine\n",
      "farright\n",
      "firefighters\n",
      "forensicscience\n",
      "france\n",
      "francetrainattack\n",
      "freedomofspeech\n",
      "genevaconventions\n",
      "germany\n",
      "guncrime\n",
      "hacking\n",
      "hashtags\n",
      "helicoptercrashes\n",
      "humanitarianresponse\n",
      "humanrights\n",
      "humanrightsact\n",
      "humantrafficking\n",
      "immigration\n",
      "india\n",
      "indonesia\n",
      "internallydisplacedpeople\n",
      "internationalcourtofjustice\n",
      "internationalcriminaljustice\n",
      "internetsafety\n",
      "iraq\n",
      "isis\n",
      "israel\n",
      "jordan\n",
      "jubilee\n",
      "judiciary\n",
      "july7\n",
      "justiceandsecurity\n",
      "kenya\n",
      "knifecrime\n",
      "lebanon\n",
      "libya\n",
      "localgovernment\n",
      "logistics\n",
      "london\n",
      "londonriots\n",
      "malaysia\n",
      "mali\n",
      "malware\n",
      "metropolitanpolice\n",
      "middleeastpeacetalks\n",
      "migration\n",
      "military\n",
      "ministryofdefence\n",
      "morocco\n",
      "mrsa\n",
      "mumbaiterrorattacks\n",
      "munichshooting\n",
      "naturaldisasters\n",
      "nigeria\n",
      "nuclearweapons\n",
      "occupy\n",
      "organisedcrime\n",
      "orlandoterrorattack\n",
      "osamabinladen\n",
      "paris\n",
      "parisattacks\n",
      "peaceandreconciliation\n",
      "philippines\n",
      "piracy\n",
      "planecrashes\n",
      "police\n",
      "protest\n",
      "refugees\n",
      "religion\n",
      "retirementage\n",
      "rio20earthsummit\n",
      "royalairforce\n",
      "royalnavy\n",
      "russia\n",
      "sanbernardinoshooting\n",
      "saudiarabia\n",
      "september11\n",
      "slavery\n",
      "somalia\n",
      "southafrica\n",
      "southchinasea\n",
      "stopandsearch\n",
      "surveillance\n",
      "sydneysiege\n",
      "syria\n",
      "taliban\n",
      "terrorism\n",
      "thailand\n",
      "torture\n",
      "traincrashes\n",
      "transport\n",
      "tunisiaattack2015\n",
      "turkey\n",
      "turkeycoupattempt\n",
      "ukcrime\n",
      "uksecurity\n",
      "uksupremecourt\n",
      "undercoverpoliceandpolicing\n",
      "unitednations\n",
      "usguncontrol\n",
      "values\n",
      "warcrimes\n",
      "warreporting\n",
      "weaponstechnology\n",
      "womeninbusiness\n",
      "woolwichattack\n",
      "worldmigration\n",
      "zikavirus\n"
     ]
    }
   ],
   "source": [
    "for i in topics:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsolatorio/ml-ai/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3445929"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(wvmodel['zika'], np.vstack(test_wvec.dropna())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsolatorio/ml-ai/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.38107796869050226"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(fsmodel['zika'], np.vstack(test_fvec.dropna())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              The World Health Organisation has convened an ...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           28-01-2016\n",
       "Name: TestData_04490, dtype: object"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[4488 + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              The United Nations security council has called...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           17-09-2016\n",
       "Name: TestData_06730, dtype: object"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[6727 + 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              We are deeply concerned that the counter-terro...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           02-02-2015\n",
       "Name: TestData_00360, dtype: object"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[359]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drugstrade    1.0\n",
       "Name: TestData_04490, dtype: float64"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.iloc[4488 + 1]\n",
    "q[q > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
