{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from growing_instability_lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub = pd.read_csv('../data/sampleSubmission.csv')\n",
    "topics = sorted(set(sample_sub.columns.difference(['id'])))\n",
    "\n",
    "topic2actual = {}\n",
    "for i in sample_sub.columns:\n",
    "    if 'id' == i:\n",
    "        continue\n",
    "    topic2actual[i] = segment(i)\n",
    "    \n",
    "target_columns = sorted(topics)\n",
    "len(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.73 s, sys: 1.31 s, total: 10 s\n",
      "Wall time: 10 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wvec_trainingX = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', 'wvec_trainingX')\n",
    "fvec_trainingX = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', 'fvec_trainingX')\n",
    "word2idx_trainingX = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', 'word2idx_trainingX')\n",
    "_word2idx = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', '_word2idx')\n",
    "trainingY = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', 'trainingY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.1 s, sys: 72 ms, total: 20.2 s\n",
      "Wall time: 20 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word2ind = _word2idx.to_dict()\n",
    "\n",
    "ind2word = {i: j + 1 for i, j in word2ind.items()}  # Remove the increment if data is fixed.\n",
    "word2ind = {j: i for i, j in ind2word.items()}\n",
    "\n",
    "ind2class = dict(enumerate(topics))\n",
    "class2ind = {j: i for i, j in ind2class.items()}\n",
    "\n",
    "num_samples = trainingY.shape[0]\n",
    "\n",
    "training_X = word2idx_trainingX.head(num_samples)\n",
    "\n",
    "training_Y = pd.DataFrame(zip(*np.where(trainingY.head(num_samples) == 1)), columns=['iloc', 'topics'])\n",
    "training_WV = wvec_trainingX.head(num_samples)\n",
    "training_FS = fvec_trainingX.head(num_samples)\n",
    "\n",
    "training_Y = training_Y.groupby('iloc')['topics'].apply(list)\n",
    "training_Y.index = trainingY.head(num_samples).index\n",
    "\n",
    "# indices = sorted(training_Y.index.copy())\n",
    "indices = sorted(training_Y.index[training_Y.index.str.contains('^201[2-4]')])\n",
    "# np.random.shuffle(indices)\n",
    "indices = pd.Index(indices)\n",
    "\n",
    "training_X = training_X.ix[indices]\n",
    "training_WV = training_WV.ix[indices]\n",
    "training_FS = training_FS.ix[indices]\n",
    "training_Y = training_Y.ix[indices]\n",
    "\n",
    "dataset = zip(training_X, training_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def generate_lstm_batch_dataset(dataset, word2ind, class2ind, max_len, batch_size=1000, shuffle=True):\n",
    "#     if shuffle:\n",
    "#         np.random.shuffle(dataset)\n",
    "\n",
    "#     num_docs = len(dataset)\n",
    "#     num_words = len(word2ind) + 1\n",
    "#     num_class = len(class2ind)\n",
    "\n",
    "#     for s in xrange(0, num_docs, batch_size):\n",
    "#         x_batch = np.zeros([batch_size, max_len, num_words])\n",
    "#         y_batch = np.zeros([batch_size, num_class])\n",
    "\n",
    "#         for ix, (features, target) in enumerate(dataset[s:s + batch_size]):\n",
    "#             # print features\n",
    "#             for idx, feat in enumerate(features):\n",
    "#                 if idx >= max_len:\n",
    "#                     break\n",
    "\n",
    "#                 # print feat, ind2word[feat]\n",
    "#                 x_batch[ix, idx, feat] = 1\n",
    "\n",
    "#             if not isinstance(target, list):\n",
    "#                 target = [target]\n",
    "                \n",
    "#             for tg in target:\n",
    "#                 y_batch[ix, tg] = 1\n",
    "\n",
    "#         yield x_batch[:ix + 1, :, :], y_batch[:ix + 1, :]\n",
    "\n",
    "\n",
    "# def infinite_lstm_dataset_generator(dataset, word2ind, class2ind, max_len, batch_size=100):\n",
    "#     while 1:\n",
    "#         for b in generate_lstm_batch_dataset(dataset, word2ind, class2ind, max_len, batch_size):\n",
    "#             yield b\n",
    "\n",
    "# # lens = []\n",
    "# # for i in dataset:\n",
    "# #     lens.append(len(i[0]))\n",
    "# # pd.Series(lens).quantile(0.999)\n",
    "# # Use the above to estimate the acceptable timeseries dimension.\n",
    "# LSTM_TIMESERIES = 100\n",
    "# id_lstm_gen = infinite_lstm_dataset_generator(dataset, word2ind, class2ind, max_len=LSTM_TIMESERIES, batch_size=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wv_sc = StandardScaler()\n",
    "fs_sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "def build_target(y, size):\n",
    "    e = np.zeros(size)\n",
    "    e[y] = 1\n",
    "    return e\n",
    "\n",
    "def build_input_output_data(X, WV, FS, Y, maxlen):\n",
    "\n",
    "    x = sequence.pad_sequences(X, maxlen=maxlen)\n",
    "    y = np.vstack(Y.map(lambda x: build_target(x, len(topics))))\n",
    "    wv = np.vstack(WV)\n",
    "    fs = np.vstack(FS)\n",
    "    \n",
    "    return x, wv, fs, y\n",
    "\n",
    "\n",
    "test_ix = training_Y.index.str.contains('^201[0-4]')\n",
    "val_ix = training_Y.index.str.contains('^2014[b]')\n",
    "\n",
    "\n",
    "maxlen = 500\n",
    "\n",
    "\n",
    "x_train, wv_train, fs_train, y_train = build_input_output_data(\n",
    "    training_X.ix[test_ix],\n",
    "    training_WV.ix[test_ix],\n",
    "    training_FS.ix[test_ix],\n",
    "    training_Y.ix[test_ix],\n",
    "    maxlen=maxlen\n",
    ")\n",
    "\n",
    "\n",
    "x_val, wv_val, fs_val, y_val = build_input_output_data(\n",
    "    training_X.ix[val_ix],\n",
    "    training_WV.ix[val_ix],\n",
    "    training_FS.ix[val_ix],\n",
    "    training_Y.ix[val_ix],\n",
    "    maxlen=maxlen\n",
    ")\n",
    "\n",
    "wv_train = wv_sc.fit_transform(wv_train)\n",
    "fs_train = fs_sc.fit_transform(fs_train)\n",
    "\n",
    "wv_val = wv_sc.transform(wv_val)\n",
    "fs_val = fs_sc.transform(fs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((56877,), (9424,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_Y.shape, training_Y.ix[training_Y.index.str.contains('^2014[b]')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Setup model\n",
    "# model_lstm = keras.models.Sequential()\n",
    "# model_lstm.add(keras.layers.Embedding(len(word2ind) + 1, 256))\n",
    "# # model_lstm.add(keras.layers.LSTM(32, return_sequences=False, input_shape=(None, len(word2ind) + 1)))\n",
    "# # model_lstm.add(keras.layers.Dropout(0.2))\n",
    "# model_lstm.add(keras.layers.LSTM(16, return_sequences=False))\n",
    "# model_lstm.add(keras.layers.Dense(128))\n",
    "# model_lstm.add(keras.layers.Activation('relu'))\n",
    "# model_lstm.add(keras.layers.Dropout(0.2))\n",
    "# model_lstm.add(keras.layers.Dense(len(class2ind)))\n",
    "# model_lstm.add(keras.layers.Activation('sigmoid'))\n",
    "# model_lstm.compile(\n",
    "#     loss='binary_crossentropy',\n",
    "#     optimizer='adam',\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# # for i in range(6):\n",
    "# #     model_lstm.fit_generator(id_lstm_gen, steps_per_epoch=len(dataset), epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "# Headline input: meant to receive sequences of 100 integers, between 1 and 10000.\n",
    "# Note that we can name any layer by passing it a \"name\" argument.\n",
    "main_input = Input(shape=(maxlen,), dtype='int32', name='main_input')\n",
    "\n",
    "# This embedding layer will encode the input sequence\n",
    "# into a sequence of dense 512-dimensional vectors.\n",
    "x = Embedding(output_dim=300, input_dim=len(word2ind) + 1, input_length=maxlen)(main_input)\n",
    "\n",
    "# A LSTM will transform the vector sequence into a single vector,\n",
    "# containing information about the entire sequence\n",
    "lstm_out = LSTM(32)(x)\n",
    "\n",
    "auxiliary_output = Dense(len(class2ind), activation='sigmoid', name='aux_output')(lstm_out)\n",
    "\n",
    "\n",
    "wv_input = Input(shape=(300,), name='wv_input')\n",
    "fs_input = Input(shape=(300,), name='fs_input')\n",
    "\n",
    "x = keras.layers.concatenate([lstm_out, wv_input, fs_input])\n",
    "\n",
    "# We stack a deep densely-connected network on top\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "# And finally we add the main logistic regression layer\n",
    "main_output = Dense(len(class2ind), activation='sigmoid', name='main_output')(x)\n",
    "\n",
    "model = Model(inputs=[main_input, wv_input, fs_input], outputs=[main_output, auxiliary_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as K\n",
    "\n",
    "\n",
    "def f1_micro(y_true, y_pred):\n",
    "    TP = K.metrics.true_positives(y_true, K.round(y_pred))\n",
    "    FP = K.metrics.false_positives(y_true, K.round(y_pred))\n",
    "    FN = K.metrics.false_negatives(y_true, K.round(y_pred))\n",
    "    \n",
    "    p = K.reduce_sum(TP) / (K.reduce_sum(TP) + K.reduce_sum(FP))\n",
    "    r = K.reduce_sum(TP) / (K.reduce_sum(TP) + K.reduce_sum(FN))\n",
    "    \n",
    "    return (2.0 * p * r) / (p + r)\n",
    "\n",
    "\n",
    "import keras.backend as KB\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "\n",
    "    # Count positive samples.\n",
    "    c1 = KB.sum(KB.round(KB.clip(y_true * y_pred, 0, 1)))\n",
    "    c2 = KB.sum(K.round(KB.clip(y_pred, 0, 1)))\n",
    "    c3 = KB.sum(K.round(KB.clip(y_true, 0, 1)))\n",
    "\n",
    "    # If there are no true samples, fix the F1 score at 0.\n",
    "    if c3 == 0:\n",
    "        return 0\n",
    "\n",
    "    # How many selected items are relevant?\n",
    "    precision = c1 / c2\n",
    "\n",
    "    # How many relevant items are selected?\n",
    "    recall = c1 / c3\n",
    "\n",
    "    # Calculate f1_score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input (InputLayer)          (None, 500)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 500, 300)      105478200                                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 32)            42624                                        \n",
      "____________________________________________________________________________________________________\n",
      "wv_input (InputLayer)            (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "fs_input (InputLayer)            (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 632)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 128)           81024                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 256)           33024                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 128)           32896                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 160)           20640                                        \n",
      "____________________________________________________________________________________________________\n",
      "aux_output (Dense)               (None, 160)           5280                                         \n",
      "====================================================================================================\n",
      "Total params: 105,693,688\n",
      "Trainable params: 105,693,688\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss={'main_output': 'categorical_crossentropy', 'aux_output': 'categorical_crossentropy'},\n",
    "              loss_weights={'main_output': 1., 'aux_output': 0.2}, metrics=['accuracy', f1_micro])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.callbacks import EarlyStopping\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "# model.fit(X, y, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import keras.backend as K\n",
    "# K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.train_on_batch(\n",
    "#     {'main_input': x_train[:10], 'wv_input': np.vstack(training_WV)[:10], 'fs_input': np.vstack(training_FS)[:10]},\n",
    "#     {'main_output': y_train[:10], 'aux_output': y_train[:10]}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 5.01 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# And trained it via:\n",
    "batch_size = 700\n",
    "model.fit(\n",
    "    {'main_input': x_train, 'wv_input': wv_train, 'fs_input': fs_train},\n",
    "    {'main_output': y_train, 'aux_output': y_train},\n",
    "    epochs=1, batch_size=batch_size,   # 500\n",
    "    validation_split=0.2,\n",
    "    validation_data=(\n",
    "        {'main_input': x_val, 'wv_input': wv_val, 'fs_input': fs_val},\n",
    "        {'main_output': y_val, 'aux_output': y_val}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 54s - loss: 5.2118 - main_output_loss: 3.9216 - aux_output_loss: 6.4508 - main_output_acc: 0.3954 - main_output_f1_micro: 0.0964 - aux_output_acc: 0.0505 - aux_output_f1_micro: 0.0566 - val_loss: 4.4711 - val_main_output_loss: 3.1595 - val_aux_output_loss: 6.5580 - val_main_output_acc: 0.5260 - val_main_output_f1_micro: 0.1166 - val_aux_output_acc: 0.0423 - val_aux_output_f1_micro: 0.0602\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 54s - loss: 4.6088 - main_output_loss: 3.3304 - aux_output_loss: 6.3919 - main_output_acc: 0.4880 - main_output_f1_micro: 0.1348 - aux_output_acc: 0.0505 - aux_output_f1_micro: 0.0630 - val_loss: 4.1412 - val_main_output_loss: 2.8350 - val_aux_output_loss: 6.5310 - val_main_output_acc: 0.5757 - val_main_output_f1_micro: 0.1521 - val_aux_output_acc: 0.0423 - val_aux_output_f1_micro: 0.0654\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 54s - loss: 4.3826 - main_output_loss: 3.1100 - aux_output_loss: 6.3630 - main_output_acc: 0.5213 - main_output_f1_micro: 0.1680 - aux_output_acc: 0.0505 - aux_output_f1_micro: 0.0674 - val_loss: 4.0103 - val_main_output_loss: 2.7072 - val_aux_output_loss: 6.5155 - val_main_output_acc: 0.5750 - val_main_output_f1_micro: 0.1830 - val_aux_output_acc: 0.0423 - val_aux_output_f1_micro: 0.0691\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 54s - loss: 4.2421 - main_output_loss: 2.9739 - aux_output_loss: 6.3410 - main_output_acc: 0.5374 - main_output_f1_micro: 0.1968 - aux_output_acc: 0.0584 - aux_output_f1_micro: 0.0706 - val_loss: 3.9290 - val_main_output_loss: 2.6312 - val_aux_output_loss: 6.4889 - val_main_output_acc: 0.6002 - val_main_output_f1_micro: 0.2099 - val_aux_output_acc: 0.0780 - val_aux_output_f1_micro: 0.0720\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 54s - loss: 4.1318 - main_output_loss: 2.8689 - aux_output_loss: 6.3149 - main_output_acc: 0.5506 - main_output_f1_micro: 0.2220 - aux_output_acc: 0.0877 - aux_output_f1_micro: 0.0732 - val_loss: 3.8395 - val_main_output_loss: 2.5497 - val_aux_output_loss: 6.4491 - val_main_output_acc: 0.6071 - val_main_output_f1_micro: 0.2338 - val_aux_output_acc: 0.0780 - val_aux_output_f1_micro: 0.0744\n",
      "\n",
      "Done with epoch: 5\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 54s - loss: 4.0476 - main_output_loss: 2.7944 - aux_output_loss: 6.2658 - main_output_acc: 0.5594 - main_output_f1_micro: 0.2445 - aux_output_acc: 0.0876 - aux_output_f1_micro: 0.0755 - val_loss: 3.7397 - val_main_output_loss: 2.4672 - val_aux_output_loss: 6.3627 - val_main_output_acc: 0.6214 - val_main_output_f1_micro: 0.2549 - val_aux_output_acc: 0.0777 - val_aux_output_f1_micro: 0.0766\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 54s - loss: 3.9594 - main_output_loss: 2.7230 - aux_output_loss: 6.1822 - main_output_acc: 0.5714 - main_output_f1_micro: 0.2645 - aux_output_acc: 0.0876 - aux_output_f1_micro: 0.0777 - val_loss: 3.6650 - val_main_output_loss: 2.4119 - val_aux_output_loss: 6.2656 - val_main_output_acc: 0.6179 - val_main_output_f1_micro: 0.2738 - val_aux_output_acc: 0.0777 - val_aux_output_f1_micro: 0.0789\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 54s - loss: 3.8861 - main_output_loss: 2.6686 - aux_output_loss: 6.0876 - main_output_acc: 0.5771 - main_output_f1_micro: 0.2825 - aux_output_acc: 0.0876 - aux_output_f1_micro: 0.0801 - val_loss: 3.5900 - val_main_output_loss: 2.3480 - val_aux_output_loss: 6.2100 - val_main_output_acc: 0.6238 - val_main_output_f1_micro: 0.2909 - val_aux_output_acc: 0.0779 - val_aux_output_f1_micro: 0.0813\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 54s - loss: 3.7951 - main_output_loss: 2.5996 - aux_output_loss: 5.9777 - main_output_acc: 0.5878 - main_output_f1_micro: 0.2988 - aux_output_acc: 0.0882 - aux_output_f1_micro: 0.0824 - val_loss: 3.5240 - val_main_output_loss: 2.3094 - val_aux_output_loss: 6.0729 - val_main_output_acc: 0.6373 - val_main_output_f1_micro: 0.3065 - val_aux_output_acc: 0.0788 - val_aux_output_f1_micro: 0.0836\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 54s - loss: 3.7359 - main_output_loss: 2.5588 - aux_output_loss: 5.8856 - main_output_acc: 0.5939 - main_output_f1_micro: 0.3138 - aux_output_acc: 0.0918 - aux_output_f1_micro: 0.0847 - val_loss: 3.4378 - val_main_output_loss: 2.2438 - val_aux_output_loss: 5.9704 - val_main_output_acc: 0.6434 - val_main_output_f1_micro: 0.3208 - val_aux_output_acc: 0.0827 - val_aux_output_f1_micro: 0.0858\n",
      "\n",
      "Done with epoch: 10\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 55s - loss: 3.6570 - main_output_loss: 2.5001 - aux_output_loss: 5.7846 - main_output_acc: 0.6016 - main_output_f1_micro: 0.3274 - aux_output_acc: 0.1019 - aux_output_f1_micro: 0.0869 - val_loss: 3.3622 - val_main_output_loss: 2.1893 - val_aux_output_loss: 5.8643 - val_main_output_acc: 0.6555 - val_main_output_f1_micro: 0.3339 - val_aux_output_acc: 0.0958 - val_aux_output_f1_micro: 0.0880\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 54s - loss: 3.5879 - main_output_loss: 2.4496 - aux_output_loss: 5.6911 - main_output_acc: 0.6065 - main_output_f1_micro: 0.3400 - aux_output_acc: 0.1109 - aux_output_f1_micro: 0.0890 - val_loss: 3.2984 - val_main_output_loss: 2.1418 - val_aux_output_loss: 5.7828 - val_main_output_acc: 0.6529 - val_main_output_f1_micro: 0.3461 - val_aux_output_acc: 0.1022 - val_aux_output_f1_micro: 0.0900\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 54s - loss: 3.5301 - main_output_loss: 2.4090 - aux_output_loss: 5.6052 - main_output_acc: 0.6100 - main_output_f1_micro: 0.3519 - aux_output_acc: 0.1196 - aux_output_f1_micro: 0.0908 - val_loss: 3.2121 - val_main_output_loss: 2.0751 - val_aux_output_loss: 5.6849 - val_main_output_acc: 0.6666 - val_main_output_f1_micro: 0.3575 - val_aux_output_acc: 0.1122 - val_aux_output_f1_micro: 0.0916\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 54s - loss: 3.4532 - main_output_loss: 2.3534 - aux_output_loss: 5.4991 - main_output_acc: 0.6182 - main_output_f1_micro: 0.3627 - aux_output_acc: 0.1315 - aux_output_f1_micro: 0.0923 - val_loss: 3.1662 - val_main_output_loss: 2.0401 - val_aux_output_loss: 5.6306 - val_main_output_acc: 0.6778 - val_main_output_f1_micro: 0.3678 - val_aux_output_acc: 0.1198 - val_aux_output_f1_micro: 0.0929\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 54s - loss: 3.3937 - main_output_loss: 2.3145 - aux_output_loss: 5.3958 - main_output_acc: 0.6237 - main_output_f1_micro: 0.3728 - aux_output_acc: 0.1541 - aux_output_f1_micro: 0.0935 - val_loss: 3.0905 - val_main_output_loss: 1.9907 - val_aux_output_loss: 5.4993 - val_main_output_acc: 0.6729 - val_main_output_f1_micro: 0.3777 - val_aux_output_acc: 0.1521 - val_aux_output_f1_micro: 0.0940\n",
      "\n",
      "Done with epoch: 15\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 54s - loss: 3.3400 - main_output_loss: 2.2825 - aux_output_loss: 5.2877 - main_output_acc: 0.6289 - main_output_f1_micro: 0.3824 - aux_output_acc: 0.1804 - aux_output_f1_micro: 0.0945 - val_loss: 3.0519 - val_main_output_loss: 1.9723 - val_aux_output_loss: 5.3980 - val_main_output_acc: 0.6805 - val_main_output_f1_micro: 0.3871 - val_aux_output_acc: 0.1752 - val_aux_output_f1_micro: 0.0949\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 54s - loss: 3.2711 - main_output_loss: 2.2385 - aux_output_loss: 5.1631 - main_output_acc: 0.6369 - main_output_f1_micro: 0.3914 - aux_output_acc: 0.2085 - aux_output_f1_micro: 0.0953 - val_loss: 2.9996 - val_main_output_loss: 1.9489 - val_aux_output_loss: 5.2536 - val_main_output_acc: 0.6907 - val_main_output_f1_micro: 0.3958 - val_aux_output_acc: 0.2108 - val_aux_output_f1_micro: 0.0957\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56877/56877 [==============================] - 54s - loss: 3.2128 - main_output_loss: 2.2059 - aux_output_loss: 5.0345 - main_output_acc: 0.6402 - main_output_f1_micro: 0.4000 - aux_output_acc: 0.2362 - aux_output_f1_micro: 0.0960 - val_loss: 2.9241 - val_main_output_loss: 1.8979 - val_aux_output_loss: 5.1315 - val_main_output_acc: 0.6983 - val_main_output_f1_micro: 0.4041 - val_aux_output_acc: 0.2373 - val_aux_output_f1_micro: 0.0964\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 54s - loss: 3.1506 - main_output_loss: 2.1699 - aux_output_loss: 4.9034 - main_output_acc: 0.6480 - main_output_f1_micro: 0.4080 - aux_output_acc: 0.2592 - aux_output_f1_micro: 0.0967 - val_loss: 2.8511 - val_main_output_loss: 1.8475 - val_aux_output_loss: 5.0183 - val_main_output_acc: 0.6963 - val_main_output_f1_micro: 0.4118 - val_aux_output_acc: 0.2504 - val_aux_output_f1_micro: 0.0969\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 54s - loss: 3.0919 - main_output_loss: 2.1370 - aux_output_loss: 4.7748 - main_output_acc: 0.6520 - main_output_f1_micro: 0.4156 - aux_output_acc: 0.2859 - aux_output_f1_micro: 0.0972 - val_loss: 2.8028 - val_main_output_loss: 1.8273 - val_aux_output_loss: 4.8775 - val_main_output_acc: 0.6994 - val_main_output_f1_micro: 0.4192 - val_aux_output_acc: 0.2858 - val_aux_output_f1_micro: 0.0974\n",
      "\n",
      "Done with epoch: 20\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 54s - loss: 3.0379 - main_output_loss: 2.1093 - aux_output_loss: 4.6433 - main_output_acc: 0.6554 - main_output_f1_micro: 0.4227 - aux_output_acc: 0.3097 - aux_output_f1_micro: 0.0977 - val_loss: 2.7438 - val_main_output_loss: 1.7945 - val_aux_output_loss: 4.7464 - val_main_output_acc: 0.7099 - val_main_output_f1_micro: 0.4263 - val_aux_output_acc: 0.3027 - val_aux_output_f1_micro: 0.0979\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.9837 - main_output_loss: 2.0801 - aux_output_loss: 4.5178 - main_output_acc: 0.6608 - main_output_f1_micro: 0.4298 - aux_output_acc: 0.3344 - aux_output_f1_micro: 0.0981 - val_loss: 2.7003 - val_main_output_loss: 1.7740 - val_aux_output_loss: 4.6317 - val_main_output_acc: 0.7088 - val_main_output_f1_micro: 0.4333 - val_aux_output_acc: 0.3339 - val_aux_output_f1_micro: 0.0983\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.9283 - main_output_loss: 2.0502 - aux_output_loss: 4.3903 - main_output_acc: 0.6672 - main_output_f1_micro: 0.4366 - aux_output_acc: 0.3557 - aux_output_f1_micro: 0.0985 - val_loss: 2.6407 - val_main_output_loss: 1.7410 - val_aux_output_loss: 4.4983 - val_main_output_acc: 0.7204 - val_main_output_f1_micro: 0.4398 - val_aux_output_acc: 0.3544 - val_aux_output_f1_micro: 0.0986\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.8781 - main_output_loss: 2.0228 - aux_output_loss: 4.2767 - main_output_acc: 0.6707 - main_output_f1_micro: 0.4429 - aux_output_acc: 0.3769 - aux_output_f1_micro: 0.0988 - val_loss: 2.5961 - val_main_output_loss: 1.7167 - val_aux_output_loss: 4.3969 - val_main_output_acc: 0.7191 - val_main_output_f1_micro: 0.4460 - val_aux_output_acc: 0.3765 - val_aux_output_f1_micro: 0.0989\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.8337 - main_output_loss: 1.9995 - aux_output_loss: 4.1713 - main_output_acc: 0.6760 - main_output_f1_micro: 0.4490 - aux_output_acc: 0.3926 - aux_output_f1_micro: 0.0991 - val_loss: 2.5489 - val_main_output_loss: 1.6961 - val_aux_output_loss: 4.2644 - val_main_output_acc: 0.7290 - val_main_output_f1_micro: 0.4520 - val_aux_output_acc: 0.3985 - val_aux_output_f1_micro: 0.0992\n",
      "\n",
      "Done with epoch: 25\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.7769 - main_output_loss: 1.9669 - aux_output_loss: 4.0501 - main_output_acc: 0.6796 - main_output_f1_micro: 0.4549 - aux_output_acc: 0.4170 - aux_output_f1_micro: 0.0993 - val_loss: 2.4960 - val_main_output_loss: 1.6632 - val_aux_output_loss: 4.1639 - val_main_output_acc: 0.7297 - val_main_output_f1_micro: 0.4577 - val_aux_output_acc: 0.4194 - val_aux_output_f1_micro: 0.0994\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.7371 - main_output_loss: 1.9476 - aux_output_loss: 3.9471 - main_output_acc: 0.6832 - main_output_f1_micro: 0.4605 - aux_output_acc: 0.4343 - aux_output_f1_micro: 0.0996 - val_loss: 2.4515 - val_main_output_loss: 1.6409 - val_aux_output_loss: 4.0531 - val_main_output_acc: 0.7462 - val_main_output_f1_micro: 0.4634 - val_aux_output_acc: 0.4310 - val_aux_output_f1_micro: 0.0997\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.6900 - main_output_loss: 1.9216 - aux_output_loss: 3.8422 - main_output_acc: 0.6886 - main_output_f1_micro: 0.4662 - aux_output_acc: 0.4533 - aux_output_f1_micro: 0.0998 - val_loss: 2.4074 - val_main_output_loss: 1.6172 - val_aux_output_loss: 3.9512 - val_main_output_acc: 0.7427 - val_main_output_f1_micro: 0.4689 - val_aux_output_acc: 0.4499 - val_aux_output_f1_micro: 0.0999\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.6470 - main_output_loss: 1.8988 - aux_output_loss: 3.7411 - main_output_acc: 0.6902 - main_output_f1_micro: 0.4716 - aux_output_acc: 0.4676 - aux_output_f1_micro: 0.1000 - val_loss: 2.3759 - val_main_output_loss: 1.6071 - val_aux_output_loss: 3.8441 - val_main_output_acc: 0.7452 - val_main_output_f1_micro: 0.4743 - val_aux_output_acc: 0.4711 - val_aux_output_f1_micro: 0.1000\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.5995 - main_output_loss: 1.8715 - aux_output_loss: 3.6399 - main_output_acc: 0.6958 - main_output_f1_micro: 0.4769 - aux_output_acc: 0.4846 - aux_output_f1_micro: 0.1001 - val_loss: 2.3243 - val_main_output_loss: 1.5727 - val_aux_output_loss: 3.7578 - val_main_output_acc: 0.7498 - val_main_output_f1_micro: 0.4795 - val_aux_output_acc: 0.4757 - val_aux_output_f1_micro: 0.1002\n",
      "\n",
      "Done with epoch: 30\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.5607 - main_output_loss: 1.8516 - aux_output_loss: 3.5457 - main_output_acc: 0.6991 - main_output_f1_micro: 0.4821 - aux_output_acc: 0.4986 - aux_output_f1_micro: 0.1003 - val_loss: 2.2923 - val_main_output_loss: 1.5636 - val_aux_output_loss: 3.6437 - val_main_output_acc: 0.7454 - val_main_output_f1_micro: 0.4846 - val_aux_output_acc: 0.5035 - val_aux_output_f1_micro: 0.1004\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.5239 - main_output_loss: 1.8332 - aux_output_loss: 3.4534 - main_output_acc: 0.7023 - main_output_f1_micro: 0.4871 - aux_output_acc: 0.5163 - aux_output_f1_micro: 0.1005 - val_loss: 2.2398 - val_main_output_loss: 1.5334 - val_aux_output_loss: 3.5321 - val_main_output_acc: 0.7375 - val_main_output_f1_micro: 0.4896 - val_aux_output_acc: 0.5158 - val_aux_output_f1_micro: 0.1005\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.4882 - main_output_loss: 1.8122 - aux_output_loss: 3.3799 - main_output_acc: 0.7051 - main_output_f1_micro: 0.4921 - aux_output_acc: 0.5265 - aux_output_f1_micro: 0.1006 - val_loss: 2.2180 - val_main_output_loss: 1.5271 - val_aux_output_loss: 3.4542 - val_main_output_acc: 0.7504 - val_main_output_f1_micro: 0.4945 - val_aux_output_acc: 0.5251 - val_aux_output_f1_micro: 0.1007\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.4474 - main_output_loss: 1.7900 - aux_output_loss: 3.2870 - main_output_acc: 0.7100 - main_output_f1_micro: 0.4969 - aux_output_acc: 0.5414 - aux_output_f1_micro: 0.1008 - val_loss: 2.1817 - val_main_output_loss: 1.5084 - val_aux_output_loss: 3.3668 - val_main_output_acc: 0.7572 - val_main_output_f1_micro: 0.4994 - val_aux_output_acc: 0.5398 - val_aux_output_f1_micro: 0.1008\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56877/56877 [==============================] - 54s - loss: 2.4201 - main_output_loss: 1.7781 - aux_output_loss: 3.2101 - main_output_acc: 0.7107 - main_output_f1_micro: 0.5018 - aux_output_acc: 0.5532 - aux_output_f1_micro: 0.1009 - val_loss: 2.1514 - val_main_output_loss: 1.4922 - val_aux_output_loss: 3.2963 - val_main_output_acc: 0.7571 - val_main_output_f1_micro: 0.5041 - val_aux_output_acc: 0.5457 - val_aux_output_f1_micro: 0.1010\n",
      "\n",
      "Done with epoch: 35\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.3810 - main_output_loss: 1.7538 - aux_output_loss: 3.1363 - main_output_acc: 0.7167 - main_output_f1_micro: 0.5064 - aux_output_acc: 0.5650 - aux_output_f1_micro: 0.1010 - val_loss: 2.1175 - val_main_output_loss: 1.4740 - val_aux_output_loss: 3.2177 - val_main_output_acc: 0.7616 - val_main_output_f1_micro: 0.5087 - val_aux_output_acc: 0.5666 - val_aux_output_f1_micro: 0.1011\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.3590 - main_output_loss: 1.7448 - aux_output_loss: 3.0711 - main_output_acc: 0.7140 - main_output_f1_micro: 0.5109 - aux_output_acc: 0.5753 - aux_output_f1_micro: 0.1011 - val_loss: 2.0935 - val_main_output_loss: 1.4640 - val_aux_output_loss: 3.1474 - val_main_output_acc: 0.7699 - val_main_output_f1_micro: 0.5132 - val_aux_output_acc: 0.5723 - val_aux_output_f1_micro: 0.1012\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.3272 - main_output_loss: 1.7266 - aux_output_loss: 3.0031 - main_output_acc: 0.7179 - main_output_f1_micro: 0.5153 - aux_output_acc: 0.5848 - aux_output_f1_micro: 0.1013 - val_loss: 2.0605 - val_main_output_loss: 1.4456 - val_aux_output_loss: 3.0746 - val_main_output_acc: 0.7674 - val_main_output_f1_micro: 0.5175 - val_aux_output_acc: 0.5871 - val_aux_output_f1_micro: 0.1013\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.2951 - main_output_loss: 1.7073 - aux_output_loss: 2.9386 - main_output_acc: 0.7257 - main_output_f1_micro: 0.5197 - aux_output_acc: 0.5958 - aux_output_f1_micro: 0.1014 - val_loss: 2.0300 - val_main_output_loss: 1.4257 - val_aux_output_loss: 3.0216 - val_main_output_acc: 0.7714 - val_main_output_f1_micro: 0.5218 - val_aux_output_acc: 0.5903 - val_aux_output_f1_micro: 0.1014\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.2726 - main_output_loss: 1.6964 - aux_output_loss: 2.8809 - main_output_acc: 0.7268 - main_output_f1_micro: 0.5239 - aux_output_acc: 0.6049 - aux_output_f1_micro: 0.1015 - val_loss: 2.0089 - val_main_output_loss: 1.4189 - val_aux_output_loss: 2.9501 - val_main_output_acc: 0.7750 - val_main_output_f1_micro: 0.5260 - val_aux_output_acc: 0.6028 - val_aux_output_f1_micro: 0.1015\n",
      "\n",
      "Done with epoch: 40\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.2490 - main_output_loss: 1.6851 - aux_output_loss: 2.8197 - main_output_acc: 0.7279 - main_output_f1_micro: 0.5280 - aux_output_acc: 0.6144 - aux_output_f1_micro: 0.1016 - val_loss: 1.9885 - val_main_output_loss: 1.4123 - val_aux_output_loss: 2.8810 - val_main_output_acc: 0.7708 - val_main_output_f1_micro: 0.5301 - val_aux_output_acc: 0.6153 - val_aux_output_f1_micro: 0.1016\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.2138 - main_output_loss: 1.6626 - aux_output_loss: 2.7559 - main_output_acc: 0.7291 - main_output_f1_micro: 0.5321 - aux_output_acc: 0.6221 - aux_output_f1_micro: 0.1017 - val_loss: 1.9535 - val_main_output_loss: 1.3913 - val_aux_output_loss: 2.8113 - val_main_output_acc: 0.7735 - val_main_output_f1_micro: 0.5342 - val_aux_output_acc: 0.6187 - val_aux_output_f1_micro: 0.1018\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.1906 - main_output_loss: 1.6514 - aux_output_loss: 2.6959 - main_output_acc: 0.7329 - main_output_f1_micro: 0.5362 - aux_output_acc: 0.6322 - aux_output_f1_micro: 0.1019 - val_loss: 1.9318 - val_main_output_loss: 1.3807 - val_aux_output_loss: 2.7557 - val_main_output_acc: 0.7783 - val_main_output_f1_micro: 0.5381 - val_aux_output_acc: 0.6312 - val_aux_output_f1_micro: 0.1019\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.1599 - main_output_loss: 1.6319 - aux_output_loss: 2.6403 - main_output_acc: 0.7366 - main_output_f1_micro: 0.5401 - aux_output_acc: 0.6399 - aux_output_f1_micro: 0.1020 - val_loss: 1.9139 - val_main_output_loss: 1.3711 - val_aux_output_loss: 2.7140 - val_main_output_acc: 0.7698 - val_main_output_f1_micro: 0.5420 - val_aux_output_acc: 0.6348 - val_aux_output_f1_micro: 0.1021\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.1383 - main_output_loss: 1.6203 - aux_output_loss: 2.5903 - main_output_acc: 0.7367 - main_output_f1_micro: 0.5439 - aux_output_acc: 0.6477 - aux_output_f1_micro: 0.1021 - val_loss: 1.8924 - val_main_output_loss: 1.3597 - val_aux_output_loss: 2.6636 - val_main_output_acc: 0.7813 - val_main_output_f1_micro: 0.5458 - val_aux_output_acc: 0.6404 - val_aux_output_f1_micro: 0.1022\n",
      "\n",
      "Done with epoch: 45\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.1155 - main_output_loss: 1.6075 - aux_output_loss: 2.5402 - main_output_acc: 0.7401 - main_output_f1_micro: 0.5477 - aux_output_acc: 0.6529 - aux_output_f1_micro: 0.1023 - val_loss: 1.8726 - val_main_output_loss: 1.3510 - val_aux_output_loss: 2.6078 - val_main_output_acc: 0.7793 - val_main_output_f1_micro: 0.5495 - val_aux_output_acc: 0.6499 - val_aux_output_f1_micro: 0.1023\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.0968 - main_output_loss: 1.5989 - aux_output_loss: 2.4895 - main_output_acc: 0.7419 - main_output_f1_micro: 0.5514 - aux_output_acc: 0.6608 - aux_output_f1_micro: 0.1024 - val_loss: 1.8576 - val_main_output_loss: 1.3447 - val_aux_output_loss: 2.5641 - val_main_output_acc: 0.7830 - val_main_output_f1_micro: 0.5533 - val_aux_output_acc: 0.6595 - val_aux_output_f1_micro: 0.1025\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.0724 - main_output_loss: 1.5838 - aux_output_loss: 2.4429 - main_output_acc: 0.7419 - main_output_f1_micro: 0.5552 - aux_output_acc: 0.6708 - aux_output_f1_micro: 0.1025 - val_loss: 1.8229 - val_main_output_loss: 1.3211 - val_aux_output_loss: 2.5087 - val_main_output_acc: 0.7826 - val_main_output_f1_micro: 0.5570 - val_aux_output_acc: 0.6652 - val_aux_output_f1_micro: 0.1026\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.0545 - main_output_loss: 1.5745 - aux_output_loss: 2.4002 - main_output_acc: 0.7453 - main_output_f1_micro: 0.5588 - aux_output_acc: 0.6765 - aux_output_f1_micro: 0.1027 - val_loss: 1.8056 - val_main_output_loss: 1.3133 - val_aux_output_loss: 2.4618 - val_main_output_acc: 0.7825 - val_main_output_f1_micro: 0.5606 - val_aux_output_acc: 0.6717 - val_aux_output_f1_micro: 0.1028\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.0365 - main_output_loss: 1.5651 - aux_output_loss: 2.3568 - main_output_acc: 0.7462 - main_output_f1_micro: 0.5623 - aux_output_acc: 0.6816 - aux_output_f1_micro: 0.1029 - val_loss: 1.7922 - val_main_output_loss: 1.3070 - val_aux_output_loss: 2.4259 - val_main_output_acc: 0.7816 - val_main_output_f1_micro: 0.5641 - val_aux_output_acc: 0.6786 - val_aux_output_f1_micro: 0.1030\n",
      "\n",
      "Done with epoch: 50\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 54s - loss: 2.0147 - main_output_loss: 1.5515 - aux_output_loss: 2.3161 - main_output_acc: 0.7507 - main_output_f1_micro: 0.5659 - aux_output_acc: 0.6892 - aux_output_f1_micro: 0.1031 - val_loss: 1.7716 - val_main_output_loss: 1.2954 - val_aux_output_loss: 2.3809 - val_main_output_acc: 0.7887 - val_main_output_f1_micro: 0.5677 - val_aux_output_acc: 0.6872 - val_aux_output_f1_micro: 0.1032\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56877/56877 [==============================] - 54s - loss: 1.9892 - main_output_loss: 1.5347 - aux_output_loss: 2.2726 - main_output_acc: 0.7502 - main_output_f1_micro: 0.5694 - aux_output_acc: 0.6944 - aux_output_f1_micro: 0.1033 - val_loss: 1.7565 - val_main_output_loss: 1.2890 - val_aux_output_loss: 2.3375 - val_main_output_acc: 0.7746 - val_main_output_f1_micro: 0.5711 - val_aux_output_acc: 0.6896 - val_aux_output_f1_micro: 0.1034\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.9757 - main_output_loss: 1.5292 - aux_output_loss: 2.2328 - main_output_acc: 0.7538 - main_output_f1_micro: 0.5728 - aux_output_acc: 0.7013 - aux_output_f1_micro: 0.1035 - val_loss: 1.7306 - val_main_output_loss: 1.2723 - val_aux_output_loss: 2.2917 - val_main_output_acc: 0.7858 - val_main_output_f1_micro: 0.5745 - val_aux_output_acc: 0.6980 - val_aux_output_f1_micro: 0.1036\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.9598 - main_output_loss: 1.5207 - aux_output_loss: 2.1956 - main_output_acc: 0.7544 - main_output_f1_micro: 0.5762 - aux_output_acc: 0.7062 - aux_output_f1_micro: 0.1037 - val_loss: 1.7158 - val_main_output_loss: 1.2634 - val_aux_output_loss: 2.2619 - val_main_output_acc: 0.7956 - val_main_output_f1_micro: 0.5779 - val_aux_output_acc: 0.7129 - val_aux_output_f1_micro: 0.1038\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.9386 - main_output_loss: 1.5060 - aux_output_loss: 2.1628 - main_output_acc: 0.7556 - main_output_f1_micro: 0.5795 - aux_output_acc: 0.7124 - aux_output_f1_micro: 0.1040 - val_loss: 1.7130 - val_main_output_loss: 1.2667 - val_aux_output_loss: 2.2313 - val_main_output_acc: 0.7895 - val_main_output_f1_micro: 0.5812 - val_aux_output_acc: 0.7100 - val_aux_output_f1_micro: 0.1041\n",
      "\n",
      "Done with epoch: 55\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.9207 - main_output_loss: 1.4954 - aux_output_loss: 2.1264 - main_output_acc: 0.7566 - main_output_f1_micro: 0.5828 - aux_output_acc: 0.7165 - aux_output_f1_micro: 0.1042 - val_loss: 1.6861 - val_main_output_loss: 1.2479 - val_aux_output_loss: 2.1912 - val_main_output_acc: 0.7926 - val_main_output_f1_micro: 0.5845 - val_aux_output_acc: 0.7230 - val_aux_output_f1_micro: 0.1043\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.9007 - main_output_loss: 1.4826 - aux_output_loss: 2.0904 - main_output_acc: 0.7580 - main_output_f1_micro: 0.5861 - aux_output_acc: 0.7228 - aux_output_f1_micro: 0.1044 - val_loss: 1.6809 - val_main_output_loss: 1.2473 - val_aux_output_loss: 2.1679 - val_main_output_acc: 0.7973 - val_main_output_f1_micro: 0.5878 - val_aux_output_acc: 0.7213 - val_aux_output_f1_micro: 0.1046\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.8934 - main_output_loss: 1.4815 - aux_output_loss: 2.0592 - main_output_acc: 0.7580 - main_output_f1_micro: 0.5894 - aux_output_acc: 0.7257 - aux_output_f1_micro: 0.1047 - val_loss: 1.6715 - val_main_output_loss: 1.2442 - val_aux_output_loss: 2.1364 - val_main_output_acc: 0.7913 - val_main_output_f1_micro: 0.5910 - val_aux_output_acc: 0.7262 - val_aux_output_f1_micro: 0.1048\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.8786 - main_output_loss: 1.4732 - aux_output_loss: 2.0270 - main_output_acc: 0.7599 - main_output_f1_micro: 0.5926 - aux_output_acc: 0.7298 - aux_output_f1_micro: 0.1050 - val_loss: 1.6551 - val_main_output_loss: 1.2351 - val_aux_output_loss: 2.0997 - val_main_output_acc: 0.7935 - val_main_output_f1_micro: 0.5942 - val_aux_output_acc: 0.7258 - val_aux_output_f1_micro: 0.1051\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.8597 - main_output_loss: 1.4606 - aux_output_loss: 1.9957 - main_output_acc: 0.7605 - main_output_f1_micro: 0.5957 - aux_output_acc: 0.7337 - aux_output_f1_micro: 0.1053 - val_loss: 1.6395 - val_main_output_loss: 1.2254 - val_aux_output_loss: 2.0708 - val_main_output_acc: 0.7826 - val_main_output_f1_micro: 0.5973 - val_aux_output_acc: 0.7289 - val_aux_output_f1_micro: 0.1054\n",
      "\n",
      "Done with epoch: 60\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.8449 - main_output_loss: 1.4516 - aux_output_loss: 1.9664 - main_output_acc: 0.7603 - main_output_f1_micro: 0.5988 - aux_output_acc: 0.7379 - aux_output_f1_micro: 0.1056 - val_loss: 1.6340 - val_main_output_loss: 1.2246 - val_aux_output_loss: 2.0469 - val_main_output_acc: 0.7829 - val_main_output_f1_micro: 0.6004 - val_aux_output_acc: 0.7378 - val_aux_output_f1_micro: 0.1058\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.8381 - main_output_loss: 1.4499 - aux_output_loss: 1.9407 - main_output_acc: 0.7618 - main_output_f1_micro: 0.6019 - aux_output_acc: 0.7414 - aux_output_f1_micro: 0.1059 - val_loss: 1.6271 - val_main_output_loss: 1.2229 - val_aux_output_loss: 2.0207 - val_main_output_acc: 0.7869 - val_main_output_f1_micro: 0.6034 - val_aux_output_acc: 0.7361 - val_aux_output_f1_micro: 0.1061\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.8203 - main_output_loss: 1.4372 - aux_output_loss: 1.9156 - main_output_acc: 0.7647 - main_output_f1_micro: 0.6050 - aux_output_acc: 0.7441 - aux_output_f1_micro: 0.1062 - val_loss: 1.6053 - val_main_output_loss: 1.2059 - val_aux_output_loss: 1.9967 - val_main_output_acc: 0.7919 - val_main_output_f1_micro: 0.6065 - val_aux_output_acc: 0.7400 - val_aux_output_f1_micro: 0.1064\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.8145 - main_output_loss: 1.4363 - aux_output_loss: 1.8911 - main_output_acc: 0.7660 - main_output_f1_micro: 0.6079 - aux_output_acc: 0.7465 - aux_output_f1_micro: 0.1066 - val_loss: 1.5987 - val_main_output_loss: 1.2049 - val_aux_output_loss: 1.9686 - val_main_output_acc: 0.7921 - val_main_output_f1_micro: 0.6094 - val_aux_output_acc: 0.7443 - val_aux_output_f1_micro: 0.1068\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.7974 - main_output_loss: 1.4246 - aux_output_loss: 1.8642 - main_output_acc: 0.7628 - main_output_f1_micro: 0.6108 - aux_output_acc: 0.7498 - aux_output_f1_micro: 0.1070 - val_loss: 1.5834 - val_main_output_loss: 1.1951 - val_aux_output_loss: 1.9415 - val_main_output_acc: 0.7959 - val_main_output_f1_micro: 0.6123 - val_aux_output_acc: 0.7463 - val_aux_output_f1_micro: 0.1072\n",
      "\n",
      "Done with epoch: 65\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.7860 - main_output_loss: 1.4174 - aux_output_loss: 1.8427 - main_output_acc: 0.7648 - main_output_f1_micro: 0.6137 - aux_output_acc: 0.7541 - aux_output_f1_micro: 0.1074 - val_loss: 1.5803 - val_main_output_loss: 1.1956 - val_aux_output_loss: 1.9234 - val_main_output_acc: 0.7934 - val_main_output_f1_micro: 0.6151 - val_aux_output_acc: 0.7540 - val_aux_output_f1_micro: 0.1076\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.7767 - main_output_loss: 1.4129 - aux_output_loss: 1.8187 - main_output_acc: 0.7660 - main_output_f1_micro: 0.6166 - aux_output_acc: 0.7560 - aux_output_f1_micro: 0.1079 - val_loss: 1.5710 - val_main_output_loss: 1.1917 - val_aux_output_loss: 1.8962 - val_main_output_acc: 0.7926 - val_main_output_f1_micro: 0.6180 - val_aux_output_acc: 0.7546 - val_aux_output_f1_micro: 0.1081\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.7605 - main_output_loss: 1.4011 - aux_output_loss: 1.7971 - main_output_acc: 0.7678 - main_output_f1_micro: 0.6194 - aux_output_acc: 0.7584 - aux_output_f1_micro: 0.1083 - val_loss: 1.5544 - val_main_output_loss: 1.1809 - val_aux_output_loss: 1.8675 - val_main_output_acc: 0.7998 - val_main_output_f1_micro: 0.6208 - val_aux_output_acc: 0.7592 - val_aux_output_f1_micro: 0.1085\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56877/56877 [==============================] - 76s - loss: 1.7577 - main_output_loss: 1.4024 - aux_output_loss: 1.7764 - main_output_acc: 0.7700 - main_output_f1_micro: 0.6221 - aux_output_acc: 0.7593 - aux_output_f1_micro: 0.1087 - val_loss: 1.5486 - val_main_output_loss: 1.1782 - val_aux_output_loss: 1.8520 - val_main_output_acc: 0.7963 - val_main_output_f1_micro: 0.6235 - val_aux_output_acc: 0.7546 - val_aux_output_f1_micro: 0.1089\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.7429 - main_output_loss: 1.3917 - aux_output_loss: 1.7561 - main_output_acc: 0.7709 - main_output_f1_micro: 0.6248 - aux_output_acc: 0.7618 - aux_output_f1_micro: 0.1091 - val_loss: 1.5413 - val_main_output_loss: 1.1744 - val_aux_output_loss: 1.8347 - val_main_output_acc: 0.7902 - val_main_output_f1_micro: 0.6262 - val_aux_output_acc: 0.7626 - val_aux_output_f1_micro: 0.1094\n",
      "\n",
      "Done with epoch: 70\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.7346 - main_output_loss: 1.3872 - aux_output_loss: 1.7367 - main_output_acc: 0.7706 - main_output_f1_micro: 0.6275 - aux_output_acc: 0.7647 - aux_output_f1_micro: 0.1096 - val_loss: 1.5279 - val_main_output_loss: 1.1659 - val_aux_output_loss: 1.8095 - val_main_output_acc: 0.7964 - val_main_output_f1_micro: 0.6289 - val_aux_output_acc: 0.7624 - val_aux_output_f1_micro: 0.1098\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.7296 - main_output_loss: 1.3861 - aux_output_loss: 1.7177 - main_output_acc: 0.7711 - main_output_f1_micro: 0.6302 - aux_output_acc: 0.7684 - aux_output_f1_micro: 0.1100 - val_loss: 1.5211 - val_main_output_loss: 1.1626 - val_aux_output_loss: 1.7928 - val_main_output_acc: 0.7945 - val_main_output_f1_micro: 0.6315 - val_aux_output_acc: 0.7617 - val_aux_output_f1_micro: 0.1102\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.7127 - main_output_loss: 1.3730 - aux_output_loss: 1.6985 - main_output_acc: 0.7708 - main_output_f1_micro: 0.6328 - aux_output_acc: 0.7683 - aux_output_f1_micro: 0.1105 - val_loss: 1.5149 - val_main_output_loss: 1.1607 - val_aux_output_loss: 1.7708 - val_main_output_acc: 0.7972 - val_main_output_f1_micro: 0.6341 - val_aux_output_acc: 0.7615 - val_aux_output_f1_micro: 0.1107\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.7023 - main_output_loss: 1.3664 - aux_output_loss: 1.6797 - main_output_acc: 0.7729 - main_output_f1_micro: 0.6354 - aux_output_acc: 0.7722 - aux_output_f1_micro: 0.1109 - val_loss: 1.5071 - val_main_output_loss: 1.1560 - val_aux_output_loss: 1.7558 - val_main_output_acc: 0.7930 - val_main_output_f1_micro: 0.6367 - val_aux_output_acc: 0.7670 - val_aux_output_f1_micro: 0.1111\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.6884 - main_output_loss: 1.3553 - aux_output_loss: 1.6659 - main_output_acc: 0.7720 - main_output_f1_micro: 0.6379 - aux_output_acc: 0.7726 - aux_output_f1_micro: 0.1113 - val_loss: 1.5019 - val_main_output_loss: 1.1535 - val_aux_output_loss: 1.7419 - val_main_output_acc: 0.7952 - val_main_output_f1_micro: 0.6392 - val_aux_output_acc: 0.7741 - val_aux_output_f1_micro: 0.1116\n",
      "\n",
      "Done with epoch: 75\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.6801 - main_output_loss: 1.3499 - aux_output_loss: 1.6511 - main_output_acc: 0.7763 - main_output_f1_micro: 0.6405 - aux_output_acc: 0.7744 - aux_output_f1_micro: 0.1118 - val_loss: 1.4951 - val_main_output_loss: 1.1497 - val_aux_output_loss: 1.7270 - val_main_output_acc: 0.7942 - val_main_output_f1_micro: 0.6417 - val_aux_output_acc: 0.7742 - val_aux_output_f1_micro: 0.1121\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.6840 - main_output_loss: 1.3569 - aux_output_loss: 1.6359 - main_output_acc: 0.7712 - main_output_f1_micro: 0.6430 - aux_output_acc: 0.7728 - aux_output_f1_micro: 0.1123 - val_loss: 1.4922 - val_main_output_loss: 1.1502 - val_aux_output_loss: 1.7100 - val_main_output_acc: 0.7822 - val_main_output_f1_micro: 0.6442 - val_aux_output_acc: 0.7727 - val_aux_output_f1_micro: 0.1126\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.6674 - main_output_loss: 1.3433 - aux_output_loss: 1.6205 - main_output_acc: 0.7755 - main_output_f1_micro: 0.6454 - aux_output_acc: 0.7758 - aux_output_f1_micro: 0.1129 - val_loss: 1.4845 - val_main_output_loss: 1.1447 - val_aux_output_loss: 1.6992 - val_main_output_acc: 0.7947 - val_main_output_f1_micro: 0.6466 - val_aux_output_acc: 0.7724 - val_aux_output_f1_micro: 0.1131\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.6636 - main_output_loss: 1.3424 - aux_output_loss: 1.6058 - main_output_acc: 0.7763 - main_output_f1_micro: 0.6478 - aux_output_acc: 0.7776 - aux_output_f1_micro: 0.1134 - val_loss: 1.4726 - val_main_output_loss: 1.1369 - val_aux_output_loss: 1.6783 - val_main_output_acc: 0.7918 - val_main_output_f1_micro: 0.6490 - val_aux_output_acc: 0.7763 - val_aux_output_f1_micro: 0.1137\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.6538 - main_output_loss: 1.3353 - aux_output_loss: 1.5924 - main_output_acc: 0.7735 - main_output_f1_micro: 0.6502 - aux_output_acc: 0.7789 - aux_output_f1_micro: 0.1139 - val_loss: 1.4678 - val_main_output_loss: 1.1352 - val_aux_output_loss: 1.6629 - val_main_output_acc: 0.7877 - val_main_output_f1_micro: 0.6514 - val_aux_output_acc: 0.7792 - val_aux_output_f1_micro: 0.1142\n",
      "\n",
      "Done with epoch: 80\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.6469 - main_output_loss: 1.3317 - aux_output_loss: 1.5758 - main_output_acc: 0.7756 - main_output_f1_micro: 0.6526 - aux_output_acc: 0.7808 - aux_output_f1_micro: 0.1144 - val_loss: 1.4604 - val_main_output_loss: 1.1302 - val_aux_output_loss: 1.6509 - val_main_output_acc: 0.7926 - val_main_output_f1_micro: 0.6538 - val_aux_output_acc: 0.7808 - val_aux_output_f1_micro: 0.1147\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.6405 - main_output_loss: 1.3280 - aux_output_loss: 1.5624 - main_output_acc: 0.7748 - main_output_f1_micro: 0.6549 - aux_output_acc: 0.7788 - aux_output_f1_micro: 0.1149 - val_loss: 1.4537 - val_main_output_loss: 1.1263 - val_aux_output_loss: 1.6370 - val_main_output_acc: 0.7895 - val_main_output_f1_micro: 0.6560 - val_aux_output_acc: 0.7853 - val_aux_output_f1_micro: 0.1152\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.6329 - main_output_loss: 1.3233 - aux_output_loss: 1.5481 - main_output_acc: 0.7740 - main_output_f1_micro: 0.6572 - aux_output_acc: 0.7825 - aux_output_f1_micro: 0.1155 - val_loss: 1.4512 - val_main_output_loss: 1.1250 - val_aux_output_loss: 1.6307 - val_main_output_acc: 0.7955 - val_main_output_f1_micro: 0.6583 - val_aux_output_acc: 0.7824 - val_aux_output_f1_micro: 0.1158\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.6184 - main_output_loss: 1.3109 - aux_output_loss: 1.5378 - main_output_acc: 0.7752 - main_output_f1_micro: 0.6594 - aux_output_acc: 0.7834 - aux_output_f1_micro: 0.1160 - val_loss: 1.4373 - val_main_output_loss: 1.1147 - val_aux_output_loss: 1.6131 - val_main_output_acc: 0.7915 - val_main_output_f1_micro: 0.6605 - val_aux_output_acc: 0.7820 - val_aux_output_f1_micro: 0.1163\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.6130 - main_output_loss: 1.3087 - aux_output_loss: 1.5215 - main_output_acc: 0.7746 - main_output_f1_micro: 0.6616 - aux_output_acc: 0.7839 - aux_output_f1_micro: 0.1165 - val_loss: 1.4313 - val_main_output_loss: 1.1122 - val_aux_output_loss: 1.5956 - val_main_output_acc: 0.7899 - val_main_output_f1_micro: 0.6627 - val_aux_output_acc: 0.7864 - val_aux_output_f1_micro: 0.1168\n",
      "\n",
      "Done with epoch: 85\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56877/56877 [==============================] - 53s - loss: 1.6070 - main_output_loss: 1.3045 - aux_output_loss: 1.5124 - main_output_acc: 0.7732 - main_output_f1_micro: 0.6638 - aux_output_acc: 0.7851 - aux_output_f1_micro: 0.1171 - val_loss: 1.4296 - val_main_output_loss: 1.1127 - val_aux_output_loss: 1.5845 - val_main_output_acc: 0.7967 - val_main_output_f1_micro: 0.6649 - val_aux_output_acc: 0.7855 - val_aux_output_f1_micro: 0.1173\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.6053 - main_output_loss: 1.3051 - aux_output_loss: 1.5010 - main_output_acc: 0.7761 - main_output_f1_micro: 0.6660 - aux_output_acc: 0.7871 - aux_output_f1_micro: 0.1176 - val_loss: 1.4213 - val_main_output_loss: 1.1073 - val_aux_output_loss: 1.5697 - val_main_output_acc: 0.7932 - val_main_output_f1_micro: 0.6671 - val_aux_output_acc: 0.7855 - val_aux_output_f1_micro: 0.1179\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.5996 - main_output_loss: 1.3014 - aux_output_loss: 1.4911 - main_output_acc: 0.7772 - main_output_f1_micro: 0.6682 - aux_output_acc: 0.7885 - aux_output_f1_micro: 0.1182 - val_loss: 1.4131 - val_main_output_loss: 1.1005 - val_aux_output_loss: 1.5629 - val_main_output_acc: 0.7884 - val_main_output_f1_micro: 0.6693 - val_aux_output_acc: 0.7869 - val_aux_output_f1_micro: 0.1184\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.5926 - main_output_loss: 1.2964 - aux_output_loss: 1.4808 - main_output_acc: 0.7775 - main_output_f1_micro: 0.6703 - aux_output_acc: 0.7872 - aux_output_f1_micro: 0.1187 - val_loss: 1.4177 - val_main_output_loss: 1.1069 - val_aux_output_loss: 1.5543 - val_main_output_acc: 0.7968 - val_main_output_f1_micro: 0.6714 - val_aux_output_acc: 0.7844 - val_aux_output_f1_micro: 0.1190\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.5870 - main_output_loss: 1.2927 - aux_output_loss: 1.4711 - main_output_acc: 0.7789 - main_output_f1_micro: 0.6724 - aux_output_acc: 0.7891 - aux_output_f1_micro: 0.1192 - val_loss: 1.4138 - val_main_output_loss: 1.1048 - val_aux_output_loss: 1.5450 - val_main_output_acc: 0.8036 - val_main_output_f1_micro: 0.6735 - val_aux_output_acc: 0.7880 - val_aux_output_f1_micro: 0.1195\n",
      "\n",
      "Done with epoch: 90\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.5793 - main_output_loss: 1.2868 - aux_output_loss: 1.4623 - main_output_acc: 0.7801 - main_output_f1_micro: 0.6745 - aux_output_acc: 0.7902 - aux_output_f1_micro: 0.1198 - val_loss: 1.4006 - val_main_output_loss: 1.0931 - val_aux_output_loss: 1.5374 - val_main_output_acc: 0.8048 - val_main_output_f1_micro: 0.6755 - val_aux_output_acc: 0.7885 - val_aux_output_f1_micro: 0.1201\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 54s - loss: 1.5749 - main_output_loss: 1.2845 - aux_output_loss: 1.4523 - main_output_acc: 0.7777 - main_output_f1_micro: 0.6765 - aux_output_acc: 0.7894 - aux_output_f1_micro: 0.1204 - val_loss: 1.3991 - val_main_output_loss: 1.0933 - val_aux_output_loss: 1.5287 - val_main_output_acc: 0.7991 - val_main_output_f1_micro: 0.6775 - val_aux_output_acc: 0.7950 - val_aux_output_f1_micro: 0.1208\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.5653 - main_output_loss: 1.2768 - aux_output_loss: 1.4423 - main_output_acc: 0.7802 - main_output_f1_micro: 0.6785 - aux_output_acc: 0.7921 - aux_output_f1_micro: 0.1211 - val_loss: 1.3877 - val_main_output_loss: 1.0851 - val_aux_output_loss: 1.5132 - val_main_output_acc: 0.7907 - val_main_output_f1_micro: 0.6795 - val_aux_output_acc: 0.7946 - val_aux_output_f1_micro: 0.1214\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.5695 - main_output_loss: 1.2829 - aux_output_loss: 1.4328 - main_output_acc: 0.7774 - main_output_f1_micro: 0.6805 - aux_output_acc: 0.7920 - aux_output_f1_micro: 0.1217 - val_loss: 1.3919 - val_main_output_loss: 1.0897 - val_aux_output_loss: 1.5105 - val_main_output_acc: 0.7906 - val_main_output_f1_micro: 0.6815 - val_aux_output_acc: 0.7915 - val_aux_output_f1_micro: 0.1220\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.5629 - main_output_loss: 1.2782 - aux_output_loss: 1.4236 - main_output_acc: 0.7783 - main_output_f1_micro: 0.6824 - aux_output_acc: 0.7933 - aux_output_f1_micro: 0.1223 - val_loss: 1.3928 - val_main_output_loss: 1.0933 - val_aux_output_loss: 1.4977 - val_main_output_acc: 0.7844 - val_main_output_f1_micro: 0.6834 - val_aux_output_acc: 0.7953 - val_aux_output_f1_micro: 0.1226\n",
      "\n",
      "Done with epoch: 95\n",
      "\n",
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.5537 - main_output_loss: 1.2710 - aux_output_loss: 1.4138 - main_output_acc: 0.7817 - main_output_f1_micro: 0.6844 - aux_output_acc: 0.7946 - aux_output_f1_micro: 0.1229 - val_loss: 1.3793 - val_main_output_loss: 1.0822 - val_aux_output_loss: 1.4851 - val_main_output_acc: 0.7969 - val_main_output_f1_micro: 0.6853 - val_aux_output_acc: 0.7956 - val_aux_output_f1_micro: 0.1233\n",
      "Epoch 2/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.5482 - main_output_loss: 1.2670 - aux_output_loss: 1.4060 - main_output_acc: 0.7811 - main_output_f1_micro: 0.6863 - aux_output_acc: 0.7947 - aux_output_f1_micro: 0.1236 - val_loss: 1.3849 - val_main_output_loss: 1.0889 - val_aux_output_loss: 1.4799 - val_main_output_acc: 0.7939 - val_main_output_f1_micro: 0.6872 - val_aux_output_acc: 0.7922 - val_aux_output_f1_micro: 0.1238\n",
      "Epoch 3/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.5412 - main_output_loss: 1.2616 - aux_output_loss: 1.3981 - main_output_acc: 0.7810 - main_output_f1_micro: 0.6881 - aux_output_acc: 0.7947 - aux_output_f1_micro: 0.1241 - val_loss: 1.3801 - val_main_output_loss: 1.0851 - val_aux_output_loss: 1.4752 - val_main_output_acc: 0.7940 - val_main_output_f1_micro: 0.6891 - val_aux_output_acc: 0.7971 - val_aux_output_f1_micro: 0.1244\n",
      "Epoch 4/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.5424 - main_output_loss: 1.2634 - aux_output_loss: 1.3950 - main_output_acc: 0.7808 - main_output_f1_micro: 0.6900 - aux_output_acc: 0.7922 - aux_output_f1_micro: 0.1247 - val_loss: 1.3652 - val_main_output_loss: 1.0722 - val_aux_output_loss: 1.4651 - val_main_output_acc: 0.7955 - val_main_output_f1_micro: 0.6909 - val_aux_output_acc: 0.7987 - val_aux_output_f1_micro: 0.1250\n",
      "Epoch 5/5\n",
      "56877/56877 [==============================] - 53s - loss: 1.5393 - main_output_loss: 1.2625 - aux_output_loss: 1.3838 - main_output_acc: 0.7823 - main_output_f1_micro: 0.6918 - aux_output_acc: 0.7961 - aux_output_f1_micro: 0.1253 - val_loss: 1.3725 - val_main_output_loss: 1.0813 - val_aux_output_loss: 1.4562 - val_main_output_acc: 0.8079 - val_main_output_f1_micro: 0.6927 - val_aux_output_acc: 0.7994 - val_aux_output_f1_micro: 0.1256\n",
      "\n",
      "Done with epoch: 100\n",
      "\n",
      "CPU times: user 1h 49min 4s, sys: 9min 34s, total: 1h 58min 38s\n",
      "Wall time: 1h 31min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_name = 'models/lstm-word2vec-fasttext_2012-2014-data_categorical-crossentropy-2014-b-val-sc_wv_fs.model'\n",
    "epochs = 5\n",
    "for i in xrange(0, 100 // epochs):\n",
    "    hist = model.fit(\n",
    "        {'main_input': x_train, 'wv_input': wv_train, 'fs_input': fs_train},\n",
    "        {'main_output': y_train, 'aux_output': y_train},\n",
    "        epochs=epochs, batch_size=batch_size,   # 500\n",
    "        validation_split=0.2,\n",
    "        validation_data=(\n",
    "            {'main_input': x_val, 'wv_input': wv_val, 'fs_input': fs_val},\n",
    "            {'main_output': y_val, 'aux_output': y_val}\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.save(model_name.format(i))\n",
    "    print\n",
    "    print('Done with epoch: {}'.format((i + 1) * epochs))\n",
    "    with open('lstm-word2vec-fasttext.epoch.csv', 'a') as fl:\n",
    "        fl.write(model_name + '\\n')\n",
    "        fl.write('Epoch {}\\n'.format((i + 1) * epochs))\n",
    "        fl.write('{}\\n'.format(datetime.now()))\n",
    "        fl.write('\\n'.join(['{}: {}'.format(k, v[0]) for k, v in hist.history.items()]))\n",
    "        fl.write('\\n\\n')\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 109s - loss: 1.4289 - main_output_loss: 1.1954 - aux_output_loss: 1.1671 - main_output_acc: 0.7844 - main_output_f1_micro: 0.9071 - aux_output_acc: 0.8001 - aux_output_f1_micro: 0.3321 - val_loss: 1.2712 - val_main_output_loss: 1.0274 - val_aux_output_loss: 1.2192 - val_main_output_acc: 0.8023 - val_main_output_f1_micro: 0.9076 - val_aux_output_acc: 0.8053 - val_aux_output_f1_micro: 0.3324\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 109s - loss: 1.4164 - main_output_loss: 1.1849 - aux_output_loss: 1.1579 - main_output_acc: 0.7872 - main_output_f1_micro: 0.9082 - aux_output_acc: 0.8011 - aux_output_f1_micro: 0.3328 - val_loss: 1.2646 - val_main_output_loss: 1.0234 - val_aux_output_loss: 1.2058 - val_main_output_acc: 0.8031 - val_main_output_f1_micro: 0.9088 - val_aux_output_acc: 0.8084 - val_aux_output_f1_micro: 0.3345\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 109s - loss: 1.4145 - main_output_loss: 1.1839 - aux_output_loss: 1.1530 - main_output_acc: 0.7860 - main_output_f1_micro: 0.9092 - aux_output_acc: 0.8010 - aux_output_f1_micro: 0.3356 - val_loss: 1.2670 - val_main_output_loss: 1.0257 - val_aux_output_loss: 1.2068 - val_main_output_acc: 0.7894 - val_main_output_f1_micro: 0.9096 - val_aux_output_acc: 0.8162 - val_aux_output_f1_micro: 0.3360\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 109s - loss: 1.4061 - main_output_loss: 1.1762 - aux_output_loss: 1.1493 - main_output_acc: 0.7849 - main_output_f1_micro: 0.9100 - aux_output_acc: 0.7999 - aux_output_f1_micro: 0.3364 - val_loss: 1.2672 - val_main_output_loss: 1.0265 - val_aux_output_loss: 1.2033 - val_main_output_acc: 0.8096 - val_main_output_f1_micro: 0.9103 - val_aux_output_acc: 0.8103 - val_aux_output_f1_micro: 0.3371\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 109s - loss: 1.4095 - main_output_loss: 1.1804 - aux_output_loss: 1.1454 - main_output_acc: 0.7898 - main_output_f1_micro: 0.9105 - aux_output_acc: 0.8015 - aux_output_f1_micro: 0.3376 - val_loss: 1.2629 - val_main_output_loss: 1.0220 - val_aux_output_loss: 1.2048 - val_main_output_acc: 0.8070 - val_main_output_f1_micro: 0.9106 - val_aux_output_acc: 0.8170 - val_aux_output_f1_micro: 0.3385\n",
      "\n",
      "Done with epoch: 505\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 109s - loss: 1.4051 - main_output_loss: 1.1764 - aux_output_loss: 1.1437 - main_output_acc: 0.7910 - main_output_f1_micro: 0.9110 - aux_output_acc: 0.7998 - aux_output_f1_micro: 0.3399 - val_loss: 1.2631 - val_main_output_loss: 1.0235 - val_aux_output_loss: 1.1981 - val_main_output_acc: 0.7962 - val_main_output_f1_micro: 0.9112 - val_aux_output_acc: 0.8157 - val_aux_output_f1_micro: 0.3408\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 109s - loss: 1.3984 - main_output_loss: 1.1700 - aux_output_loss: 1.1421 - main_output_acc: 0.7871 - main_output_f1_micro: 0.9114 - aux_output_acc: 0.7997 - aux_output_f1_micro: 0.3414 - val_loss: 1.2605 - val_main_output_loss: 1.0217 - val_aux_output_loss: 1.1938 - val_main_output_acc: 0.8058 - val_main_output_f1_micro: 0.9117 - val_aux_output_acc: 0.8122 - val_aux_output_f1_micro: 0.3415\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 108s - loss: 1.3987 - main_output_loss: 1.1715 - aux_output_loss: 1.1357 - main_output_acc: 0.7873 - main_output_f1_micro: 0.9119 - aux_output_acc: 0.8005 - aux_output_f1_micro: 0.3418 - val_loss: 1.2548 - val_main_output_loss: 1.0174 - val_aux_output_loss: 1.1869 - val_main_output_acc: 0.8000 - val_main_output_f1_micro: 0.9121 - val_aux_output_acc: 0.8138 - val_aux_output_f1_micro: 0.3422\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 109s - loss: 1.3960 - main_output_loss: 1.1691 - aux_output_loss: 1.1349 - main_output_acc: 0.7863 - main_output_f1_micro: 0.9123 - aux_output_acc: 0.8010 - aux_output_f1_micro: 0.3425 - val_loss: 1.2563 - val_main_output_loss: 1.0183 - val_aux_output_loss: 1.1902 - val_main_output_acc: 0.7964 - val_main_output_f1_micro: 0.9125 - val_aux_output_acc: 0.8128 - val_aux_output_f1_micro: 0.3432\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 108s - loss: 1.3964 - main_output_loss: 1.1696 - aux_output_loss: 1.1340 - main_output_acc: 0.7886 - main_output_f1_micro: 0.9127 - aux_output_acc: 0.8018 - aux_output_f1_micro: 0.3441 - val_loss: 1.2488 - val_main_output_loss: 1.0109 - val_aux_output_loss: 1.1891 - val_main_output_acc: 0.8042 - val_main_output_f1_micro: 0.9128 - val_aux_output_acc: 0.8068 - val_aux_output_f1_micro: 0.3447\n",
      "\n",
      "Done with epoch: 510\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 108s - loss: 1.3924 - main_output_loss: 1.1664 - aux_output_loss: 1.1301 - main_output_acc: 0.7880 - main_output_f1_micro: 0.9130 - aux_output_acc: 0.8023 - aux_output_f1_micro: 0.3456 - val_loss: 1.2527 - val_main_output_loss: 1.0161 - val_aux_output_loss: 1.1828 - val_main_output_acc: 0.8060 - val_main_output_f1_micro: 0.9132 - val_aux_output_acc: 0.8075 - val_aux_output_f1_micro: 0.3464\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 108s - loss: 1.3938 - main_output_loss: 1.1676 - aux_output_loss: 1.1308 - main_output_acc: 0.7891 - main_output_f1_micro: 0.9134 - aux_output_acc: 0.7998 - aux_output_f1_micro: 0.3471 - val_loss: 1.2546 - val_main_output_loss: 1.0186 - val_aux_output_loss: 1.1796 - val_main_output_acc: 0.8020 - val_main_output_f1_micro: 0.9135 - val_aux_output_acc: 0.8034 - val_aux_output_f1_micro: 0.3478\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 108s - loss: 1.3905 - main_output_loss: 1.1651 - aux_output_loss: 1.1271 - main_output_acc: 0.7882 - main_output_f1_micro: 0.9136 - aux_output_acc: 0.8007 - aux_output_f1_micro: 0.3487 - val_loss: 1.2548 - val_main_output_loss: 1.0192 - val_aux_output_loss: 1.1778 - val_main_output_acc: 0.8007 - val_main_output_f1_micro: 0.9137 - val_aux_output_acc: 0.8137 - val_aux_output_f1_micro: 0.3493\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 108s - loss: 1.3942 - main_output_loss: 1.1688 - aux_output_loss: 1.1266 - main_output_acc: 0.7871 - main_output_f1_micro: 0.9139 - aux_output_acc: 0.7994 - aux_output_f1_micro: 0.3499 - val_loss: 1.2506 - val_main_output_loss: 1.0152 - val_aux_output_loss: 1.1769 - val_main_output_acc: 0.7989 - val_main_output_f1_micro: 0.9140 - val_aux_output_acc: 0.8073 - val_aux_output_f1_micro: 0.3506\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 108s - loss: 1.3878 - main_output_loss: 1.1631 - aux_output_loss: 1.1231 - main_output_acc: 0.7864 - main_output_f1_micro: 0.9141 - aux_output_acc: 0.8004 - aux_output_f1_micro: 0.3514 - val_loss: 1.2484 - val_main_output_loss: 1.0132 - val_aux_output_loss: 1.1759 - val_main_output_acc: 0.7935 - val_main_output_f1_micro: 0.9142 - val_aux_output_acc: 0.8042 - val_aux_output_f1_micro: 0.3522\n",
      "\n",
      "Done with epoch: 515\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 108s - loss: 1.3890 - main_output_loss: 1.1646 - aux_output_loss: 1.1219 - main_output_acc: 0.7876 - main_output_f1_micro: 0.9143 - aux_output_acc: 0.7979 - aux_output_f1_micro: 0.3526 - val_loss: 1.2493 - val_main_output_loss: 1.0146 - val_aux_output_loss: 1.1731 - val_main_output_acc: 0.8025 - val_main_output_f1_micro: 0.9144 - val_aux_output_acc: 0.8126 - val_aux_output_f1_micro: 0.3530\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 108s - loss: 1.3837 - main_output_loss: 1.1599 - aux_output_loss: 1.1191 - main_output_acc: 0.7882 - main_output_f1_micro: 0.9145 - aux_output_acc: 0.8014 - aux_output_f1_micro: 0.3533 - val_loss: 1.2477 - val_main_output_loss: 1.0138 - val_aux_output_loss: 1.1694 - val_main_output_acc: 0.7996 - val_main_output_f1_micro: 0.9146 - val_aux_output_acc: 0.8061 - val_aux_output_f1_micro: 0.3538\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 108s - loss: 1.3862 - main_output_loss: 1.1625 - aux_output_loss: 1.1187 - main_output_acc: 0.7850 - main_output_f1_micro: 0.9148 - aux_output_acc: 0.8010 - aux_output_f1_micro: 0.3544 - val_loss: 1.2494 - val_main_output_loss: 1.0155 - val_aux_output_loss: 1.1695 - val_main_output_acc: 0.8110 - val_main_output_f1_micro: 0.9149 - val_aux_output_acc: 0.8181 - val_aux_output_f1_micro: 0.3550\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 108s - loss: 1.3788 - main_output_loss: 1.1558 - aux_output_loss: 1.1148 - main_output_acc: 0.7862 - main_output_f1_micro: 0.9150 - aux_output_acc: 0.8019 - aux_output_f1_micro: 0.3556 - val_loss: 1.2434 - val_main_output_loss: 1.0105 - val_aux_output_loss: 1.1645 - val_main_output_acc: 0.7984 - val_main_output_f1_micro: 0.9151 - val_aux_output_acc: 0.8069 - val_aux_output_f1_micro: 0.3563\n",
      "Epoch 5/5\n",
      "46800/94731 [=============>................] - ETA: 54s - loss: 1.3753 - main_output_loss: 1.1529 - aux_output_loss: 1.1120 - main_output_acc: 0.7851 - main_output_f1_micro: 0.9153 - aux_output_acc: 0.8031 - aux_output_f1_micro: 0.3566"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# i = 100\n",
    "# batch_size = 600\n",
    "# for j in xrange(i, i + (100 // epochs)):\n",
    "#     hist = model.fit(\n",
    "#         {'main_input': x_train, 'wv_input': wv_train, 'fs_input': fs_train},\n",
    "#         {'main_output': y_train, 'aux_output': y_train},\n",
    "#         epochs=epochs, batch_size=batch_size,   # 500\n",
    "#         validation_split=0.2,\n",
    "#         validation_data=(\n",
    "#             {'main_input': x_val, 'wv_input': wv_val, 'fs_input': fs_val},\n",
    "#             {'main_output': y_val, 'aux_output': y_val}\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "#     model.save(model_name.format(i))\n",
    "#     print\n",
    "#     print('Done with epoch: {}'.format((j + 1) * epochs))\n",
    "#     with open('lstm-word2vec-fasttext.epoch.csv', 'a') as fl:\n",
    "#         fl.write(model_name + '\\n')\n",
    "#         fl.write('Epoch {}\\n'.format((j + 1) * epochs))\n",
    "#         fl.write('{}\\n'.format(datetime.now()))\n",
    "#         fl.write('\\n'.join(['{}: {}'.format(k, v[0]) for k, v in hist.history.items()]))\n",
    "#         fl.write('\\n\\n')\n",
    "#     print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = keras.models.load_model(\n",
    "#     'models/lstm-word2vec-fasttext_2010-2014-data_categorical-crossentropy-2014-b-val-standard_scaled_wv_fs.model',\n",
    "#     custom_objects={'f1_micro': f1_micro}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = model.predict({'main_input': x_train[:100], 'wv_input': wv_train[:100], 'fs_input': fs_train[:100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f818a7711d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAd+LGAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f818a749850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "ix = 29\n",
    "pd.Series(g[0][ix]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f818a6a56d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f818a65b7d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(g[1][ix]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([136]),), (array([136]),), (array([], dtype=int64),))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh = 0.5\n",
    "np.where(y_train[ix] == 1), np.where(g[0][ix] > thresh), np.where(g[1][ix] > thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wvmodel = Word2Vec.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fsmodel = fasttext.load_model('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.fasttext.model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_fasttext(tokens, stopwords=[]):\n",
    "    global fsmodel\n",
    "    # This requires fsmodel to be present in the namespace.\n",
    "    fs_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    ).map(lambda x: np.array([fsmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return fs_feature_vec\n",
    "\n",
    "\n",
    "def transform_unsupervised_sentiment_neuron(tokens, stopwords=[]):\n",
    "    # This requires fsmodel to be present in the namespace.\n",
    "    \n",
    "    usn_feature_vec = usnmodel.transform(tokens)\n",
    "\n",
    "    # usn_feature_vec = tokens.map(\n",
    "    #     lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    # ).map(lambda x: np.array([usnmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return usn_feature_vec\n",
    "\n",
    "\n",
    "def transform_word2vec(tokens, stopwords=[]):\n",
    "    global wvmodel\n",
    "    # This requires wvmodel to be present in the namespace.\n",
    "    wv_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords and w in wvmodel.wv.vocab)]\n",
    "    ).map(lambda x: np.array([wvmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return wv_feature_vec\n",
    "\n",
    "\n",
    "def parallel_generate_word_vectors(samp, transformer, stopwords, batch, num_proc):\n",
    "    with Parallel(n_jobs=num_proc) as parallel:\n",
    "        dataset = []\n",
    "        is_break = False\n",
    "        i = 0\n",
    "\n",
    "        while not is_break:\n",
    "            payload = []\n",
    "\n",
    "            for j in xrange(num_proc):\n",
    "                t_df = samp[(i + j) * batch: (i + 1 + j) * batch]\n",
    "\n",
    "                if t_df.empty:\n",
    "                    is_break = True\n",
    "                    continue\n",
    "\n",
    "                payload.append(\n",
    "                    delayed(transformer)(\n",
    "                        t_df, stopwords\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            print('Current batch in main thread: {}'.format((i + j) * batch))\n",
    "\n",
    "            if payload:\n",
    "                results = parallel(payload)\n",
    "                dataset.extend(results)\n",
    "                i += num_proc\n",
    "\n",
    "    return pd.concat(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_classes(pred, scale_param=0.75, min_thresh=0.05, thresh = 0.5):\n",
    "#     mx = pred.mean() + 3 * pred.std()\n",
    "    return np.where(pred > thresh)[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2idx_transform(word, _word2idx):\n",
    "    return _word2idx.get(word, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features_for(df, min_batch=2000, stopwords=[], num_proc=7):\n",
    "    df_tokens = transform_text(df)\n",
    "    \n",
    "    batch = min(df_tokens.shape[0] / num_proc, min_batch)\n",
    "\n",
    "    print('Computing fs features...')\n",
    "    fvec = parallel_generate_word_vectors(df_tokens, transform_fasttext, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Computing wv features...')\n",
    "    wvec = parallel_generate_word_vectors(df_tokens, transform_word2vec, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Mapping word indices...')\n",
    "    word_indices = df_tokens.map(lambda x: [word2idx_transform(i, _word2idx) for i in x.split()])\n",
    "    \n",
    "    return word_indices, wvec, fvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/TestData.json') as fl:\n",
    "    data = json.load(fl)\n",
    "    test_df = pd.DataFrame(data['TestData']).T\n",
    "    del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fs features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Computing wv features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Mapping word indices...\n",
      "CPU times: user 42.6 s, sys: 5.86 s, total: 48.5 s\n",
      "Wall time: 2min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_word_indices,test_wvec, test_fvec = extract_features_for(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert(np.all(test_wvec[test_wvec.isnull()].index == test_fvec[test_fvec.isnull()].index))\n",
    "test_null_index = test_wvec[test_wvec.isnull()].index.union(test_fvec[test_fvec.isnull()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'TestData_02543', u'TestData_05012', u'TestData_05830'], dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_null_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 296 ms, sys: 24 ms, total: 320 ms\n",
      "Wall time: 322 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "maxlen = 500\n",
    "\n",
    "valid_test_index = test_word_indices.index.difference(test_null_index)\n",
    "x_test = sequence.pad_sequences(test_word_indices.ix[valid_test_index], maxlen=maxlen)\n",
    "wv_test = np.vstack(test_wvec.ix[valid_test_index])\n",
    "fs_test = np.vstack(test_fvec.ix[valid_test_index])\n",
    "\n",
    "wv_test = wv_sc.transform(wv_test)\n",
    "fs_test = fs_sc.transform(fs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "test_probas = model.predict({'main_input': x_test, 'wv_input': wv_test, 'fs_input': fs_test}, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_test_probas, aux_test_probas = test_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.65745963e-17,   4.08251530e-08,   1.34244910e-13, ...,\n",
       "          3.76827146e-11,   1.90825684e-16,   2.75790669e-17],\n",
       "       [  9.29182839e-19,   7.13581347e-11,   1.73532100e-09, ...,\n",
       "          1.27923679e-11,   3.19252435e-16,   5.64526780e-19],\n",
       "       [  9.91674617e-28,   6.62142571e-18,   5.94651540e-17, ...,\n",
       "          2.33727083e-11,   4.23336304e-23,   2.28839766e-27],\n",
       "       ..., \n",
       "       [  4.79648331e-14,   1.60800468e-03,   5.28303266e-01, ...,\n",
       "          7.12104750e-11,   1.05402762e-06,   1.94575479e-14],\n",
       "       [  6.08170816e-24,   2.74276726e-06,   2.33980973e-10, ...,\n",
       "          1.57224440e-13,   2.18795956e-17,   4.28040167e-25],\n",
       "       [  1.08473231e-15,   1.39423209e-05,   4.13959497e-05, ...,\n",
       "          4.23294910e-09,   1.88571676e-11,   3.38907729e-16]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_test_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_df.ix[test_df.index.difference(test_null_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2542, 5011, 5829]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_index = [int(s.split('_')[1]) - 1 for s in test_null_index]  # Subtract 1 since test index starts at 1 while enumerate starts at 0\n",
    "skip_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7578, 160), (7581, 3))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_test_probas.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28 ms, sys: 8 ms, total: 36 ms\n",
      "Wall time: 31.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# valid_test_feature_vec found below!\n",
    "test_values = np.zeros([main_test_probas.shape[0], len(topics)])\n",
    "for ix, pred in enumerate(main_test_probas):\n",
    "    for v in get_classes(pred, thresh=0.5):\n",
    "        test_values[ix][v] = 1\n",
    "\n",
    "test_sub_df = pd.DataFrame(\n",
    "    test_values,\n",
    "    index=test_df.ix[test_df.index.difference(test_null_index)].index,\n",
    "    columns=topics\n",
    ")\n",
    "\n",
    "null_test_df = pd.DataFrame(\n",
    "    np.zeros((len(test_null_index), len(topics))),\n",
    "    index=test_null_index,\n",
    "    columns=topics\n",
    ")\n",
    "\n",
    "test_sub_df = test_sub_df.append(null_test_df)\n",
    "test_sub_df = test_sub_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# init_test_sub_df = test_sub_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11656.0, 13075.0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init_test_sub_df.sum().sum(), \n",
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9891.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init_test_sub_df.sum().sum(), \n",
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56877/56877 [==============================] - 53s - loss: 1.5393 - main_output_loss: 1.2625 - aux_output_loss: 1.3838 - main_output_acc: 0.7823 - main_output_f1_micro: 0.6918 - aux_output_acc: 0.7961 - aux_output_f1_micro: 0.1253 - val_loss: 1.3725 - val_main_output_loss: 1.0813 - val_aux_output_loss: 1.4562 - val_main_output_acc: 0.8079 - val_main_output_f1_micro: 0.6927 - val_aux_output_acc: 0.7994 - val_aux_output_f1_micro: 0.1256\n"
     ]
    }
   ],
   "source": [
    "print '56877/56877 [==============================] - 53s - loss: 1.5393 - main_output_loss: 1.2625 - aux_output_loss: 1.3838 - main_output_acc: 0.7823 - main_output_f1_micro: 0.6918 - aux_output_acc: 0.7961 - aux_output_f1_micro: 0.1253 - val_loss: 1.3725 - val_main_output_loss: 1.0813 - val_aux_output_loss: 1.4562 - val_main_output_acc: 0.8079 - val_main_output_f1_micro: 0.6927 - val_aux_output_acc: 0.7994 - val_aux_output_f1_micro: 0.1256'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_sub_df.astype(int).reset_index().rename(\n",
    "    columns={'index': 'id'}\n",
    ").sort_values('id').to_csv(\n",
    "    'lstm_300-word2vec_300-fasttext_300-maxlen_500-dense_128_256_128-cat_cross-epoch_200-batch_size_500-val_main_output_f1_micro_0.6927-main_output_f1_micro_0.6918-main_output_loss_1.2625-data_2012_2014-val_data_2014-thresh_0.5-with_sc_wv_fs.csv', \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7581, 160)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36 ms, sys: 0 ns, total: 36 ms\n",
      "Wall time: 32.6 ms\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# adjust_index = 0\n",
    "# # valid_test_feature_vec found below!\n",
    "# test_values = np.zeros([test_df.shape[0], len(topics)])\n",
    "# for ix, pred in enumerate(main_test_probas):\n",
    "#     if ix in skip_index:\n",
    "#         test_values[ix] = np.nan\n",
    "#         # Increment adjust index so that we have the correct index for other samples\n",
    "#         adjust_index += 1\n",
    "#         continue\n",
    "\n",
    "#     for v in get_classes(pred, thresh=0.05):\n",
    "#         test_values[ix + adjust_index][v] = 1\n",
    "\n",
    "# test_sub_df = pd.DataFrame(test_values, columns=sorted(topics), index=test_df.index)\n",
    "\n",
    "# q = test_sub_df.sum(axis=1)\n",
    "# assert(len(q[q.isnull()].index.difference(test_null_index)) == 0)\n",
    "\n",
    "# test_sub_df = test_sub_df.fillna(0)\n",
    "\n",
    "# # for i in test_feature_vec[test_feature_vec.isnull()].index:\n",
    "# #     test_sub_df.ix[i] = np.zeros(len(topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestData_02543    0.0\n",
       "TestData_05012    0.0\n",
       "TestData_05830    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.ix[test_null_index].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13075.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_sub_df.astype(int).reset_index().rename(\n",
    "#     columns={'index': 'id'}\n",
    "# ).sort_values('id').to_csv(\n",
    "#     'lstm_300-word2vec_300-fasttext_300-maxlen_500-dense_64_64_64-cat_cross-epoch_210-batch_size_750-val_main_output_f1_micro_0.5760-main_output_f1_micro_0.5751-main_output_loss_0.9143-data_2010_2013-val_data_2014-thresh_0.05.csv', \n",
    "#     index=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: zikavirus, dtype: float64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = test_sub_df['zikavirus']\n",
    "e[e==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14328"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_submission = pd.read_csv('basic_nn_submission_0.649_accuracy_multi_class.csv')\n",
    "top_submission.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9280"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_index_lstm_sub = pd.read_csv('lstm.2014b_training_700_maxlen_64cell_100epochs_0.0025_threshold.csv')\n",
    "wrong_index_lstm_sub.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34952"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_sub = pd.read_csv('basic_nn_submission_full_training_data_0.9958_validation_accuracy_binary_crossentropy.csv')\n",
    "some_sub.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2197, 160)\n",
      "(3957, 160)\n",
      "(12, 160)\n",
      "(959, 160)\n"
     ]
    }
   ],
   "source": [
    "print top_submission.set_index('id')[top_submission.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print wrong_index_lstm_sub.set_index('id')[wrong_index_lstm_sub.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print some_sub.set_index('id')[some_sub.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print test_sub_df[test_sub_df.sum(axis=1) == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestData_00011     0\n",
       "TestData_00012     0\n",
       "TestData_00015     0\n",
       "TestData_00027     3\n",
       "TestData_00029     0\n",
       "TestData_00038     1\n",
       "TestData_00042     5\n",
       "TestData_00053     4\n",
       "TestData_00056     1\n",
       "TestData_00060     1\n",
       "TestData_00066     0\n",
       "TestData_00085     0\n",
       "TestData_00087     1\n",
       "TestData_00090     0\n",
       "TestData_00092     0\n",
       "TestData_00107     3\n",
       "TestData_00111     0\n",
       "TestData_00114     0\n",
       "TestData_00115     1\n",
       "TestData_00118     0\n",
       "TestData_00119     0\n",
       "TestData_00121     0\n",
       "TestData_00123     0\n",
       "TestData_00125     0\n",
       "TestData_00127     0\n",
       "TestData_00128     1\n",
       "TestData_00139     1\n",
       "TestData_00140     1\n",
       "TestData_00144     0\n",
       "TestData_00147     2\n",
       "                  ..\n",
       "TestData_07445     0\n",
       "TestData_07456     3\n",
       "TestData_07461     1\n",
       "TestData_07462     4\n",
       "TestData_07465     0\n",
       "TestData_07468     0\n",
       "TestData_07471     1\n",
       "TestData_07475     0\n",
       "TestData_07486    10\n",
       "TestData_07495     1\n",
       "TestData_07509     0\n",
       "TestData_07514     3\n",
       "TestData_07515     1\n",
       "TestData_07523     0\n",
       "TestData_07533     2\n",
       "TestData_07534     2\n",
       "TestData_07542     1\n",
       "TestData_07544     2\n",
       "TestData_07545     0\n",
       "TestData_07552     2\n",
       "TestData_07556     5\n",
       "TestData_07563     1\n",
       "TestData_07565     0\n",
       "TestData_07566     0\n",
       "TestData_07569     0\n",
       "TestData_07571     3\n",
       "TestData_07572     1\n",
       "TestData_07579     6\n",
       "TestData_07580     2\n",
       "TestData_07581     3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_submission.set_index('id').ix[q[q == 0].index].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1712,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.sum(axis=1)\n",
    "q[q==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7581.000000\n",
       "mean        1.304709\n",
       "std         1.046046\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         1.000000\n",
       "75%         2.000000\n",
       "max         7.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = trainingY.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    236286.000000\n",
       "mean          1.392787\n",
       "std           0.762577\n",
       "min           1.000000\n",
       "25%           1.000000\n",
       "50%           1.000000\n",
       "75%           2.000000\n",
       "max          15.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bodyText</th>\n",
       "      <th>topics</th>\n",
       "      <th>webPublicationDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TestData_03241</th>\n",
       "      <td>A special British police unit was put on stand...</td>\n",
       "      <td>[]</td>\n",
       "      <td>15-11-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_04088</th>\n",
       "      <td>The youngest convict in a fatal gang-rape in N...</td>\n",
       "      <td>[]</td>\n",
       "      <td>20-12-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_06306</th>\n",
       "      <td>Former New York City mayor Rudy Giuliani has s...</td>\n",
       "      <td>[]</td>\n",
       "      <td>28-07-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_06083</th>\n",
       "      <td>John Cantlie, the British journalist who has b...</td>\n",
       "      <td>[]</td>\n",
       "      <td>13-07-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_05896</th>\n",
       "      <td>Lawyers for the companies that manufactured an...</td>\n",
       "      <td>[]</td>\n",
       "      <td>20-06-2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         bodyText topics  \\\n",
       "TestData_03241  A special British police unit was put on stand...     []   \n",
       "TestData_04088  The youngest convict in a fatal gang-rape in N...     []   \n",
       "TestData_06306  Former New York City mayor Rudy Giuliani has s...     []   \n",
       "TestData_06083  John Cantlie, the British journalist who has b...     []   \n",
       "TestData_05896  Lawyers for the companies that manufactured an...     []   \n",
       "\n",
       "               webPublicationDate  \n",
       "TestData_03241         15-11-2015  \n",
       "TestData_04088         20-12-2015  \n",
       "TestData_06306         28-07-2016  \n",
       "TestData_06083         13-07-2016  \n",
       "TestData_05896         20-06-2016  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ix = 'TestData_03241'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "london        1.0\n",
       "police        1.0\n",
       "terrorism     1.0\n",
       "uksecurity    1.0\n",
       "Name: TestData_03241, dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "london                1\n",
       "metropolitanpolice    1\n",
       "police                1\n",
       "uksecurity            1\n",
       "Name: TestData_03241, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = top_submission.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "immigration           1\n",
       "july7                 1\n",
       "london                1\n",
       "metropolitanpolice    1\n",
       "police                1\n",
       "terrorism             1\n",
       "ukcrime               1\n",
       "uksecurity            1\n",
       "Name: TestData_03241, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = some_sub.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "guncrime                       1\n",
       "knifecrime                     1\n",
       "london                         1\n",
       "metropolitanpolice             1\n",
       "occupy                         1\n",
       "police                         1\n",
       "protest                        1\n",
       "ukcrime                        1\n",
       "undercoverpoliceandpolicing    1\n",
       "Name: TestData_03241, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = wrong_index_lstm_sub.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Counter-terrorism policy\n",
    " \n",
    "Foreign policy\n",
    " \n",
    "Defence policy\n",
    " \n",
    "Islamic State\n",
    " \n",
    "Syria\n",
    " \n",
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = trainingY.sum()\n",
    "unseen_topics = s[s.isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activism',\n",
       " 'bastilledaytruckattack',\n",
       " 'berlinchristmasmarketattack',\n",
       " 'brusselsattacks',\n",
       " 'charliehebdoattack',\n",
       " 'francetrainattack',\n",
       " 'munichshooting',\n",
       " 'orlandoterrorattack',\n",
       " 'parisattacks',\n",
       " 'peaceandreconciliation',\n",
       " 'sanbernardinoshooting',\n",
       " 'tunisiaattack2015',\n",
       " 'turkeycoupattempt',\n",
       " 'zikavirus'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(topics).intersection(unseen_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activism\n",
      "afghanistan\n",
      "aid\n",
      "algerianhostagecrisis\n",
      "alqaida\n",
      "alshabaab\n",
      "antiwar\n",
      "arabandmiddleeastprotests\n",
      "armstrade\n",
      "australianguncontrol\n",
      "australiansecurityandcounterterrorism\n",
      "bastilledaytruckattack\n",
      "belgium\n",
      "berlinchristmasmarketattack\n",
      "bigdata\n",
      "biometrics\n",
      "bokoharam\n",
      "bostonmarathonbombing\n",
      "britisharmy\n",
      "brusselsattacks\n",
      "cameroon\n",
      "carers\n",
      "charliehebdoattack\n",
      "chemicalweapons\n",
      "clusterbombs\n",
      "cobra\n",
      "conflictanddevelopment\n",
      "controversy\n",
      "criminaljustice\n",
      "cybercrime\n",
      "cyberwar\n",
      "darknet\n",
      "dataprotection\n",
      "debate\n",
      "defence\n",
      "deflation\n",
      "drones\n",
      "drugs\n",
      "drugspolicy\n",
      "drugstrade\n",
      "earthquakes\n",
      "ebola\n",
      "economy\n",
      "egypt\n",
      "encryption\n",
      "energy\n",
      "espionage\n",
      "ethics\n",
      "europeanarrestwarrant\n",
      "europeancourtofhumanrights\n",
      "events\n",
      "extradition\n",
      "famine\n",
      "farright\n",
      "firefighters\n",
      "forensicscience\n",
      "france\n",
      "francetrainattack\n",
      "freedomofspeech\n",
      "genevaconventions\n",
      "germany\n",
      "guncrime\n",
      "hacking\n",
      "hashtags\n",
      "helicoptercrashes\n",
      "humanitarianresponse\n",
      "humanrights\n",
      "humanrightsact\n",
      "humantrafficking\n",
      "immigration\n",
      "india\n",
      "indonesia\n",
      "internallydisplacedpeople\n",
      "internationalcourtofjustice\n",
      "internationalcriminaljustice\n",
      "internetsafety\n",
      "iraq\n",
      "isis\n",
      "israel\n",
      "jordan\n",
      "jubilee\n",
      "judiciary\n",
      "july7\n",
      "justiceandsecurity\n",
      "kenya\n",
      "knifecrime\n",
      "lebanon\n",
      "libya\n",
      "localgovernment\n",
      "logistics\n",
      "london\n",
      "londonriots\n",
      "malaysia\n",
      "mali\n",
      "malware\n",
      "metropolitanpolice\n",
      "middleeastpeacetalks\n",
      "migration\n",
      "military\n",
      "ministryofdefence\n",
      "morocco\n",
      "mrsa\n",
      "mumbaiterrorattacks\n",
      "munichshooting\n",
      "naturaldisasters\n",
      "nigeria\n",
      "nuclearweapons\n",
      "occupy\n",
      "organisedcrime\n",
      "orlandoterrorattack\n",
      "osamabinladen\n",
      "paris\n",
      "parisattacks\n",
      "peaceandreconciliation\n",
      "philippines\n",
      "piracy\n",
      "planecrashes\n",
      "police\n",
      "protest\n",
      "refugees\n",
      "religion\n",
      "retirementage\n",
      "rio20earthsummit\n",
      "royalairforce\n",
      "royalnavy\n",
      "russia\n",
      "sanbernardinoshooting\n",
      "saudiarabia\n",
      "september11\n",
      "slavery\n",
      "somalia\n",
      "southafrica\n",
      "southchinasea\n",
      "stopandsearch\n",
      "surveillance\n",
      "sydneysiege\n",
      "syria\n",
      "taliban\n",
      "terrorism\n",
      "thailand\n",
      "torture\n",
      "traincrashes\n",
      "transport\n",
      "tunisiaattack2015\n",
      "turkey\n",
      "turkeycoupattempt\n",
      "ukcrime\n",
      "uksecurity\n",
      "uksupremecourt\n",
      "undercoverpoliceandpolicing\n",
      "unitednations\n",
      "usguncontrol\n",
      "values\n",
      "warcrimes\n",
      "warreporting\n",
      "weaponstechnology\n",
      "womeninbusiness\n",
      "woolwichattack\n",
      "worldmigration\n",
      "zikavirus\n"
     ]
    }
   ],
   "source": [
    "for i in topics:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsolatorio/ml-ai/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3445929"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(wvmodel['zika'], np.vstack(test_wvec.dropna())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsolatorio/ml-ai/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.38107796869050226"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(fsmodel['zika'], np.vstack(test_fvec.dropna())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              The World Health Organisation has convened an ...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           28-01-2016\n",
       "Name: TestData_04490, dtype: object"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[4488 + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              The United Nations security council has called...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           17-09-2016\n",
       "Name: TestData_06730, dtype: object"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[6727 + 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              We are deeply concerned that the counter-terro...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           02-02-2015\n",
       "Name: TestData_00360, dtype: object"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[359]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drugstrade    1.0\n",
       "Name: TestData_04490, dtype: float64"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.iloc[4488 + 1]\n",
    "q[q > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
