{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from growing_instability_lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub = pd.read_csv('../data/sampleSubmission.csv')\n",
    "topics = sorted(set(sample_sub.columns.difference(['id'])))\n",
    "\n",
    "topic2actual = {}\n",
    "for i in sample_sub.columns:\n",
    "    if 'id' == i:\n",
    "        continue\n",
    "    topic2actual[i] = segment(i)\n",
    "    \n",
    "target_columns = sorted(topics)\n",
    "len(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.75 s, sys: 2.44 s, total: 11.2 s\n",
      "Wall time: 13.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wvec_trainingX = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', 'wvec_trainingX')\n",
    "fvec_trainingX = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', 'fvec_trainingX')\n",
    "word2idx_trainingX = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', 'word2idx_trainingX')\n",
    "_word2idx = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', '_word2idx')\n",
    "trainingY = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', 'trainingY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.3 s, sys: 48 ms, total: 20.3 s\n",
      "Wall time: 20.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word2ind = _word2idx.to_dict()\n",
    "\n",
    "ind2word = {i: j + 1 for i, j in word2ind.items()}  # Remove the increment if data is fixed.\n",
    "word2ind = {j: i for i, j in ind2word.items()}\n",
    "\n",
    "ind2class = dict(enumerate(topics))\n",
    "class2ind = {j: i for i, j in ind2class.items()}\n",
    "\n",
    "num_samples = trainingY.shape[0]\n",
    "\n",
    "training_X = word2idx_trainingX.head(num_samples)\n",
    "\n",
    "training_Y = pd.DataFrame(zip(*np.where(trainingY.head(num_samples) == 1)), columns=['iloc', 'topics'])\n",
    "training_WV = wvec_trainingX.head(num_samples)\n",
    "training_FS = fvec_trainingX.head(num_samples)\n",
    "\n",
    "training_Y = training_Y.groupby('iloc')['topics'].apply(list)\n",
    "training_Y.index = trainingY.head(num_samples).index\n",
    "\n",
    "# indices = sorted(training_Y.index.copy())\n",
    "indices = sorted(training_Y.index[training_Y.index.str.contains('^201[0-9]')])\n",
    "# np.random.shuffle(indices)\n",
    "indices = pd.Index(indices)\n",
    "\n",
    "training_X = training_X.ix[indices]\n",
    "training_WV = training_WV.ix[indices]\n",
    "training_FS = training_FS.ix[indices]\n",
    "training_Y = training_Y.ix[indices]\n",
    "\n",
    "dataset = zip(training_X, training_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def generate_lstm_batch_dataset(dataset, word2ind, class2ind, max_len, batch_size=1000, shuffle=True):\n",
    "#     if shuffle:\n",
    "#         np.random.shuffle(dataset)\n",
    "\n",
    "#     num_docs = len(dataset)\n",
    "#     num_words = len(word2ind) + 1\n",
    "#     num_class = len(class2ind)\n",
    "\n",
    "#     for s in xrange(0, num_docs, batch_size):\n",
    "#         x_batch = np.zeros([batch_size, max_len, num_words])\n",
    "#         y_batch = np.zeros([batch_size, num_class])\n",
    "\n",
    "#         for ix, (features, target) in enumerate(dataset[s:s + batch_size]):\n",
    "#             # print features\n",
    "#             for idx, feat in enumerate(features):\n",
    "#                 if idx >= max_len:\n",
    "#                     break\n",
    "\n",
    "#                 # print feat, ind2word[feat]\n",
    "#                 x_batch[ix, idx, feat] = 1\n",
    "\n",
    "#             if not isinstance(target, list):\n",
    "#                 target = [target]\n",
    "                \n",
    "#             for tg in target:\n",
    "#                 y_batch[ix, tg] = 1\n",
    "\n",
    "#         yield x_batch[:ix + 1, :, :], y_batch[:ix + 1, :]\n",
    "\n",
    "\n",
    "# def infinite_lstm_dataset_generator(dataset, word2ind, class2ind, max_len, batch_size=100):\n",
    "#     while 1:\n",
    "#         for b in generate_lstm_batch_dataset(dataset, word2ind, class2ind, max_len, batch_size):\n",
    "#             yield b\n",
    "\n",
    "# # lens = []\n",
    "# # for i in dataset:\n",
    "# #     lens.append(len(i[0]))\n",
    "# # pd.Series(lens).quantile(0.999)\n",
    "# # Use the above to estimate the acceptable timeseries dimension.\n",
    "# LSTM_TIMESERIES = 100\n",
    "# id_lstm_gen = infinite_lstm_dataset_generator(dataset, word2ind, class2ind, max_len=LSTM_TIMESERIES, batch_size=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wv_sc = StandardScaler()\n",
    "fs_sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "def build_target(y, size):\n",
    "    e = np.zeros(size)\n",
    "    e[y] = 1\n",
    "    return e\n",
    "\n",
    "def build_input_output_data(X, WV, FS, Y, maxlen):\n",
    "\n",
    "    x = sequence.pad_sequences(X, maxlen=maxlen)\n",
    "    y = np.vstack(Y.map(lambda x: build_target(x, len(topics))))\n",
    "    wv = np.vstack(WV)\n",
    "    fs = np.vstack(FS)\n",
    "    \n",
    "    return x, wv, fs, y\n",
    "\n",
    "\n",
    "test_ix = training_Y.index.str.contains('^201[0-3]')\n",
    "val_ix = training_Y.index.str.contains('^2014[ab]')\n",
    "\n",
    "\n",
    "maxlen = 500\n",
    "\n",
    "\n",
    "x_train, wv_train, fs_train, y_train = build_input_output_data(\n",
    "    training_X.ix[test_ix],\n",
    "    training_WV.ix[test_ix],\n",
    "    training_FS.ix[test_ix],\n",
    "    training_Y.ix[test_ix],\n",
    "    maxlen=maxlen\n",
    ")\n",
    "\n",
    "\n",
    "x_val, wv_val, fs_val, y_val = build_input_output_data(\n",
    "    training_X.ix[val_ix],\n",
    "    training_WV.ix[val_ix],\n",
    "    training_FS.ix[val_ix],\n",
    "    training_Y.ix[val_ix],\n",
    "    maxlen=maxlen\n",
    ")\n",
    "\n",
    "wv_train = wv_sc.fit_transform(wv_train)\n",
    "fs_train = fs_sc.fit_transform(fs_train)\n",
    "\n",
    "wv_val = wv_sc.transform(wv_val)\n",
    "fs_val = fs_sc.transform(fs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((94731,), (19387,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_Y.shape, training_Y.ix[training_Y.index.str.contains('^2014[ab]')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Setup model\n",
    "# model_lstm = keras.models.Sequential()\n",
    "# model_lstm.add(keras.layers.Embedding(len(word2ind) + 1, 256))\n",
    "# # model_lstm.add(keras.layers.LSTM(32, return_sequences=False, input_shape=(None, len(word2ind) + 1)))\n",
    "# # model_lstm.add(keras.layers.Dropout(0.2))\n",
    "# model_lstm.add(keras.layers.LSTM(16, return_sequences=False))\n",
    "# model_lstm.add(keras.layers.Dense(128))\n",
    "# model_lstm.add(keras.layers.Activation('relu'))\n",
    "# model_lstm.add(keras.layers.Dropout(0.2))\n",
    "# model_lstm.add(keras.layers.Dense(len(class2ind)))\n",
    "# model_lstm.add(keras.layers.Activation('sigmoid'))\n",
    "# model_lstm.compile(\n",
    "#     loss='binary_crossentropy',\n",
    "#     optimizer='adam',\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# # for i in range(6):\n",
    "# #     model_lstm.fit_generator(id_lstm_gen, steps_per_epoch=len(dataset), epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "# Headline input: meant to receive sequences of 100 integers, between 1 and 10000.\n",
    "# Note that we can name any layer by passing it a \"name\" argument.\n",
    "main_input = Input(shape=(maxlen,), dtype='int32', name='main_input')\n",
    "\n",
    "# This embedding layer will encode the input sequence\n",
    "# into a sequence of dense 512-dimensional vectors.\n",
    "x = Embedding(output_dim=300, input_dim=len(word2ind) + 1, input_length=maxlen)(main_input)\n",
    "\n",
    "# A LSTM will transform the vector sequence into a single vector,\n",
    "# containing information about the entire sequence\n",
    "lstm_out = LSTM(32)(x)\n",
    "\n",
    "auxiliary_output = Dense(len(class2ind), activation='sigmoid', name='aux_output')(lstm_out)\n",
    "\n",
    "\n",
    "wv_input = Input(shape=(300,), name='wv_input')\n",
    "fs_input = Input(shape=(300,), name='fs_input')\n",
    "\n",
    "x = keras.layers.concatenate([lstm_out, wv_input, fs_input])\n",
    "\n",
    "# We stack a deep densely-connected network on top\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "# And finally we add the main logistic regression layer\n",
    "main_output = Dense(len(class2ind), activation='sigmoid', name='main_output')(x)\n",
    "\n",
    "model = Model(inputs=[main_input, wv_input, fs_input], outputs=[main_output, auxiliary_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as K\n",
    "\n",
    "\n",
    "def f1_micro(y_true, y_pred):\n",
    "    TP = K.metrics.true_positives(y_true, K.round(y_pred))\n",
    "    FP = K.metrics.false_positives(y_true, K.round(y_pred))\n",
    "    FN = K.metrics.false_negatives(y_true, K.round(y_pred))\n",
    "    \n",
    "    p = K.reduce_sum(TP) / (K.reduce_sum(TP) + K.reduce_sum(FP))\n",
    "    r = K.reduce_sum(TP) / (K.reduce_sum(TP) + K.reduce_sum(FN))\n",
    "    \n",
    "    return (2.0 * p * r) / (p + r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input (InputLayer)          (None, 500)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)          (None, 500, 300)      105478200                                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                    (None, 32)            42624                                        \n",
      "____________________________________________________________________________________________________\n",
      "wv_input (InputLayer)            (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "fs_input (InputLayer)            (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 632)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 128)           81024                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 256)           33024                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 128)           32896                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 160)           20640                                        \n",
      "____________________________________________________________________________________________________\n",
      "aux_output (Dense)               (None, 160)           5280                                         \n",
      "====================================================================================================\n",
      "Total params: 105,693,688\n",
      "Trainable params: 105,693,688\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss={'main_output': 'categorical_crossentropy', 'aux_output': 'categorical_crossentropy'},\n",
    "              loss_weights={'main_output': 1., 'aux_output': 0.2}, metrics=['accuracy', f1_micro])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.callbacks import EarlyStopping\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "# model.fit(X, y, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import keras.backend as K\n",
    "# K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.train_on_batch(\n",
    "#     {'main_input': x_train[:10], 'wv_input': np.vstack(training_WV)[:10], 'fs_input': np.vstack(training_FS)[:10]},\n",
    "#     {'main_output': y_train[:10], 'aux_output': y_train[:10]}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 75344 samples, validate on 19387 samples\n",
      "Epoch 1/1\n",
      "75344/75344 [==============================] - 90s - loss: 5.7852 - main_output_loss: 4.4710 - aux_output_loss: 6.5708 - main_output_acc: 0.3146 - main_output_f1_micro: 0.0806 - aux_output_acc: 0.0219 - aux_output_f1_micro: 0.0543 - val_loss: 5.2099 - val_main_output_loss: 3.8744 - val_aux_output_loss: 6.6773 - val_main_output_acc: 0.5009 - val_main_output_f1_micro: 0.1174 - val_aux_output_acc: 0.0247 - val_aux_output_f1_micro: 0.0627\n",
      "CPU times: user 2min 37s, sys: 13.7 s, total: 2min 51s\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# And trained it via:\n",
    "batch_size = 600\n",
    "model.fit(\n",
    "    {'main_input': x_train, 'wv_input': wv_train, 'fs_input': fs_train},\n",
    "    {'main_output': y_train, 'aux_output': y_train},\n",
    "    epochs=1, batch_size=batch_size,   # 500\n",
    "    validation_split=0.2,\n",
    "    validation_data=(\n",
    "        {'main_input': x_val, 'wv_input': wv_val, 'fs_input': fs_val},\n",
    "        {'main_output': y_val, 'aux_output': y_val}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 75344 samples, validate on 19387 samples\n",
      "Epoch 1/5\n",
      "75344/75344 [==============================] - 90s - loss: 4.6000 - main_output_loss: 3.3217 - aux_output_loss: 6.3916 - main_output_acc: 0.5008 - main_output_f1_micro: 0.1473 - aux_output_acc: 0.0711 - aux_output_f1_micro: 0.0670 - val_loss: 4.9924 - val_main_output_loss: 3.6438 - val_aux_output_loss: 6.7431 - val_main_output_acc: 0.5482 - val_main_output_f1_micro: 0.1750 - val_aux_output_acc: 0.0781 - val_aux_output_f1_micro: 0.0705\n",
      "Epoch 2/5\n",
      "75344/75344 [==============================] - 91s - loss: 4.3330 - main_output_loss: 3.0616 - aux_output_loss: 6.3572 - main_output_acc: 0.5308 - main_output_f1_micro: 0.1987 - aux_output_acc: 0.0835 - aux_output_f1_micro: 0.0729 - val_loss: 4.9120 - val_main_output_loss: 3.5592 - val_aux_output_loss: 6.7639 - val_main_output_acc: 0.5620 - val_main_output_f1_micro: 0.2208 - val_aux_output_acc: 0.0778 - val_aux_output_f1_micro: 0.0751\n",
      "Epoch 3/5\n",
      "75344/75344 [==============================] - 91s - loss: 4.1892 - main_output_loss: 2.9228 - aux_output_loss: 6.3320 - main_output_acc: 0.5487 - main_output_f1_micro: 0.2398 - aux_output_acc: 0.0836 - aux_output_f1_micro: 0.0769 - val_loss: 4.8715 - val_main_output_loss: 3.5123 - val_aux_output_loss: 6.7962 - val_main_output_acc: 0.5638 - val_main_output_f1_micro: 0.2575 - val_aux_output_acc: 0.0785 - val_aux_output_f1_micro: 0.0785\n",
      "Epoch 4/5\n",
      "75344/75344 [==============================] - 90s - loss: 4.0785 - main_output_loss: 2.8173 - aux_output_loss: 6.3059 - main_output_acc: 0.5651 - main_output_f1_micro: 0.2730 - aux_output_acc: 0.0846 - aux_output_f1_micro: 0.0798 - val_loss: 4.8663 - val_main_output_loss: 3.5062 - val_aux_output_loss: 6.8007 - val_main_output_acc: 0.5733 - val_main_output_f1_micro: 0.2880 - val_aux_output_acc: 0.0784 - val_aux_output_f1_micro: 0.0811\n",
      "Epoch 5/5\n",
      "75344/75344 [==============================] - 91s - loss: 4.0055 - main_output_loss: 2.7539 - aux_output_loss: 6.2580 - main_output_acc: 0.5694 - main_output_f1_micro: 0.3010 - aux_output_acc: 0.0864 - aux_output_f1_micro: 0.0823 - val_loss: 4.8542 - val_main_output_loss: 3.4963 - val_aux_output_loss: 6.7895 - val_main_output_acc: 0.5749 - val_main_output_f1_micro: 0.3136 - val_aux_output_acc: 0.0785 - val_aux_output_f1_micro: 0.0836\n",
      "\n",
      "Done with epoch: 5\n",
      "\n",
      "Train on 75344 samples, validate on 19387 samples\n",
      "Epoch 1/5\n",
      "75344/75344 [==============================] - 90s - loss: 3.9252 - main_output_loss: 2.6872 - aux_output_loss: 6.1901 - main_output_acc: 0.5791 - main_output_f1_micro: 0.3248 - aux_output_acc: 0.0869 - aux_output_f1_micro: 0.0847 - val_loss: 4.8498 - val_main_output_loss: 3.4925 - val_aux_output_loss: 6.7866 - val_main_output_acc: 0.5765 - val_main_output_f1_micro: 0.3358 - val_aux_output_acc: 0.0796 - val_aux_output_f1_micro: 0.0858\n",
      "Epoch 2/5\n",
      "75344/75344 [==============================] - 91s - loss: 3.8424 - main_output_loss: 2.6201 - aux_output_loss: 6.1115 - main_output_acc: 0.5875 - main_output_f1_micro: 0.3454 - aux_output_acc: 0.0869 - aux_output_f1_micro: 0.0869 - val_loss: 4.8105 - val_main_output_loss: 3.4838 - val_aux_output_loss: 6.6333 - val_main_output_acc: 0.5781 - val_main_output_f1_micro: 0.3549 - val_aux_output_acc: 0.0796 - val_aux_output_f1_micro: 0.0881\n",
      "Epoch 3/5\n",
      "75344/75344 [==============================] - 90s - loss: 3.7736 - main_output_loss: 2.5692 - aux_output_loss: 6.0222 - main_output_acc: 0.5916 - main_output_f1_micro: 0.3635 - aux_output_acc: 0.0870 - aux_output_f1_micro: 0.0892 - val_loss: 4.8096 - val_main_output_loss: 3.4852 - val_aux_output_loss: 6.6218 - val_main_output_acc: 0.5775 - val_main_output_f1_micro: 0.3719 - val_aux_output_acc: 0.0797 - val_aux_output_f1_micro: 0.0904\n",
      "Epoch 4/5\n",
      "75344/75344 [==============================] - 91s - loss: 3.7098 - main_output_loss: 2.5185 - aux_output_loss: 5.9567 - main_output_acc: 0.5987 - main_output_f1_micro: 0.3793 - aux_output_acc: 0.0871 - aux_output_f1_micro: 0.0914 - val_loss: 4.8206 - val_main_output_loss: 3.4902 - val_aux_output_loss: 6.6522 - val_main_output_acc: 0.5771 - val_main_output_f1_micro: 0.3867 - val_aux_output_acc: 0.0803 - val_aux_output_f1_micro: 0.0924\n",
      "Epoch 5/5\n",
      "75344/75344 [==============================] - 91s - loss: 3.6163 - main_output_loss: 2.4596 - aux_output_loss: 5.7836 - main_output_acc: 0.6052 - main_output_f1_micro: 0.3934 - aux_output_acc: 0.1015 - aux_output_f1_micro: 0.0935 - val_loss: 4.8281 - val_main_output_loss: 3.5022 - val_aux_output_loss: 6.6294 - val_main_output_acc: 0.5733 - val_main_output_f1_micro: 0.4001 - val_aux_output_acc: 0.0700 - val_aux_output_f1_micro: 0.0946\n",
      "\n",
      "Done with epoch: 10\n",
      "\n",
      "Train on 75344 samples, validate on 19387 samples\n",
      "Epoch 1/5\n",
      "75344/75344 [==============================] - 91s - loss: 3.5359 - main_output_loss: 2.4116 - aux_output_loss: 5.6218 - main_output_acc: 0.6128 - main_output_f1_micro: 0.4061 - aux_output_acc: 0.1429 - aux_output_f1_micro: 0.0955 - val_loss: 4.8432 - val_main_output_loss: 3.5295 - val_aux_output_loss: 6.5683 - val_main_output_acc: 0.5721 - val_main_output_f1_micro: 0.4121 - val_aux_output_acc: 0.0795 - val_aux_output_f1_micro: 0.0963\n",
      "Epoch 2/5\n",
      "75344/75344 [==============================] - 91s - loss: 3.4552 - main_output_loss: 2.3670 - aux_output_loss: 5.4410 - main_output_acc: 0.6194 - main_output_f1_micro: 0.4176 - aux_output_acc: 0.1745 - aux_output_f1_micro: 0.0969 - val_loss: 4.8635 - val_main_output_loss: 3.5557 - val_aux_output_loss: 6.5393 - val_main_output_acc: 0.5720 - val_main_output_f1_micro: 0.4231 - val_aux_output_acc: 0.0884 - val_aux_output_f1_micro: 0.0973\n",
      "Epoch 3/5\n",
      "75344/75344 [==============================] - 90s - loss: 3.3802 - main_output_loss: 2.3273 - aux_output_loss: 5.2642 - main_output_acc: 0.6259 - main_output_f1_micro: 0.4281 - aux_output_acc: 0.2067 - aux_output_f1_micro: 0.0977 - val_loss: 4.9016 - val_main_output_loss: 3.5985 - val_aux_output_loss: 6.5152 - val_main_output_acc: 0.5698 - val_main_output_f1_micro: 0.4330 - val_aux_output_acc: 0.0957 - val_aux_output_f1_micro: 0.0980\n",
      "Epoch 4/5\n",
      "75344/75344 [==============================] - 90s - loss: 3.3001 - main_output_loss: 2.2826 - aux_output_loss: 5.0874 - main_output_acc: 0.6316 - main_output_f1_micro: 0.4375 - aux_output_acc: 0.2400 - aux_output_f1_micro: 0.0983 - val_loss: 4.8899 - val_main_output_loss: 3.5990 - val_aux_output_loss: 6.4549 - val_main_output_acc: 0.5647 - val_main_output_f1_micro: 0.4421 - val_aux_output_acc: 0.1021 - val_aux_output_f1_micro: 0.0985\n",
      "Epoch 5/5\n",
      "75344/75344 [==============================] - 90s - loss: 3.2302 - main_output_loss: 2.2467 - aux_output_loss: 4.9175 - main_output_acc: 0.6353 - main_output_f1_micro: 0.4463 - aux_output_acc: 0.2704 - aux_output_f1_micro: 0.0987 - val_loss: 4.9109 - val_main_output_loss: 3.6264 - val_aux_output_loss: 6.4225 - val_main_output_acc: 0.5705 - val_main_output_f1_micro: 0.4506 - val_aux_output_acc: 0.1116 - val_aux_output_f1_micro: 0.0988\n",
      "\n",
      "Done with epoch: 15\n",
      "\n",
      "Train on 75344 samples, validate on 19387 samples\n",
      "Epoch 1/5\n",
      "75344/75344 [==============================] - 90s - loss: 3.1530 - main_output_loss: 2.2083 - aux_output_loss: 4.7235 - main_output_acc: 0.6408 - main_output_f1_micro: 0.4544 - aux_output_acc: 0.3033 - aux_output_f1_micro: 0.0990 - val_loss: 4.9506 - val_main_output_loss: 3.6738 - val_aux_output_loss: 6.3844 - val_main_output_acc: 0.5623 - val_main_output_f1_micro: 0.4583 - val_aux_output_acc: 0.1201 - val_aux_output_f1_micro: 0.0991\n",
      "Epoch 2/5\n",
      "75344/75344 [==============================] - 90s - loss: 3.0696 - main_output_loss: 2.1663 - aux_output_loss: 4.5164 - main_output_acc: 0.6504 - main_output_f1_micro: 0.4619 - aux_output_acc: 0.3371 - aux_output_f1_micro: 0.0992 - val_loss: 4.9455 - val_main_output_loss: 3.6823 - val_aux_output_loss: 6.3158 - val_main_output_acc: 0.5618 - val_main_output_f1_micro: 0.4655 - val_aux_output_acc: 0.1349 - val_aux_output_f1_micro: 0.0994\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75344/75344 [==============================] - 90s - loss: 2.9898 - main_output_loss: 2.1310 - aux_output_loss: 4.2941 - main_output_acc: 0.6539 - main_output_f1_micro: 0.4688 - aux_output_acc: 0.3793 - aux_output_f1_micro: 0.0995 - val_loss: 4.9381 - val_main_output_loss: 3.6945 - val_aux_output_loss: 6.2183 - val_main_output_acc: 0.5605 - val_main_output_f1_micro: 0.4722 - val_aux_output_acc: 0.1483 - val_aux_output_f1_micro: 0.0996\n",
      "Epoch 4/5\n",
      "75344/75344 [==============================] - 90s - loss: 2.9121 - main_output_loss: 2.0950 - aux_output_loss: 4.0857 - main_output_acc: 0.6603 - main_output_f1_micro: 0.4754 - aux_output_acc: 0.4132 - aux_output_f1_micro: 0.0997 - val_loss: 4.9576 - val_main_output_loss: 3.7256 - val_aux_output_loss: 6.1600 - val_main_output_acc: 0.5622 - val_main_output_f1_micro: 0.4787 - val_aux_output_acc: 0.1607 - val_aux_output_f1_micro: 0.0998\n",
      "Epoch 5/5\n",
      "75344/75344 [==============================] - 90s - loss: 2.8381 - main_output_loss: 2.0547 - aux_output_loss: 3.9169 - main_output_acc: 0.6663 - main_output_f1_micro: 0.4816 - aux_output_acc: 0.4388 - aux_output_f1_micro: 0.1000 - val_loss: 5.0378 - val_main_output_loss: 3.8082 - val_aux_output_loss: 6.1478 - val_main_output_acc: 0.5549 - val_main_output_f1_micro: 0.4846 - val_aux_output_acc: 0.1707 - val_aux_output_f1_micro: 0.1001\n",
      "\n",
      "Done with epoch: 20\n",
      "\n",
      "Train on 75344 samples, validate on 19387 samples\n",
      "Epoch 1/5\n",
      "75344/75344 [==============================] - 90s - loss: 2.7703 - main_output_loss: 2.0185 - aux_output_loss: 3.7590 - main_output_acc: 0.6714 - main_output_f1_micro: 0.4875 - aux_output_acc: 0.4620 - aux_output_f1_micro: 0.1001 - val_loss: 5.0551 - val_main_output_loss: 3.8309 - val_aux_output_loss: 6.1214 - val_main_output_acc: 0.5502 - val_main_output_f1_micro: 0.4905 - val_aux_output_acc: 0.1741 - val_aux_output_f1_micro: 0.1003\n",
      "Epoch 2/5\n",
      "75344/75344 [==============================] - 90s - loss: 2.7082 - main_output_loss: 1.9853 - aux_output_loss: 3.6144 - main_output_acc: 0.6786 - main_output_f1_micro: 0.4932 - aux_output_acc: 0.4842 - aux_output_f1_micro: 0.1004 - val_loss: 5.0724 - val_main_output_loss: 3.8585 - val_aux_output_loss: 6.0694 - val_main_output_acc: 0.5494 - val_main_output_f1_micro: 0.4960 - val_aux_output_acc: 0.1875 - val_aux_output_f1_micro: 0.1005\n",
      "Epoch 3/5\n",
      "75344/75344 [==============================] - 90s - loss: 2.6495 - main_output_loss: 1.9540 - aux_output_loss: 3.4772 - main_output_acc: 0.6823 - main_output_f1_micro: 0.4986 - aux_output_acc: 0.5076 - aux_output_f1_micro: 0.1006 - val_loss: 5.1624 - val_main_output_loss: 3.9433 - val_aux_output_loss: 6.0952 - val_main_output_acc: 0.5446 - val_main_output_f1_micro: 0.5014 - val_aux_output_acc: 0.1968 - val_aux_output_f1_micro: 0.1008\n",
      "Epoch 4/5\n",
      "75344/75344 [==============================] - 90s - loss: 2.6070 - main_output_loss: 1.9319 - aux_output_loss: 3.3759 - main_output_acc: 0.6870 - main_output_f1_micro: 0.5040 - aux_output_acc: 0.5242 - aux_output_f1_micro: 0.1009 - val_loss: 5.1714 - val_main_output_loss: 3.9661 - val_aux_output_loss: 6.0265 - val_main_output_acc: 0.5419 - val_main_output_f1_micro: 0.5066 - val_aux_output_acc: 0.2119 - val_aux_output_f1_micro: 0.1011\n",
      "Epoch 5/5\n",
      "75344/75344 [==============================] - 90s - loss: 2.5438 - main_output_loss: 1.9001 - aux_output_loss: 3.2184 - main_output_acc: 0.6925 - main_output_f1_micro: 0.5090 - aux_output_acc: 0.5500 - aux_output_f1_micro: 0.1012 - val_loss: 5.1930 - val_main_output_loss: 3.9877 - val_aux_output_loss: 6.0267 - val_main_output_acc: 0.5358 - val_main_output_f1_micro: 0.5114 - val_aux_output_acc: 0.2208 - val_aux_output_f1_micro: 0.1013\n",
      "\n",
      "Done with epoch: 25\n",
      "\n",
      "Train on 75344 samples, validate on 19387 samples\n",
      "Epoch 1/5\n",
      "75344/75344 [==============================] - 90s - loss: 2.4864 - main_output_loss: 1.8672 - aux_output_loss: 3.0960 - main_output_acc: 0.6989 - main_output_f1_micro: 0.5138 - aux_output_acc: 0.5691 - aux_output_f1_micro: 0.1015 - val_loss: 5.2536 - val_main_output_loss: 4.0565 - val_aux_output_loss: 5.9852 - val_main_output_acc: 0.5388 - val_main_output_f1_micro: 0.5162 - val_aux_output_acc: 0.2329 - val_aux_output_f1_micro: 0.1016\n",
      "Epoch 2/5\n",
      "75344/75344 [==============================] - 90s - loss: 2.4412 - main_output_loss: 1.8429 - aux_output_loss: 2.9913 - main_output_acc: 0.7021 - main_output_f1_micro: 0.5186 - aux_output_acc: 0.5866 - aux_output_f1_micro: 0.1017 - val_loss: 5.2825 - val_main_output_loss: 4.0866 - val_aux_output_loss: 5.9792 - val_main_output_acc: 0.5347 - val_main_output_f1_micro: 0.5209 - val_aux_output_acc: 0.2372 - val_aux_output_f1_micro: 0.1018\n",
      "Epoch 3/5\n",
      "75344/75344 [==============================] - 90s - loss: 2.4258 - main_output_loss: 1.8327 - aux_output_loss: 2.9653 - main_output_acc: 0.7053 - main_output_f1_micro: 0.5232 - aux_output_acc: 0.5891 - aux_output_f1_micro: 0.1018 - val_loss: 5.3208 - val_main_output_loss: 4.1197 - val_aux_output_loss: 6.0053 - val_main_output_acc: 0.5419 - val_main_output_f1_micro: 0.5255 - val_aux_output_acc: 0.2439 - val_aux_output_f1_micro: 0.1019\n",
      "Epoch 4/5\n",
      "75344/75344 [==============================] - 90s - loss: 2.3534 - main_output_loss: 1.7908 - aux_output_loss: 2.8128 - main_output_acc: 0.7119 - main_output_f1_micro: 0.5277 - aux_output_acc: 0.6127 - aux_output_f1_micro: 0.1020 - val_loss: 5.3110 - val_main_output_loss: 4.1109 - val_aux_output_loss: 6.0003 - val_main_output_acc: 0.5403 - val_main_output_f1_micro: 0.5299 - val_aux_output_acc: 0.2499 - val_aux_output_f1_micro: 0.1021\n",
      "Epoch 5/5\n",
      "75344/75344 [==============================] - 90s - loss: 2.3076 - main_output_loss: 1.7632 - aux_output_loss: 2.7222 - main_output_acc: 0.7161 - main_output_f1_micro: 0.5321 - aux_output_acc: 0.6273 - aux_output_f1_micro: 0.1022 - val_loss: 5.4782 - val_main_output_loss: 4.2788 - val_aux_output_loss: 5.9967 - val_main_output_acc: 0.5324 - val_main_output_f1_micro: 0.5342 - val_aux_output_acc: 0.2557 - val_aux_output_f1_micro: 0.1023\n",
      "\n",
      "Done with epoch: 30\n",
      "\n",
      "Train on 75344 samples, validate on 19387 samples\n",
      "Epoch 1/5\n",
      "75344/75344 [==============================] - 90s - loss: 2.2772 - main_output_loss: 1.7482 - aux_output_loss: 2.6448 - main_output_acc: 0.7170 - main_output_f1_micro: 0.5363 - aux_output_acc: 0.6411 - aux_output_f1_micro: 0.1024 - val_loss: 5.5104 - val_main_output_loss: 4.3022 - val_aux_output_loss: 6.0411 - val_main_output_acc: 0.5242 - val_main_output_f1_micro: 0.5384 - val_aux_output_acc: 0.2559 - val_aux_output_f1_micro: 0.1024\n",
      "Epoch 2/5\n",
      "75344/75344 [==============================] - 90s - loss: 2.2343 - main_output_loss: 1.7192 - aux_output_loss: 2.5755 - main_output_acc: 0.7217 - main_output_f1_micro: 0.5405 - aux_output_acc: 0.6528 - aux_output_f1_micro: 0.1025 - val_loss: 5.5509 - val_main_output_loss: 4.3405 - val_aux_output_loss: 6.0519 - val_main_output_acc: 0.5290 - val_main_output_f1_micro: 0.5426 - val_aux_output_acc: 0.2564 - val_aux_output_f1_micro: 0.1025\n",
      "Epoch 3/5\n",
      "75344/75344 [==============================] - 90s - loss: 2.2037 - main_output_loss: 1.7016 - aux_output_loss: 2.5105 - main_output_acc: 0.7227 - main_output_f1_micro: 0.5445 - aux_output_acc: 0.6629 - aux_output_f1_micro: 0.1026 - val_loss: 5.5752 - val_main_output_loss: 4.3724 - val_aux_output_loss: 6.0142 - val_main_output_acc: 0.5218 - val_main_output_f1_micro: 0.5465 - val_aux_output_acc: 0.2635 - val_aux_output_f1_micro: 0.1027\n",
      "Epoch 4/5\n",
      "75344/75344 [==============================] - 90s - loss: 2.1745 - main_output_loss: 1.6857 - aux_output_loss: 2.4440 - main_output_acc: 0.7286 - main_output_f1_micro: 0.5485 - aux_output_acc: 0.6712 - aux_output_f1_micro: 0.1027 - val_loss: 5.6072 - val_main_output_loss: 4.4005 - val_aux_output_loss: 6.0332 - val_main_output_acc: 0.5186 - val_main_output_f1_micro: 0.5504 - val_aux_output_acc: 0.2650 - val_aux_output_f1_micro: 0.1028\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75344/75344 [==============================] - 90s - loss: 2.1450 - main_output_loss: 1.6685 - aux_output_loss: 2.3827 - main_output_acc: 0.7296 - main_output_f1_micro: 0.5523 - aux_output_acc: 0.6813 - aux_output_f1_micro: 0.1028 - val_loss: 5.6917 - val_main_output_loss: 4.4828 - val_aux_output_loss: 6.0446 - val_main_output_acc: 0.5152 - val_main_output_f1_micro: 0.5542 - val_aux_output_acc: 0.2682 - val_aux_output_f1_micro: 0.1029\n",
      "\n",
      "Done with epoch: 35\n",
      "\n",
      "Train on 75344 samples, validate on 19387 samples\n",
      "Epoch 1/5\n",
      "75344/75344 [==============================] - 90s - loss: 2.1167 - main_output_loss: 1.6514 - aux_output_loss: 2.3263 - main_output_acc: 0.7317 - main_output_f1_micro: 0.5561 - aux_output_acc: 0.6892 - aux_output_f1_micro: 0.1030 - val_loss: 5.7081 - val_main_output_loss: 4.4931 - val_aux_output_loss: 6.0755 - val_main_output_acc: 0.5176 - val_main_output_f1_micro: 0.5579 - val_aux_output_acc: 0.2702 - val_aux_output_f1_micro: 0.1030\n",
      "Epoch 2/5\n",
      "75344/75344 [==============================] - 90s - loss: 2.0902 - main_output_loss: 1.6359 - aux_output_loss: 2.2715 - main_output_acc: 0.7370 - main_output_f1_micro: 0.5598 - aux_output_acc: 0.6979 - aux_output_f1_micro: 0.1031 - val_loss: 5.7425 - val_main_output_loss: 4.5291 - val_aux_output_loss: 6.0666 - val_main_output_acc: 0.5156 - val_main_output_f1_micro: 0.5616 - val_aux_output_acc: 0.2709 - val_aux_output_f1_micro: 0.1031\n",
      "Epoch 3/5\n",
      "75344/75344 [==============================] - 89s - loss: 2.0571 - main_output_loss: 1.6129 - aux_output_loss: 2.2209 - main_output_acc: 0.7361 - main_output_f1_micro: 0.5634 - aux_output_acc: 0.7062 - aux_output_f1_micro: 0.1032 - val_loss: 5.8500 - val_main_output_loss: 4.6307 - val_aux_output_loss: 6.0964 - val_main_output_acc: 0.5160 - val_main_output_f1_micro: 0.5652 - val_aux_output_acc: 0.2770 - val_aux_output_f1_micro: 0.1032\n",
      "Epoch 4/5\n",
      "75344/75344 [==============================] - 90s - loss: 2.0313 - main_output_loss: 1.5968 - aux_output_loss: 2.1725 - main_output_acc: 0.7411 - main_output_f1_micro: 0.5670 - aux_output_acc: 0.7130 - aux_output_f1_micro: 0.1033 - val_loss: 5.8892 - val_main_output_loss: 4.6637 - val_aux_output_loss: 6.1278 - val_main_output_acc: 0.5065 - val_main_output_f1_micro: 0.5688 - val_aux_output_acc: 0.2743 - val_aux_output_f1_micro: 0.1034\n",
      "Epoch 5/5\n",
      "75344/75344 [==============================] - 90s - loss: 2.0180 - main_output_loss: 1.5922 - aux_output_loss: 2.1287 - main_output_acc: 0.7416 - main_output_f1_micro: 0.5705 - aux_output_acc: 0.7189 - aux_output_f1_micro: 0.1034 - val_loss: 5.9376 - val_main_output_loss: 4.7091 - val_aux_output_loss: 6.1426 - val_main_output_acc: 0.5065 - val_main_output_f1_micro: 0.5723 - val_aux_output_acc: 0.2761 - val_aux_output_f1_micro: 0.1035\n",
      "\n",
      "Done with epoch: 40\n",
      "\n",
      "Train on 75344 samples, validate on 19387 samples\n",
      "Epoch 1/5\n",
      "75344/75344 [==============================] - 90s - loss: 1.9895 - main_output_loss: 1.5724 - aux_output_loss: 2.0855 - main_output_acc: 0.7467 - main_output_f1_micro: 0.5740 - aux_output_acc: 0.7247 - aux_output_f1_micro: 0.1036 - val_loss: 5.9618 - val_main_output_loss: 4.7327 - val_aux_output_loss: 6.1458 - val_main_output_acc: 0.5067 - val_main_output_f1_micro: 0.5758 - val_aux_output_acc: 0.2778 - val_aux_output_f1_micro: 0.1036\n",
      "Epoch 2/5\n",
      "75344/75344 [==============================] - 90s - loss: 1.9736 - main_output_loss: 1.5644 - aux_output_loss: 2.0458 - main_output_acc: 0.7453 - main_output_f1_micro: 0.5775 - aux_output_acc: 0.7301 - aux_output_f1_micro: 0.1037 - val_loss: 5.9943 - val_main_output_loss: 4.7578 - val_aux_output_loss: 6.1822 - val_main_output_acc: 0.5038 - val_main_output_f1_micro: 0.5792 - val_aux_output_acc: 0.2809 - val_aux_output_f1_micro: 0.1038\n",
      "Epoch 3/5\n",
      "75344/75344 [==============================] - 90s - loss: 1.9532 - main_output_loss: 1.5516 - aux_output_loss: 2.0082 - main_output_acc: 0.7469 - main_output_f1_micro: 0.5808 - aux_output_acc: 0.7364 - aux_output_f1_micro: 0.1039 - val_loss: 6.0559 - val_main_output_loss: 4.8146 - val_aux_output_loss: 6.2068 - val_main_output_acc: 0.4999 - val_main_output_f1_micro: 0.5825 - val_aux_output_acc: 0.2802 - val_aux_output_f1_micro: 0.1040\n",
      "Epoch 4/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.9299 - main_output_loss: 1.5359 - aux_output_loss: 1.9700 - main_output_acc: 0.7493 - main_output_f1_micro: 0.5841 - aux_output_acc: 0.7397 - aux_output_f1_micro: 0.1041 - val_loss: 6.1066 - val_main_output_loss: 4.8631 - val_aux_output_loss: 6.2176 - val_main_output_acc: 0.5050 - val_main_output_f1_micro: 0.5857 - val_aux_output_acc: 0.2784 - val_aux_output_f1_micro: 0.1041\n",
      "Epoch 5/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.9126 - main_output_loss: 1.5250 - aux_output_loss: 1.9378 - main_output_acc: 0.7507 - main_output_f1_micro: 0.5873 - aux_output_acc: 0.7441 - aux_output_f1_micro: 0.1043 - val_loss: 6.1625 - val_main_output_loss: 4.9177 - val_aux_output_loss: 6.2241 - val_main_output_acc: 0.4971 - val_main_output_f1_micro: 0.5889 - val_aux_output_acc: 0.2794 - val_aux_output_f1_micro: 0.1043\n",
      "\n",
      "Done with epoch: 45\n",
      "\n",
      "Train on 75344 samples, validate on 19387 samples\n",
      "Epoch 1/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.8937 - main_output_loss: 1.5128 - aux_output_loss: 1.9044 - main_output_acc: 0.7537 - main_output_f1_micro: 0.5904 - aux_output_acc: 0.7483 - aux_output_f1_micro: 0.1044 - val_loss: 6.2349 - val_main_output_loss: 4.9819 - val_aux_output_loss: 6.2649 - val_main_output_acc: 0.4995 - val_main_output_f1_micro: 0.5920 - val_aux_output_acc: 0.2851 - val_aux_output_f1_micro: 0.1045\n",
      "Epoch 2/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.8765 - main_output_loss: 1.5023 - aux_output_loss: 1.8711 - main_output_acc: 0.7550 - main_output_f1_micro: 0.5935 - aux_output_acc: 0.7528 - aux_output_f1_micro: 0.1047 - val_loss: 6.2456 - val_main_output_loss: 4.9966 - val_aux_output_loss: 6.2452 - val_main_output_acc: 0.4984 - val_main_output_f1_micro: 0.5951 - val_aux_output_acc: 0.2895 - val_aux_output_f1_micro: 0.1048\n",
      "Epoch 3/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.8657 - main_output_loss: 1.4971 - aux_output_loss: 1.8430 - main_output_acc: 0.7558 - main_output_f1_micro: 0.5966 - aux_output_acc: 0.7542 - aux_output_f1_micro: 0.1049 - val_loss: 6.2646 - val_main_output_loss: 5.0064 - val_aux_output_loss: 6.2913 - val_main_output_acc: 0.4979 - val_main_output_f1_micro: 0.5981 - val_aux_output_acc: 0.2911 - val_aux_output_f1_micro: 0.1050\n",
      "Epoch 4/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.8479 - main_output_loss: 1.4845 - aux_output_loss: 1.8170 - main_output_acc: 0.7545 - main_output_f1_micro: 0.5996 - aux_output_acc: 0.7560 - aux_output_f1_micro: 0.1051 - val_loss: 6.3347 - val_main_output_loss: 5.0699 - val_aux_output_loss: 6.3239 - val_main_output_acc: 0.4925 - val_main_output_f1_micro: 0.6011 - val_aux_output_acc: 0.2869 - val_aux_output_f1_micro: 0.1052\n",
      "Epoch 5/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.8295 - main_output_loss: 1.4711 - aux_output_loss: 1.7922 - main_output_acc: 0.7563 - main_output_f1_micro: 0.6026 - aux_output_acc: 0.7590 - aux_output_f1_micro: 0.1054 - val_loss: 6.2880 - val_main_output_loss: 5.0227 - val_aux_output_loss: 6.3265 - val_main_output_acc: 0.4907 - val_main_output_f1_micro: 0.6040 - val_aux_output_acc: 0.2888 - val_aux_output_f1_micro: 0.1055\n",
      "\n",
      "Done with epoch: 50\n",
      "\n",
      "Train on 75344 samples, validate on 19387 samples\n",
      "Epoch 1/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.8173 - main_output_loss: 1.4635 - aux_output_loss: 1.7691 - main_output_acc: 0.7573 - main_output_f1_micro: 0.6055 - aux_output_acc: 0.7622 - aux_output_f1_micro: 0.1056 - val_loss: 6.3878 - val_main_output_loss: 5.1181 - val_aux_output_loss: 6.3481 - val_main_output_acc: 0.4944 - val_main_output_f1_micro: 0.6069 - val_aux_output_acc: 0.2877 - val_aux_output_f1_micro: 0.1057\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75344/75344 [==============================] - 89s - loss: 1.8040 - main_output_loss: 1.4552 - aux_output_loss: 1.7441 - main_output_acc: 0.7592 - main_output_f1_micro: 0.6083 - aux_output_acc: 0.7637 - aux_output_f1_micro: 0.1059 - val_loss: 6.4274 - val_main_output_loss: 5.1515 - val_aux_output_loss: 6.3794 - val_main_output_acc: 0.4899 - val_main_output_f1_micro: 0.6098 - val_aux_output_acc: 0.2861 - val_aux_output_f1_micro: 0.1060\n",
      "Epoch 3/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.7953 - main_output_loss: 1.4509 - aux_output_loss: 1.7222 - main_output_acc: 0.7620 - main_output_f1_micro: 0.6111 - aux_output_acc: 0.7664 - aux_output_f1_micro: 0.1061 - val_loss: 6.5305 - val_main_output_loss: 5.2443 - val_aux_output_loss: 6.4311 - val_main_output_acc: 0.4846 - val_main_output_f1_micro: 0.6125 - val_aux_output_acc: 0.2868 - val_aux_output_f1_micro: 0.1063\n",
      "Epoch 4/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.7815 - main_output_loss: 1.4419 - aux_output_loss: 1.6979 - main_output_acc: 0.7602 - main_output_f1_micro: 0.6139 - aux_output_acc: 0.7672 - aux_output_f1_micro: 0.1064 - val_loss: 6.5395 - val_main_output_loss: 5.2565 - val_aux_output_loss: 6.4147 - val_main_output_acc: 0.4858 - val_main_output_f1_micro: 0.6152 - val_aux_output_acc: 0.2909 - val_aux_output_f1_micro: 0.1066\n",
      "Epoch 5/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.7697 - main_output_loss: 1.4339 - aux_output_loss: 1.6789 - main_output_acc: 0.7642 - main_output_f1_micro: 0.6166 - aux_output_acc: 0.7696 - aux_output_f1_micro: 0.1067 - val_loss: 6.6166 - val_main_output_loss: 5.3352 - val_aux_output_loss: 6.4067 - val_main_output_acc: 0.4868 - val_main_output_f1_micro: 0.6179 - val_aux_output_acc: 0.2928 - val_aux_output_f1_micro: 0.1069\n",
      "\n",
      "Done with epoch: 55\n",
      "\n",
      "Train on 75344 samples, validate on 19387 samples\n",
      "Epoch 1/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.7565 - main_output_loss: 1.4246 - aux_output_loss: 1.6596 - main_output_acc: 0.7635 - main_output_f1_micro: 0.6192 - aux_output_acc: 0.7708 - aux_output_f1_micro: 0.1070 - val_loss: 6.6213 - val_main_output_loss: 5.3308 - val_aux_output_loss: 6.4523 - val_main_output_acc: 0.4830 - val_main_output_f1_micro: 0.6205 - val_aux_output_acc: 0.2928 - val_aux_output_f1_micro: 0.1071\n",
      "Epoch 2/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.7424 - main_output_loss: 1.4142 - aux_output_loss: 1.6413 - main_output_acc: 0.7650 - main_output_f1_micro: 0.6218 - aux_output_acc: 0.7726 - aux_output_f1_micro: 0.1073 - val_loss: 6.6979 - val_main_output_loss: 5.4035 - val_aux_output_loss: 6.4718 - val_main_output_acc: 0.4847 - val_main_output_f1_micro: 0.6231 - val_aux_output_acc: 0.2909 - val_aux_output_f1_micro: 0.1075\n",
      "Epoch 3/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.7366 - main_output_loss: 1.4120 - aux_output_loss: 1.6233 - main_output_acc: 0.7657 - main_output_f1_micro: 0.6243 - aux_output_acc: 0.7746 - aux_output_f1_micro: 0.1076 - val_loss: 6.7845 - val_main_output_loss: 5.4845 - val_aux_output_loss: 6.4999 - val_main_output_acc: 0.4834 - val_main_output_f1_micro: 0.6256 - val_aux_output_acc: 0.2922 - val_aux_output_f1_micro: 0.1078\n",
      "Epoch 4/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.7240 - main_output_loss: 1.4030 - aux_output_loss: 1.6054 - main_output_acc: 0.7630 - main_output_f1_micro: 0.6268 - aux_output_acc: 0.7754 - aux_output_f1_micro: 0.1079 - val_loss: 6.8265 - val_main_output_loss: 5.5192 - val_aux_output_loss: 6.5362 - val_main_output_acc: 0.4770 - val_main_output_f1_micro: 0.6280 - val_aux_output_acc: 0.2952 - val_aux_output_f1_micro: 0.1081\n",
      "Epoch 5/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.7117 - main_output_loss: 1.3937 - aux_output_loss: 1.5901 - main_output_acc: 0.7661 - main_output_f1_micro: 0.6292 - aux_output_acc: 0.7745 - aux_output_f1_micro: 0.1083 - val_loss: 6.7972 - val_main_output_loss: 5.4967 - val_aux_output_loss: 6.5028 - val_main_output_acc: 0.4801 - val_main_output_f1_micro: 0.6304 - val_aux_output_acc: 0.2941 - val_aux_output_f1_micro: 0.1085\n",
      "\n",
      "Done with epoch: 60\n",
      "\n",
      "Train on 75344 samples, validate on 19387 samples\n",
      "Epoch 1/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.7062 - main_output_loss: 1.3907 - aux_output_loss: 1.5772 - main_output_acc: 0.7674 - main_output_f1_micro: 0.6316 - aux_output_acc: 0.7776 - aux_output_f1_micro: 0.1086 - val_loss: 6.8233 - val_main_output_loss: 5.5134 - val_aux_output_loss: 6.5497 - val_main_output_acc: 0.4769 - val_main_output_f1_micro: 0.6328 - val_aux_output_acc: 0.2945 - val_aux_output_f1_micro: 0.1088\n",
      "Epoch 2/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.6922 - main_output_loss: 1.3801 - aux_output_loss: 1.5605 - main_output_acc: 0.7683 - main_output_f1_micro: 0.6340 - aux_output_acc: 0.7800 - aux_output_f1_micro: 0.1090 - val_loss: 6.9575 - val_main_output_loss: 5.6434 - val_aux_output_loss: 6.5708 - val_main_output_acc: 0.4768 - val_main_output_f1_micro: 0.6352 - val_aux_output_acc: 0.2947 - val_aux_output_f1_micro: 0.1092\n",
      "Epoch 3/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.6896 - main_output_loss: 1.3805 - aux_output_loss: 1.5454 - main_output_acc: 0.7671 - main_output_f1_micro: 0.6363 - aux_output_acc: 0.7790 - aux_output_f1_micro: 0.1093 - val_loss: 6.8776 - val_main_output_loss: 5.5668 - val_aux_output_loss: 6.5537 - val_main_output_acc: 0.4755 - val_main_output_f1_micro: 0.6374 - val_aux_output_acc: 0.2982 - val_aux_output_f1_micro: 0.1095\n",
      "Epoch 4/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.6817 - main_output_loss: 1.3755 - aux_output_loss: 1.5309 - main_output_acc: 0.7676 - main_output_f1_micro: 0.6385 - aux_output_acc: 0.7823 - aux_output_f1_micro: 0.1097 - val_loss: 6.9418 - val_main_output_loss: 5.6164 - val_aux_output_loss: 6.6270 - val_main_output_acc: 0.4718 - val_main_output_f1_micro: 0.6397 - val_aux_output_acc: 0.2923 - val_aux_output_f1_micro: 0.1099\n",
      "Epoch 5/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.6699 - main_output_loss: 1.3662 - aux_output_loss: 1.5184 - main_output_acc: 0.7686 - main_output_f1_micro: 0.6408 - aux_output_acc: 0.7822 - aux_output_f1_micro: 0.1101 - val_loss: 6.9939 - val_main_output_loss: 5.6660 - val_aux_output_loss: 6.6393 - val_main_output_acc: 0.4735 - val_main_output_f1_micro: 0.6419 - val_aux_output_acc: 0.2924 - val_aux_output_f1_micro: 0.1103\n",
      "\n",
      "Done with epoch: 65\n",
      "\n",
      "Train on 75344 samples, validate on 19387 samples\n",
      "Epoch 1/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.6607 - main_output_loss: 1.3595 - aux_output_loss: 1.5060 - main_output_acc: 0.7709 - main_output_f1_micro: 0.6429 - aux_output_acc: 0.7832 - aux_output_f1_micro: 0.1105 - val_loss: 7.0718 - val_main_output_loss: 5.7439 - val_aux_output_loss: 6.6398 - val_main_output_acc: 0.4755 - val_main_output_f1_micro: 0.6440 - val_aux_output_acc: 0.2990 - val_aux_output_f1_micro: 0.1106\n",
      "Epoch 2/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.6502 - main_output_loss: 1.3515 - aux_output_loss: 1.4935 - main_output_acc: 0.7726 - main_output_f1_micro: 0.6451 - aux_output_acc: 0.7855 - aux_output_f1_micro: 0.1108 - val_loss: 7.0636 - val_main_output_loss: 5.7312 - val_aux_output_loss: 6.6624 - val_main_output_acc: 0.4740 - val_main_output_f1_micro: 0.6462 - val_aux_output_acc: 0.2946 - val_aux_output_f1_micro: 0.1110\n",
      "Epoch 3/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.6453 - main_output_loss: 1.3486 - aux_output_loss: 1.4833 - main_output_acc: 0.7711 - main_output_f1_micro: 0.6472 - aux_output_acc: 0.7832 - aux_output_f1_micro: 0.1112 - val_loss: 7.1163 - val_main_output_loss: 5.7771 - val_aux_output_loss: 6.6960 - val_main_output_acc: 0.4745 - val_main_output_f1_micro: 0.6483 - val_aux_output_acc: 0.2908 - val_aux_output_f1_micro: 0.1114\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75344/75344 [==============================] - 89s - loss: 1.6352 - main_output_loss: 1.3408 - aux_output_loss: 1.4722 - main_output_acc: 0.7719 - main_output_f1_micro: 0.6493 - aux_output_acc: 0.7844 - aux_output_f1_micro: 0.1116 - val_loss: 7.1936 - val_main_output_loss: 5.8464 - val_aux_output_loss: 6.7360 - val_main_output_acc: 0.4771 - val_main_output_f1_micro: 0.6504 - val_aux_output_acc: 0.2975 - val_aux_output_f1_micro: 0.1118\n",
      "Epoch 5/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.6302 - main_output_loss: 1.3381 - aux_output_loss: 1.4601 - main_output_acc: 0.7720 - main_output_f1_micro: 0.6514 - aux_output_acc: 0.7851 - aux_output_f1_micro: 0.1120 - val_loss: 7.1479 - val_main_output_loss: 5.8037 - val_aux_output_loss: 6.7210 - val_main_output_acc: 0.4779 - val_main_output_f1_micro: 0.6524 - val_aux_output_acc: 0.2948 - val_aux_output_f1_micro: 0.1121\n",
      "\n",
      "Done with epoch: 70\n",
      "\n",
      "Train on 75344 samples, validate on 19387 samples\n",
      "Epoch 1/5\n",
      "75344/75344 [==============================] - 90s - loss: 1.6205 - main_output_loss: 1.3310 - aux_output_loss: 1.4478 - main_output_acc: 0.7750 - main_output_f1_micro: 0.6534 - aux_output_acc: 0.7861 - aux_output_f1_micro: 0.1123 - val_loss: 7.1689 - val_main_output_loss: 5.8197 - val_aux_output_loss: 6.7459 - val_main_output_acc: 0.4696 - val_main_output_f1_micro: 0.6544 - val_aux_output_acc: 0.2925 - val_aux_output_f1_micro: 0.1126\n",
      "Epoch 2/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.6174 - main_output_loss: 1.3293 - aux_output_loss: 1.4405 - main_output_acc: 0.7742 - main_output_f1_micro: 0.6554 - aux_output_acc: 0.7867 - aux_output_f1_micro: 0.1127 - val_loss: 7.1927 - val_main_output_loss: 5.8352 - val_aux_output_loss: 6.7874 - val_main_output_acc: 0.4659 - val_main_output_f1_micro: 0.6564 - val_aux_output_acc: 0.2956 - val_aux_output_f1_micro: 0.1129\n",
      "Epoch 3/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.6061 - main_output_loss: 1.3202 - aux_output_loss: 1.4295 - main_output_acc: 0.7743 - main_output_f1_micro: 0.6573 - aux_output_acc: 0.7875 - aux_output_f1_micro: 0.1131 - val_loss: 7.3870 - val_main_output_loss: 6.0257 - val_aux_output_loss: 6.8066 - val_main_output_acc: 0.4672 - val_main_output_f1_micro: 0.6583 - val_aux_output_acc: 0.2981 - val_aux_output_f1_micro: 0.1133\n",
      "Epoch 4/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.6018 - main_output_loss: 1.3174 - aux_output_loss: 1.4220 - main_output_acc: 0.7753 - main_output_f1_micro: 0.6592 - aux_output_acc: 0.7884 - aux_output_f1_micro: 0.1135 - val_loss: 7.3064 - val_main_output_loss: 5.9462 - val_aux_output_loss: 6.8010 - val_main_output_acc: 0.4694 - val_main_output_f1_micro: 0.6602 - val_aux_output_acc: 0.2982 - val_aux_output_f1_micro: 0.1137\n",
      "Epoch 5/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.6017 - main_output_loss: 1.3190 - aux_output_loss: 1.4138 - main_output_acc: 0.7755 - main_output_f1_micro: 0.6611 - aux_output_acc: 0.7884 - aux_output_f1_micro: 0.1140 - val_loss: 7.4215 - val_main_output_loss: 6.0568 - val_aux_output_loss: 6.8233 - val_main_output_acc: 0.4720 - val_main_output_f1_micro: 0.6621 - val_aux_output_acc: 0.2994 - val_aux_output_f1_micro: 0.1142\n",
      "\n",
      "Done with epoch: 75\n",
      "\n",
      "Train on 75344 samples, validate on 19387 samples\n",
      "Epoch 1/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.5956 - main_output_loss: 1.3143 - aux_output_loss: 1.4065 - main_output_acc: 0.7751 - main_output_f1_micro: 0.6630 - aux_output_acc: 0.7888 - aux_output_f1_micro: 0.1144 - val_loss: 7.3516 - val_main_output_loss: 5.9780 - val_aux_output_loss: 6.8678 - val_main_output_acc: 0.4705 - val_main_output_f1_micro: 0.6639 - val_aux_output_acc: 0.2978 - val_aux_output_f1_micro: 0.1146\n",
      "Epoch 2/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.5920 - main_output_loss: 1.3125 - aux_output_loss: 1.3976 - main_output_acc: 0.7760 - main_output_f1_micro: 0.6648 - aux_output_acc: 0.7884 - aux_output_f1_micro: 0.1148 - val_loss: 7.3250 - val_main_output_loss: 5.9594 - val_aux_output_loss: 6.8280 - val_main_output_acc: 0.4673 - val_main_output_f1_micro: 0.6657 - val_aux_output_acc: 0.3008 - val_aux_output_f1_micro: 0.1150\n",
      "Epoch 3/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.5827 - main_output_loss: 1.3046 - aux_output_loss: 1.3905 - main_output_acc: 0.7736 - main_output_f1_micro: 0.6666 - aux_output_acc: 0.7896 - aux_output_f1_micro: 0.1152 - val_loss: 7.4062 - val_main_output_loss: 6.0355 - val_aux_output_loss: 6.8536 - val_main_output_acc: 0.4718 - val_main_output_f1_micro: 0.6675 - val_aux_output_acc: 0.2977 - val_aux_output_f1_micro: 0.1154\n",
      "Epoch 4/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.5811 - main_output_loss: 1.3045 - aux_output_loss: 1.3834 - main_output_acc: 0.7754 - main_output_f1_micro: 0.6684 - aux_output_acc: 0.7890 - aux_output_f1_micro: 0.1157 - val_loss: 7.3850 - val_main_output_loss: 6.0084 - val_aux_output_loss: 6.8829 - val_main_output_acc: 0.4687 - val_main_output_f1_micro: 0.6693 - val_aux_output_acc: 0.2975 - val_aux_output_f1_micro: 0.1159\n",
      "Epoch 5/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.5718 - main_output_loss: 1.2967 - aux_output_loss: 1.3752 - main_output_acc: 0.7763 - main_output_f1_micro: 0.6701 - aux_output_acc: 0.7913 - aux_output_f1_micro: 0.1161 - val_loss: 7.5391 - val_main_output_loss: 6.1569 - val_aux_output_loss: 6.9111 - val_main_output_acc: 0.4670 - val_main_output_f1_micro: 0.6710 - val_aux_output_acc: 0.3033 - val_aux_output_f1_micro: 0.1163\n",
      "\n",
      "Done with epoch: 80\n",
      "\n",
      "Train on 75344 samples, validate on 19387 samples\n",
      "Epoch 1/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.5700 - main_output_loss: 1.2962 - aux_output_loss: 1.3690 - main_output_acc: 0.7766 - main_output_f1_micro: 0.6718 - aux_output_acc: 0.7899 - aux_output_f1_micro: 0.1165 - val_loss: 7.5306 - val_main_output_loss: 6.1447 - val_aux_output_loss: 6.9293 - val_main_output_acc: 0.4623 - val_main_output_f1_micro: 0.6727 - val_aux_output_acc: 0.3001 - val_aux_output_f1_micro: 0.1167\n",
      "Epoch 2/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.5597 - main_output_loss: 1.2877 - aux_output_loss: 1.3604 - main_output_acc: 0.7770 - main_output_f1_micro: 0.6735 - aux_output_acc: 0.7890 - aux_output_f1_micro: 0.1170 - val_loss: 7.5497 - val_main_output_loss: 6.1608 - val_aux_output_loss: 6.9443 - val_main_output_acc: 0.4656 - val_main_output_f1_micro: 0.6744 - val_aux_output_acc: 0.2990 - val_aux_output_f1_micro: 0.1172\n",
      "Epoch 3/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.5557 - main_output_loss: 1.2850 - aux_output_loss: 1.3535 - main_output_acc: 0.7765 - main_output_f1_micro: 0.6752 - aux_output_acc: 0.7912 - aux_output_f1_micro: 0.1174 - val_loss: 7.5305 - val_main_output_loss: 6.1400 - val_aux_output_loss: 6.9526 - val_main_output_acc: 0.4684 - val_main_output_f1_micro: 0.6760 - val_aux_output_acc: 0.3022 - val_aux_output_f1_micro: 0.1176\n",
      "Epoch 4/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.5502 - main_output_loss: 1.2811 - aux_output_loss: 1.3454 - main_output_acc: 0.7765 - main_output_f1_micro: 0.6768 - aux_output_acc: 0.7909 - aux_output_f1_micro: 0.1178 - val_loss: 7.5488 - val_main_output_loss: 6.1629 - val_aux_output_loss: 6.9293 - val_main_output_acc: 0.4662 - val_main_output_f1_micro: 0.6776 - val_aux_output_acc: 0.3030 - val_aux_output_f1_micro: 0.1181\n",
      "Epoch 5/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.5473 - main_output_loss: 1.2797 - aux_output_loss: 1.3379 - main_output_acc: 0.7779 - main_output_f1_micro: 0.6784 - aux_output_acc: 0.7915 - aux_output_f1_micro: 0.1183 - val_loss: 7.6549 - val_main_output_loss: 6.2568 - val_aux_output_loss: 6.9905 - val_main_output_acc: 0.4692 - val_main_output_f1_micro: 0.6792 - val_aux_output_acc: 0.3010 - val_aux_output_f1_micro: 0.1185\n",
      "\n",
      "Done with epoch: 85\n",
      "\n",
      "Train on 75344 samples, validate on 19387 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75344/75344 [==============================] - 89s - loss: 1.5408 - main_output_loss: 1.2745 - aux_output_loss: 1.3317 - main_output_acc: 0.7768 - main_output_f1_micro: 0.6800 - aux_output_acc: 0.7907 - aux_output_f1_micro: 0.1188 - val_loss: 7.7118 - val_main_output_loss: 6.3145 - val_aux_output_loss: 6.9864 - val_main_output_acc: 0.4625 - val_main_output_f1_micro: 0.6807 - val_aux_output_acc: 0.3032 - val_aux_output_f1_micro: 0.1190\n",
      "Epoch 2/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.5407 - main_output_loss: 1.2754 - aux_output_loss: 1.3268 - main_output_acc: 0.7780 - main_output_f1_micro: 0.6815 - aux_output_acc: 0.7919 - aux_output_f1_micro: 0.1192 - val_loss: 7.6968 - val_main_output_loss: 6.2877 - val_aux_output_loss: 7.0458 - val_main_output_acc: 0.4592 - val_main_output_f1_micro: 0.6823 - val_aux_output_acc: 0.3005 - val_aux_output_f1_micro: 0.1195\n",
      "Epoch 3/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.5366 - main_output_loss: 1.2727 - aux_output_loss: 1.3197 - main_output_acc: 0.7786 - main_output_f1_micro: 0.6830 - aux_output_acc: 0.7933 - aux_output_f1_micro: 0.1197 - val_loss: 7.6782 - val_main_output_loss: 6.2666 - val_aux_output_loss: 7.0579 - val_main_output_acc: 0.4592 - val_main_output_f1_micro: 0.6838 - val_aux_output_acc: 0.2976 - val_aux_output_f1_micro: 0.1199\n",
      "Epoch 4/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.5302 - main_output_loss: 1.2670 - aux_output_loss: 1.3159 - main_output_acc: 0.7797 - main_output_f1_micro: 0.6845 - aux_output_acc: 0.7919 - aux_output_f1_micro: 0.1202 - val_loss: 7.7514 - val_main_output_loss: 6.3392 - val_aux_output_loss: 7.0610 - val_main_output_acc: 0.4593 - val_main_output_f1_micro: 0.6852 - val_aux_output_acc: 0.3001 - val_aux_output_f1_micro: 0.1204\n",
      "Epoch 5/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.5245 - main_output_loss: 1.2628 - aux_output_loss: 1.3085 - main_output_acc: 0.7776 - main_output_f1_micro: 0.6860 - aux_output_acc: 0.7940 - aux_output_f1_micro: 0.1206 - val_loss: 7.7377 - val_main_output_loss: 6.3287 - val_aux_output_loss: 7.0452 - val_main_output_acc: 0.4603 - val_main_output_f1_micro: 0.6867 - val_aux_output_acc: 0.2973 - val_aux_output_f1_micro: 0.1208\n",
      "\n",
      "Done with epoch: 90\n",
      "\n",
      "Train on 75344 samples, validate on 19387 samples\n",
      "Epoch 1/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.5256 - main_output_loss: 1.2647 - aux_output_loss: 1.3046 - main_output_acc: 0.7792 - main_output_f1_micro: 0.6874 - aux_output_acc: 0.7939 - aux_output_f1_micro: 0.1211 - val_loss: 7.8286 - val_main_output_loss: 6.4086 - val_aux_output_loss: 7.0996 - val_main_output_acc: 0.4580 - val_main_output_f1_micro: 0.6881 - val_aux_output_acc: 0.3006 - val_aux_output_f1_micro: 0.1213\n",
      "Epoch 2/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.5188 - main_output_loss: 1.2588 - aux_output_loss: 1.3000 - main_output_acc: 0.7791 - main_output_f1_micro: 0.6888 - aux_output_acc: 0.7932 - aux_output_f1_micro: 0.1216 - val_loss: 7.8325 - val_main_output_loss: 6.4147 - val_aux_output_loss: 7.0891 - val_main_output_acc: 0.4531 - val_main_output_f1_micro: 0.6895 - val_aux_output_acc: 0.3000 - val_aux_output_f1_micro: 0.1218\n",
      "Epoch 3/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.5132 - main_output_loss: 1.2546 - aux_output_loss: 1.2930 - main_output_acc: 0.7813 - main_output_f1_micro: 0.6902 - aux_output_acc: 0.7931 - aux_output_f1_micro: 0.1220 - val_loss: 7.8174 - val_main_output_loss: 6.3997 - val_aux_output_loss: 7.0885 - val_main_output_acc: 0.4592 - val_main_output_f1_micro: 0.6909 - val_aux_output_acc: 0.3005 - val_aux_output_f1_micro: 0.1223\n",
      "Epoch 4/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.5142 - main_output_loss: 1.2561 - aux_output_loss: 1.2904 - main_output_acc: 0.7769 - main_output_f1_micro: 0.6916 - aux_output_acc: 0.7946 - aux_output_f1_micro: 0.1225 - val_loss: 7.9069 - val_main_output_loss: 6.4792 - val_aux_output_loss: 7.1385 - val_main_output_acc: 0.4552 - val_main_output_f1_micro: 0.6923 - val_aux_output_acc: 0.2989 - val_aux_output_f1_micro: 0.1228\n",
      "Epoch 5/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.5102 - main_output_loss: 1.2534 - aux_output_loss: 1.2836 - main_output_acc: 0.7784 - main_output_f1_micro: 0.6929 - aux_output_acc: 0.7934 - aux_output_f1_micro: 0.1230 - val_loss: 7.9353 - val_main_output_loss: 6.5014 - val_aux_output_loss: 7.1691 - val_main_output_acc: 0.4578 - val_main_output_f1_micro: 0.6936 - val_aux_output_acc: 0.3006 - val_aux_output_f1_micro: 0.1232\n",
      "\n",
      "Done with epoch: 95\n",
      "\n",
      "Train on 75344 samples, validate on 19387 samples\n",
      "Epoch 1/5\n",
      "75344/75344 [==============================] - 90s - loss: 1.5057 - main_output_loss: 1.2501 - aux_output_loss: 1.2779 - main_output_acc: 0.7793 - main_output_f1_micro: 0.6943 - aux_output_acc: 0.7929 - aux_output_f1_micro: 0.1235 - val_loss: 7.8535 - val_main_output_loss: 6.4271 - val_aux_output_loss: 7.1319 - val_main_output_acc: 0.4554 - val_main_output_f1_micro: 0.6949 - val_aux_output_acc: 0.3004 - val_aux_output_f1_micro: 0.1238\n",
      "Epoch 2/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.4961 - main_output_loss: 1.2413 - aux_output_loss: 1.2737 - main_output_acc: 0.7781 - main_output_f1_micro: 0.6956 - aux_output_acc: 0.7944 - aux_output_f1_micro: 0.1240 - val_loss: 7.8731 - val_main_output_loss: 6.4383 - val_aux_output_loss: 7.1741 - val_main_output_acc: 0.4508 - val_main_output_f1_micro: 0.6962 - val_aux_output_acc: 0.2967 - val_aux_output_f1_micro: 0.1243\n",
      "Epoch 3/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.5007 - main_output_loss: 1.2468 - aux_output_loss: 1.2696 - main_output_acc: 0.7810 - main_output_f1_micro: 0.6969 - aux_output_acc: 0.7944 - aux_output_f1_micro: 0.1245 - val_loss: 7.9719 - val_main_output_loss: 6.5313 - val_aux_output_loss: 7.2030 - val_main_output_acc: 0.4593 - val_main_output_f1_micro: 0.6975 - val_aux_output_acc: 0.3046 - val_aux_output_f1_micro: 0.1248\n",
      "Epoch 4/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.5023 - main_output_loss: 1.2493 - aux_output_loss: 1.2649 - main_output_acc: 0.7774 - main_output_f1_micro: 0.6981 - aux_output_acc: 0.7948 - aux_output_f1_micro: 0.1250 - val_loss: 7.8862 - val_main_output_loss: 6.4473 - val_aux_output_loss: 7.1945 - val_main_output_acc: 0.4550 - val_main_output_f1_micro: 0.6988 - val_aux_output_acc: 0.3055 - val_aux_output_f1_micro: 0.1253\n",
      "Epoch 5/5\n",
      "75344/75344 [==============================] - 89s - loss: 1.4959 - main_output_loss: 1.2434 - aux_output_loss: 1.2628 - main_output_acc: 0.7813 - main_output_f1_micro: 0.6994 - aux_output_acc: 0.7943 - aux_output_f1_micro: 0.1256 - val_loss: 8.0336 - val_main_output_loss: 6.5889 - val_aux_output_loss: 7.2234 - val_main_output_acc: 0.4520 - val_main_output_f1_micro: 0.7000 - val_aux_output_acc: 0.3014 - val_aux_output_f1_micro: 0.1259\n",
      "\n",
      "Done with epoch: 100\n",
      "\n",
      "CPU times: user 4h 19min 18s, sys: 22min 37s, total: 4h 41min 56s\n",
      "Wall time: 2h 31min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_name = 'models/lstm-word2vec-fasttext_2010-2013-data_categorical-crossentropy-2014-val-standard_scaled_wv_fs.model'\n",
    "epochs = 5\n",
    "for i in xrange(0, 100 // epochs):\n",
    "    hist = model.fit(\n",
    "        {'main_input': x_train, 'wv_input': wv_train, 'fs_input': fs_train},\n",
    "        {'main_output': y_train, 'aux_output': y_train},\n",
    "        epochs=epochs, batch_size=batch_size,   # 500\n",
    "        validation_split=0.2,\n",
    "        validation_data=(\n",
    "            {'main_input': x_val, 'wv_input': wv_val, 'fs_input': fs_val},\n",
    "            {'main_output': y_val, 'aux_output': y_val}\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.save(model_name.format(i))\n",
    "    print\n",
    "    print('Done with epoch: {}'.format((i + 1) * epochs))\n",
    "    with open('lstm-word2vec-fasttext.epoch.csv', 'a') as fl:\n",
    "        fl.write(model_name + '\\n')\n",
    "        fl.write('Epoch {}\\n'.format((i + 1) * epochs))\n",
    "        fl.write('{}\\n'.format(datetime.now()))\n",
    "        fl.write('\\n'.join(['{}: {}'.format(k, v[0]) for k, v in hist.history.items()]))\n",
    "        fl.write('\\n\\n')\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aux_output_acc': [0.79290984432695777,\n",
       "  0.79438308487654385,\n",
       "  0.79438308231970844,\n",
       "  0.79479452806892203,\n",
       "  0.79429017601941743],\n",
       " 'aux_output_f1_micro': [0.1234986738998575,\n",
       "  0.12401480770007925,\n",
       "  0.12451566183964496,\n",
       "  0.12503920535460655,\n",
       "  0.1255943038298917],\n",
       " 'aux_output_loss': [1.2778704689297866,\n",
       "  1.273654517372542,\n",
       "  1.2695746469279969,\n",
       "  1.2649296698714041,\n",
       "  1.2627735187936979],\n",
       " 'loss': [1.5057219573078857,\n",
       "  1.4960603192369506,\n",
       "  1.5006809289426555,\n",
       "  1.5023055333928157,\n",
       "  1.4959213040036541],\n",
       " 'main_output_acc': [0.77933211667341751,\n",
       "  0.77812432584602587,\n",
       "  0.78100444626772725,\n",
       "  0.77738106652641781,\n",
       "  0.78125662523537187],\n",
       " 'main_output_f1_micro': [0.69425208673884242,\n",
       "  0.69557244688063624,\n",
       "  0.69686611359679895,\n",
       "  0.6981417263774361,\n",
       "  0.69938933478467002],\n",
       " 'main_output_loss': [1.2501478531882626,\n",
       "  1.2413294074084253,\n",
       "  1.2467659947016001,\n",
       "  1.2493195939934869,\n",
       "  1.2433665936275207],\n",
       " 'val_aux_output_acc': [0.3003559006425997,\n",
       "  0.29674523754622117,\n",
       "  0.30458554342045535,\n",
       "  0.30551399893617903,\n",
       "  0.30138752201317742],\n",
       " 'val_aux_output_f1_micro': [0.12375047030734901,\n",
       "  0.1242677424078618,\n",
       "  0.12477800052864933,\n",
       "  0.12531811952077507,\n",
       "  0.12588067729239946],\n",
       " 'val_aux_output_loss': [7.1319106510721362,\n",
       "  7.174107221746147,\n",
       "  7.2029811089580074,\n",
       "  7.1944922763357928,\n",
       "  7.2233526114061766],\n",
       " 'val_loss': [7.8535167824744248,\n",
       "  7.8731235894336837,\n",
       "  7.9718743083881254,\n",
       "  7.8861974180590195,\n",
       "  8.0335640556306718],\n",
       " 'val_main_output_acc': [0.45535667345843212,\n",
       "  0.45076596162290528,\n",
       "  0.45932841160768773,\n",
       "  0.45499560514554999,\n",
       "  0.45195233367309307],\n",
       " 'val_main_output_f1_micro': [0.69491764721828853,\n",
       "  0.6962340986703458,\n",
       "  0.69752032078148107,\n",
       "  0.69877450236001593,\n",
       "  0.70001912077036355],\n",
       " 'val_main_output_loss': [6.4271345950700365,\n",
       "  6.4383020746324835,\n",
       "  6.5312781552087342,\n",
       "  6.4472989816125033,\n",
       "  6.5888934890771473]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# for j in xrange(i, i + (100 // epochs)):\n",
    "#     hist = model.fit(\n",
    "#         {'main_input': x_train, 'wv_input': wv_train, 'fs_input': fs_train},\n",
    "#         {'main_output': y_train, 'aux_output': y_train},\n",
    "#         epochs=epochs, batch_size=batch_size,   # 500\n",
    "#         validation_split=0.2,\n",
    "#         validation_data=(\n",
    "#             {'main_input': x_val, 'wv_input': wv_val, 'fs_input': fs_val},\n",
    "#             {'main_output': y_val, 'aux_output': y_val}\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "#     model.save(model_name.format(i))\n",
    "#     print\n",
    "#     print('Done with epoch: {}'.format((j + 1) * epochs))\n",
    "#     with open('lstm-word2vec-fasttext.epoch.csv', 'a') as fl:\n",
    "#         fl.write(model_name + '\\n')\n",
    "#         fl.write('Epoch {}\\n'.format((j + 1) * epochs))\n",
    "#         fl.write('{}\\n'.format(datetime.now()))\n",
    "#         fl.write('\\n'.join(['{}: {}'.format(k, v[0]) for k, v in hist.history.items()]))\n",
    "#         fl.write('\\n\\n')\n",
    "#     print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = model.predict({'main_input': x_train[:100], 'wv_input': wv_train[:100], 'fs_input': fs_train[:100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9761f83c10>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAWAKEdwBYAoR3AFgChHcAWAK/T+zc8h8s7jSqgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9761f83310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "ix = 29\n",
    "pd.Series(g[0][ix]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9761e636d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f96d73824d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(g[1][ix]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([ 1, 98]),), (array([ 1, 98]),), (array([ 1, 98]),))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh = 0.5\n",
    "np.where(y_train[ix] == 1), np.where(g[0][ix] > thresh), np.where(g[1][ix] > thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wvmodel = Word2Vec.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fsmodel = fasttext.load_model('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.fasttext.model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_fasttext(tokens, stopwords=[]):\n",
    "    global fsmodel\n",
    "    # This requires fsmodel to be present in the namespace.\n",
    "    fs_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    ).map(lambda x: np.array([fsmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return fs_feature_vec\n",
    "\n",
    "\n",
    "def transform_unsupervised_sentiment_neuron(tokens, stopwords=[]):\n",
    "    # This requires fsmodel to be present in the namespace.\n",
    "    \n",
    "    usn_feature_vec = usnmodel.transform(tokens)\n",
    "\n",
    "    # usn_feature_vec = tokens.map(\n",
    "    #     lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    # ).map(lambda x: np.array([usnmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return usn_feature_vec\n",
    "\n",
    "\n",
    "def transform_word2vec(tokens, stopwords=[]):\n",
    "    global wvmodel\n",
    "    # This requires wvmodel to be present in the namespace.\n",
    "    wv_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords and w in wvmodel.wv.vocab)]\n",
    "    ).map(lambda x: np.array([wvmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return wv_feature_vec\n",
    "\n",
    "\n",
    "def parallel_generate_word_vectors(samp, transformer, stopwords, batch, num_proc):\n",
    "    with Parallel(n_jobs=num_proc) as parallel:\n",
    "        dataset = []\n",
    "        is_break = False\n",
    "        i = 0\n",
    "\n",
    "        while not is_break:\n",
    "            payload = []\n",
    "\n",
    "            for j in xrange(num_proc):\n",
    "                t_df = samp[(i + j) * batch: (i + 1 + j) * batch]\n",
    "\n",
    "                if t_df.empty:\n",
    "                    is_break = True\n",
    "                    continue\n",
    "\n",
    "                payload.append(\n",
    "                    delayed(transformer)(\n",
    "                        t_df, stopwords\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            print('Current batch in main thread: {}'.format((i + j) * batch))\n",
    "\n",
    "            if payload:\n",
    "                results = parallel(payload)\n",
    "                dataset.extend(results)\n",
    "                i += num_proc\n",
    "\n",
    "    return pd.concat(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_classes(pred, scale_param=0.75, min_thresh=0.05, thresh = 0.5):\n",
    "#     mx = pred.mean() + 3 * pred.std()\n",
    "    return np.where(pred > thresh)[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2idx_transform(word, _word2idx):\n",
    "    return _word2idx.get(word, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features_for(df, min_batch=2000, stopwords=[], num_proc=7):\n",
    "    df_tokens = transform_text(df)\n",
    "    \n",
    "    batch = min(df_tokens.shape[0] / num_proc, min_batch)\n",
    "\n",
    "    print('Computing fs features...')\n",
    "    fvec = parallel_generate_word_vectors(df_tokens, transform_fasttext, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Computing wv features...')\n",
    "    wvec = parallel_generate_word_vectors(df_tokens, transform_word2vec, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Mapping word indices...')\n",
    "    word_indices = df_tokens.map(lambda x: [word2idx_transform(i, _word2idx) for i in x.split()])\n",
    "    \n",
    "    return word_indices, wvec, fvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/TestData.json') as fl:\n",
    "    data = json.load(fl)\n",
    "    test_df = pd.DataFrame(data['TestData']).T\n",
    "    del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fs features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Computing wv features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Mapping word indices...\n",
      "CPU times: user 45.7 s, sys: 7.08 s, total: 52.8 s\n",
      "Wall time: 2min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_word_indices,test_wvec, test_fvec = extract_features_for(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert(np.all(test_wvec[test_wvec.isnull()].index == test_fvec[test_fvec.isnull()].index))\n",
    "test_null_index = test_wvec[test_wvec.isnull()].index.union(test_fvec[test_fvec.isnull()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'TestData_02543', u'TestData_05012', u'TestData_05830'], dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_null_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bodyText</th>\n",
       "      <th>topics</th>\n",
       "      <th>webPublicationDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TestData_00001</th>\n",
       "      <td>On 5 April, a two-year-old accidentally squeez...</td>\n",
       "      <td>[]</td>\n",
       "      <td>01-01-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_00002</th>\n",
       "      <td>Looking back at 2014 from the perspective of a...</td>\n",
       "      <td>[]</td>\n",
       "      <td>01-01-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_00003</th>\n",
       "      <td>A 22-year-old man arrested by police investiga...</td>\n",
       "      <td>[]</td>\n",
       "      <td>01-01-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_00004</th>\n",
       "      <td>The place where nine-year-old Najia Warshaga l...</td>\n",
       "      <td>[]</td>\n",
       "      <td>01-01-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_00005</th>\n",
       "      <td>The annual Beaujolais contest, the showcase fo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>01-01-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_00006</th>\n",
       "      <td>It would be comforting to think 2015 will brin...</td>\n",
       "      <td>[]</td>\n",
       "      <td>01-01-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_00007</th>\n",
       "      <td>Just after 7pm on the evening of Saturday 28 M...</td>\n",
       "      <td>[]</td>\n",
       "      <td>02-01-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_00008</th>\n",
       "      <td>Police are hunting gunmen who fired at a crowd...</td>\n",
       "      <td>[]</td>\n",
       "      <td>02-01-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_00009</th>\n",
       "      <td>The US has imposed economic sanctions against ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>02-01-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_00010</th>\n",
       "      <td>Sony Entertainment is unable to confirm that h...</td>\n",
       "      <td>[]</td>\n",
       "      <td>02-01-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_00011</th>\n",
       "      <td>HM: Hugh Muir JV: John Vidal SG: Suzanne Golde...</td>\n",
       "      <td>[]</td>\n",
       "      <td>02-01-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_00012</th>\n",
       "      <td>January 5 Costa prize category winners announc...</td>\n",
       "      <td>[]</td>\n",
       "      <td>02-01-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_00013</th>\n",
       "      <td>A Libyan man accused of masterminding the 1998...</td>\n",
       "      <td>[]</td>\n",
       "      <td>03-01-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_00014</th>\n",
       "      <td>An African pensioner whose house was targeted ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04-01-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_00015</th>\n",
       "      <td>He remains one of the most controversial scien...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04-01-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_00016</th>\n",
       "      <td>Dresden, the city where I lived for 10 years, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04-01-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_00017</th>\n",
       "      <td>Sitting on a wooden bench on a Dresden square ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>04-01-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_00018</th>\n",
       "      <td>Saudi Arabia is on alert for jihadi attacks af...</td>\n",
       "      <td>[]</td>\n",
       "      <td>05-01-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_00019</th>\n",
       "      <td>Bright winter sunshine drenched the John Josep...</td>\n",
       "      <td>[]</td>\n",
       "      <td>05-01-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_00020</th>\n",
       "      <td>First Valencia laid on a guard of honour for R...</td>\n",
       "      <td>[]</td>\n",
       "      <td>05-01-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_00021</th>\n",
       "      <td>Whether the men on the fishing boat that sank ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>05-01-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_00022</th>\n",
       "      <td>Clevelands mayor says he doesnt trust the st...</td>\n",
       "      <td>[]</td>\n",
       "      <td>05-01-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_00023</th>\n",
       "      <td>Madonna is the original queen of pop media. Na...</td>\n",
       "      <td>[]</td>\n",
       "      <td>05-01-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_00024</th>\n",
       "      <td>The Green party would scrap the building of ne...</td>\n",
       "      <td>[]</td>\n",
       "      <td>05-01-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_00025</th>\n",
       "      <td>A fresh coalition row has broken out after Nic...</td>\n",
       "      <td>[]</td>\n",
       "      <td>06-01-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_00026</th>\n",
       "      <td>In conjunction with the joint military action ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>06-01-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_00027</th>\n",
       "      <td>Sonys CEO, Kaz Hirai, has spoken out about th...</td>\n",
       "      <td>[]</td>\n",
       "      <td>06-01-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_00028</th>\n",
       "      <td>Special courts run by Pakistans army will try...</td>\n",
       "      <td>[]</td>\n",
       "      <td>06-01-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_00029</th>\n",
       "      <td>The mother of a 12-year-old Cleveland boy shot...</td>\n",
       "      <td>[]</td>\n",
       "      <td>06-01-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_00030</th>\n",
       "      <td>Los Angeles police broke up a protest outside ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>06-01-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_07552</th>\n",
       "      <td>The Aleppo Thaer al-Halabi left behind was a g...</td>\n",
       "      <td>[]</td>\n",
       "      <td>23-12-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_07553</th>\n",
       "      <td>As the police officers looked at the body on P...</td>\n",
       "      <td>[]</td>\n",
       "      <td>23-12-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_07554</th>\n",
       "      <td>British policy on Syria has been wrong every ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>23-12-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_07555</th>\n",
       "      <td>A Serbian woman who survived what was said to ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>24-12-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_07556</th>\n",
       "      <td>Islamic State commanders in Syria have communi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>24-12-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_07557</th>\n",
       "      <td>Chibok girls are released by Boko Haram With a...</td>\n",
       "      <td>[]</td>\n",
       "      <td>24-12-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_07558</th>\n",
       "      <td>The world must harness the power of love rathe...</td>\n",
       "      <td>[]</td>\n",
       "      <td>25-12-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_07559</th>\n",
       "      <td>It has become known as the first genocide of t...</td>\n",
       "      <td>[]</td>\n",
       "      <td>25-12-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_07560</th>\n",
       "      <td>A typhoon slammed into central Philippines lat...</td>\n",
       "      <td>[]</td>\n",
       "      <td>25-12-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_07561</th>\n",
       "      <td>The Donald Trump victory, the fallout from Bre...</td>\n",
       "      <td>[]</td>\n",
       "      <td>26-12-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_07562</th>\n",
       "      <td>A former News Corp journalist says she was for...</td>\n",
       "      <td>[]</td>\n",
       "      <td>27-12-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_07563</th>\n",
       "      <td>Indian police arrested four men on Monday on s...</td>\n",
       "      <td>[]</td>\n",
       "      <td>27-12-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_07564</th>\n",
       "      <td>The Palestinian president has expressed hope t...</td>\n",
       "      <td>[]</td>\n",
       "      <td>27-12-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_07565</th>\n",
       "      <td>A Facebook safety check for Bangkok, which the...</td>\n",
       "      <td>[]</td>\n",
       "      <td>28-12-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_07566</th>\n",
       "      <td>There is no evidence of a successful cyberatta...</td>\n",
       "      <td>[]</td>\n",
       "      <td>28-12-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_07567</th>\n",
       "      <td>The Czech government is to set up a specialist...</td>\n",
       "      <td>[]</td>\n",
       "      <td>28-12-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_07568</th>\n",
       "      <td>The Todd Carney cup for bad publicity in the N...</td>\n",
       "      <td>[]</td>\n",
       "      <td>28-12-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_07569</th>\n",
       "      <td>The birth of Americana This year marked 40 yea...</td>\n",
       "      <td>[]</td>\n",
       "      <td>28-12-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_07570</th>\n",
       "      <td>Naveed Baloch was crossing a road in central B...</td>\n",
       "      <td>[]</td>\n",
       "      <td>29-12-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_07571</th>\n",
       "      <td>An airstrike by the US-led coalition operating...</td>\n",
       "      <td>[]</td>\n",
       "      <td>29-12-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_07572</th>\n",
       "      <td>A century, a hundred years, a ton: whatever it...</td>\n",
       "      <td>[]</td>\n",
       "      <td>29-12-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_07573</th>\n",
       "      <td>Six months after the international criminal co...</td>\n",
       "      <td>[]</td>\n",
       "      <td>29-12-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_07574</th>\n",
       "      <td>As Lord Dubs has himself reflected (A&amp;nbsp;hos...</td>\n",
       "      <td>[]</td>\n",
       "      <td>29-12-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_07575</th>\n",
       "      <td>Major western cities are tightening security f...</td>\n",
       "      <td>[]</td>\n",
       "      <td>30-12-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_07576</th>\n",
       "      <td>What was Theresa May thinking in attacking the...</td>\n",
       "      <td>[]</td>\n",
       "      <td>30-12-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_07577</th>\n",
       "      <td>Guards at the Faslane submarine base on the Cl...</td>\n",
       "      <td>[]</td>\n",
       "      <td>30-12-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_07578</th>\n",
       "      <td>A ceasefire across Syria appeared to be holdin...</td>\n",
       "      <td>[]</td>\n",
       "      <td>30-12-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_07579</th>\n",
       "      <td>Civil war. Climate change. Starvation. Natural...</td>\n",
       "      <td>[]</td>\n",
       "      <td>31-12-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_07580</th>\n",
       "      <td>A tentative ceasefire is holding in most parts...</td>\n",
       "      <td>[]</td>\n",
       "      <td>31-12-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_07581</th>\n",
       "      <td>The UN security council has unanimously adopte...</td>\n",
       "      <td>[]</td>\n",
       "      <td>31-12-2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7578 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         bodyText topics  \\\n",
       "TestData_00001  On 5 April, a two-year-old accidentally squeez...     []   \n",
       "TestData_00002  Looking back at 2014 from the perspective of a...     []   \n",
       "TestData_00003  A 22-year-old man arrested by police investiga...     []   \n",
       "TestData_00004  The place where nine-year-old Najia Warshaga l...     []   \n",
       "TestData_00005  The annual Beaujolais contest, the showcase fo...     []   \n",
       "TestData_00006  It would be comforting to think 2015 will brin...     []   \n",
       "TestData_00007  Just after 7pm on the evening of Saturday 28 M...     []   \n",
       "TestData_00008  Police are hunting gunmen who fired at a crowd...     []   \n",
       "TestData_00009  The US has imposed economic sanctions against ...     []   \n",
       "TestData_00010  Sony Entertainment is unable to confirm that h...     []   \n",
       "TestData_00011  HM: Hugh Muir JV: John Vidal SG: Suzanne Golde...     []   \n",
       "TestData_00012  January 5 Costa prize category winners announc...     []   \n",
       "TestData_00013  A Libyan man accused of masterminding the 1998...     []   \n",
       "TestData_00014  An African pensioner whose house was targeted ...     []   \n",
       "TestData_00015  He remains one of the most controversial scien...     []   \n",
       "TestData_00016  Dresden, the city where I lived for 10 years, ...     []   \n",
       "TestData_00017  Sitting on a wooden bench on a Dresden square ...     []   \n",
       "TestData_00018  Saudi Arabia is on alert for jihadi attacks af...     []   \n",
       "TestData_00019  Bright winter sunshine drenched the John Josep...     []   \n",
       "TestData_00020  First Valencia laid on a guard of honour for R...     []   \n",
       "TestData_00021  Whether the men on the fishing boat that sank ...     []   \n",
       "TestData_00022  Clevelands mayor says he doesnt trust the st...     []   \n",
       "TestData_00023  Madonna is the original queen of pop media. Na...     []   \n",
       "TestData_00024  The Green party would scrap the building of ne...     []   \n",
       "TestData_00025  A fresh coalition row has broken out after Nic...     []   \n",
       "TestData_00026  In conjunction with the joint military action ...     []   \n",
       "TestData_00027  Sonys CEO, Kaz Hirai, has spoken out about th...     []   \n",
       "TestData_00028  Special courts run by Pakistans army will try...     []   \n",
       "TestData_00029  The mother of a 12-year-old Cleveland boy shot...     []   \n",
       "TestData_00030  Los Angeles police broke up a protest outside ...     []   \n",
       "...                                                           ...    ...   \n",
       "TestData_07552  The Aleppo Thaer al-Halabi left behind was a g...     []   \n",
       "TestData_07553  As the police officers looked at the body on P...     []   \n",
       "TestData_07554  British policy on Syria has been wrong every ...     []   \n",
       "TestData_07555  A Serbian woman who survived what was said to ...     []   \n",
       "TestData_07556  Islamic State commanders in Syria have communi...     []   \n",
       "TestData_07557  Chibok girls are released by Boko Haram With a...     []   \n",
       "TestData_07558  The world must harness the power of love rathe...     []   \n",
       "TestData_07559  It has become known as the first genocide of t...     []   \n",
       "TestData_07560  A typhoon slammed into central Philippines lat...     []   \n",
       "TestData_07561  The Donald Trump victory, the fallout from Bre...     []   \n",
       "TestData_07562  A former News Corp journalist says she was for...     []   \n",
       "TestData_07563  Indian police arrested four men on Monday on s...     []   \n",
       "TestData_07564  The Palestinian president has expressed hope t...     []   \n",
       "TestData_07565  A Facebook safety check for Bangkok, which the...     []   \n",
       "TestData_07566  There is no evidence of a successful cyberatta...     []   \n",
       "TestData_07567  The Czech government is to set up a specialist...     []   \n",
       "TestData_07568  The Todd Carney cup for bad publicity in the N...     []   \n",
       "TestData_07569  The birth of Americana This year marked 40 yea...     []   \n",
       "TestData_07570  Naveed Baloch was crossing a road in central B...     []   \n",
       "TestData_07571  An airstrike by the US-led coalition operating...     []   \n",
       "TestData_07572  A century, a hundred years, a ton: whatever it...     []   \n",
       "TestData_07573  Six months after the international criminal co...     []   \n",
       "TestData_07574  As Lord Dubs has himself reflected (A&nbsp;hos...     []   \n",
       "TestData_07575  Major western cities are tightening security f...     []   \n",
       "TestData_07576  What was Theresa May thinking in attacking the...     []   \n",
       "TestData_07577  Guards at the Faslane submarine base on the Cl...     []   \n",
       "TestData_07578  A ceasefire across Syria appeared to be holdin...     []   \n",
       "TestData_07579  Civil war. Climate change. Starvation. Natural...     []   \n",
       "TestData_07580  A tentative ceasefire is holding in most parts...     []   \n",
       "TestData_07581  The UN security council has unanimously adopte...     []   \n",
       "\n",
       "               webPublicationDate  \n",
       "TestData_00001         01-01-2015  \n",
       "TestData_00002         01-01-2015  \n",
       "TestData_00003         01-01-2015  \n",
       "TestData_00004         01-01-2015  \n",
       "TestData_00005         01-01-2015  \n",
       "TestData_00006         01-01-2015  \n",
       "TestData_00007         02-01-2015  \n",
       "TestData_00008         02-01-2015  \n",
       "TestData_00009         02-01-2015  \n",
       "TestData_00010         02-01-2015  \n",
       "TestData_00011         02-01-2015  \n",
       "TestData_00012         02-01-2015  \n",
       "TestData_00013         03-01-2015  \n",
       "TestData_00014         04-01-2015  \n",
       "TestData_00015         04-01-2015  \n",
       "TestData_00016         04-01-2015  \n",
       "TestData_00017         04-01-2015  \n",
       "TestData_00018         05-01-2015  \n",
       "TestData_00019         05-01-2015  \n",
       "TestData_00020         05-01-2015  \n",
       "TestData_00021         05-01-2015  \n",
       "TestData_00022         05-01-2015  \n",
       "TestData_00023         05-01-2015  \n",
       "TestData_00024         05-01-2015  \n",
       "TestData_00025         06-01-2015  \n",
       "TestData_00026         06-01-2015  \n",
       "TestData_00027         06-01-2015  \n",
       "TestData_00028         06-01-2015  \n",
       "TestData_00029         06-01-2015  \n",
       "TestData_00030         06-01-2015  \n",
       "...                           ...  \n",
       "TestData_07552         23-12-2016  \n",
       "TestData_07553         23-12-2016  \n",
       "TestData_07554         23-12-2016  \n",
       "TestData_07555         24-12-2016  \n",
       "TestData_07556         24-12-2016  \n",
       "TestData_07557         24-12-2016  \n",
       "TestData_07558         25-12-2016  \n",
       "TestData_07559         25-12-2016  \n",
       "TestData_07560         25-12-2016  \n",
       "TestData_07561         26-12-2016  \n",
       "TestData_07562         27-12-2016  \n",
       "TestData_07563         27-12-2016  \n",
       "TestData_07564         27-12-2016  \n",
       "TestData_07565         28-12-2016  \n",
       "TestData_07566         28-12-2016  \n",
       "TestData_07567         28-12-2016  \n",
       "TestData_07568         28-12-2016  \n",
       "TestData_07569         28-12-2016  \n",
       "TestData_07570         29-12-2016  \n",
       "TestData_07571         29-12-2016  \n",
       "TestData_07572         29-12-2016  \n",
       "TestData_07573         29-12-2016  \n",
       "TestData_07574         29-12-2016  \n",
       "TestData_07575         30-12-2016  \n",
       "TestData_07576         30-12-2016  \n",
       "TestData_07577         30-12-2016  \n",
       "TestData_07578         30-12-2016  \n",
       "TestData_07579         31-12-2016  \n",
       "TestData_07580         31-12-2016  \n",
       "TestData_07581         31-12-2016  \n",
       "\n",
       "[7578 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 312 ms, sys: 8 ms, total: 320 ms\n",
      "Wall time: 323 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "maxlen = 500\n",
    "\n",
    "valid_test_index = test_word_indices.index.difference(test_null_index)\n",
    "x_test = sequence.pad_sequences(test_word_indices.ix[valid_test_index], maxlen=maxlen)\n",
    "wv_test = np.vstack(test_wvec.ix[valid_test_index])\n",
    "fs_test = np.vstack(test_fvec.ix[valid_test_index])\n",
    "\n",
    "wv_test = wv_sc.transform(wv_test)\n",
    "fs_test = fs_sc.transform(fs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_probas = model.predict({'main_input': x_test, 'wv_input': wv_test, 'fs_input': fs_test}, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_test_probas, aux_test_probas = test_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.78057731e-24,   7.19655091e-08,   5.58075374e-12, ...,\n",
       "          4.79360933e-05,   3.82946334e-21,   7.24491334e-25],\n",
       "       [  1.41906216e-27,   2.17561091e-11,   1.81838026e-15, ...,\n",
       "          1.17292763e-17,   7.47898582e-21,   2.59653755e-28],\n",
       "       [  4.57799233e-20,   7.50593529e-07,   1.46957273e-11, ...,\n",
       "          1.28544229e-06,   2.85309862e-13,   1.26649546e-19],\n",
       "       ..., \n",
       "       [  6.86277835e-09,   8.64830315e-02,   4.80795920e-01, ...,\n",
       "          2.41652684e-04,   2.75913662e-05,   4.74667727e-09],\n",
       "       [  5.49575189e-38,   4.44857619e-07,   2.41020888e-18, ...,\n",
       "          3.25327984e-17,   3.73860250e-27,   0.00000000e+00],\n",
       "       [  5.66381877e-34,   1.14101375e-07,   7.23591365e-09, ...,\n",
       "          1.22702917e-18,   9.29351163e-23,   8.46117803e-34]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_test_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df.ix[test_df.index.difference(test_null_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2542, 5011, 5829]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_index = [int(s.split('_')[1]) - 1 for s in test_null_index]  # Subtract 1 since test index starts at 1 while enumerate starts at 0\n",
    "skip_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7578, 160), (7581, 3))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_test_probas.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36 ms, sys: 0 ns, total: 36 ms\n",
      "Wall time: 31.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# valid_test_feature_vec found below!\n",
    "test_values = np.zeros([main_test_probas.shape[0], len(topics)])\n",
    "for ix, pred in enumerate(main_test_probas):\n",
    "    for v in get_classes(pred, thresh=0.5):\n",
    "        test_values[ix][v] = 1\n",
    "\n",
    "test_sub_df = pd.DataFrame(\n",
    "    test_values,\n",
    "    index=test_df.ix[test_df.index.difference(test_null_index)].index,\n",
    "    columns=topics\n",
    ")\n",
    "\n",
    "null_test_df = pd.DataFrame(\n",
    "    np.zeros((len(test_null_index), len(topics))),\n",
    "    index=test_null_index,\n",
    "    columns=topics\n",
    ")\n",
    "\n",
    "test_sub_df = test_sub_df.append(null_test_df)\n",
    "test_sub_df = test_sub_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75344/75344 [==============================] - 89s - loss: 1.4959 - main_output_loss: 1.2434 - aux_output_loss: 1.2628 - main_output_acc: 0.7813 - main_output_f1_micro: 0.6994 - aux_output_acc: 0.7943 - aux_output_f1_micro: 0.1256 - val_loss: 8.0336 - val_main_output_loss: 6.5889 - val_aux_output_loss: 7.2234 - val_main_output_acc: 0.4520 - val_main_output_f1_micro: 0.7000 - val_aux_output_acc: 0.3014 - val_aux_output_f1_micro: 0.1259\n"
     ]
    }
   ],
   "source": [
    "print '75344/75344 [==============================] - 89s - loss: 1.4959 - main_output_loss: 1.2434 - aux_output_loss: 1.2628 - main_output_acc: 0.7813 - main_output_f1_micro: 0.6994 - aux_output_acc: 0.7943 - aux_output_f1_micro: 0.1256 - val_loss: 8.0336 - val_main_output_loss: 6.5889 - val_aux_output_loss: 7.2234 - val_main_output_acc: 0.4520 - val_main_output_f1_micro: 0.7000 - val_aux_output_acc: 0.3014 - val_aux_output_f1_micro: 0.1259'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_sub_df.astype(int).reset_index().rename(\n",
    "    columns={'index': 'id'}\n",
    ").sort_values('id').to_csv(\n",
    "    'lstm_300-word2vec_300-fasttext_300-maxlen_500-dense_128_256_128-cat_cross-epoch_100-batch_size_500-val_main_output_f1_micro_0.7000-main_output_f1_micro_0.6994-main_output_loss_1.2434-data_2010_2013-val_data_2014-thresh_0.5-with_standard_scaler_wv_fs.csv', \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7581, 160)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36 ms, sys: 0 ns, total: 36 ms\n",
      "Wall time: 32.6 ms\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# adjust_index = 0\n",
    "# # valid_test_feature_vec found below!\n",
    "# test_values = np.zeros([test_df.shape[0], len(topics)])\n",
    "# for ix, pred in enumerate(main_test_probas):\n",
    "#     if ix in skip_index:\n",
    "#         test_values[ix] = np.nan\n",
    "#         # Increment adjust index so that we have the correct index for other samples\n",
    "#         adjust_index += 1\n",
    "#         continue\n",
    "\n",
    "#     for v in get_classes(pred, thresh=0.05):\n",
    "#         test_values[ix + adjust_index][v] = 1\n",
    "\n",
    "# test_sub_df = pd.DataFrame(test_values, columns=sorted(topics), index=test_df.index)\n",
    "\n",
    "# q = test_sub_df.sum(axis=1)\n",
    "# assert(len(q[q.isnull()].index.difference(test_null_index)) == 0)\n",
    "\n",
    "# test_sub_df = test_sub_df.fillna(0)\n",
    "\n",
    "# # for i in test_feature_vec[test_feature_vec.isnull()].index:\n",
    "# #     test_sub_df.ix[i] = np.zeros(len(topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestData_02543    0.0\n",
       "TestData_05012    0.0\n",
       "TestData_05830    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.ix[test_null_index].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9771.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sub_df.astype(int).reset_index().rename(\n",
    "    columns={'index': 'id'}\n",
    ").sort_values('id').to_csv(\n",
    "    'lstm_300-word2vec_300-fasttext_300-maxlen_500-dense_64_64_64-cat_cross-epoch_210-batch_size_750-val_main_output_f1_micro_0.5760-main_output_f1_micro_0.5751-main_output_loss_0.9143-data_2010_2013-val_data_2014-thresh_0.05.csv', \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: zikavirus, dtype: float64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = test_sub_df['zikavirus']\n",
    "e[e==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14328"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_submission = pd.read_csv('basic_nn_submission_0.649_accuracy_multi_class.csv')\n",
    "top_submission.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9280"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_index_lstm_sub = pd.read_csv('lstm.2014b_training_700_maxlen_64cell_100epochs_0.0025_threshold.csv')\n",
    "wrong_index_lstm_sub.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34952"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_sub = pd.read_csv('basic_nn_submission_full_training_data_0.9958_validation_accuracy_binary_crossentropy.csv')\n",
    "some_sub.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2197, 160)\n",
      "(3957, 160)\n",
      "(12, 160)\n",
      "(1503, 160)\n"
     ]
    }
   ],
   "source": [
    "print top_submission.set_index('id')[top_submission.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print wrong_index_lstm_sub.set_index('id')[wrong_index_lstm_sub.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print some_sub.set_index('id')[some_sub.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print test_sub_df[test_sub_df.sum(axis=1) == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestData_00011     0\n",
       "TestData_00012     0\n",
       "TestData_00015     0\n",
       "TestData_00027     3\n",
       "TestData_00029     0\n",
       "TestData_00038     1\n",
       "TestData_00042     5\n",
       "TestData_00053     4\n",
       "TestData_00056     1\n",
       "TestData_00060     1\n",
       "TestData_00066     0\n",
       "TestData_00085     0\n",
       "TestData_00087     1\n",
       "TestData_00090     0\n",
       "TestData_00092     0\n",
       "TestData_00107     3\n",
       "TestData_00111     0\n",
       "TestData_00114     0\n",
       "TestData_00115     1\n",
       "TestData_00118     0\n",
       "TestData_00119     0\n",
       "TestData_00121     0\n",
       "TestData_00123     0\n",
       "TestData_00125     0\n",
       "TestData_00127     0\n",
       "TestData_00128     1\n",
       "TestData_00139     1\n",
       "TestData_00140     1\n",
       "TestData_00144     0\n",
       "TestData_00147     2\n",
       "                  ..\n",
       "TestData_07445     0\n",
       "TestData_07456     3\n",
       "TestData_07461     1\n",
       "TestData_07462     4\n",
       "TestData_07465     0\n",
       "TestData_07468     0\n",
       "TestData_07471     1\n",
       "TestData_07475     0\n",
       "TestData_07486    10\n",
       "TestData_07495     1\n",
       "TestData_07509     0\n",
       "TestData_07514     3\n",
       "TestData_07515     1\n",
       "TestData_07523     0\n",
       "TestData_07533     2\n",
       "TestData_07534     2\n",
       "TestData_07542     1\n",
       "TestData_07544     2\n",
       "TestData_07545     0\n",
       "TestData_07552     2\n",
       "TestData_07556     5\n",
       "TestData_07563     1\n",
       "TestData_07565     0\n",
       "TestData_07566     0\n",
       "TestData_07569     0\n",
       "TestData_07571     3\n",
       "TestData_07572     1\n",
       "TestData_07579     6\n",
       "TestData_07580     2\n",
       "TestData_07581     3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_submission.set_index('id').ix[q[q == 0].index].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1222,)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.sum(axis=1)\n",
    "q[q==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7581.000000\n",
       "mean        2.160929\n",
       "std         1.739411\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         2.000000\n",
       "75%         3.000000\n",
       "max        13.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = trainingY.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    236286.000000\n",
       "mean          1.392787\n",
       "std           0.762577\n",
       "min           1.000000\n",
       "25%           1.000000\n",
       "50%           1.000000\n",
       "75%           2.000000\n",
       "max          15.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bodyText</th>\n",
       "      <th>topics</th>\n",
       "      <th>webPublicationDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TestData_03241</th>\n",
       "      <td>A special British police unit was put on stand...</td>\n",
       "      <td>[]</td>\n",
       "      <td>15-11-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_04088</th>\n",
       "      <td>The youngest convict in a fatal gang-rape in N...</td>\n",
       "      <td>[]</td>\n",
       "      <td>20-12-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_06306</th>\n",
       "      <td>Former New York City mayor Rudy Giuliani has s...</td>\n",
       "      <td>[]</td>\n",
       "      <td>28-07-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_06083</th>\n",
       "      <td>John Cantlie, the British journalist who has b...</td>\n",
       "      <td>[]</td>\n",
       "      <td>13-07-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_05896</th>\n",
       "      <td>Lawyers for the companies that manufactured an...</td>\n",
       "      <td>[]</td>\n",
       "      <td>20-06-2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         bodyText topics  \\\n",
       "TestData_03241  A special British police unit was put on stand...     []   \n",
       "TestData_04088  The youngest convict in a fatal gang-rape in N...     []   \n",
       "TestData_06306  Former New York City mayor Rudy Giuliani has s...     []   \n",
       "TestData_06083  John Cantlie, the British journalist who has b...     []   \n",
       "TestData_05896  Lawyers for the companies that manufactured an...     []   \n",
       "\n",
       "               webPublicationDate  \n",
       "TestData_03241         15-11-2015  \n",
       "TestData_04088         20-12-2015  \n",
       "TestData_06306         28-07-2016  \n",
       "TestData_06083         13-07-2016  \n",
       "TestData_05896         20-06-2016  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ix = 'TestData_04088'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "humanrights    1.0\n",
       "india          1.0\n",
       "Name: TestData_04088, dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ukcrime    1\n",
       "Name: TestData_04088, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = top_submission.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "humanrights    1\n",
       "india          1\n",
       "protest        1\n",
       "ukcrime        1\n",
       "Name: TestData_04088, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = some_sub.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "humanrights    1\n",
       "Name: TestData_02924, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = wrong_index_lstm_sub.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Counter-terrorism policy\n",
    " \n",
    "Foreign policy\n",
    " \n",
    "Defence policy\n",
    " \n",
    "Islamic State\n",
    " \n",
    "Syria\n",
    " \n",
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = trainingY.sum()\n",
    "unseen_topics = s[s.isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activism',\n",
       " 'bastilledaytruckattack',\n",
       " 'berlinchristmasmarketattack',\n",
       " 'brusselsattacks',\n",
       " 'charliehebdoattack',\n",
       " 'francetrainattack',\n",
       " 'munichshooting',\n",
       " 'orlandoterrorattack',\n",
       " 'parisattacks',\n",
       " 'peaceandreconciliation',\n",
       " 'sanbernardinoshooting',\n",
       " 'tunisiaattack2015',\n",
       " 'turkeycoupattempt',\n",
       " 'zikavirus'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(topics).intersection(unseen_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activism\n",
      "afghanistan\n",
      "aid\n",
      "algerianhostagecrisis\n",
      "alqaida\n",
      "alshabaab\n",
      "antiwar\n",
      "arabandmiddleeastprotests\n",
      "armstrade\n",
      "australianguncontrol\n",
      "australiansecurityandcounterterrorism\n",
      "bastilledaytruckattack\n",
      "belgium\n",
      "berlinchristmasmarketattack\n",
      "bigdata\n",
      "biometrics\n",
      "bokoharam\n",
      "bostonmarathonbombing\n",
      "britisharmy\n",
      "brusselsattacks\n",
      "cameroon\n",
      "carers\n",
      "charliehebdoattack\n",
      "chemicalweapons\n",
      "clusterbombs\n",
      "cobra\n",
      "conflictanddevelopment\n",
      "controversy\n",
      "criminaljustice\n",
      "cybercrime\n",
      "cyberwar\n",
      "darknet\n",
      "dataprotection\n",
      "debate\n",
      "defence\n",
      "deflation\n",
      "drones\n",
      "drugs\n",
      "drugspolicy\n",
      "drugstrade\n",
      "earthquakes\n",
      "ebola\n",
      "economy\n",
      "egypt\n",
      "encryption\n",
      "energy\n",
      "espionage\n",
      "ethics\n",
      "europeanarrestwarrant\n",
      "europeancourtofhumanrights\n",
      "events\n",
      "extradition\n",
      "famine\n",
      "farright\n",
      "firefighters\n",
      "forensicscience\n",
      "france\n",
      "francetrainattack\n",
      "freedomofspeech\n",
      "genevaconventions\n",
      "germany\n",
      "guncrime\n",
      "hacking\n",
      "hashtags\n",
      "helicoptercrashes\n",
      "humanitarianresponse\n",
      "humanrights\n",
      "humanrightsact\n",
      "humantrafficking\n",
      "immigration\n",
      "india\n",
      "indonesia\n",
      "internallydisplacedpeople\n",
      "internationalcourtofjustice\n",
      "internationalcriminaljustice\n",
      "internetsafety\n",
      "iraq\n",
      "isis\n",
      "israel\n",
      "jordan\n",
      "jubilee\n",
      "judiciary\n",
      "july7\n",
      "justiceandsecurity\n",
      "kenya\n",
      "knifecrime\n",
      "lebanon\n",
      "libya\n",
      "localgovernment\n",
      "logistics\n",
      "london\n",
      "londonriots\n",
      "malaysia\n",
      "mali\n",
      "malware\n",
      "metropolitanpolice\n",
      "middleeastpeacetalks\n",
      "migration\n",
      "military\n",
      "ministryofdefence\n",
      "morocco\n",
      "mrsa\n",
      "mumbaiterrorattacks\n",
      "munichshooting\n",
      "naturaldisasters\n",
      "nigeria\n",
      "nuclearweapons\n",
      "occupy\n",
      "organisedcrime\n",
      "orlandoterrorattack\n",
      "osamabinladen\n",
      "paris\n",
      "parisattacks\n",
      "peaceandreconciliation\n",
      "philippines\n",
      "piracy\n",
      "planecrashes\n",
      "police\n",
      "protest\n",
      "refugees\n",
      "religion\n",
      "retirementage\n",
      "rio20earthsummit\n",
      "royalairforce\n",
      "royalnavy\n",
      "russia\n",
      "sanbernardinoshooting\n",
      "saudiarabia\n",
      "september11\n",
      "slavery\n",
      "somalia\n",
      "southafrica\n",
      "southchinasea\n",
      "stopandsearch\n",
      "surveillance\n",
      "sydneysiege\n",
      "syria\n",
      "taliban\n",
      "terrorism\n",
      "thailand\n",
      "torture\n",
      "traincrashes\n",
      "transport\n",
      "tunisiaattack2015\n",
      "turkey\n",
      "turkeycoupattempt\n",
      "ukcrime\n",
      "uksecurity\n",
      "uksupremecourt\n",
      "undercoverpoliceandpolicing\n",
      "unitednations\n",
      "usguncontrol\n",
      "values\n",
      "warcrimes\n",
      "warreporting\n",
      "weaponstechnology\n",
      "womeninbusiness\n",
      "woolwichattack\n",
      "worldmigration\n",
      "zikavirus\n"
     ]
    }
   ],
   "source": [
    "for i in topics:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsolatorio/ml-ai/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3445929"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(wvmodel['zika'], np.vstack(test_wvec.dropna())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsolatorio/ml-ai/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.38107796869050226"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(fsmodel['zika'], np.vstack(test_fvec.dropna())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              The World Health Organisation has convened an ...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           28-01-2016\n",
       "Name: TestData_04490, dtype: object"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[4488 + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              The United Nations security council has called...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           17-09-2016\n",
       "Name: TestData_06730, dtype: object"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[6727 + 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              We are deeply concerned that the counter-terro...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           02-02-2015\n",
       "Name: TestData_00360, dtype: object"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[359]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drugstrade    1.0\n",
       "Name: TestData_04490, dtype: float64"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.iloc[4488 + 1]\n",
    "q[q > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
