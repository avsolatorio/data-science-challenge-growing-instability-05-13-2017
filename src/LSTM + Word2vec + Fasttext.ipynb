{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from growing_instability_lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub = pd.read_csv('../data/sampleSubmission.csv')\n",
    "topics = sorted(set(sample_sub.columns.difference(['id'])))\n",
    "\n",
    "topic2actual = {}\n",
    "for i in sample_sub.columns:\n",
    "    if 'id' == i:\n",
    "        continue\n",
    "    topic2actual[i] = segment(i)\n",
    "    \n",
    "target_columns = sorted(topics)\n",
    "len(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.74 s, sys: 2.25 s, total: 11 s\n",
      "Wall time: 13.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wvec_trainingX = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', 'wvec_trainingX')\n",
    "fvec_trainingX = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', 'fvec_trainingX')\n",
    "word2idx_trainingX = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', 'word2idx_trainingX')\n",
    "_word2idx = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', '_word2idx')\n",
    "trainingY = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', 'trainingY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.8 s, sys: 72 ms, total: 19.9 s\n",
      "Wall time: 19.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word2ind = _word2idx.to_dict()\n",
    "\n",
    "ind2word = {i: j + 1 for i, j in word2ind.items()}  # Remove the increment if data is fixed.\n",
    "word2ind = {j: i for i, j in ind2word.items()}\n",
    "\n",
    "ind2class = dict(enumerate(topics))\n",
    "class2ind = {j: i for i, j in ind2class.items()}\n",
    "\n",
    "num_samples = trainingY.shape[0]\n",
    "\n",
    "training_X = word2idx_trainingX.head(num_samples)\n",
    "\n",
    "training_Y = pd.DataFrame(zip(*np.where(trainingY.head(num_samples) == 1)), columns=['iloc', 'topics'])\n",
    "training_WV = wvec_trainingX.head(num_samples)\n",
    "training_FS = fvec_trainingX.head(num_samples)\n",
    "\n",
    "training_Y = training_Y.groupby('iloc')['topics'].apply(list)\n",
    "training_Y.index = trainingY.head(num_samples).index\n",
    "\n",
    "# indices = sorted(training_Y.index.copy())\n",
    "indices = sorted(training_Y.index[training_Y.index.str.contains('^201[0-9]')])\n",
    "# np.random.shuffle(indices)\n",
    "indices = pd.Index(indices)\n",
    "\n",
    "training_X = training_X.ix[indices]\n",
    "training_WV = training_WV.ix[indices]\n",
    "training_FS = training_FS.ix[indices]\n",
    "training_Y = training_Y.ix[indices]\n",
    "\n",
    "dataset = zip(training_X, training_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def generate_lstm_batch_dataset(dataset, word2ind, class2ind, max_len, batch_size=1000, shuffle=True):\n",
    "#     if shuffle:\n",
    "#         np.random.shuffle(dataset)\n",
    "\n",
    "#     num_docs = len(dataset)\n",
    "#     num_words = len(word2ind) + 1\n",
    "#     num_class = len(class2ind)\n",
    "\n",
    "#     for s in xrange(0, num_docs, batch_size):\n",
    "#         x_batch = np.zeros([batch_size, max_len, num_words])\n",
    "#         y_batch = np.zeros([batch_size, num_class])\n",
    "\n",
    "#         for ix, (features, target) in enumerate(dataset[s:s + batch_size]):\n",
    "#             # print features\n",
    "#             for idx, feat in enumerate(features):\n",
    "#                 if idx >= max_len:\n",
    "#                     break\n",
    "\n",
    "#                 # print feat, ind2word[feat]\n",
    "#                 x_batch[ix, idx, feat] = 1\n",
    "\n",
    "#             if not isinstance(target, list):\n",
    "#                 target = [target]\n",
    "                \n",
    "#             for tg in target:\n",
    "#                 y_batch[ix, tg] = 1\n",
    "\n",
    "#         yield x_batch[:ix + 1, :, :], y_batch[:ix + 1, :]\n",
    "\n",
    "\n",
    "# def infinite_lstm_dataset_generator(dataset, word2ind, class2ind, max_len, batch_size=100):\n",
    "#     while 1:\n",
    "#         for b in generate_lstm_batch_dataset(dataset, word2ind, class2ind, max_len, batch_size):\n",
    "#             yield b\n",
    "\n",
    "# # lens = []\n",
    "# # for i in dataset:\n",
    "# #     lens.append(len(i[0]))\n",
    "# # pd.Series(lens).quantile(0.999)\n",
    "# # Use the above to estimate the acceptable timeseries dimension.\n",
    "# LSTM_TIMESERIES = 100\n",
    "# id_lstm_gen = infinite_lstm_dataset_generator(dataset, word2ind, class2ind, max_len=LSTM_TIMESERIES, batch_size=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wv_sc = StandardScaler()\n",
    "fs_sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "def build_target(y, size):\n",
    "    e = np.zeros(size)\n",
    "    e[y] = 1\n",
    "    return e\n",
    "\n",
    "def build_input_output_data(X, WV, FS, Y, maxlen):\n",
    "\n",
    "    x = sequence.pad_sequences(X, maxlen=maxlen)\n",
    "    y = np.vstack(Y.map(lambda x: build_target(x, len(topics))))\n",
    "    wv = np.vstack(WV)\n",
    "    fs = np.vstack(FS)\n",
    "    \n",
    "    return x, wv, fs, y\n",
    "\n",
    "\n",
    "test_ix = training_Y.index.str.contains('^201[0-4]')\n",
    "val_ix = training_Y.index.str.contains('^2014[b]')\n",
    "\n",
    "\n",
    "maxlen = 500\n",
    "\n",
    "\n",
    "x_train, wv_train, fs_train, y_train = build_input_output_data(\n",
    "    training_X.ix[test_ix],\n",
    "    training_WV.ix[test_ix],\n",
    "    training_FS.ix[test_ix],\n",
    "    training_Y.ix[test_ix],\n",
    "    maxlen=maxlen\n",
    ")\n",
    "\n",
    "\n",
    "x_val, wv_val, fs_val, y_val = build_input_output_data(\n",
    "    training_X.ix[val_ix],\n",
    "    training_WV.ix[val_ix],\n",
    "    training_FS.ix[val_ix],\n",
    "    training_Y.ix[val_ix],\n",
    "    maxlen=maxlen\n",
    ")\n",
    "\n",
    "wv_train = wv_sc.fit_transform(wv_train)\n",
    "fs_train = fs_sc.fit_transform(fs_train)\n",
    "\n",
    "wv_val = wv_sc.transform(wv_val)\n",
    "fs_val = fs_sc.transform(fs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((94731,), (9424,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_Y.shape, training_Y.ix[training_Y.index.str.contains('^2014[b]')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Setup model\n",
    "# model_lstm = keras.models.Sequential()\n",
    "# model_lstm.add(keras.layers.Embedding(len(word2ind) + 1, 256))\n",
    "# # model_lstm.add(keras.layers.LSTM(32, return_sequences=False, input_shape=(None, len(word2ind) + 1)))\n",
    "# # model_lstm.add(keras.layers.Dropout(0.2))\n",
    "# model_lstm.add(keras.layers.LSTM(16, return_sequences=False))\n",
    "# model_lstm.add(keras.layers.Dense(128))\n",
    "# model_lstm.add(keras.layers.Activation('relu'))\n",
    "# model_lstm.add(keras.layers.Dropout(0.2))\n",
    "# model_lstm.add(keras.layers.Dense(len(class2ind)))\n",
    "# model_lstm.add(keras.layers.Activation('sigmoid'))\n",
    "# model_lstm.compile(\n",
    "#     loss='binary_crossentropy',\n",
    "#     optimizer='adam',\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# # for i in range(6):\n",
    "# #     model_lstm.fit_generator(id_lstm_gen, steps_per_epoch=len(dataset), epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "# Headline input: meant to receive sequences of 100 integers, between 1 and 10000.\n",
    "# Note that we can name any layer by passing it a \"name\" argument.\n",
    "main_input = Input(shape=(maxlen,), dtype='int32', name='main_input')\n",
    "\n",
    "# This embedding layer will encode the input sequence\n",
    "# into a sequence of dense 512-dimensional vectors.\n",
    "x = Embedding(output_dim=300, input_dim=len(word2ind) + 1, input_length=maxlen)(main_input)\n",
    "\n",
    "# A LSTM will transform the vector sequence into a single vector,\n",
    "# containing information about the entire sequence\n",
    "lstm_out = LSTM(32)(x)\n",
    "\n",
    "auxiliary_output = Dense(len(class2ind), activation='sigmoid', name='aux_output')(lstm_out)\n",
    "\n",
    "\n",
    "wv_input = Input(shape=(300,), name='wv_input')\n",
    "fs_input = Input(shape=(300,), name='fs_input')\n",
    "\n",
    "x = keras.layers.concatenate([lstm_out, wv_input, fs_input])\n",
    "\n",
    "# We stack a deep densely-connected network on top\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "# And finally we add the main logistic regression layer\n",
    "main_output = Dense(len(class2ind), activation='sigmoid', name='main_output')(x)\n",
    "\n",
    "model = Model(inputs=[main_input, wv_input, fs_input], outputs=[main_output, auxiliary_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as K\n",
    "\n",
    "\n",
    "def f1_micro(y_true, y_pred):\n",
    "    TP = K.metrics.true_positives(y_true, K.round(y_pred))\n",
    "    FP = K.metrics.false_positives(y_true, K.round(y_pred))\n",
    "    FN = K.metrics.false_negatives(y_true, K.round(y_pred))\n",
    "    \n",
    "    p = K.reduce_sum(TP) / (K.reduce_sum(TP) + K.reduce_sum(FP))\n",
    "    r = K.reduce_sum(TP) / (K.reduce_sum(TP) + K.reduce_sum(FN))\n",
    "    \n",
    "    return (2.0 * p * r) / (p + r)\n",
    "\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "\n",
    "    # Count positive samples.\n",
    "    c1 = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    c2 = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    c3 = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "\n",
    "    # If there are no true samples, fix the F1 score at 0.\n",
    "    if c3 == 0:\n",
    "        return 0\n",
    "\n",
    "    # How many selected items are relevant?\n",
    "    precision = c1 / c2\n",
    "\n",
    "    # How many relevant items are selected?\n",
    "    recall = c1 / c3\n",
    "\n",
    "    # Calculate f1_score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input (InputLayer)          (None, 500)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 500, 300)      105478200                                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 32)            42624                                        \n",
      "____________________________________________________________________________________________________\n",
      "wv_input (InputLayer)            (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "fs_input (InputLayer)            (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 632)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 128)           81024                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 256)           33024                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 128)           32896                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 160)           20640                                        \n",
      "____________________________________________________________________________________________________\n",
      "aux_output (Dense)               (None, 160)           5280                                         \n",
      "====================================================================================================\n",
      "Total params: 105,693,688\n",
      "Trainable params: 105,693,688\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss={'main_output': 'categorical_crossentropy', 'aux_output': 'categorical_crossentropy'},\n",
    "              loss_weights={'main_output': 1., 'aux_output': 0.2}, metrics=['accuracy', f1_micro])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.callbacks import EarlyStopping\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "# model.fit(X, y, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import keras.backend as K\n",
    "# K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.train_on_batch(\n",
    "#     {'main_input': x_train[:10], 'wv_input': np.vstack(training_WV)[:10], 'fs_input': np.vstack(training_FS)[:10]},\n",
    "#     {'main_output': y_train[:10], 'aux_output': y_train[:10]}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/1\n",
      "94731/94731 [==============================] - 101s - loss: 6.5440 - main_output_loss: 5.1776 - aux_output_loss: 6.8321 - main_output_acc: 0.2264 - main_output_f1_micro: 0.0686 - aux_output_acc: 0.0424 - aux_output_f1_micro: 0.0486 - val_loss: 4.7639 - val_main_output_loss: 3.4273 - val_aux_output_loss: 6.6827 - val_main_output_acc: 0.5110 - val_main_output_f1_micro: 0.1113 - val_aux_output_acc: 0.0780 - val_aux_output_f1_micro: 0.0606\n",
      "CPU times: user 2min 7s, sys: 10.4 s, total: 2min 17s\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# And trained it via:\n",
    "batch_size = 600\n",
    "model.fit(\n",
    "    {'main_input': x_train, 'wv_input': wv_train, 'fs_input': fs_train},\n",
    "    {'main_output': y_train, 'aux_output': y_train},\n",
    "    epochs=1, batch_size=batch_size,   # 500\n",
    "    validation_split=0.2,\n",
    "    validation_data=(\n",
    "        {'main_input': x_val, 'wv_input': wv_val, 'fs_input': fs_val},\n",
    "        {'main_output': y_val, 'aux_output': y_val}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 3.81 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_name = 'models/lstm-word2vec-fasttext_2010-2014-data_categorical-crossentropy-2014-b-val-sc_wv_fs-continued.model'\n",
    "epochs = 5\n",
    "# for i in xrange(0, 100 // epochs):\n",
    "#     hist = model.fit(\n",
    "#         {'main_input': x_train, 'wv_input': wv_train, 'fs_input': fs_train},\n",
    "#         {'main_output': y_train, 'aux_output': y_train},\n",
    "#         epochs=epochs, batch_size=batch_size,   # 500\n",
    "#         validation_split=0.2,\n",
    "#         validation_data=(\n",
    "#             {'main_input': x_val, 'wv_input': wv_val, 'fs_input': fs_val},\n",
    "#             {'main_output': y_val, 'aux_output': y_val}\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "#     model.save(model_name.format(i))\n",
    "#     print\n",
    "#     print('Done with epoch: {}'.format((i + 1) * epochs))\n",
    "#     with open('lstm-word2vec-fasttext.epoch.csv', 'a') as fl:\n",
    "#         fl.write(model_name + '\\n')\n",
    "#         fl.write('Epoch {}\\n'.format((i + 1) * epochs))\n",
    "#         fl.write('{}\\n'.format(datetime.now()))\n",
    "#         fl.write('\\n'.join(['{}: {}'.format(k, v[0]) for k, v in hist.history.items()]))\n",
    "#         fl.write('\\n\\n')\n",
    "#     print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 109s - loss: 1.4289 - main_output_loss: 1.1954 - aux_output_loss: 1.1671 - main_output_acc: 0.7844 - main_output_f1_micro: 0.9071 - aux_output_acc: 0.8001 - aux_output_f1_micro: 0.3321 - val_loss: 1.2712 - val_main_output_loss: 1.0274 - val_aux_output_loss: 1.2192 - val_main_output_acc: 0.8023 - val_main_output_f1_micro: 0.9076 - val_aux_output_acc: 0.8053 - val_aux_output_f1_micro: 0.3324\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 109s - loss: 1.4164 - main_output_loss: 1.1849 - aux_output_loss: 1.1579 - main_output_acc: 0.7872 - main_output_f1_micro: 0.9082 - aux_output_acc: 0.8011 - aux_output_f1_micro: 0.3328 - val_loss: 1.2646 - val_main_output_loss: 1.0234 - val_aux_output_loss: 1.2058 - val_main_output_acc: 0.8031 - val_main_output_f1_micro: 0.9088 - val_aux_output_acc: 0.8084 - val_aux_output_f1_micro: 0.3345\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 109s - loss: 1.4145 - main_output_loss: 1.1839 - aux_output_loss: 1.1530 - main_output_acc: 0.7860 - main_output_f1_micro: 0.9092 - aux_output_acc: 0.8010 - aux_output_f1_micro: 0.3356 - val_loss: 1.2670 - val_main_output_loss: 1.0257 - val_aux_output_loss: 1.2068 - val_main_output_acc: 0.7894 - val_main_output_f1_micro: 0.9096 - val_aux_output_acc: 0.8162 - val_aux_output_f1_micro: 0.3360\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 109s - loss: 1.4061 - main_output_loss: 1.1762 - aux_output_loss: 1.1493 - main_output_acc: 0.7849 - main_output_f1_micro: 0.9100 - aux_output_acc: 0.7999 - aux_output_f1_micro: 0.3364 - val_loss: 1.2672 - val_main_output_loss: 1.0265 - val_aux_output_loss: 1.2033 - val_main_output_acc: 0.8096 - val_main_output_f1_micro: 0.9103 - val_aux_output_acc: 0.8103 - val_aux_output_f1_micro: 0.3371\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 109s - loss: 1.4095 - main_output_loss: 1.1804 - aux_output_loss: 1.1454 - main_output_acc: 0.7898 - main_output_f1_micro: 0.9105 - aux_output_acc: 0.8015 - aux_output_f1_micro: 0.3376 - val_loss: 1.2629 - val_main_output_loss: 1.0220 - val_aux_output_loss: 1.2048 - val_main_output_acc: 0.8070 - val_main_output_f1_micro: 0.9106 - val_aux_output_acc: 0.8170 - val_aux_output_f1_micro: 0.3385\n",
      "\n",
      "Done with epoch: 505\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 109s - loss: 1.4051 - main_output_loss: 1.1764 - aux_output_loss: 1.1437 - main_output_acc: 0.7910 - main_output_f1_micro: 0.9110 - aux_output_acc: 0.7998 - aux_output_f1_micro: 0.3399 - val_loss: 1.2631 - val_main_output_loss: 1.0235 - val_aux_output_loss: 1.1981 - val_main_output_acc: 0.7962 - val_main_output_f1_micro: 0.9112 - val_aux_output_acc: 0.8157 - val_aux_output_f1_micro: 0.3408\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 109s - loss: 1.3984 - main_output_loss: 1.1700 - aux_output_loss: 1.1421 - main_output_acc: 0.7871 - main_output_f1_micro: 0.9114 - aux_output_acc: 0.7997 - aux_output_f1_micro: 0.3414 - val_loss: 1.2605 - val_main_output_loss: 1.0217 - val_aux_output_loss: 1.1938 - val_main_output_acc: 0.8058 - val_main_output_f1_micro: 0.9117 - val_aux_output_acc: 0.8122 - val_aux_output_f1_micro: 0.3415\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 108s - loss: 1.3987 - main_output_loss: 1.1715 - aux_output_loss: 1.1357 - main_output_acc: 0.7873 - main_output_f1_micro: 0.9119 - aux_output_acc: 0.8005 - aux_output_f1_micro: 0.3418 - val_loss: 1.2548 - val_main_output_loss: 1.0174 - val_aux_output_loss: 1.1869 - val_main_output_acc: 0.8000 - val_main_output_f1_micro: 0.9121 - val_aux_output_acc: 0.8138 - val_aux_output_f1_micro: 0.3422\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 109s - loss: 1.3960 - main_output_loss: 1.1691 - aux_output_loss: 1.1349 - main_output_acc: 0.7863 - main_output_f1_micro: 0.9123 - aux_output_acc: 0.8010 - aux_output_f1_micro: 0.3425 - val_loss: 1.2563 - val_main_output_loss: 1.0183 - val_aux_output_loss: 1.1902 - val_main_output_acc: 0.7964 - val_main_output_f1_micro: 0.9125 - val_aux_output_acc: 0.8128 - val_aux_output_f1_micro: 0.3432\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 108s - loss: 1.3964 - main_output_loss: 1.1696 - aux_output_loss: 1.1340 - main_output_acc: 0.7886 - main_output_f1_micro: 0.9127 - aux_output_acc: 0.8018 - aux_output_f1_micro: 0.3441 - val_loss: 1.2488 - val_main_output_loss: 1.0109 - val_aux_output_loss: 1.1891 - val_main_output_acc: 0.8042 - val_main_output_f1_micro: 0.9128 - val_aux_output_acc: 0.8068 - val_aux_output_f1_micro: 0.3447\n",
      "\n",
      "Done with epoch: 510\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 108s - loss: 1.3924 - main_output_loss: 1.1664 - aux_output_loss: 1.1301 - main_output_acc: 0.7880 - main_output_f1_micro: 0.9130 - aux_output_acc: 0.8023 - aux_output_f1_micro: 0.3456 - val_loss: 1.2527 - val_main_output_loss: 1.0161 - val_aux_output_loss: 1.1828 - val_main_output_acc: 0.8060 - val_main_output_f1_micro: 0.9132 - val_aux_output_acc: 0.8075 - val_aux_output_f1_micro: 0.3464\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 108s - loss: 1.3938 - main_output_loss: 1.1676 - aux_output_loss: 1.1308 - main_output_acc: 0.7891 - main_output_f1_micro: 0.9134 - aux_output_acc: 0.7998 - aux_output_f1_micro: 0.3471 - val_loss: 1.2546 - val_main_output_loss: 1.0186 - val_aux_output_loss: 1.1796 - val_main_output_acc: 0.8020 - val_main_output_f1_micro: 0.9135 - val_aux_output_acc: 0.8034 - val_aux_output_f1_micro: 0.3478\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 108s - loss: 1.3905 - main_output_loss: 1.1651 - aux_output_loss: 1.1271 - main_output_acc: 0.7882 - main_output_f1_micro: 0.9136 - aux_output_acc: 0.8007 - aux_output_f1_micro: 0.3487 - val_loss: 1.2548 - val_main_output_loss: 1.0192 - val_aux_output_loss: 1.1778 - val_main_output_acc: 0.8007 - val_main_output_f1_micro: 0.9137 - val_aux_output_acc: 0.8137 - val_aux_output_f1_micro: 0.3493\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 108s - loss: 1.3942 - main_output_loss: 1.1688 - aux_output_loss: 1.1266 - main_output_acc: 0.7871 - main_output_f1_micro: 0.9139 - aux_output_acc: 0.7994 - aux_output_f1_micro: 0.3499 - val_loss: 1.2506 - val_main_output_loss: 1.0152 - val_aux_output_loss: 1.1769 - val_main_output_acc: 0.7989 - val_main_output_f1_micro: 0.9140 - val_aux_output_acc: 0.8073 - val_aux_output_f1_micro: 0.3506\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 108s - loss: 1.3878 - main_output_loss: 1.1631 - aux_output_loss: 1.1231 - main_output_acc: 0.7864 - main_output_f1_micro: 0.9141 - aux_output_acc: 0.8004 - aux_output_f1_micro: 0.3514 - val_loss: 1.2484 - val_main_output_loss: 1.0132 - val_aux_output_loss: 1.1759 - val_main_output_acc: 0.7935 - val_main_output_f1_micro: 0.9142 - val_aux_output_acc: 0.8042 - val_aux_output_f1_micro: 0.3522\n",
      "\n",
      "Done with epoch: 515\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 108s - loss: 1.3890 - main_output_loss: 1.1646 - aux_output_loss: 1.1219 - main_output_acc: 0.7876 - main_output_f1_micro: 0.9143 - aux_output_acc: 0.7979 - aux_output_f1_micro: 0.3526 - val_loss: 1.2493 - val_main_output_loss: 1.0146 - val_aux_output_loss: 1.1731 - val_main_output_acc: 0.8025 - val_main_output_f1_micro: 0.9144 - val_aux_output_acc: 0.8126 - val_aux_output_f1_micro: 0.3530\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 108s - loss: 1.3837 - main_output_loss: 1.1599 - aux_output_loss: 1.1191 - main_output_acc: 0.7882 - main_output_f1_micro: 0.9145 - aux_output_acc: 0.8014 - aux_output_f1_micro: 0.3533 - val_loss: 1.2477 - val_main_output_loss: 1.0138 - val_aux_output_loss: 1.1694 - val_main_output_acc: 0.7996 - val_main_output_f1_micro: 0.9146 - val_aux_output_acc: 0.8061 - val_aux_output_f1_micro: 0.3538\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 108s - loss: 1.3862 - main_output_loss: 1.1625 - aux_output_loss: 1.1187 - main_output_acc: 0.7850 - main_output_f1_micro: 0.9148 - aux_output_acc: 0.8010 - aux_output_f1_micro: 0.3544 - val_loss: 1.2494 - val_main_output_loss: 1.0155 - val_aux_output_loss: 1.1695 - val_main_output_acc: 0.8110 - val_main_output_f1_micro: 0.9149 - val_aux_output_acc: 0.8181 - val_aux_output_f1_micro: 0.3550\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 108s - loss: 1.3788 - main_output_loss: 1.1558 - aux_output_loss: 1.1148 - main_output_acc: 0.7862 - main_output_f1_micro: 0.9150 - aux_output_acc: 0.8019 - aux_output_f1_micro: 0.3556 - val_loss: 1.2434 - val_main_output_loss: 1.0105 - val_aux_output_loss: 1.1645 - val_main_output_acc: 0.7984 - val_main_output_f1_micro: 0.9151 - val_aux_output_acc: 0.8069 - val_aux_output_f1_micro: 0.3563\n",
      "Epoch 5/5\n",
      "46800/94731 [=============>................] - ETA: 54s - loss: 1.3753 - main_output_loss: 1.1529 - aux_output_loss: 1.1120 - main_output_acc: 0.7851 - main_output_f1_micro: 0.9153 - aux_output_acc: 0.8031 - aux_output_f1_micro: 0.3566"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "i = 100\n",
    "batch_size = 600\n",
    "for j in xrange(i, i + (100 // epochs)):\n",
    "    hist = model.fit(\n",
    "        {'main_input': x_train, 'wv_input': wv_train, 'fs_input': fs_train},\n",
    "        {'main_output': y_train, 'aux_output': y_train},\n",
    "        epochs=epochs, batch_size=batch_size,   # 500\n",
    "        validation_split=0.2,\n",
    "        validation_data=(\n",
    "            {'main_input': x_val, 'wv_input': wv_val, 'fs_input': fs_val},\n",
    "            {'main_output': y_val, 'aux_output': y_val}\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.save(model_name.format(i))\n",
    "    print\n",
    "    print('Done with epoch: {}'.format((j + 1) * epochs))\n",
    "    with open('lstm-word2vec-fasttext.epoch.csv', 'a') as fl:\n",
    "        fl.write(model_name + '\\n')\n",
    "        fl.write('Epoch {}\\n'.format((j + 1) * epochs))\n",
    "        fl.write('{}\\n'.format(datetime.now()))\n",
    "        fl.write('\\n'.join(['{}: {}'.format(k, v[0]) for k, v in hist.history.items()]))\n",
    "        fl.write('\\n\\n')\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = keras.models.load_model(\n",
    "#     'models/lstm-word2vec-fasttext_2010-2014-data_categorical-crossentropy-2014-b-val-standard_scaled_wv_fs.model',\n",
    "#     custom_objects={'f1_micro': f1_micro}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = model.predict({'main_input': x_train[:100], 'wv_input': wv_train[:100], 'fs_input': fs_train[:100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1b91cfd650>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsAYR3AFgDSK4A8AaRHAHgDXo/wHfnFVtrN8WqAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b91d0f090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "ix = 29\n",
    "pd.Series(g[0][ix]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1b91d22350>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGQdJREFUeJzt3X2wHOdV5/Hfb+ZaCs6L49gKMZI2VwSxu8JkE3Nx4t2t\nXSoEYkNK4iVUyZAlrg2l2ipcZDehFotQLnD+oAJLWKCMiQtMgAoxsQkggljhmJCCzWJ8RRLbshG+\nOIotLbHkxG/Y2PKdOfzR3XNb45nuZ6xrdffo+6lSeaanPfO4PX105vTT53FECAAwX3pNDwAAsP4I\n7gAwhwjuADCHCO4AMIcI7gAwhwjuADCHCO4AMIcI7gAwhwjuADCHFpr64AsvvDAWFxeb+ngA6KSD\nBw8+EhGb6vZrLLgvLi5qeXm5qY8HgE6y/aWU/SjLAMAcIrgDwBwiuAPAHCK4A8AcIrgDwBwiuAPA\nHCK4A8AcIrgDHfHMcwPdevCoWBoTKQjuQEd85u9P6Mdv+YLuP/5PTQ8FHUBwBzriucFQknRyddjw\nSNAFBHegIwbDrBwzpCyDBAR3oCOKoF4EeaAKwR3oiGFejSFzRwqCO9ARgyjKMg0PBJ1AcAc6Yjik\nLIN0BHegI0aZO8EdCQjuQEcUMZ3YjhQEd6AjRmUZLqgiAcEd6IjRPHdSdyQguAMdwTx3zILgDnTE\nMLhDFekI7kBHDLiJCTMguAMdsVaWaXgg6ASCO9ARzJbBLJKCu+3LbR+2vWL7mgmvX2X7hO3P539+\nZP2HCpzdiqDOYh1IsVC3g+2+pOslfYeko5LutL0vIu4d2/X3IuLqF2GMAET7AcwmJXO/VNJKRDwQ\nEScl3Sxp14s7LADjBkyFxAxSgvtmSQ+Vnh/Nt437ftt32b7V9tZ1GR2AkSKmU5VBivW6oPrHkhYj\n4vWSbpP0W5N2sr3H9rLt5RMnTqzTRwNnBy6oYhYpwf2YpHImviXfNhIRX4mIZ/Onvy7pWya9UUTc\nGBFLEbG0adOmFzJe4Kw1oOaOGaQE9zslbbe9zfYGSbsl7SvvYPui0tOdku5bvyECkMqLdRDcUa92\ntkxErNq+WtIBSX1JN0XEIdvXSVqOiH2Sfsz2Tkmrkr4q6aoXcczAWamI6TQOQ4ra4C5JEbFf0v6x\nbdeWHu+VtHd9hwagbFSWIbYjAXeoAh3BSkyYBcEd6IjizlRmyyAFwR3oiNFiHQR3JCC4Ax0xavlL\nWQYJCO5AR9DyF7MguAMdwUpMmAXBHegIau6YBcEd6AgWyMYsCO5ARwxoHIYZENyBjqDlL2ZBcAc6\ngpWYMAuCO9ARrMSEWRDcgY4oYjqzZZCC4A50xJCpkJgBwR3oiLWVmBoeCDqB4A50BC1/MQuCO9AR\nQfsBzIDgDnQENzFhFgR3oCOK5fUoyyAFwR3oiCFrqGIGBHegI2j5i1kQ3IGOGLX8pSyDBAR3oCNo\n+YtZENyBjqD9AGZBcAc6Yq39QMMDQScQ3IGOoCskZkFwBzqCNVQxi6Tgbvty24dtr9i+pmK/77cd\ntpfWb4gApLUVmAjuSFEb3G33JV0v6QpJOyRdaXvHhP1eLuk9ku5Y70ECKHeFJLijXkrmfqmklYh4\nICJOSrpZ0q4J+31A0gclPbOO4wOQW+sK2fBA0AkpwX2zpIdKz4/m20ZsXyJpa0T8SdUb2d5je9n2\n8okTJ2YeLHA2G9I4DDM47QuqtnuSPiTpfXX7RsSNEbEUEUubNm063Y8Gziq0H8AsUoL7MUlbS8+3\n5NsKL5d0saS/sH1E0psl7Uu5qPqX95/QL/zZ4fTRAmcx2g9gFinB/U5J221vs71B0m5J+4oXI+Lx\niLgwIhYjYlHSX0vaGRHLdW/8Z4ce1kc+e+SFjRw4yxQxnbIMUtQG94hYlXS1pAOS7pP08Yg4ZPs6\n2ztP58MHEVz5BxKt9ZZpeCDohIWUnSJiv6T9Y9uunbLvt6V++GBAcAdSFedKkLkjQaN3qK4OCe5A\nKrpCYhaNBvfBcKjVYZCJAAlYQxWzaDxzl+hyB6QYtfzlhEGChjP37Eu6yi13QKVyQCe2I0UrMndq\niEC1cimG8wUpGg3uw1HmzpcVqDI4JXPnfEG9VmTu1BCBauV4TnBHipbU3PmyAlVOLcs0OBB0RsOZ\ne/YtpYYIVKMsg1mRuQMdEFxQxYxaUXMfDPiyAlWKgL7QM5k7krQkc6eICFQpau4LfTMBAUlaEdz5\nmQlUK/Kfc/o92g8gSSuCOzV3oFpRijmn32MNVSRpR82d4A5UouaOWbUicye4A9XKmTtlGaRoxTx3\nyjJAtSIB2rDQUwQLdqBes5n7gMwdSFGcIgs9n/IcmKbZ4B5MhQRSDEdTIbNTloQIdai5Ax0wKsv0\ni8ydcwbVWjFbhpo7UK18QVUiIUK9VtTcueMOqFZULhfI3JGIzB3ogMFY5s5lKtSh5g50QHGOjMoy\nZO6owTx3oAOKee3FVEgSItRpdg3V/Ps54DcmUGk8c+cmJtRJCu62L7d92PaK7WsmvP7fbN9t+/O2\n/8r2jrr3LH81V+nnDlRaq7n7lOfANLXB3XZf0vWSrpC0Q9KVE4L370bEN0fEGyT9nKQP1X5y6bvJ\nT0ygWrnlr8Q5g3opmfulklYi4oGIOCnpZkm7yjtExBOlpy/VqYn5RFHahZo7UG38DlUSd9RZSNhn\ns6SHSs+PSnrT+E62f1TSeyVtkPSWujctfzmZswtUe15ZhoQINdbtgmpEXB8Rr5P0E5J+atI+tvfY\nXra9/MhXvjLaTs0dqDZkKiRmlBLcj0naWnq+Jd82zc2SvmfSCxFxY0QsRcTSBRdcMNpOFgJUK06R\ntZuYOGdQLSW43ylpu+1ttjdI2i1pX3kH29tLT79b0v11b1pOPKi5A9XWpkLS8hdpamvuEbFq+2pJ\nByT1Jd0UEYdsXydpOSL2Sbra9lslPSfpUUnvqn3f0gVV5rkD1UYXVHvMlkGalAuqioj9kvaPbbu2\n9Pg9M38ymTuQbJS5L9A4DGkau0O1/NUkCwGqjVr+krkjUXPBnZuYgGRr89zJ3JGmwd4y5Zo7X1Sg\nymDsDlWCO+q0oixDzR2oVkx93DBqP9DkaNAFlGWADqAsg1m1oiyzylRIoNJgrLcMNzGhDpk70AFr\nZRla/iJNO2ru9JYBKhX5DzcxIVVzZRkydyBZcY4UNXcSd9RpRebOT0ygWnEBdQOLdSBRg8GdxTqA\nVGvtB2j5izTtKMtQcwcqrdXc86mQJESo0XhZ5py+ydyBGqPeMqM7VJscDbqg8amQG/o9Wv4CNQas\nxIQZNX4T08Zz+mTuQI3x2TKUZVCn8bLMxoUeV/6BGhEhu1RzJ3NHjcbLMgR3oN4gQj1bPed3qHLO\noEaDZZnMxoU+X1SgxmAo9W31yNyRqPnM/ZweNXegRkSo18sCvETLX9Rr/CambLYMwR2oMhjmZZn8\njCVzR53GL6huWCBzB+oMIrKyjCnLIE3jd6hmF1T5jQlUGQ5DvZ5LZRmCO6o1nrlvXGCeO1BnGFK/\nt3ZBleCOOg1eUM1r7kyFBGplUyGzAC/R8hf1Gp0K2XN2OzXBHag2LC6oZrGd9gOo1WhZZqHX00LP\nBHegxmAYWVmGmjsSNTrPvdeTej26QgJ1hiH17FFZht4yqJMU3G1fbvuw7RXb10x4/b2277V9l+3b\nbb825X3J3IE0w7GbmDhlUKc2uNvuS7pe0hWSdki60vaOsd0+J2kpIl4v6VZJP1f3vhHZz8x+z1rl\ndjug0mCYzXM3NXckSsncL5W0EhEPRMRJSTdL2lXeISI+HRFP50//WtKWujfNau4mcwcSZJm75fyi\nKmUZ1EkJ7pslPVR6fjTfNs27Jf1pyof3e1aflZiAWsO8K6SUnTfcoYo6C+v5ZrbfKWlJ0n+e8voe\nSXsk6byv+/pR5s4XFahWlGUkyTZlGdRKydyPSdpaer4l33YK22+V9H5JOyPi2UlvFBE3RsRSRCxt\nfMlG9fvZ7dRk7kC1wVCju1P7NmUZ1EoJ7ndK2m57m+0NknZL2lfewfYbJX1YWWA/nvTJkX1J+72e\nIqghAlWyCQjZ437PtPxFrdrgHhGrkq6WdEDSfZI+HhGHbF9ne2e+289LepmkW2x/3va+KW+39r7K\nvqTFmpBk78B0g1LNvWe6QqJeUs09IvZL2j+27drS47fO+sER2Tz3Po2QgFpFP3cpK88Q3FGn0d4y\n/fyCqiSt0vYXmGqY3xciZeVMkiHUabQr5ELfZO5AguFw7e5UMnekaLRx2KmZO19WYJpBxOju1Gy2\nTLPjQfs1WpZZKC0+wGwZYLrhcK0s0zPtB1Cv2a6QJnMHUpRr7r0e89xRr8GyTFFzz4ZAzR2YbhDZ\nnakS7QeQptHMvZ+3/JXI3IEqw2EovyVEPVsDThfUaLzmvjZbhitEwDSDsZo7ZRnUYbYM0AHjXSEp\nY6JOs/PcS5n7Kr8zgamGp7QfoOaOeo3foTpaE5IvKzDVqWUZgjvqNXxBtZS58zMTmGoYpZa/lGWQ\noAU1d6ZCAnWGUZot02O2DOo1V5YJUXMHEpW7QvadXbMCqjR6E1O/1xv1cydzB6YbDmNUlunRFRIJ\nGi3LnJK5M88dmGoYp3aFJLijTqNlmfI8d76swHSDCPWKZfZsUZVBncYz96KOyGwZYLrhcOwmJqI7\najR6E1N5DVVupwamG5S6Qtr80kW9xm9iov0AUG88c+cmJtRpvCxDy1+g3jBf/0DKV2IiuKNGw5k7\nLX+BFFn7geyxbQ2YXIYazbb87dPyF0iRzZYpyjJco0I9au5AB8R4y1/KMqjR+GIdPea5A7UGw1i7\niYmaOxI0GtzLC2QT3IHJIuKUrpA9s0A26rWo5s6XFZikSNL7lGUwg6Tgbvty24dtr9i+ZsLr/8n2\n39petf2O1A8vt/yl5g5MVgTyXmmBbOYfoE5tcLfdl3S9pCsk7ZB0pe0dY7s9KOkqSb87y4efukA2\nwR2YpDg3TpktQ+aOGgsJ+1wqaSUiHpAk2zdL2iXp3mKHiDiSvzZTPnHKPHf6uQMTFYG8T8tfzCCl\nLLNZ0kOl50fzbTOzvcf2su1laW22TNYrg9+ZwCTDsZp7j/YDSHBGL6hGxI0RsRQRS9JaJtK3qbkD\nUxRZeh7b8/YDDQ4InZAS3I9J2lp6viXfdtoWeqWr/3xbgYmKaY9rZRmuUaFeSnC/U9J229tsb5C0\nW9K+dfnw/Mu6QHAHphqM19x7zHNHvdrgHhGrkq6WdEDSfZI+HhGHbF9ne6ck2f5W20cl/YCkD9s+\nlPLh5cydsgwwWVFfd6krJPPcUSdltowiYr+k/WPbri09vlNZuWYmRSay0O+RuQNTFHMN+vRzxwwa\n7i2TfTyZOzDdWlkme25uYkKCxrtCSkXNnW8rMElRX1/rCinKMqjVeG8ZKfvSkrkDkw1jLLjTFRIJ\n2pG595ktA0wzGJ8K2bMism6RwDTNBnczzx2oM8rcS+0HJOa6o1o7MneCOzDVePuBUbM9MndUaEXN\nvd/rUXMHphh1hSy1/JXW+rwDkzS+zF7xTzJ3YLJJLX/L24FJGi7LMM8dqDNq+euxmjupOyq0InPv\nM88dmKrIe/JcaBTc6S+DKq24oNrvmcU6gCkGz7uJKQ/unDKo0IrgTs0dmO75KzFl2zlnUKUVwZ3V\n3IHpRv3cSysxSayjimqtqLmTuQPTDSa0/JXI3FGtJZl7j5o7MMWo5W+PzB3pWtHyl8wdmG685e/a\nbJmmRoQuaEnmbq3yTQUmel5XyOImJjJ3VGhFzZ3GYcB04/3cR5k7wR0VGg3u5QWyuUMVmGy85e9o\nnjvnDCo0FtxdetxnNXdgqvGyDO0HkKLRzL2w0CdzB6aZ1n6AUiaqNJe5ey13p+YOTDcYu4mpKMuQ\nuKNKK8oyC/RzB6Z6/kpM2XYSIlRprixTiu49k7kD0zyv5S8rMSFBOzL3PvPcgWkG+anRG2s/wCQE\nVGkwuFNzR3OiQ1nvaJ57frbS8hcpkoK77cttH7a9YvuaCa9vtP17+et32F6sf9O1h8xzX3P8yWf0\njhs+q9vufbjpocytvZ+4W993w2f17Oqg6aEkGYy1/DU1dySoDe62+5Kul3SFpB2SrrS9Y2y3d0t6\nNCK+QdIvSvpg7fuWHvd7VgQ/MyNCP/mJu7X8pUf147d8QQ8/8UzTQ5o7Bw59WR/7mwf1uQcf06/c\nvtL0cJKM19z73KGKBCmZ+6WSViLigYg4KelmSbvG9tkl6bfyx7dK+naX5zpO4LHMXZIe++fnkgY9\nr245eFSfuu+4rvr3i3p2daCf+P27OlU+aLvHnj6pn/rDe/RvL3qFvveNm3XDZ/5B9xx7vOlh1SqS\nHj9vJSa+Gy/Eo0+d1PKRr+r4k/OdPC0k7LNZ0kOl50clvWnaPhGxavtxSRdIeiRlEOedu0GSdMkH\nbtNrLzhXG/qtuLfqjHvwq0/rTdtepWvfvkOLF5yrn/7je/WWX/jM6C8/nJ4nnnlOjz51Ur951bdq\n6/nn6v+uPKJ3/sYd2vSyjU0PrVKR9BRBfcNCdn7s+e2DevUrNp6158sL8fTJgY499s+j5695xUv0\n8pekhMHuOaP/Vbb3SNojSedv3jba/oOX/iu97sKX6uCXHtXhh588azOSN2x9pd77nd+oXs/64csW\n9ejTz+n+4082Pay58rZveo0u3nyeJOnX/su36Ka/+mInvm8Xnfc1Ov/ccyRJOy56hT7wPRfryCNP\n6fiTz7K4/AzO6ff0zte8Vttf/TId+cpTuvf/P6FnOnLtpfCpxP1c97Pf9mWSfjoi3pY/3ytJEfGz\npX0O5Pv8P9sLkr4saVNUvPnS0lIsLy8nDhMAIEm2D0bEUt1+Kb/n7pS03fY22xsk7Za0b2yffZLe\nlT9+h6Q/rwrsAIAXV21ZJq+hXy3pgKS+pJsi4pDt6yQtR8Q+Sb8h6Xdsr0j6qrK/AAAADUmquUfE\nfkn7x7ZdW3r8jKQfWN+hAQBeKC6zA8AcIrgDwBwiuAPAHCK4A8AcIrgDwByqvYnpRftg+0lJhxv5\n8NlcqMQ2Cg1jnOuvK2NlnOur7eN8bURsqtupyaYKh1Pusmqa7WXGuX66Mk6pO2NlnOurK+OsQ1kG\nAOYQwR0A5lCTwf3GBj97FoxzfXVlnFJ3xso411dXxlmpsQuqAIAXD2UZAJhDjQT3ugW3m2J7q+1P\n277X9iHb78m3v8r2bbbvz/95fgvG2rf9OdufzJ9vyxcnX8kXK9/Q9BglyfYrbd9q++9s32f7spYe\nz/+R/z+/x/bHbL+kDcfU9k22j9u+p7Rt4vFz5pfz8d5l+5KGx/nz+f/3u2z/ge1Xll7bm4/zsO23\nnalxThtr6bX32Q7bF+bPGzump+uMB/fEBbebsirpfRGxQ9KbJf1oPrZrJN0eEdsl3Z4/b9p7JN1X\nev5BSb+YL1L+qLJFy9vglyT9n4j4N5L+nbIxt+p42t4s6cckLUXExcpaW+9WO47pRyRdPrZt2vG7\nQtL2/M8eSTecoTFKk8d5m6SLI+L1kv5e0l5Jys+p3ZK+Kf93fjWPC2fKR/T8scr2VknfKenB0uYm\nj+npiYgz+kfSZZIOlJ7vlbT3TI8jcax/JOk7lN1sdVG+7SJlc/SbHNcWZSf1WyR9UpKV3XSxMOkY\nNzjO8yR9Ufm1ndL2th3PYg3gVym79+OTkt7WlmMqaVHSPXXHT9KHJV05ab8mxjn22vdK+mj++JRz\nXtlaEZc1eUzzbbcqS0COSLqwDcf0dP40UZaZtOD25gbGUcn2oqQ3SrpD0tdGxD/mL31Z0tc2NKzC\n/5b0PyUVi2deIOmxiFjNn7flmG6TdELSb+YlpF+3/VK17HhGxDFJ/0tZxvaPkh6XdFDtPKbS9OPX\n5nPrv0r60/xx68Zpe5ekYxHxhbGXWjfWVFxQncD2yyT9vqT/HhFPlF+L7K/vxqYY2X67pOMRcbCp\nMcxgQdIlkm6IiDdKekpjJZimj6ck5TXrXcr+Mvo6SS/VhJ/tbdSG41fH9vuVlTw/2vRYJrF9rqSf\nlHRt3b5d0kRwPyZpa+n5lnxbK9g+R1lg/2hEfCLf/LDti/LXL5J0vKnxSfoPknbaPiLpZmWlmV+S\n9Mp8cXKpPcf0qKSjEXFH/vxWZcG+TcdTkt4q6YsRcSIinpP0CWXHuY3HVJp+/Fp3btm+StLbJf1Q\n/heR1L5xvk7ZX+xfyM+rLZL+1vZr1L6xJmsiuKcsuN0I21a2Hux9EfGh0kvlBcDfpawW34iI2BsR\nWyJiUdmx+/OI+CFJn1a2OLnU8BgLEfFlSQ/Z/tf5pm+XdK9adDxzD0p6s+1z8+9AMc7WHdPctOO3\nT9IP5zM83izp8VL55oyzfbmy8uHOiHi69NI+Sbttb7S9TdnFyr9pYoySFBF3R8SrI2IxP6+OSrok\n//626pjOpIlCv6TvUnb1/B8kvb/pCw+lcf1HZT9x75L0+fzPdymrad8u6X5Jn5L0qqbHmo/32yR9\nMn/89cpOkBVJt0ja2PT48nG9QdJyfkz/UNL5bTyekn5G0t9JukfS70ja2IZjKuljyq4DPKcs6Lx7\n2vFTdmH9+vy8ulvZ7J8mx7mirF5dnEu/Vtr//fk4D0u6ouljOvb6Ea1dUG3smJ7uH+5QBYA5xAVV\nAJhDBHcAmEMEdwCYQwR3AJhDBHcAmEMEdwCYQwR3AJhDBHcAmEP/AvtNMzy6dhNYAAAAAElFTkSu\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b91cfaf50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(g[1][ix]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([ 1, 98]),), (array([ 1, 98]),), (array([98]),))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh = 0.5\n",
    "np.where(y_train[ix] == 1), np.where(g[0][ix] > thresh), np.where(g[1][ix] > thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wvmodel = Word2Vec.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fsmodel = fasttext.load_model('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.fasttext.model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_fasttext(tokens, stopwords=[]):\n",
    "    global fsmodel\n",
    "    # This requires fsmodel to be present in the namespace.\n",
    "    fs_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    ).map(lambda x: np.array([fsmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return fs_feature_vec\n",
    "\n",
    "\n",
    "def transform_unsupervised_sentiment_neuron(tokens, stopwords=[]):\n",
    "    # This requires fsmodel to be present in the namespace.\n",
    "    \n",
    "    usn_feature_vec = usnmodel.transform(tokens)\n",
    "\n",
    "    # usn_feature_vec = tokens.map(\n",
    "    #     lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    # ).map(lambda x: np.array([usnmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return usn_feature_vec\n",
    "\n",
    "\n",
    "def transform_word2vec(tokens, stopwords=[]):\n",
    "    global wvmodel\n",
    "    # This requires wvmodel to be present in the namespace.\n",
    "    wv_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords and w in wvmodel.wv.vocab)]\n",
    "    ).map(lambda x: np.array([wvmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return wv_feature_vec\n",
    "\n",
    "\n",
    "def parallel_generate_word_vectors(samp, transformer, stopwords, batch, num_proc):\n",
    "    with Parallel(n_jobs=num_proc) as parallel:\n",
    "        dataset = []\n",
    "        is_break = False\n",
    "        i = 0\n",
    "\n",
    "        while not is_break:\n",
    "            payload = []\n",
    "\n",
    "            for j in xrange(num_proc):\n",
    "                t_df = samp[(i + j) * batch: (i + 1 + j) * batch]\n",
    "\n",
    "                if t_df.empty:\n",
    "                    is_break = True\n",
    "                    continue\n",
    "\n",
    "                payload.append(\n",
    "                    delayed(transformer)(\n",
    "                        t_df, stopwords\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            print('Current batch in main thread: {}'.format((i + j) * batch))\n",
    "\n",
    "            if payload:\n",
    "                results = parallel(payload)\n",
    "                dataset.extend(results)\n",
    "                i += num_proc\n",
    "\n",
    "    return pd.concat(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_classes(pred, scale_param=0.75, min_thresh=0.05, thresh = 0.5):\n",
    "#     mx = pred.mean() + 3 * pred.std()\n",
    "    return np.where(pred > thresh)[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2idx_transform(word, _word2idx):\n",
    "    return _word2idx.get(word, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features_for(df, min_batch=2000, stopwords=[], num_proc=7):\n",
    "    df_tokens = transform_text(df)\n",
    "    \n",
    "    batch = min(df_tokens.shape[0] / num_proc, min_batch)\n",
    "\n",
    "    print('Computing fs features...')\n",
    "    fvec = parallel_generate_word_vectors(df_tokens, transform_fasttext, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Computing wv features...')\n",
    "    wvec = parallel_generate_word_vectors(df_tokens, transform_word2vec, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Mapping word indices...')\n",
    "    word_indices = df_tokens.map(lambda x: [word2idx_transform(i, _word2idx) for i in x.split()])\n",
    "    \n",
    "    return word_indices, wvec, fvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/TestData.json') as fl:\n",
    "    data = json.load(fl)\n",
    "    test_df = pd.DataFrame(data['TestData']).T\n",
    "    del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fs features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Computing wv features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Mapping word indices...\n",
      "CPU times: user 42.2 s, sys: 1.35 s, total: 43.6 s\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_word_indices,test_wvec, test_fvec = extract_features_for(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert(np.all(test_wvec[test_wvec.isnull()].index == test_fvec[test_fvec.isnull()].index))\n",
    "test_null_index = test_wvec[test_wvec.isnull()].index.union(test_fvec[test_fvec.isnull()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'TestData_02543', u'TestData_05012', u'TestData_05830'], dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_null_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 320 ms, sys: 8 ms, total: 328 ms\n",
      "Wall time: 325 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "maxlen = 500\n",
    "\n",
    "valid_test_index = test_word_indices.index.difference(test_null_index)\n",
    "x_test = sequence.pad_sequences(test_word_indices.ix[valid_test_index], maxlen=maxlen)\n",
    "wv_test = np.vstack(test_wvec.ix[valid_test_index])\n",
    "fs_test = np.vstack(test_fvec.ix[valid_test_index])\n",
    "\n",
    "wv_test = wv_sc.transform(wv_test)\n",
    "fs_test = fs_sc.transform(fs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "test_probas = model.predict({'main_input': x_test, 'wv_input': wv_test, 'fs_input': fs_test}, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_test_probas, aux_test_probas = test_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   1.82190677e-12,   3.68772671e-33, ...,\n",
       "          9.05655075e-28,   3.80061459e-38,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   3.34601623e-13,   2.96633003e-16, ...,\n",
       "          4.71167883e-24,   4.38951405e-28,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   1.77334140e-28,   1.67610621e-27, ...,\n",
       "          1.74565462e-21,   0.00000000e+00,   0.00000000e+00],\n",
       "       ..., \n",
       "       [  1.68597471e-20,   8.46422743e-03,   4.88739699e-01, ...,\n",
       "          5.80828940e-09,   7.10273753e-07,   1.30730112e-20],\n",
       "       [  0.00000000e+00,   1.58763978e-05,   6.77688754e-13, ...,\n",
       "          7.01947215e-16,   1.78152081e-18,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   2.07335197e-05,   5.55427141e-05, ...,\n",
       "          5.01941072e-21,   1.07501716e-18,   0.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_test_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_df.ix[test_df.index.difference(test_null_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2542, 5011, 5829]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_index = [int(s.split('_')[1]) - 1 for s in test_null_index]  # Subtract 1 since test index starts at 1 while enumerate starts at 0\n",
    "skip_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7578, 160), (7581, 3))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_test_probas.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36 ms, sys: 0 ns, total: 36 ms\n",
      "Wall time: 31 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# valid_test_feature_vec found below!\n",
    "test_values = np.zeros([main_test_probas.shape[0], len(topics)])\n",
    "for ix, pred in enumerate(main_test_probas):\n",
    "    for v in get_classes(pred, thresh=0.5):\n",
    "        test_values[ix][v] = 1\n",
    "\n",
    "test_sub_df = pd.DataFrame(\n",
    "    test_values,\n",
    "    index=test_df.ix[test_df.index.difference(test_null_index)].index,\n",
    "    columns=topics\n",
    ")\n",
    "\n",
    "null_test_df = pd.DataFrame(\n",
    "    np.zeros((len(test_null_index), len(topics))),\n",
    "    index=test_null_index,\n",
    "    columns=topics\n",
    ")\n",
    "\n",
    "test_sub_df = test_sub_df.append(null_test_df)\n",
    "test_sub_df = test_sub_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# init_test_sub_df = test_sub_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11656.0, 13075.0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_test_sub_df.sum().sum(), test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_sub_df.astype(int).reset_index().rename(\n",
    "    columns={'index': 'id'}\n",
    ").sort_values('id').to_csv(\n",
    "    'lstm_300-word2vec_300-fasttext_300-maxlen_500-dense_128_256_128-cat_cross-epoch_200-batch_size_500-val_main_output_f1_micro_0.9270-main_output_f1_micro_0.9270-main_output_loss_1.0989-data_2010_2014-val_data_2014-thresh_0.5-with_sc_wv_fs.csv', \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7581, 160)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36 ms, sys: 0 ns, total: 36 ms\n",
      "Wall time: 32.6 ms\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# adjust_index = 0\n",
    "# # valid_test_feature_vec found below!\n",
    "# test_values = np.zeros([test_df.shape[0], len(topics)])\n",
    "# for ix, pred in enumerate(main_test_probas):\n",
    "#     if ix in skip_index:\n",
    "#         test_values[ix] = np.nan\n",
    "#         # Increment adjust index so that we have the correct index for other samples\n",
    "#         adjust_index += 1\n",
    "#         continue\n",
    "\n",
    "#     for v in get_classes(pred, thresh=0.05):\n",
    "#         test_values[ix + adjust_index][v] = 1\n",
    "\n",
    "# test_sub_df = pd.DataFrame(test_values, columns=sorted(topics), index=test_df.index)\n",
    "\n",
    "# q = test_sub_df.sum(axis=1)\n",
    "# assert(len(q[q.isnull()].index.difference(test_null_index)) == 0)\n",
    "\n",
    "# test_sub_df = test_sub_df.fillna(0)\n",
    "\n",
    "# # for i in test_feature_vec[test_feature_vec.isnull()].index:\n",
    "# #     test_sub_df.ix[i] = np.zeros(len(topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestData_02543    0.0\n",
       "TestData_05012    0.0\n",
       "TestData_05830    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.ix[test_null_index].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13075.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_sub_df.astype(int).reset_index().rename(\n",
    "#     columns={'index': 'id'}\n",
    "# ).sort_values('id').to_csv(\n",
    "#     'lstm_300-word2vec_300-fasttext_300-maxlen_500-dense_64_64_64-cat_cross-epoch_210-batch_size_750-val_main_output_f1_micro_0.5760-main_output_f1_micro_0.5751-main_output_loss_0.9143-data_2010_2013-val_data_2014-thresh_0.05.csv', \n",
    "#     index=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: zikavirus, dtype: float64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = test_sub_df['zikavirus']\n",
    "e[e==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14328"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_submission = pd.read_csv('basic_nn_submission_0.649_accuracy_multi_class.csv')\n",
    "top_submission.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9280"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_index_lstm_sub = pd.read_csv('lstm.2014b_training_700_maxlen_64cell_100epochs_0.0025_threshold.csv')\n",
    "wrong_index_lstm_sub.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34952"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_sub = pd.read_csv('basic_nn_submission_full_training_data_0.9958_validation_accuracy_binary_crossentropy.csv')\n",
    "some_sub.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2197, 160)\n",
      "(3957, 160)\n",
      "(12, 160)\n",
      "(959, 160)\n"
     ]
    }
   ],
   "source": [
    "print top_submission.set_index('id')[top_submission.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print wrong_index_lstm_sub.set_index('id')[wrong_index_lstm_sub.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print some_sub.set_index('id')[some_sub.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print test_sub_df[test_sub_df.sum(axis=1) == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestData_00011     0\n",
       "TestData_00012     0\n",
       "TestData_00015     0\n",
       "TestData_00027     3\n",
       "TestData_00029     0\n",
       "TestData_00038     1\n",
       "TestData_00042     5\n",
       "TestData_00053     4\n",
       "TestData_00056     1\n",
       "TestData_00060     1\n",
       "TestData_00066     0\n",
       "TestData_00085     0\n",
       "TestData_00087     1\n",
       "TestData_00090     0\n",
       "TestData_00092     0\n",
       "TestData_00107     3\n",
       "TestData_00111     0\n",
       "TestData_00114     0\n",
       "TestData_00115     1\n",
       "TestData_00118     0\n",
       "TestData_00119     0\n",
       "TestData_00121     0\n",
       "TestData_00123     0\n",
       "TestData_00125     0\n",
       "TestData_00127     0\n",
       "TestData_00128     1\n",
       "TestData_00139     1\n",
       "TestData_00140     1\n",
       "TestData_00144     0\n",
       "TestData_00147     2\n",
       "                  ..\n",
       "TestData_07445     0\n",
       "TestData_07456     3\n",
       "TestData_07461     1\n",
       "TestData_07462     4\n",
       "TestData_07465     0\n",
       "TestData_07468     0\n",
       "TestData_07471     1\n",
       "TestData_07475     0\n",
       "TestData_07486    10\n",
       "TestData_07495     1\n",
       "TestData_07509     0\n",
       "TestData_07514     3\n",
       "TestData_07515     1\n",
       "TestData_07523     0\n",
       "TestData_07533     2\n",
       "TestData_07534     2\n",
       "TestData_07542     1\n",
       "TestData_07544     2\n",
       "TestData_07545     0\n",
       "TestData_07552     2\n",
       "TestData_07556     5\n",
       "TestData_07563     1\n",
       "TestData_07565     0\n",
       "TestData_07566     0\n",
       "TestData_07569     0\n",
       "TestData_07571     3\n",
       "TestData_07572     1\n",
       "TestData_07579     6\n",
       "TestData_07580     2\n",
       "TestData_07581     3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_submission.set_index('id').ix[q[q == 0].index].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(959,)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.sum(axis=1)\n",
    "q[q==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7581.000000\n",
       "mean        1.724707\n",
       "std         1.204568\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         2.000000\n",
       "75%         2.000000\n",
       "max        10.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = trainingY.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    236286.000000\n",
       "mean          1.392787\n",
       "std           0.762577\n",
       "min           1.000000\n",
       "25%           1.000000\n",
       "50%           1.000000\n",
       "75%           2.000000\n",
       "max          15.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bodyText</th>\n",
       "      <th>topics</th>\n",
       "      <th>webPublicationDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TestData_03241</th>\n",
       "      <td>A special British police unit was put on stand...</td>\n",
       "      <td>[]</td>\n",
       "      <td>15-11-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_04088</th>\n",
       "      <td>The youngest convict in a fatal gang-rape in N...</td>\n",
       "      <td>[]</td>\n",
       "      <td>20-12-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_06306</th>\n",
       "      <td>Former New York City mayor Rudy Giuliani has s...</td>\n",
       "      <td>[]</td>\n",
       "      <td>28-07-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_06083</th>\n",
       "      <td>John Cantlie, the British journalist who has b...</td>\n",
       "      <td>[]</td>\n",
       "      <td>13-07-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_05896</th>\n",
       "      <td>Lawyers for the companies that manufactured an...</td>\n",
       "      <td>[]</td>\n",
       "      <td>20-06-2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         bodyText topics  \\\n",
       "TestData_03241  A special British police unit was put on stand...     []   \n",
       "TestData_04088  The youngest convict in a fatal gang-rape in N...     []   \n",
       "TestData_06306  Former New York City mayor Rudy Giuliani has s...     []   \n",
       "TestData_06083  John Cantlie, the British journalist who has b...     []   \n",
       "TestData_05896  Lawyers for the companies that manufactured an...     []   \n",
       "\n",
       "               webPublicationDate  \n",
       "TestData_03241         15-11-2015  \n",
       "TestData_04088         20-12-2015  \n",
       "TestData_06306         28-07-2016  \n",
       "TestData_06083         13-07-2016  \n",
       "TestData_05896         20-06-2016  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ix = 'TestData_03241'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "london        1.0\n",
       "police        1.0\n",
       "terrorism     1.0\n",
       "uksecurity    1.0\n",
       "Name: TestData_03241, dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "london                1\n",
       "metropolitanpolice    1\n",
       "police                1\n",
       "uksecurity            1\n",
       "Name: TestData_03241, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = top_submission.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "immigration           1\n",
       "july7                 1\n",
       "london                1\n",
       "metropolitanpolice    1\n",
       "police                1\n",
       "terrorism             1\n",
       "ukcrime               1\n",
       "uksecurity            1\n",
       "Name: TestData_03241, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = some_sub.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "guncrime                       1\n",
       "knifecrime                     1\n",
       "london                         1\n",
       "metropolitanpolice             1\n",
       "occupy                         1\n",
       "police                         1\n",
       "protest                        1\n",
       "ukcrime                        1\n",
       "undercoverpoliceandpolicing    1\n",
       "Name: TestData_03241, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = wrong_index_lstm_sub.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Counter-terrorism policy\n",
    " \n",
    "Foreign policy\n",
    " \n",
    "Defence policy\n",
    " \n",
    "Islamic State\n",
    " \n",
    "Syria\n",
    " \n",
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = trainingY.sum()\n",
    "unseen_topics = s[s.isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activism',\n",
       " 'bastilledaytruckattack',\n",
       " 'berlinchristmasmarketattack',\n",
       " 'brusselsattacks',\n",
       " 'charliehebdoattack',\n",
       " 'francetrainattack',\n",
       " 'munichshooting',\n",
       " 'orlandoterrorattack',\n",
       " 'parisattacks',\n",
       " 'peaceandreconciliation',\n",
       " 'sanbernardinoshooting',\n",
       " 'tunisiaattack2015',\n",
       " 'turkeycoupattempt',\n",
       " 'zikavirus'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(topics).intersection(unseen_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activism\n",
      "afghanistan\n",
      "aid\n",
      "algerianhostagecrisis\n",
      "alqaida\n",
      "alshabaab\n",
      "antiwar\n",
      "arabandmiddleeastprotests\n",
      "armstrade\n",
      "australianguncontrol\n",
      "australiansecurityandcounterterrorism\n",
      "bastilledaytruckattack\n",
      "belgium\n",
      "berlinchristmasmarketattack\n",
      "bigdata\n",
      "biometrics\n",
      "bokoharam\n",
      "bostonmarathonbombing\n",
      "britisharmy\n",
      "brusselsattacks\n",
      "cameroon\n",
      "carers\n",
      "charliehebdoattack\n",
      "chemicalweapons\n",
      "clusterbombs\n",
      "cobra\n",
      "conflictanddevelopment\n",
      "controversy\n",
      "criminaljustice\n",
      "cybercrime\n",
      "cyberwar\n",
      "darknet\n",
      "dataprotection\n",
      "debate\n",
      "defence\n",
      "deflation\n",
      "drones\n",
      "drugs\n",
      "drugspolicy\n",
      "drugstrade\n",
      "earthquakes\n",
      "ebola\n",
      "economy\n",
      "egypt\n",
      "encryption\n",
      "energy\n",
      "espionage\n",
      "ethics\n",
      "europeanarrestwarrant\n",
      "europeancourtofhumanrights\n",
      "events\n",
      "extradition\n",
      "famine\n",
      "farright\n",
      "firefighters\n",
      "forensicscience\n",
      "france\n",
      "francetrainattack\n",
      "freedomofspeech\n",
      "genevaconventions\n",
      "germany\n",
      "guncrime\n",
      "hacking\n",
      "hashtags\n",
      "helicoptercrashes\n",
      "humanitarianresponse\n",
      "humanrights\n",
      "humanrightsact\n",
      "humantrafficking\n",
      "immigration\n",
      "india\n",
      "indonesia\n",
      "internallydisplacedpeople\n",
      "internationalcourtofjustice\n",
      "internationalcriminaljustice\n",
      "internetsafety\n",
      "iraq\n",
      "isis\n",
      "israel\n",
      "jordan\n",
      "jubilee\n",
      "judiciary\n",
      "july7\n",
      "justiceandsecurity\n",
      "kenya\n",
      "knifecrime\n",
      "lebanon\n",
      "libya\n",
      "localgovernment\n",
      "logistics\n",
      "london\n",
      "londonriots\n",
      "malaysia\n",
      "mali\n",
      "malware\n",
      "metropolitanpolice\n",
      "middleeastpeacetalks\n",
      "migration\n",
      "military\n",
      "ministryofdefence\n",
      "morocco\n",
      "mrsa\n",
      "mumbaiterrorattacks\n",
      "munichshooting\n",
      "naturaldisasters\n",
      "nigeria\n",
      "nuclearweapons\n",
      "occupy\n",
      "organisedcrime\n",
      "orlandoterrorattack\n",
      "osamabinladen\n",
      "paris\n",
      "parisattacks\n",
      "peaceandreconciliation\n",
      "philippines\n",
      "piracy\n",
      "planecrashes\n",
      "police\n",
      "protest\n",
      "refugees\n",
      "religion\n",
      "retirementage\n",
      "rio20earthsummit\n",
      "royalairforce\n",
      "royalnavy\n",
      "russia\n",
      "sanbernardinoshooting\n",
      "saudiarabia\n",
      "september11\n",
      "slavery\n",
      "somalia\n",
      "southafrica\n",
      "southchinasea\n",
      "stopandsearch\n",
      "surveillance\n",
      "sydneysiege\n",
      "syria\n",
      "taliban\n",
      "terrorism\n",
      "thailand\n",
      "torture\n",
      "traincrashes\n",
      "transport\n",
      "tunisiaattack2015\n",
      "turkey\n",
      "turkeycoupattempt\n",
      "ukcrime\n",
      "uksecurity\n",
      "uksupremecourt\n",
      "undercoverpoliceandpolicing\n",
      "unitednations\n",
      "usguncontrol\n",
      "values\n",
      "warcrimes\n",
      "warreporting\n",
      "weaponstechnology\n",
      "womeninbusiness\n",
      "woolwichattack\n",
      "worldmigration\n",
      "zikavirus\n"
     ]
    }
   ],
   "source": [
    "for i in topics:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsolatorio/ml-ai/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3445929"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(wvmodel['zika'], np.vstack(test_wvec.dropna())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsolatorio/ml-ai/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.38107796869050226"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(fsmodel['zika'], np.vstack(test_fvec.dropna())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              The World Health Organisation has convened an ...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           28-01-2016\n",
       "Name: TestData_04490, dtype: object"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[4488 + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              The United Nations security council has called...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           17-09-2016\n",
       "Name: TestData_06730, dtype: object"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[6727 + 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              We are deeply concerned that the counter-terro...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           02-02-2015\n",
       "Name: TestData_00360, dtype: object"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[359]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drugstrade    1.0\n",
       "Name: TestData_04490, dtype: float64"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.iloc[4488 + 1]\n",
    "q[q > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
