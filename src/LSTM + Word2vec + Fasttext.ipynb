{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from growing_instability_lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub = pd.read_csv('../data/sampleSubmission.csv')\n",
    "topics = sorted(set(sample_sub.columns.difference(['id'])))\n",
    "\n",
    "topic2actual = {}\n",
    "for i in sample_sub.columns:\n",
    "    if 'id' == i:\n",
    "        continue\n",
    "    topic2actual[i] = segment(i)\n",
    "    \n",
    "target_columns = sorted(topics)\n",
    "len(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.9 s, sys: 3.56 s, total: 27.5 s\n",
      "Wall time: 32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# wvec_trainingX = pd.read_hdf('training_data_wv_fs_no_stopwords', 'wvec_trainingX')\n",
    "# fvec_trainingX = pd.read_hdf('training_data_wv_fs_no_stopwords', 'fvec_trainingX')\n",
    "word2idx_trainingX = pd.read_hdf('training_data_wv_fs_no_stopwords', 'word2idx_trainingX')\n",
    "# _word2idx = pd.read_hdf('training_data_wv_fs_no_stopwords', '_word2idx')\n",
    "# trainingY = pd.read_hdf('training_data_wv_fs_no_stopwords', 'trainingY_fasttext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4775"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2idx_trainingX[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1890288"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fvec_trainingX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2005a_TrainingData_50466   NaN\n",
       "1999b_TrainingData_26958   NaN\n",
       "2003a_TrainingData_47804   NaN\n",
       "1999a_TrainingData_25096   NaN\n",
       "2012a_TrainingData_55452   NaN\n",
       "2004a_TrainingData_48954   NaN\n",
       "2008a_TrainingData_65998   NaN\n",
       "2013a_TrainingData_52734   NaN\n",
       "2000b_TrainingData_35244   NaN\n",
       "2001a_TrainingData_40325   NaN\n",
       "2005b_TrainingData_49338   NaN\n",
       "2001b_TrainingData_44132   NaN\n",
       "2010b_TrainingData_55071   NaN\n",
       "2002b_TrainingData_45159   NaN\n",
       "2006a_TrainingData_52970   NaN\n",
       "2014b_TrainingData_52907   NaN\n",
       "2006b_TrainingData_54181   NaN\n",
       "2007b_TrainingData_61985   NaN\n",
       "2007a_TrainingData_60094   NaN\n",
       "2010a_TrainingData_44129   NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = trainingY.sum(axis=1)\n",
    "x[x.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ddf = df.ix[trainingY.index]\n",
    "parsed_body = transform_text(ddf)\n",
    "\n",
    "parsed_body_tokens = parsed_body.str.split(' ')\n",
    "words_per_doc = parsed_body_tokens.map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4775"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([idx2word.get(i, ' ') for i in word2idx_trainingX.head().iloc[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary = set()\n",
    "\n",
    "for b in parsed_body_tokens:\n",
    "    vocabulary.update(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {i: j for j, i in _word2idx.to_dict().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = parsed_body\n",
    "\n",
    "ind2word = {i + 1: j for i, j in enumerate(vocabulary)}\n",
    "ind2class = dict(enumerate(topics))\n",
    "\n",
    "class2ind = {j: i for i, j in ind2class.items()}\n",
    "word2ind = {j: i for i, j in ind2word.items()}\n",
    "\n",
    "trainingX = parsed_body_tokens.map(lambda x: [word2ind[i] for i in x])\n",
    "trainingY = ddf.topics.map(lambda x: [class2ind[i] for i in x if i in class2ind])\n",
    "\n",
    "dataset = zip(trainingX, trainingY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_lstm_batch_dataset(dataset, word2ind, class2ind, max_len, batch_size=1000, shuffle=True):\n",
    "    if shuffle:\n",
    "        np.random.shuffle(dataset)\n",
    "\n",
    "    num_docs = len(dataset)\n",
    "    num_words = len(word2ind) + 1\n",
    "    num_class = len(class2ind)\n",
    "\n",
    "    for s in xrange(0, num_docs, batch_size):\n",
    "        x_batch = np.zeros([batch_size, max_len, num_words])\n",
    "        y_batch = np.zeros([batch_size, num_class])\n",
    "\n",
    "        for ix, (features, target) in enumerate(dataset[s:s + batch_size]):\n",
    "            # print features\n",
    "            for idx, feat in enumerate(features):\n",
    "                if idx >= max_len:\n",
    "                    break\n",
    "\n",
    "                # print feat, ind2word[feat]\n",
    "                x_batch[ix, idx, feat] = 1\n",
    "\n",
    "            if not isinstance(target, list):\n",
    "                target = [target]\n",
    "                \n",
    "            for tg in target:\n",
    "                y_batch[ix, tg] = 1\n",
    "\n",
    "        yield x_batch[:ix + 1, :, :], y_batch[:ix + 1, :]\n",
    "\n",
    "\n",
    "def infinite_lstm_dataset_generator(dataset, word2ind, class2ind, max_len, batch_size=100):\n",
    "    while 1:\n",
    "        for b in generate_lstm_batch_dataset(dataset, word2ind, class2ind, max_len, batch_size):\n",
    "            yield b\n",
    "\n",
    "# lens = []\n",
    "# for i in dataset:\n",
    "#     lens.append(len(i[0]))\n",
    "# pd.Series(lens).quantile(0.999)\n",
    "# Use the above to estimate the acceptable timeseries dimension.\n",
    "LSTM_TIMESERIES = 100\n",
    "id_lstm_gen = infinite_lstm_dataset_generator(dataset, word2ind, class2ind, max_len=LSTM_TIMESERIES, batch_size=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83408"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)\n",
    "max(ind2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "maxlen = 700\n",
    "x_train = sequence.pad_sequences(trainingX, maxlen=maxlen)\n",
    "\n",
    "def build_target(y, size):\n",
    "    e = np.zeros(size)\n",
    "    e[y] = 1\n",
    "    return e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setup model\n",
    "model_lstm = keras.models.Sequential()\n",
    "model_lstm.add(keras.layers.Embedding(len(word2ind) + 1, 256))\n",
    "# model_lstm.add(keras.layers.LSTM(32, return_sequences=False, input_shape=(None, len(word2ind) + 1)))\n",
    "# model_lstm.add(keras.layers.Dropout(0.2))\n",
    "model_lstm.add(keras.layers.LSTM(16, return_sequences=False))\n",
    "model_lstm.add(keras.layers.Dense(128))\n",
    "model_lstm.add(keras.layers.Activation('relu'))\n",
    "model_lstm.add(keras.layers.Dropout(0.2))\n",
    "model_lstm.add(keras.layers.Dense(len(class2ind)))\n",
    "model_lstm.add(keras.layers.Activation('sigmoid'))\n",
    "model_lstm.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# for i in range(6):\n",
    "#     model_lstm.fit_generator(id_lstm_gen, steps_per_epoch=len(dataset), epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = np.vstack(trainingY.map(lambda x: build_target(x, len(topics)))).sum(axis=0) + 1\n",
    "W = 1 / w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9424/9424 [==============================] - 7s - loss: 0.6876 - acc: 0.7456     \n",
      "Epoch 2/10\n",
      "9424/9424 [==============================] - 7s - loss: 0.6455 - acc: 0.9165     \n",
      "Epoch 3/10\n",
      "9424/9424 [==============================] - 7s - loss: 0.5017 - acc: 0.9832     \n",
      "Epoch 4/10\n",
      "9424/9424 [==============================] - 7s - loss: 0.2621 - acc: 0.9904     \n",
      "Epoch 5/10\n",
      "9424/9424 [==============================] - 7s - loss: 0.0956 - acc: 0.9905     \n",
      "Epoch 6/10\n",
      "9424/9424 [==============================] - 7s - loss: 0.0556 - acc: 0.9905     \n",
      "Epoch 7/10\n",
      "9424/9424 [==============================] - 7s - loss: 0.0512 - acc: 0.9905     \n",
      "Epoch 8/10\n",
      "9424/9424 [==============================] - 7s - loss: 0.0490 - acc: 0.9905     \n",
      "Epoch 9/10\n",
      "9424/9424 [==============================] - 7s - loss: 0.0475 - acc: 0.9905     \n",
      "Epoch 10/10\n",
      "9424/9424 [==============================] - 7s - loss: 0.0469 - acc: 0.9905     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd4f13ffad0>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm.fit(\n",
    "    x_train, np.vstack(trainingY.map(lambda x: build_target(x, len(topics)))),\n",
    "    batch_size=1000,\n",
    "    epochs=10,\n",
    "#     class_weight=W\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = trainingX.iloc[7]\n",
    "tx = [sequence.pad_sequences([x[:maxlen]], maxlen=maxlen)]\n",
    "for i in np.random.randint(len(x), size=20):\n",
    "    tx.append(sequence.pad_sequences([x[i: i + maxlen]], maxlen=maxlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 41,  66,  76,  77,  78,  90, 120, 125, 136]),)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(model_lstm.predict_proba(np.vstack(tx)).mean(axis=0) > 0.045)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s     \n"
     ]
    }
   ],
   "source": [
    "train_probs = model_lstm.predict_proba(x_train[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[44043, 30574, 48019, ..., 44213, 70192, 54583],\n",
       "       [    0,     0,     0, ..., 19794,  2801,     1],\n",
       "       [65504, 58152, 32046, ..., 23253, 36643,     1],\n",
       "       ..., \n",
       "       [45154, 26871, 61827, ..., 37246,  2803,     1],\n",
       "       [    0,     0,     0, ..., 31059, 73698,     1],\n",
       "       [    0,     0,     0, ..., 32046, 17607,     1]], dtype=int32)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2014b_TrainingData_00001            [105, 66]\n",
       "2014b_TrainingData_00024                 [41]\n",
       "2014b_TrainingData_00041                [131]\n",
       "2014b_TrainingData_00054                [125]\n",
       "2014b_TrainingData_00135                 [56]\n",
       "2014b_TrainingData_00143      [1, 76, 98, 28]\n",
       "2014b_TrainingData_00173                  [2]\n",
       "2014b_TrainingData_00175        [77, 120, 76]\n",
       "2014b_TrainingData_00183                [118]\n",
       "2014b_TrainingData_00204            [90, 142]\n",
       "2014b_TrainingData_00206    [77, 136, 120, 2]\n",
       "2014b_TrainingData_00236                 [76]\n",
       "2014b_TrainingData_00240           [134, 117]\n",
       "2014b_TrainingData_00244                [142]\n",
       "2014b_TrainingData_00250                 [90]\n",
       "2014b_TrainingData_00266            [41, 105]\n",
       "2014b_TrainingData_00272                [134]\n",
       "2014b_TrainingData_00277                 [90]\n",
       "2014b_TrainingData_00278                 [70]\n",
       "2014b_TrainingData_00282                [118]\n",
       "2014b_TrainingData_00286                [120]\n",
       "2014b_TrainingData_00290                 [60]\n",
       "2014b_TrainingData_00291                [125]\n",
       "2014b_TrainingData_00320                 [71]\n",
       "2014b_TrainingData_00346                [118]\n",
       "2014b_TrainingData_00357                [118]\n",
       "2014b_TrainingData_00358            [125, 60]\n",
       "2014b_TrainingData_00360                 [60]\n",
       "2014b_TrainingData_00362                 [42]\n",
       "2014b_TrainingData_00364                  [1]\n",
       "                                  ...        \n",
       "2014b_TrainingData_00566                 [78]\n",
       "2014b_TrainingData_00569        [95, 90, 117]\n",
       "2014b_TrainingData_00570                [146]\n",
       "2014b_TrainingData_00574                [104]\n",
       "2014b_TrainingData_00578                 [90]\n",
       "2014b_TrainingData_00579                 [90]\n",
       "2014b_TrainingData_00583            [78, 153]\n",
       "2014b_TrainingData_00589                 [71]\n",
       "2014b_TrainingData_00590                 [78]\n",
       "2014b_TrainingData_00591                 [90]\n",
       "2014b_TrainingData_00596                [120]\n",
       "2014b_TrainingData_00603                [146]\n",
       "2014b_TrainingData_00605                 [56]\n",
       "2014b_TrainingData_00606                 [62]\n",
       "2014b_TrainingData_00611                  [1]\n",
       "2014b_TrainingData_00619            [78, 150]\n",
       "2014b_TrainingData_00623                [116]\n",
       "2014b_TrainingData_00627                 [78]\n",
       "2014b_TrainingData_00628                [131]\n",
       "2014b_TrainingData_00633                 [70]\n",
       "2014b_TrainingData_00636                [120]\n",
       "2014b_TrainingData_00637                 [78]\n",
       "2014b_TrainingData_00651        [78, 59, 150]\n",
       "2014b_TrainingData_00652                 [56]\n",
       "2014b_TrainingData_00653           [125, 118]\n",
       "2014b_TrainingData_00660                 [89]\n",
       "2014b_TrainingData_00666                 [60]\n",
       "2014b_TrainingData_00669                 [90]\n",
       "2014b_TrainingData_00670                 [56]\n",
       "2014b_TrainingData_00671             [87, 43]\n",
       "Name: topics, dtype: object"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingY.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0103271 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00869188 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00862108 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00884387 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00883101 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00868308 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00854737 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00878521 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.010576 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00858472 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00869002 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.0105259 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00889062 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00881112 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.0129772 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.0112118 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.0089952 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.0162712 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00849792 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00896468 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.0150186 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.0156671 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00873983 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.0134905 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00854617 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.0089775 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00888454 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00861401 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.0134501 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00886419 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00863967 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00857017 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.0087827 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.0143633 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00894468 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00882784 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00889634 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00841401 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00910249 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00873633 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00903634 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00847759 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00897631 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00885842 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00875635 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00869999 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00867802 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00869185 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00842232 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00899343 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.0161396 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00883769 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00864608 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.0086811 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00874974 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00866953 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00873297 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00871571 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.0144143 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00866794 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.0123232 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.0087299 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00853016 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00869085 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.0087339 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.0086185 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00879795 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00887987 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00846528 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00869238 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00867382 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00899716 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00878501 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00896093 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.0138611 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00848441 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00850032 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00901354 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00865778 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00914485 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00858526 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00897263 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00904431 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00896435 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00869499 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00851585 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00870012 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00868612 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00896306 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00893522 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00874179 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00868962 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.0089057 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00891745 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00859801 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00857099 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00854542 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00854598 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00854278 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n",
      "0.00874715 (array([ 76,  77,  78,  90, 120, 125, 136]),)\n"
     ]
    }
   ],
   "source": [
    "for i in train_probs:\n",
    "    print np.mean(i), np.where(i > np.mean(i) + 3 * np.std(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_classes(pred, scale_param=0.75, min_thresh=0.05):\n",
    "    mx = pred.mean() + 3 * pred.std()\n",
    "    return np.where(pred > mx)[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/TestData.json') as fl:\n",
    "    data = json.load(fl)\n",
    "    test_df = pd.DataFrame(data['TestData']).T\n",
    "    del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.69 s, sys: 200 ms, total: 4.89 s\n",
      "Wall time: 4.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_parsed_body = transform_text(test_df)\n",
    "test_parsed_body_tokens = test_parsed_body.str.split(' ')\n",
    "testX = test_parsed_body_tokens.map(lambda x: [word2ind.get(i, 0) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = sequence.pad_sequences(testX, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7581/7581 [==============================] - 25s    \n"
     ]
    }
   ],
   "source": [
    "test_probas = model_lstm.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10968"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(test_probas > 0.002)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7581, 3)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 244 ms, sys: 4 ms, total: 248 ms\n",
      "Wall time: 225 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# valid_test_feature_vec found below!\n",
    "\n",
    "test_values = np.zeros([test_df.shape[0], len(topics)])\n",
    "for ix, pred in enumerate(test_probas):\n",
    "    for v in get_classes(pred):\n",
    "        test_values[ix][v] = 1\n",
    "\n",
    "test_sub_df = pd.DataFrame(test_values, columns=sorted(topics), index=test_df.index)\n",
    "# for i in test_feature_vec[test_feature_vec.isnull()].index:\n",
    "#     test_sub_df.ix[i] = np.zeros(len(topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17838.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df[test_sub_df.sum(axis=1).isnull()]\n",
    "test_sub_df.sum(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sub_df.astype(int).reset_index().rename(columns={'index': 'id'}).sort_values('id').to_csv('lstm.2014b_training_700_maxlen_64cell_100epochs_0.0025_threshold.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
