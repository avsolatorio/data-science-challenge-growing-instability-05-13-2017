{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from growing_instability_lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub = pd.read_csv('../data/sampleSubmission.csv')\n",
    "topics = sorted(set(sample_sub.columns.difference(['id'])))\n",
    "\n",
    "topic2actual = {}\n",
    "for i in sample_sub.columns:\n",
    "    if 'id' == i:\n",
    "        continue\n",
    "    topic2actual[i] = segment(i)\n",
    "    \n",
    "target_columns = sorted(topics)\n",
    "len(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.81 s, sys: 2.42 s, total: 11.2 s\n",
      "Wall time: 13.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wvec_trainingX = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', 'wvec_trainingX')\n",
    "fvec_trainingX = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', 'fvec_trainingX')\n",
    "word2idx_trainingX = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', 'word2idx_trainingX')\n",
    "_word2idx = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', '_word2idx')\n",
    "trainingY = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', 'trainingY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 500\n",
    "\n",
    "top_tokens = Counter()\n",
    "for i in word2idx_trainingX:\n",
    "    top_tokens.update(set(i[:maxlen]))\n",
    "\n",
    "top_tokens = pd.DataFrame(top_tokens.most_common(), columns=['token', 'freq'])\n",
    "top_doc_tokens = top_tokens[top_tokens.freq > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_token2ind = {}\n",
    "for i, j in enumerate(top_doc_tokens.token):\n",
    "    top_token2ind[j] = i + 1  # Add 1 to start with 1 since 0 is special character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.8 s, sys: 204 ms, total: 26 s\n",
      "Wall time: 25.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word2ind = top_token2ind\n",
    "\n",
    "ind2class = dict(enumerate(topics))\n",
    "class2ind = {j: i for i, j in ind2class.items()}\n",
    "\n",
    "num_samples = trainingY.shape[0]\n",
    "\n",
    "training_X = word2idx_trainingX.head(num_samples)\n",
    "\n",
    "training_Y = pd.DataFrame(zip(*np.where(trainingY.head(num_samples) == 1)), columns=['iloc', 'topics'])\n",
    "training_WV = wvec_trainingX.head(num_samples)\n",
    "training_FS = fvec_trainingX.head(num_samples)\n",
    "\n",
    "training_Y = training_Y.groupby('iloc')['topics'].apply(list)\n",
    "training_Y.index = trainingY.head(num_samples).index\n",
    "\n",
    "# indices = sorted(training_Y.index.copy())\n",
    "indices = sorted(training_Y.index[training_Y.index.str.contains('^201[0-9]')])\n",
    "# np.random.shuffle(indices)\n",
    "indices = pd.Index(indices)\n",
    "\n",
    "training_X = training_X.ix[indices]\n",
    "training_WV = training_WV.ix[indices]\n",
    "training_FS = training_FS.ix[indices]\n",
    "training_Y = training_Y.ix[indices]\n",
    "\n",
    "# Transform index to top index\n",
    "training_X = training_X.map(lambda x: [top_token2ind.get(i, 0) for i in x])\n",
    "\n",
    "dataset = zip(training_X, training_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wv_sc = StandardScaler()\n",
    "fs_sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "def build_target(y, size):\n",
    "    e = np.zeros(size)\n",
    "    e[y] = 1\n",
    "    return e\n",
    "\n",
    "def build_input_output_data(X, WV, FS, Y, maxlen):\n",
    "\n",
    "    x = sequence.pad_sequences(X, maxlen=maxlen)\n",
    "    y = np.vstack(Y.map(lambda x: build_target(x, len(topics))))\n",
    "    wv = np.vstack(WV)\n",
    "    fs = np.vstack(FS)\n",
    "    \n",
    "    return x, wv, fs, y\n",
    "\n",
    "\n",
    "test_ix = training_Y.index.str.contains('^201[0-4]')\n",
    "val_ix = training_Y.index.str.contains('^2014[b]')\n",
    "\n",
    "\n",
    "x_train, wv_train, fs_train, y_train = build_input_output_data(\n",
    "    training_X.ix[test_ix],\n",
    "    training_WV.ix[test_ix],\n",
    "    training_FS.ix[test_ix],\n",
    "    training_Y.ix[test_ix],\n",
    "    maxlen=maxlen\n",
    ")\n",
    "\n",
    "\n",
    "x_val, wv_val, fs_val, y_val = build_input_output_data(\n",
    "    training_X.ix[val_ix],\n",
    "    training_WV.ix[val_ix],\n",
    "    training_FS.ix[val_ix],\n",
    "    training_Y.ix[val_ix],\n",
    "    maxlen=maxlen\n",
    ")\n",
    "\n",
    "wv_train = wv_sc.fit_transform(wv_train)\n",
    "fs_train = fs_sc.fit_transform(fs_train)\n",
    "\n",
    "wv_val = wv_sc.transform(wv_val)\n",
    "fs_val = fs_sc.transform(fs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((94731,), (9424,))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_Y.shape, training_Y.ix[training_Y.index.str.contains('^2014[b]')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Setup model\n",
    "# model_lstm = keras.models.Sequential()\n",
    "# model_lstm.add(keras.layers.Embedding(len(word2ind) + 1, 256))\n",
    "# # model_lstm.add(keras.layers.LSTM(32, return_sequences=False, input_shape=(None, len(word2ind) + 1)))\n",
    "# # model_lstm.add(keras.layers.Dropout(0.2))\n",
    "# model_lstm.add(keras.layers.LSTM(16, return_sequences=False))\n",
    "# model_lstm.add(keras.layers.Dense(128))\n",
    "# model_lstm.add(keras.layers.Activation('relu'))\n",
    "# model_lstm.add(keras.layers.Dropout(0.2))\n",
    "# model_lstm.add(keras.layers.Dense(len(class2ind)))\n",
    "# model_lstm.add(keras.layers.Activation('sigmoid'))\n",
    "# model_lstm.compile(\n",
    "#     loss='binary_crossentropy',\n",
    "#     optimizer='adam',\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# # for i in range(6):\n",
    "# #     model_lstm.fit_generator(id_lstm_gen, steps_per_epoch=len(dataset), epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "# Headline input: meant to receive sequences of 100 integers, between 1 and 10000.\n",
    "# Note that we can name any layer by passing it a \"name\" argument.\n",
    "main_input = Input(shape=(maxlen,), dtype='int32', name='main_input')\n",
    "\n",
    "# This embedding layer will encode the input sequence\n",
    "# into a sequence of dense 512-dimensional vectors.\n",
    "x = Embedding(output_dim=300, input_dim=len(word2ind) + 1, input_length=maxlen)(main_input)\n",
    "\n",
    "# A LSTM will transform the vector sequence into a single vector,\n",
    "# containing information about the entire sequence\n",
    "lstm_out = LSTM(32)(x)\n",
    "\n",
    "auxiliary_output = Dense(len(class2ind), activation='sigmoid', name='aux_output')(lstm_out)\n",
    "\n",
    "\n",
    "wv_input = Input(shape=(300,), name='wv_input')\n",
    "fs_input = Input(shape=(300,), name='fs_input')\n",
    "\n",
    "x = keras.layers.concatenate([lstm_out, wv_input, fs_input])\n",
    "\n",
    "# We stack a deep densely-connected network on top\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "# And finally we add the main logistic regression layer\n",
    "main_output = Dense(len(class2ind), activation='sigmoid', name='main_output')(x)\n",
    "\n",
    "model = Model(inputs=[main_input, wv_input, fs_input], outputs=[main_output, auxiliary_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as K\n",
    "\n",
    "\n",
    "def f1_micro(y_true, y_pred):\n",
    "    TP = K.metrics.true_positives(y_true, K.round(y_pred))\n",
    "    FP = K.metrics.false_positives(y_true, K.round(y_pred))\n",
    "    FN = K.metrics.false_negatives(y_true, K.round(y_pred))\n",
    "    \n",
    "    p = K.reduce_sum(TP) / (K.reduce_sum(TP) + K.reduce_sum(FP))\n",
    "    r = K.reduce_sum(TP) / (K.reduce_sum(TP) + K.reduce_sum(FN))\n",
    "    \n",
    "    return (2.0 * p * r) / (p + r)\n",
    "\n",
    "\n",
    "import keras.backend as KB\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "\n",
    "    # Count positive samples.\n",
    "    c1 = KB.sum(KB.round(KB.clip(y_true * y_pred, 0, 1)))\n",
    "    c2 = KB.sum(KB.round(KB.clip(y_pred, 0, 1)))\n",
    "    c3 = KB.sum(KB.round(KB.clip(y_true, 0, 1)))\n",
    "\n",
    "    # If there are no true samples, fix the F1 score at 0.\n",
    "    if c3 == 0:\n",
    "        return 0\n",
    "\n",
    "    # How many selected items are relevant?\n",
    "    precision = c1 / c2\n",
    "\n",
    "    # How many relevant items are selected?\n",
    "    recall = c1 / c3\n",
    "\n",
    "    # Calculate f1_score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "main_input (InputLayer)          (None, 500)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 500, 300)      26228100                                     \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 32)            42624                                        \n",
      "____________________________________________________________________________________________________\n",
      "wv_input (InputLayer)            (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "fs_input (InputLayer)            (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 632)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 128)           81024                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 256)           33024                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 128)           32896                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 160)           20640                                        \n",
      "____________________________________________________________________________________________________\n",
      "aux_output (Dense)               (None, 160)           5280                                         \n",
      "====================================================================================================\n",
      "Total params: 26,443,588\n",
      "Trainable params: 26,443,588\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss={'main_output': 'categorical_crossentropy', 'aux_output': 'categorical_crossentropy'},\n",
    "              loss_weights={'main_output': 1., 'aux_output': 0.2}, metrics=['accuracy', f1_micro])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.callbacks import EarlyStopping\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "# model.fit(X, y, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import keras.backend as K\n",
    "# K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.train_on_batch(\n",
    "#     {'main_input': x_train[:10], 'wv_input': np.vstack(training_WV)[:10], 'fs_input': np.vstack(training_FS)[:10]},\n",
    "#     {'main_output': y_train[:10], 'aux_output': y_train[:10]}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/1\n",
      "94731/94731 [==============================] - 51s - loss: 6.4264 - main_output_loss: 5.0689 - aux_output_loss: 6.7879 - main_output_acc: 0.2159 - main_output_f1_micro: 0.0646 - aux_output_acc: 0.0224 - aux_output_f1_micro: 0.0495 - val_loss: 4.9501 - val_main_output_loss: 3.6085 - val_aux_output_loss: 6.7080 - val_main_output_acc: 0.4873 - val_main_output_f1_micro: 0.0898 - val_aux_output_acc: 0.0226 - val_aux_output_f1_micro: 0.0564\n",
      "CPU times: user 1min 1s, sys: 5.48 s, total: 1min 7s\n",
      "Wall time: 51.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# And trained it via:\n",
    "batch_size = 1200\n",
    "model.fit(\n",
    "    {'main_input': x_train, 'wv_input': wv_train, 'fs_input': fs_train},\n",
    "    {'main_output': y_train, 'aux_output': y_train},\n",
    "    epochs=1, batch_size=batch_size,   # 500\n",
    "    validation_split=0.2,\n",
    "    validation_data=(\n",
    "        {'main_input': x_val, 'wv_input': wv_val, 'fs_input': fs_val},\n",
    "        {'main_output': y_val, 'aux_output': y_val}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 4.8078 - main_output_loss: 3.5175 - aux_output_loss: 6.4518 - main_output_acc: 0.4771 - main_output_f1_micro: 0.1114 - aux_output_acc: 0.0226 - aux_output_f1_micro: 0.0604 - val_loss: 4.4161 - val_main_output_loss: 3.0819 - val_aux_output_loss: 6.6709 - val_main_output_acc: 0.5578 - val_main_output_f1_micro: 0.1320 - val_aux_output_acc: 0.0427 - val_aux_output_f1_micro: 0.0637\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 4.4622 - main_output_loss: 3.1799 - aux_output_loss: 6.4113 - main_output_acc: 0.5187 - main_output_f1_micro: 0.1504 - aux_output_acc: 0.0562 - aux_output_f1_micro: 0.0661 - val_loss: 4.1918 - val_main_output_loss: 2.8589 - val_aux_output_loss: 6.6642 - val_main_output_acc: 0.5865 - val_main_output_f1_micro: 0.1678 - val_aux_output_acc: 0.0423 - val_aux_output_f1_micro: 0.0682\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 4.2921 - main_output_loss: 3.0142 - aux_output_loss: 6.3896 - main_output_acc: 0.5387 - main_output_f1_micro: 0.1835 - aux_output_acc: 0.0629 - aux_output_f1_micro: 0.0698 - val_loss: 4.0473 - val_main_output_loss: 2.7185 - val_aux_output_loss: 6.6437 - val_main_output_acc: 0.5935 - val_main_output_f1_micro: 0.1984 - val_aux_output_acc: 0.0585 - val_aux_output_f1_micro: 0.0714\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 4.1816 - main_output_loss: 2.9071 - aux_output_loss: 6.3722 - main_output_acc: 0.5530 - main_output_f1_micro: 0.2120 - aux_output_acc: 0.0704 - aux_output_f1_micro: 0.0727 - val_loss: 3.9736 - val_main_output_loss: 2.6488 - val_aux_output_loss: 6.6239 - val_main_output_acc: 0.6115 - val_main_output_f1_micro: 0.2250 - val_aux_output_acc: 0.0665 - val_aux_output_f1_micro: 0.0740\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 4.1058 - main_output_loss: 2.8346 - aux_output_loss: 6.3561 - main_output_acc: 0.5615 - main_output_f1_micro: 0.2367 - aux_output_acc: 0.0755 - aux_output_f1_micro: 0.0751 - val_loss: 3.9000 - val_main_output_loss: 2.5800 - val_aux_output_loss: 6.5998 - val_main_output_acc: 0.6056 - val_main_output_f1_micro: 0.2481 - val_aux_output_acc: 0.0726 - val_aux_output_f1_micro: 0.0762\n",
      "\n",
      "Done with epoch: 5\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 4.0374 - main_output_loss: 2.7697 - aux_output_loss: 6.3384 - main_output_acc: 0.5677 - main_output_f1_micro: 0.2586 - aux_output_acc: 0.0791 - aux_output_f1_micro: 0.0772 - val_loss: 3.8390 - val_main_output_loss: 2.5241 - val_aux_output_loss: 6.5743 - val_main_output_acc: 0.6108 - val_main_output_f1_micro: 0.2686 - val_aux_output_acc: 0.0741 - val_aux_output_f1_micro: 0.0781\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 3.9853 - main_output_loss: 2.7224 - aux_output_loss: 6.3144 - main_output_acc: 0.5746 - main_output_f1_micro: 0.2779 - aux_output_acc: 0.0810 - aux_output_f1_micro: 0.0790 - val_loss: 3.7775 - val_main_output_loss: 2.4719 - val_aux_output_loss: 6.5278 - val_main_output_acc: 0.6223 - val_main_output_f1_micro: 0.2869 - val_aux_output_acc: 0.0763 - val_aux_output_f1_micro: 0.0798\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 3.9232 - main_output_loss: 2.6681 - aux_output_loss: 6.2756 - main_output_acc: 0.5806 - main_output_f1_micro: 0.2953 - aux_output_acc: 0.0823 - aux_output_f1_micro: 0.0807 - val_loss: 3.7284 - val_main_output_loss: 2.4274 - val_aux_output_loss: 6.5052 - val_main_output_acc: 0.6272 - val_main_output_f1_micro: 0.3033 - val_aux_output_acc: 0.0780 - val_aux_output_f1_micro: 0.0815\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 3.8746 - main_output_loss: 2.6281 - aux_output_loss: 6.2326 - main_output_acc: 0.5856 - main_output_f1_micro: 0.3108 - aux_output_acc: 0.0826 - aux_output_f1_micro: 0.0823 - val_loss: 3.6628 - val_main_output_loss: 2.3812 - val_aux_output_loss: 6.4080 - val_main_output_acc: 0.6267 - val_main_output_f1_micro: 0.3182 - val_aux_output_acc: 0.0794 - val_aux_output_f1_micro: 0.0832\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 3.8167 - main_output_loss: 2.5887 - aux_output_loss: 6.1402 - main_output_acc: 0.5904 - main_output_f1_micro: 0.3251 - aux_output_acc: 0.0829 - aux_output_f1_micro: 0.0840 - val_loss: 3.6081 - val_main_output_loss: 2.3424 - val_aux_output_loss: 6.3283 - val_main_output_acc: 0.6348 - val_main_output_f1_micro: 0.3319 - val_aux_output_acc: 0.0794 - val_aux_output_f1_micro: 0.0849\n",
      "\n",
      "Done with epoch: 10\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 3.7645 - main_output_loss: 2.5492 - aux_output_loss: 6.0767 - main_output_acc: 0.5958 - main_output_f1_micro: 0.3383 - aux_output_acc: 0.0830 - aux_output_f1_micro: 0.0858 - val_loss: 3.5425 - val_main_output_loss: 2.2961 - val_aux_output_loss: 6.2319 - val_main_output_acc: 0.6356 - val_main_output_f1_micro: 0.3444 - val_aux_output_acc: 0.0791 - val_aux_output_f1_micro: 0.0866\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 3.7013 - main_output_loss: 2.5086 - aux_output_loss: 5.9637 - main_output_acc: 0.5999 - main_output_f1_micro: 0.3502 - aux_output_acc: 0.0856 - aux_output_f1_micro: 0.0875 - val_loss: 3.4732 - val_main_output_loss: 2.2522 - val_aux_output_loss: 6.1047 - val_main_output_acc: 0.6441 - val_main_output_f1_micro: 0.3558 - val_aux_output_acc: 0.0874 - val_aux_output_f1_micro: 0.0883\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 3.6296 - main_output_loss: 2.4643 - aux_output_loss: 5.8266 - main_output_acc: 0.6076 - main_output_f1_micro: 0.3612 - aux_output_acc: 0.1017 - aux_output_f1_micro: 0.0891 - val_loss: 3.4313 - val_main_output_loss: 2.2099 - val_aux_output_loss: 6.1072 - val_main_output_acc: 0.6538 - val_main_output_f1_micro: 0.3665 - val_aux_output_acc: 0.1002 - val_aux_output_f1_micro: 0.0898\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 3.5783 - main_output_loss: 2.4334 - aux_output_loss: 5.7246 - main_output_acc: 0.6108 - main_output_f1_micro: 0.3715 - aux_output_acc: 0.1298 - aux_output_f1_micro: 0.0904 - val_loss: 3.3294 - val_main_output_loss: 2.1656 - val_aux_output_loss: 5.8191 - val_main_output_acc: 0.6522 - val_main_output_f1_micro: 0.3765 - val_aux_output_acc: 0.1287 - val_aux_output_f1_micro: 0.0909\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 3.4890 - main_output_loss: 2.3854 - aux_output_loss: 5.5183 - main_output_acc: 0.6149 - main_output_f1_micro: 0.3811 - aux_output_acc: 0.1613 - aux_output_f1_micro: 0.0912 - val_loss: 3.2447 - val_main_output_loss: 2.1182 - val_aux_output_loss: 5.6329 - val_main_output_acc: 0.6562 - val_main_output_f1_micro: 0.3857 - val_aux_output_acc: 0.1548 - val_aux_output_f1_micro: 0.0915\n",
      "\n",
      "Done with epoch: 15\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 3.4014 - main_output_loss: 2.3373 - aux_output_loss: 5.3204 - main_output_acc: 0.6252 - main_output_f1_micro: 0.3900 - aux_output_acc: 0.1950 - aux_output_f1_micro: 0.0917 - val_loss: 3.1622 - val_main_output_loss: 2.0761 - val_aux_output_loss: 5.4306 - val_main_output_acc: 0.6698 - val_main_output_f1_micro: 0.3944 - val_aux_output_acc: 0.1781 - val_aux_output_f1_micro: 0.0919\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 3.3180 - main_output_loss: 2.3002 - aux_output_loss: 5.0893 - main_output_acc: 0.6292 - main_output_f1_micro: 0.3986 - aux_output_acc: 0.2334 - aux_output_f1_micro: 0.0920 - val_loss: 3.0776 - val_main_output_loss: 2.0372 - val_aux_output_loss: 5.2016 - val_main_output_acc: 0.6750 - val_main_output_f1_micro: 0.4028 - val_aux_output_acc: 0.2117 - val_aux_output_f1_micro: 0.0921\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 3.2272 - main_output_loss: 2.2633 - aux_output_loss: 4.8195 - main_output_acc: 0.6344 - main_output_f1_micro: 0.4067 - aux_output_acc: 0.2832 - aux_output_f1_micro: 0.0923 - val_loss: 2.9790 - val_main_output_loss: 1.9972 - val_aux_output_loss: 4.9090 - val_main_output_acc: 0.6836 - val_main_output_f1_micro: 0.4105 - val_aux_output_acc: 0.2816 - val_aux_output_f1_micro: 0.0924\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 3.1336 - main_output_loss: 2.2233 - aux_output_loss: 4.5514 - main_output_acc: 0.6409 - main_output_f1_micro: 0.4142 - aux_output_acc: 0.3370 - aux_output_f1_micro: 0.0926 - val_loss: 2.8695 - val_main_output_loss: 1.9341 - val_aux_output_loss: 4.6772 - val_main_output_acc: 0.6906 - val_main_output_f1_micro: 0.4179 - val_aux_output_acc: 0.3304 - val_aux_output_f1_micro: 0.0927\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 3.0397 - main_output_loss: 2.1772 - aux_output_loss: 4.3127 - main_output_acc: 0.6483 - main_output_f1_micro: 0.4214 - aux_output_acc: 0.3840 - aux_output_f1_micro: 0.0929 - val_loss: 2.7929 - val_main_output_loss: 1.9035 - val_aux_output_loss: 4.4468 - val_main_output_acc: 0.7043 - val_main_output_f1_micro: 0.4249 - val_aux_output_acc: 0.3764 - val_aux_output_f1_micro: 0.0930\n",
      "\n",
      "Done with epoch: 20\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.9632 - main_output_loss: 2.1417 - aux_output_loss: 4.1077 - main_output_acc: 0.6551 - main_output_f1_micro: 0.4282 - aux_output_acc: 0.4210 - aux_output_f1_micro: 0.0932 - val_loss: 2.7141 - val_main_output_loss: 1.8661 - val_aux_output_loss: 4.2399 - val_main_output_acc: 0.7020 - val_main_output_f1_micro: 0.4315 - val_aux_output_acc: 0.4219 - val_aux_output_f1_micro: 0.0933\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.8907 - main_output_loss: 2.1063 - aux_output_loss: 3.9221 - main_output_acc: 0.6594 - main_output_f1_micro: 0.4347 - aux_output_acc: 0.4526 - aux_output_f1_micro: 0.0934 - val_loss: 2.6462 - val_main_output_loss: 1.8345 - val_aux_output_loss: 4.0587 - val_main_output_acc: 0.7061 - val_main_output_f1_micro: 0.4379 - val_aux_output_acc: 0.4483 - val_aux_output_f1_micro: 0.0936\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.8249 - main_output_loss: 2.0756 - aux_output_loss: 3.7462 - main_output_acc: 0.6640 - main_output_f1_micro: 0.4410 - aux_output_acc: 0.4817 - aux_output_f1_micro: 0.0937 - val_loss: 2.5923 - val_main_output_loss: 1.8131 - val_aux_output_loss: 3.8958 - val_main_output_acc: 0.7104 - val_main_output_f1_micro: 0.4441 - val_aux_output_acc: 0.4722 - val_aux_output_f1_micro: 0.0938\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.7557 - main_output_loss: 2.0389 - aux_output_loss: 3.5838 - main_output_acc: 0.6709 - main_output_f1_micro: 0.4470 - aux_output_acc: 0.5080 - aux_output_f1_micro: 0.0939 - val_loss: 2.5182 - val_main_output_loss: 1.7681 - val_aux_output_loss: 3.7506 - val_main_output_acc: 0.7258 - val_main_output_f1_micro: 0.4499 - val_aux_output_acc: 0.5025 - val_aux_output_f1_micro: 0.0941\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.6928 - main_output_loss: 2.0047 - aux_output_loss: 3.4404 - main_output_acc: 0.6747 - main_output_f1_micro: 0.4527 - aux_output_acc: 0.5317 - aux_output_f1_micro: 0.0942 - val_loss: 2.4572 - val_main_output_loss: 1.7326 - val_aux_output_loss: 3.6227 - val_main_output_acc: 0.7298 - val_main_output_f1_micro: 0.4555 - val_aux_output_acc: 0.5204 - val_aux_output_f1_micro: 0.0943\n",
      "\n",
      "Done with epoch: 25\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.6352 - main_output_loss: 1.9727 - aux_output_loss: 3.3127 - main_output_acc: 0.6820 - main_output_f1_micro: 0.4583 - aux_output_acc: 0.5514 - aux_output_f1_micro: 0.0944 - val_loss: 2.4032 - val_main_output_loss: 1.7057 - val_aux_output_loss: 3.4873 - val_main_output_acc: 0.7298 - val_main_output_f1_micro: 0.4610 - val_aux_output_acc: 0.5401 - val_aux_output_f1_micro: 0.0945\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.5851 - main_output_loss: 1.9448 - aux_output_loss: 3.2015 - main_output_acc: 0.6847 - main_output_f1_micro: 0.4636 - aux_output_acc: 0.5676 - aux_output_f1_micro: 0.0946 - val_loss: 2.3583 - val_main_output_loss: 1.6795 - val_aux_output_loss: 3.3937 - val_main_output_acc: 0.7363 - val_main_output_f1_micro: 0.4663 - val_aux_output_acc: 0.5560 - val_aux_output_f1_micro: 0.0947\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.5321 - main_output_loss: 1.9122 - aux_output_loss: 3.0995 - main_output_acc: 0.6915 - main_output_f1_micro: 0.4689 - aux_output_acc: 0.5831 - aux_output_f1_micro: 0.0948 - val_loss: 2.3052 - val_main_output_loss: 1.6459 - val_aux_output_loss: 3.2966 - val_main_output_acc: 0.7428 - val_main_output_f1_micro: 0.4715 - val_aux_output_acc: 0.5730 - val_aux_output_f1_micro: 0.0949\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.4891 - main_output_loss: 1.8872 - aux_output_loss: 3.0095 - main_output_acc: 0.6944 - main_output_f1_micro: 0.4740 - aux_output_acc: 0.5971 - aux_output_f1_micro: 0.0950 - val_loss: 2.2571 - val_main_output_loss: 1.6170 - val_aux_output_loss: 3.2004 - val_main_output_acc: 0.7381 - val_main_output_f1_micro: 0.4765 - val_aux_output_acc: 0.5843 - val_aux_output_f1_micro: 0.0951\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.4486 - main_output_loss: 1.8637 - aux_output_loss: 2.9245 - main_output_acc: 0.6998 - main_output_f1_micro: 0.4790 - aux_output_acc: 0.6101 - aux_output_f1_micro: 0.0952 - val_loss: 2.2314 - val_main_output_loss: 1.6071 - val_aux_output_loss: 3.1214 - val_main_output_acc: 0.7472 - val_main_output_f1_micro: 0.4815 - val_aux_output_acc: 0.5977 - val_aux_output_f1_micro: 0.0952\n",
      "\n",
      "Done with epoch: 30\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.4090 - main_output_loss: 1.8395 - aux_output_loss: 2.8474 - main_output_acc: 0.7042 - main_output_f1_micro: 0.4839 - aux_output_acc: 0.6202 - aux_output_f1_micro: 0.0953 - val_loss: 2.1865 - val_main_output_loss: 1.5794 - val_aux_output_loss: 3.0354 - val_main_output_acc: 0.7522 - val_main_output_f1_micro: 0.4863 - val_aux_output_acc: 0.6125 - val_aux_output_f1_micro: 0.0954\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.3710 - main_output_loss: 1.8149 - aux_output_loss: 2.7808 - main_output_acc: 0.7082 - main_output_f1_micro: 0.4887 - aux_output_acc: 0.6304 - aux_output_f1_micro: 0.0955 - val_loss: 2.1559 - val_main_output_loss: 1.5603 - val_aux_output_loss: 2.9781 - val_main_output_acc: 0.7534 - val_main_output_f1_micro: 0.4911 - val_aux_output_acc: 0.6194 - val_aux_output_f1_micro: 0.0956\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.3382 - main_output_loss: 1.7953 - aux_output_loss: 2.7147 - main_output_acc: 0.7112 - main_output_f1_micro: 0.4934 - aux_output_acc: 0.6386 - aux_output_f1_micro: 0.0956 - val_loss: 2.1292 - val_main_output_loss: 1.5471 - val_aux_output_loss: 2.9109 - val_main_output_acc: 0.7582 - val_main_output_f1_micro: 0.4958 - val_aux_output_acc: 0.6299 - val_aux_output_f1_micro: 0.0957\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.3092 - main_output_loss: 1.7778 - aux_output_loss: 2.6570 - main_output_acc: 0.7143 - main_output_f1_micro: 0.4981 - aux_output_acc: 0.6470 - aux_output_f1_micro: 0.0958 - val_loss: 2.0928 - val_main_output_loss: 1.5228 - val_aux_output_loss: 2.8501 - val_main_output_acc: 0.7619 - val_main_output_f1_micro: 0.5004 - val_aux_output_acc: 0.6366 - val_aux_output_f1_micro: 0.0958\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94731/94731 [==============================] - 52s - loss: 2.2740 - main_output_loss: 1.7540 - aux_output_loss: 2.6000 - main_output_acc: 0.7173 - main_output_f1_micro: 0.5026 - aux_output_acc: 0.6542 - aux_output_f1_micro: 0.0959 - val_loss: 2.0584 - val_main_output_loss: 1.5023 - val_aux_output_loss: 2.7809 - val_main_output_acc: 0.7649 - val_main_output_f1_micro: 0.5049 - val_aux_output_acc: 0.6478 - val_aux_output_f1_micro: 0.0960\n",
      "\n",
      "Done with epoch: 35\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.2435 - main_output_loss: 1.7353 - aux_output_loss: 2.5413 - main_output_acc: 0.7192 - main_output_f1_micro: 0.5071 - aux_output_acc: 0.6623 - aux_output_f1_micro: 0.0960 - val_loss: 2.0364 - val_main_output_loss: 1.4907 - val_aux_output_loss: 2.7285 - val_main_output_acc: 0.7641 - val_main_output_f1_micro: 0.5093 - val_aux_output_acc: 0.6587 - val_aux_output_f1_micro: 0.0961\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.2152 - main_output_loss: 1.7164 - aux_output_loss: 2.4940 - main_output_acc: 0.7240 - main_output_f1_micro: 0.5115 - aux_output_acc: 0.6692 - aux_output_f1_micro: 0.0962 - val_loss: 1.9969 - val_main_output_loss: 1.4615 - val_aux_output_loss: 2.6771 - val_main_output_acc: 0.7678 - val_main_output_f1_micro: 0.5137 - val_aux_output_acc: 0.6640 - val_aux_output_f1_micro: 0.0962\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.1860 - main_output_loss: 1.6967 - aux_output_loss: 2.4465 - main_output_acc: 0.7276 - main_output_f1_micro: 0.5158 - aux_output_acc: 0.6748 - aux_output_f1_micro: 0.0963 - val_loss: 1.9792 - val_main_output_loss: 1.4545 - val_aux_output_loss: 2.6235 - val_main_output_acc: 0.7676 - val_main_output_f1_micro: 0.5179 - val_aux_output_acc: 0.6699 - val_aux_output_f1_micro: 0.0963\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.1625 - main_output_loss: 1.6825 - aux_output_loss: 2.4000 - main_output_acc: 0.7292 - main_output_f1_micro: 0.5200 - aux_output_acc: 0.6817 - aux_output_f1_micro: 0.0964 - val_loss: 1.9612 - val_main_output_loss: 1.4449 - val_aux_output_loss: 2.5813 - val_main_output_acc: 0.7728 - val_main_output_f1_micro: 0.5221 - val_aux_output_acc: 0.6781 - val_aux_output_f1_micro: 0.0965\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.1416 - main_output_loss: 1.6698 - aux_output_loss: 2.3590 - main_output_acc: 0.7344 - main_output_f1_micro: 0.5242 - aux_output_acc: 0.6882 - aux_output_f1_micro: 0.0965 - val_loss: 1.9458 - val_main_output_loss: 1.4367 - val_aux_output_loss: 2.5456 - val_main_output_acc: 0.7707 - val_main_output_f1_micro: 0.5263 - val_aux_output_acc: 0.6828 - val_aux_output_f1_micro: 0.0966\n",
      "\n",
      "Done with epoch: 40\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.1179 - main_output_loss: 1.6544 - aux_output_loss: 2.3173 - main_output_acc: 0.7326 - main_output_f1_micro: 0.5283 - aux_output_acc: 0.6932 - aux_output_f1_micro: 0.0966 - val_loss: 1.9196 - val_main_output_loss: 1.4191 - val_aux_output_loss: 2.5022 - val_main_output_acc: 0.7763 - val_main_output_f1_micro: 0.5303 - val_aux_output_acc: 0.6894 - val_aux_output_f1_micro: 0.0967\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.0930 - main_output_loss: 1.6370 - aux_output_loss: 2.2799 - main_output_acc: 0.7378 - main_output_f1_micro: 0.5323 - aux_output_acc: 0.6980 - aux_output_f1_micro: 0.0967 - val_loss: 1.8950 - val_main_output_loss: 1.4056 - val_aux_output_loss: 2.4471 - val_main_output_acc: 0.7743 - val_main_output_f1_micro: 0.5342 - val_aux_output_acc: 0.6932 - val_aux_output_f1_micro: 0.0968\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.0795 - main_output_loss: 1.6297 - aux_output_loss: 2.2491 - main_output_acc: 0.7386 - main_output_f1_micro: 0.5362 - aux_output_acc: 0.7012 - aux_output_f1_micro: 0.0969 - val_loss: 1.8804 - val_main_output_loss: 1.3954 - val_aux_output_loss: 2.4251 - val_main_output_acc: 0.7808 - val_main_output_f1_micro: 0.5381 - val_aux_output_acc: 0.7036 - val_aux_output_f1_micro: 0.0969\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.0547 - main_output_loss: 1.6124 - aux_output_loss: 2.2116 - main_output_acc: 0.7426 - main_output_f1_micro: 0.5400 - aux_output_acc: 0.7069 - aux_output_f1_micro: 0.0970 - val_loss: 1.8553 - val_main_output_loss: 1.3798 - val_aux_output_loss: 2.3779 - val_main_output_acc: 0.7847 - val_main_output_f1_micro: 0.5419 - val_aux_output_acc: 0.7085 - val_aux_output_f1_micro: 0.0971\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.0361 - main_output_loss: 1.6011 - aux_output_loss: 2.1753 - main_output_acc: 0.7414 - main_output_f1_micro: 0.5439 - aux_output_acc: 0.7101 - aux_output_f1_micro: 0.0971 - val_loss: 1.8457 - val_main_output_loss: 1.3763 - val_aux_output_loss: 2.3471 - val_main_output_acc: 0.7855 - val_main_output_f1_micro: 0.5458 - val_aux_output_acc: 0.7133 - val_aux_output_f1_micro: 0.0972\n",
      "\n",
      "Done with epoch: 45\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.0209 - main_output_loss: 1.5910 - aux_output_loss: 2.1494 - main_output_acc: 0.7431 - main_output_f1_micro: 0.5477 - aux_output_acc: 0.7128 - aux_output_f1_micro: 0.0973 - val_loss: 1.8257 - val_main_output_loss: 1.3615 - val_aux_output_loss: 2.3213 - val_main_output_acc: 0.7831 - val_main_output_f1_micro: 0.5495 - val_aux_output_acc: 0.7132 - val_aux_output_f1_micro: 0.0974\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 2.0024 - main_output_loss: 1.5790 - aux_output_loss: 2.1168 - main_output_acc: 0.7456 - main_output_f1_micro: 0.5514 - aux_output_acc: 0.7195 - aux_output_f1_micro: 0.0974 - val_loss: 1.8126 - val_main_output_loss: 1.3551 - val_aux_output_loss: 2.2874 - val_main_output_acc: 0.7836 - val_main_output_f1_micro: 0.5532 - val_aux_output_acc: 0.7197 - val_aux_output_f1_micro: 0.0975\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.9835 - main_output_loss: 1.5660 - aux_output_loss: 2.0876 - main_output_acc: 0.7469 - main_output_f1_micro: 0.5549 - aux_output_acc: 0.7224 - aux_output_f1_micro: 0.0975 - val_loss: 1.7947 - val_main_output_loss: 1.3436 - val_aux_output_loss: 2.2553 - val_main_output_acc: 0.7857 - val_main_output_f1_micro: 0.5567 - val_aux_output_acc: 0.7250 - val_aux_output_f1_micro: 0.0976\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.9690 - main_output_loss: 1.5571 - aux_output_loss: 2.0593 - main_output_acc: 0.7480 - main_output_f1_micro: 0.5585 - aux_output_acc: 0.7249 - aux_output_f1_micro: 0.0977 - val_loss: 1.7755 - val_main_output_loss: 1.3299 - val_aux_output_loss: 2.2276 - val_main_output_acc: 0.7906 - val_main_output_f1_micro: 0.5602 - val_aux_output_acc: 0.7255 - val_aux_output_f1_micro: 0.0977\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.9542 - main_output_loss: 1.5475 - aux_output_loss: 2.0334 - main_output_acc: 0.7484 - main_output_f1_micro: 0.5620 - aux_output_acc: 0.7295 - aux_output_f1_micro: 0.0978 - val_loss: 1.7592 - val_main_output_loss: 1.3206 - val_aux_output_loss: 2.1929 - val_main_output_acc: 0.7805 - val_main_output_f1_micro: 0.5637 - val_aux_output_acc: 0.7262 - val_aux_output_f1_micro: 0.0979\n",
      "\n",
      "Done with epoch: 50\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.9405 - main_output_loss: 1.5389 - aux_output_loss: 2.0079 - main_output_acc: 0.7488 - main_output_f1_micro: 0.5655 - aux_output_acc: 0.7327 - aux_output_f1_micro: 0.0980 - val_loss: 1.7519 - val_main_output_loss: 1.3174 - val_aux_output_loss: 2.1723 - val_main_output_acc: 0.7793 - val_main_output_f1_micro: 0.5672 - val_aux_output_acc: 0.7277 - val_aux_output_f1_micro: 0.0980\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.9278 - main_output_loss: 1.5309 - aux_output_loss: 1.9843 - main_output_acc: 0.7502 - main_output_f1_micro: 0.5689 - aux_output_acc: 0.7350 - aux_output_f1_micro: 0.0981 - val_loss: 1.7341 - val_main_output_loss: 1.3040 - val_aux_output_loss: 2.1509 - val_main_output_acc: 0.7894 - val_main_output_f1_micro: 0.5706 - val_aux_output_acc: 0.7371 - val_aux_output_f1_micro: 0.0982\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.9081 - main_output_loss: 1.5157 - aux_output_loss: 1.9617 - main_output_acc: 0.7539 - main_output_f1_micro: 0.5723 - aux_output_acc: 0.7376 - aux_output_f1_micro: 0.0983 - val_loss: 1.7195 - val_main_output_loss: 1.2941 - val_aux_output_loss: 2.1270 - val_main_output_acc: 0.7860 - val_main_output_f1_micro: 0.5740 - val_aux_output_acc: 0.7323 - val_aux_output_f1_micro: 0.0983\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.8993 - main_output_loss: 1.5117 - aux_output_loss: 1.9379 - main_output_acc: 0.7541 - main_output_f1_micro: 0.5756 - aux_output_acc: 0.7401 - aux_output_f1_micro: 0.0984 - val_loss: 1.7099 - val_main_output_loss: 1.2899 - val_aux_output_loss: 2.0999 - val_main_output_acc: 0.7842 - val_main_output_f1_micro: 0.5772 - val_aux_output_acc: 0.7344 - val_aux_output_f1_micro: 0.0985\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.8891 - main_output_loss: 1.5053 - aux_output_loss: 1.9189 - main_output_acc: 0.7547 - main_output_f1_micro: 0.5789 - aux_output_acc: 0.7423 - aux_output_f1_micro: 0.0985 - val_loss: 1.6988 - val_main_output_loss: 1.2837 - val_aux_output_loss: 2.0757 - val_main_output_acc: 0.7850 - val_main_output_f1_micro: 0.5805 - val_aux_output_acc: 0.7401 - val_aux_output_f1_micro: 0.0986\n",
      "\n",
      "Done with epoch: 55\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.8716 - main_output_loss: 1.4921 - aux_output_loss: 1.8975 - main_output_acc: 0.7567 - main_output_f1_micro: 0.5822 - aux_output_acc: 0.7453 - aux_output_f1_micro: 0.0987 - val_loss: 1.6873 - val_main_output_loss: 1.2767 - val_aux_output_loss: 2.0531 - val_main_output_acc: 0.7902 - val_main_output_f1_micro: 0.5838 - val_aux_output_acc: 0.7468 - val_aux_output_f1_micro: 0.0987\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.8576 - main_output_loss: 1.4825 - aux_output_loss: 1.8756 - main_output_acc: 0.7564 - main_output_f1_micro: 0.5854 - aux_output_acc: 0.7480 - aux_output_f1_micro: 0.0988 - val_loss: 1.6773 - val_main_output_loss: 1.2699 - val_aux_output_loss: 2.0369 - val_main_output_acc: 0.7899 - val_main_output_f1_micro: 0.5870 - val_aux_output_acc: 0.7432 - val_aux_output_f1_micro: 0.0989\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.8492 - main_output_loss: 1.4778 - aux_output_loss: 1.8572 - main_output_acc: 0.7569 - main_output_f1_micro: 0.5886 - aux_output_acc: 0.7501 - aux_output_f1_micro: 0.0990 - val_loss: 1.6676 - val_main_output_loss: 1.2652 - val_aux_output_loss: 2.0119 - val_main_output_acc: 0.7810 - val_main_output_f1_micro: 0.5902 - val_aux_output_acc: 0.7475 - val_aux_output_f1_micro: 0.0991\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.8377 - main_output_loss: 1.4699 - aux_output_loss: 1.8390 - main_output_acc: 0.7582 - main_output_f1_micro: 0.5917 - aux_output_acc: 0.7521 - aux_output_f1_micro: 0.0992 - val_loss: 1.6625 - val_main_output_loss: 1.2648 - val_aux_output_loss: 1.9885 - val_main_output_acc: 0.7893 - val_main_output_f1_micro: 0.5933 - val_aux_output_acc: 0.7524 - val_aux_output_f1_micro: 0.0992\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.8252 - main_output_loss: 1.4610 - aux_output_loss: 1.8210 - main_output_acc: 0.7569 - main_output_f1_micro: 0.5948 - aux_output_acc: 0.7540 - aux_output_f1_micro: 0.0993 - val_loss: 1.6522 - val_main_output_loss: 1.2585 - val_aux_output_loss: 1.9682 - val_main_output_acc: 0.7880 - val_main_output_f1_micro: 0.5964 - val_aux_output_acc: 0.7514 - val_aux_output_f1_micro: 0.0994\n",
      "\n",
      "Done with epoch: 60\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.8176 - main_output_loss: 1.4568 - aux_output_loss: 1.8041 - main_output_acc: 0.7609 - main_output_f1_micro: 0.5979 - aux_output_acc: 0.7560 - aux_output_f1_micro: 0.0995 - val_loss: 1.6349 - val_main_output_loss: 1.2434 - val_aux_output_loss: 1.9578 - val_main_output_acc: 0.7868 - val_main_output_f1_micro: 0.5994 - val_aux_output_acc: 0.7515 - val_aux_output_f1_micro: 0.0995\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.8042 - main_output_loss: 1.4465 - aux_output_loss: 1.7885 - main_output_acc: 0.7612 - main_output_f1_micro: 0.6009 - aux_output_acc: 0.7559 - aux_output_f1_micro: 0.0996 - val_loss: 1.6349 - val_main_output_loss: 1.2477 - val_aux_output_loss: 1.9359 - val_main_output_acc: 0.7899 - val_main_output_f1_micro: 0.6023 - val_aux_output_acc: 0.7591 - val_aux_output_f1_micro: 0.0997\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.8003 - main_output_loss: 1.4454 - aux_output_loss: 1.7743 - main_output_acc: 0.7609 - main_output_f1_micro: 0.6038 - aux_output_acc: 0.7588 - aux_output_f1_micro: 0.0998 - val_loss: 1.6183 - val_main_output_loss: 1.2343 - val_aux_output_loss: 1.9196 - val_main_output_acc: 0.7927 - val_main_output_f1_micro: 0.6053 - val_aux_output_acc: 0.7589 - val_aux_output_f1_micro: 0.0999\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.7883 - main_output_loss: 1.4369 - aux_output_loss: 1.7570 - main_output_acc: 0.7637 - main_output_f1_micro: 0.6067 - aux_output_acc: 0.7585 - aux_output_f1_micro: 0.1000 - val_loss: 1.6107 - val_main_output_loss: 1.2317 - val_aux_output_loss: 1.8950 - val_main_output_acc: 0.7973 - val_main_output_f1_micro: 0.6081 - val_aux_output_acc: 0.7625 - val_aux_output_f1_micro: 0.1000\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.7794 - main_output_loss: 1.4307 - aux_output_loss: 1.7434 - main_output_acc: 0.7635 - main_output_f1_micro: 0.6095 - aux_output_acc: 0.7609 - aux_output_f1_micro: 0.1001 - val_loss: 1.6026 - val_main_output_loss: 1.2268 - val_aux_output_loss: 1.8789 - val_main_output_acc: 0.7937 - val_main_output_f1_micro: 0.6108 - val_aux_output_acc: 0.7636 - val_aux_output_f1_micro: 0.1002\n",
      "\n",
      "Done with epoch: 65\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.7702 - main_output_loss: 1.4245 - aux_output_loss: 1.7283 - main_output_acc: 0.7635 - main_output_f1_micro: 0.6122 - aux_output_acc: 0.7615 - aux_output_f1_micro: 0.1003 - val_loss: 1.5956 - val_main_output_loss: 1.2223 - val_aux_output_loss: 1.8666 - val_main_output_acc: 0.7956 - val_main_output_f1_micro: 0.6136 - val_aux_output_acc: 0.7611 - val_aux_output_f1_micro: 0.1004\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.7587 - main_output_loss: 1.4158 - aux_output_loss: 1.7140 - main_output_acc: 0.7640 - main_output_f1_micro: 0.6150 - aux_output_acc: 0.7620 - aux_output_f1_micro: 0.1004 - val_loss: 1.5741 - val_main_output_loss: 1.2050 - val_aux_output_loss: 1.8457 - val_main_output_acc: 0.7915 - val_main_output_f1_micro: 0.6164 - val_aux_output_acc: 0.7647 - val_aux_output_f1_micro: 0.1005\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.7511 - main_output_loss: 1.4111 - aux_output_loss: 1.6997 - main_output_acc: 0.7648 - main_output_f1_micro: 0.6177 - aux_output_acc: 0.7662 - aux_output_f1_micro: 0.1006 - val_loss: 1.5765 - val_main_output_loss: 1.2098 - val_aux_output_loss: 1.8336 - val_main_output_acc: 0.7916 - val_main_output_f1_micro: 0.6191 - val_aux_output_acc: 0.7683 - val_aux_output_f1_micro: 0.1007\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94731/94731 [==============================] - 52s - loss: 1.7431 - main_output_loss: 1.4059 - aux_output_loss: 1.6863 - main_output_acc: 0.7658 - main_output_f1_micro: 0.6204 - aux_output_acc: 0.7666 - aux_output_f1_micro: 0.1008 - val_loss: 1.5676 - val_main_output_loss: 1.2041 - val_aux_output_loss: 1.8177 - val_main_output_acc: 0.7945 - val_main_output_f1_micro: 0.6217 - val_aux_output_acc: 0.7685 - val_aux_output_f1_micro: 0.1009\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.7366 - main_output_loss: 1.4013 - aux_output_loss: 1.6766 - main_output_acc: 0.7668 - main_output_f1_micro: 0.6231 - aux_output_acc: 0.7667 - aux_output_f1_micro: 0.1010 - val_loss: 1.5580 - val_main_output_loss: 1.1965 - val_aux_output_loss: 1.8072 - val_main_output_acc: 0.7924 - val_main_output_f1_micro: 0.6244 - val_aux_output_acc: 0.7707 - val_aux_output_f1_micro: 0.1011\n",
      "\n",
      "Done with epoch: 70\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.7275 - main_output_loss: 1.3951 - aux_output_loss: 1.6619 - main_output_acc: 0.7670 - main_output_f1_micro: 0.6257 - aux_output_acc: 0.7688 - aux_output_f1_micro: 0.1012 - val_loss: 1.5606 - val_main_output_loss: 1.2025 - val_aux_output_loss: 1.7904 - val_main_output_acc: 0.7938 - val_main_output_f1_micro: 0.6269 - val_aux_output_acc: 0.7703 - val_aux_output_f1_micro: 0.1013\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.7247 - main_output_loss: 1.3948 - aux_output_loss: 1.6495 - main_output_acc: 0.7662 - main_output_f1_micro: 0.6282 - aux_output_acc: 0.7708 - aux_output_f1_micro: 0.1014 - val_loss: 1.5461 - val_main_output_loss: 1.1901 - val_aux_output_loss: 1.7798 - val_main_output_acc: 0.7942 - val_main_output_f1_micro: 0.6295 - val_aux_output_acc: 0.7735 - val_aux_output_f1_micro: 0.1015\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.7114 - main_output_loss: 1.3832 - aux_output_loss: 1.6407 - main_output_acc: 0.7684 - main_output_f1_micro: 0.6307 - aux_output_acc: 0.7722 - aux_output_f1_micro: 0.1016 - val_loss: 1.5344 - val_main_output_loss: 1.1826 - val_aux_output_loss: 1.7593 - val_main_output_acc: 0.7920 - val_main_output_f1_micro: 0.6320 - val_aux_output_acc: 0.7726 - val_aux_output_f1_micro: 0.1016\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.7095 - main_output_loss: 1.3837 - aux_output_loss: 1.6288 - main_output_acc: 0.7688 - main_output_f1_micro: 0.6333 - aux_output_acc: 0.7720 - aux_output_f1_micro: 0.1018 - val_loss: 1.5307 - val_main_output_loss: 1.1813 - val_aux_output_loss: 1.7470 - val_main_output_acc: 0.7971 - val_main_output_f1_micro: 0.6345 - val_aux_output_acc: 0.7696 - val_aux_output_f1_micro: 0.1019\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.7016 - main_output_loss: 1.3783 - aux_output_loss: 1.6163 - main_output_acc: 0.7695 - main_output_f1_micro: 0.6357 - aux_output_acc: 0.7733 - aux_output_f1_micro: 0.1020 - val_loss: 1.5274 - val_main_output_loss: 1.1802 - val_aux_output_loss: 1.7362 - val_main_output_acc: 0.7972 - val_main_output_f1_micro: 0.6370 - val_aux_output_acc: 0.7731 - val_aux_output_f1_micro: 0.1020\n",
      "\n",
      "Done with epoch: 75\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6946 - main_output_loss: 1.3733 - aux_output_loss: 1.6067 - main_output_acc: 0.7685 - main_output_f1_micro: 0.6382 - aux_output_acc: 0.7746 - aux_output_f1_micro: 0.1022 - val_loss: 1.5216 - val_main_output_loss: 1.1757 - val_aux_output_loss: 1.7299 - val_main_output_acc: 0.7956 - val_main_output_f1_micro: 0.6394 - val_aux_output_acc: 0.7754 - val_aux_output_f1_micro: 0.1023\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6825 - main_output_loss: 1.3629 - aux_output_loss: 1.5980 - main_output_acc: 0.7685 - main_output_f1_micro: 0.6406 - aux_output_acc: 0.7753 - aux_output_f1_micro: 0.1024 - val_loss: 1.5173 - val_main_output_loss: 1.1745 - val_aux_output_loss: 1.7143 - val_main_output_acc: 0.8015 - val_main_output_f1_micro: 0.6417 - val_aux_output_acc: 0.7762 - val_aux_output_f1_micro: 0.1025\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6782 - main_output_loss: 1.3613 - aux_output_loss: 1.5845 - main_output_acc: 0.7705 - main_output_f1_micro: 0.6429 - aux_output_acc: 0.7754 - aux_output_f1_micro: 0.1026 - val_loss: 1.5063 - val_main_output_loss: 1.1655 - val_aux_output_loss: 1.7039 - val_main_output_acc: 0.8013 - val_main_output_f1_micro: 0.6441 - val_aux_output_acc: 0.7823 - val_aux_output_f1_micro: 0.1027\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6763 - main_output_loss: 1.3610 - aux_output_loss: 1.5764 - main_output_acc: 0.7699 - main_output_f1_micro: 0.6453 - aux_output_acc: 0.7762 - aux_output_f1_micro: 0.1028 - val_loss: 1.5047 - val_main_output_loss: 1.1661 - val_aux_output_loss: 1.6931 - val_main_output_acc: 0.7964 - val_main_output_f1_micro: 0.6464 - val_aux_output_acc: 0.7773 - val_aux_output_f1_micro: 0.1030\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6666 - main_output_loss: 1.3535 - aux_output_loss: 1.5657 - main_output_acc: 0.7701 - main_output_f1_micro: 0.6476 - aux_output_acc: 0.7776 - aux_output_f1_micro: 0.1031 - val_loss: 1.4976 - val_main_output_loss: 1.1610 - val_aux_output_loss: 1.6828 - val_main_output_acc: 0.7918 - val_main_output_f1_micro: 0.6488 - val_aux_output_acc: 0.7843 - val_aux_output_f1_micro: 0.1032\n",
      "\n",
      "Done with epoch: 80\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6643 - main_output_loss: 1.3525 - aux_output_loss: 1.5590 - main_output_acc: 0.7706 - main_output_f1_micro: 0.6499 - aux_output_acc: 0.7775 - aux_output_f1_micro: 0.1033 - val_loss: 1.4979 - val_main_output_loss: 1.1626 - val_aux_output_loss: 1.6763 - val_main_output_acc: 0.7989 - val_main_output_f1_micro: 0.6510 - val_aux_output_acc: 0.7825 - val_aux_output_f1_micro: 0.1034\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6546 - main_output_loss: 1.3453 - aux_output_loss: 1.5466 - main_output_acc: 0.7713 - main_output_f1_micro: 0.6522 - aux_output_acc: 0.7806 - aux_output_f1_micro: 0.1035 - val_loss: 1.4865 - val_main_output_loss: 1.1547 - val_aux_output_loss: 1.6587 - val_main_output_acc: 0.8044 - val_main_output_f1_micro: 0.6533 - val_aux_output_acc: 0.7847 - val_aux_output_f1_micro: 0.1036\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6478 - main_output_loss: 1.3402 - aux_output_loss: 1.5378 - main_output_acc: 0.7732 - main_output_f1_micro: 0.6544 - aux_output_acc: 0.7814 - aux_output_f1_micro: 0.1037 - val_loss: 1.4808 - val_main_output_loss: 1.1519 - val_aux_output_loss: 1.6447 - val_main_output_acc: 0.7962 - val_main_output_f1_micro: 0.6555 - val_aux_output_acc: 0.7843 - val_aux_output_f1_micro: 0.1039\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6429 - main_output_loss: 1.3371 - aux_output_loss: 1.5291 - main_output_acc: 0.7714 - main_output_f1_micro: 0.6566 - aux_output_acc: 0.7807 - aux_output_f1_micro: 0.1040 - val_loss: 1.4782 - val_main_output_loss: 1.1504 - val_aux_output_loss: 1.6392 - val_main_output_acc: 0.8039 - val_main_output_f1_micro: 0.6577 - val_aux_output_acc: 0.7822 - val_aux_output_f1_micro: 0.1041\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6415 - main_output_loss: 1.3366 - aux_output_loss: 1.5246 - main_output_acc: 0.7727 - main_output_f1_micro: 0.6588 - aux_output_acc: 0.7801 - aux_output_f1_micro: 0.1042 - val_loss: 1.4781 - val_main_output_loss: 1.1522 - val_aux_output_loss: 1.6293 - val_main_output_acc: 0.8000 - val_main_output_f1_micro: 0.6598 - val_aux_output_acc: 0.7847 - val_aux_output_f1_micro: 0.1043\n",
      "\n",
      "Done with epoch: 85\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6361 - main_output_loss: 1.3329 - aux_output_loss: 1.5162 - main_output_acc: 0.7732 - main_output_f1_micro: 0.6609 - aux_output_acc: 0.7815 - aux_output_f1_micro: 0.1045 - val_loss: 1.4749 - val_main_output_loss: 1.1498 - val_aux_output_loss: 1.6253 - val_main_output_acc: 0.7951 - val_main_output_f1_micro: 0.6620 - val_aux_output_acc: 0.7901 - val_aux_output_f1_micro: 0.1046\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6273 - main_output_loss: 1.3262 - aux_output_loss: 1.5059 - main_output_acc: 0.7701 - main_output_f1_micro: 0.6630 - aux_output_acc: 0.7810 - aux_output_f1_micro: 0.1047 - val_loss: 1.4623 - val_main_output_loss: 1.1396 - val_aux_output_loss: 1.6133 - val_main_output_acc: 0.7911 - val_main_output_f1_micro: 0.6641 - val_aux_output_acc: 0.7872 - val_aux_output_f1_micro: 0.1048\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6260 - main_output_loss: 1.3265 - aux_output_loss: 1.4972 - main_output_acc: 0.7734 - main_output_f1_micro: 0.6651 - aux_output_acc: 0.7825 - aux_output_f1_micro: 0.1049 - val_loss: 1.4612 - val_main_output_loss: 1.1416 - val_aux_output_loss: 1.5981 - val_main_output_acc: 0.7945 - val_main_output_f1_micro: 0.6661 - val_aux_output_acc: 0.7893 - val_aux_output_f1_micro: 0.1051\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6175 - main_output_loss: 1.3191 - aux_output_loss: 1.4923 - main_output_acc: 0.7735 - main_output_f1_micro: 0.6671 - aux_output_acc: 0.7836 - aux_output_f1_micro: 0.1052 - val_loss: 1.4602 - val_main_output_loss: 1.1405 - val_aux_output_loss: 1.5984 - val_main_output_acc: 0.7956 - val_main_output_f1_micro: 0.6682 - val_aux_output_acc: 0.7888 - val_aux_output_f1_micro: 0.1053\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6122 - main_output_loss: 1.3158 - aux_output_loss: 1.4818 - main_output_acc: 0.7729 - main_output_f1_micro: 0.6692 - aux_output_acc: 0.7834 - aux_output_f1_micro: 0.1054 - val_loss: 1.4512 - val_main_output_loss: 1.1332 - val_aux_output_loss: 1.5899 - val_main_output_acc: 0.8077 - val_main_output_f1_micro: 0.6702 - val_aux_output_acc: 0.7863 - val_aux_output_f1_micro: 0.1055\n",
      "\n",
      "Done with epoch: 90\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6090 - main_output_loss: 1.3138 - aux_output_loss: 1.4763 - main_output_acc: 0.7736 - main_output_f1_micro: 0.6712 - aux_output_acc: 0.7841 - aux_output_f1_micro: 0.1056 - val_loss: 1.4482 - val_main_output_loss: 1.1317 - val_aux_output_loss: 1.5827 - val_main_output_acc: 0.7983 - val_main_output_f1_micro: 0.6721 - val_aux_output_acc: 0.7894 - val_aux_output_f1_micro: 0.1058\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6044 - main_output_loss: 1.3104 - aux_output_loss: 1.4704 - main_output_acc: 0.7764 - main_output_f1_micro: 0.6731 - aux_output_acc: 0.7841 - aux_output_f1_micro: 0.1059 - val_loss: 1.4464 - val_main_output_loss: 1.1324 - val_aux_output_loss: 1.5700 - val_main_output_acc: 0.7972 - val_main_output_f1_micro: 0.6741 - val_aux_output_acc: 0.7968 - val_aux_output_f1_micro: 0.1060\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.6013 - main_output_loss: 1.3087 - aux_output_loss: 1.4631 - main_output_acc: 0.7747 - main_output_f1_micro: 0.6751 - aux_output_acc: 0.7849 - aux_output_f1_micro: 0.1062 - val_loss: 1.4389 - val_main_output_loss: 1.1256 - val_aux_output_loss: 1.5667 - val_main_output_acc: 0.7906 - val_main_output_f1_micro: 0.6760 - val_aux_output_acc: 0.7875 - val_aux_output_f1_micro: 0.1063\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.5976 - main_output_loss: 1.3064 - aux_output_loss: 1.4560 - main_output_acc: 0.7735 - main_output_f1_micro: 0.6770 - aux_output_acc: 0.7836 - aux_output_f1_micro: 0.1064 - val_loss: 1.4425 - val_main_output_loss: 1.1318 - val_aux_output_loss: 1.5533 - val_main_output_acc: 0.7932 - val_main_output_f1_micro: 0.6780 - val_aux_output_acc: 0.7900 - val_aux_output_f1_micro: 0.1065\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.5887 - main_output_loss: 1.2989 - aux_output_loss: 1.4490 - main_output_acc: 0.7739 - main_output_f1_micro: 0.6789 - aux_output_acc: 0.7864 - aux_output_f1_micro: 0.1067 - val_loss: 1.4344 - val_main_output_loss: 1.1241 - val_aux_output_loss: 1.5513 - val_main_output_acc: 0.8054 - val_main_output_f1_micro: 0.6798 - val_aux_output_acc: 0.7923 - val_aux_output_f1_micro: 0.1068\n",
      "\n",
      "Done with epoch: 95\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.5893 - main_output_loss: 1.3008 - aux_output_loss: 1.4425 - main_output_acc: 0.7756 - main_output_f1_micro: 0.6808 - aux_output_acc: 0.7853 - aux_output_f1_micro: 0.1069 - val_loss: 1.4272 - val_main_output_loss: 1.1199 - val_aux_output_loss: 1.5369 - val_main_output_acc: 0.7994 - val_main_output_f1_micro: 0.6817 - val_aux_output_acc: 0.7894 - val_aux_output_f1_micro: 0.1071\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.5866 - main_output_loss: 1.2991 - aux_output_loss: 1.4378 - main_output_acc: 0.7761 - main_output_f1_micro: 0.6826 - aux_output_acc: 0.7862 - aux_output_f1_micro: 0.1072 - val_loss: 1.4255 - val_main_output_loss: 1.1193 - val_aux_output_loss: 1.5309 - val_main_output_acc: 0.7999 - val_main_output_f1_micro: 0.6835 - val_aux_output_acc: 0.7935 - val_aux_output_f1_micro: 0.1073\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.5792 - main_output_loss: 1.2932 - aux_output_loss: 1.4304 - main_output_acc: 0.7761 - main_output_f1_micro: 0.6845 - aux_output_acc: 0.7870 - aux_output_f1_micro: 0.1075 - val_loss: 1.4155 - val_main_output_loss: 1.1104 - val_aux_output_loss: 1.5255 - val_main_output_acc: 0.7958 - val_main_output_f1_micro: 0.6854 - val_aux_output_acc: 0.7893 - val_aux_output_f1_micro: 0.1076\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.5741 - main_output_loss: 1.2892 - aux_output_loss: 1.4245 - main_output_acc: 0.7752 - main_output_f1_micro: 0.6863 - aux_output_acc: 0.7871 - aux_output_f1_micro: 0.1077 - val_loss: 1.4189 - val_main_output_loss: 1.1143 - val_aux_output_loss: 1.5229 - val_main_output_acc: 0.8024 - val_main_output_f1_micro: 0.6871 - val_aux_output_acc: 0.7928 - val_aux_output_f1_micro: 0.1079\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 52s - loss: 1.5703 - main_output_loss: 1.2866 - aux_output_loss: 1.4184 - main_output_acc: 0.7738 - main_output_f1_micro: 0.6880 - aux_output_acc: 0.7856 - aux_output_f1_micro: 0.1080 - val_loss: 1.4146 - val_main_output_loss: 1.1102 - val_aux_output_loss: 1.5218 - val_main_output_acc: 0.8017 - val_main_output_f1_micro: 0.6889 - val_aux_output_acc: 0.7924 - val_aux_output_f1_micro: 0.1082\n",
      "\n",
      "Done with epoch: 100\n",
      "\n",
      "CPU times: user 1h 43min 17s, sys: 9min 19s, total: 1h 52min 37s\n",
      "Wall time: 1h 27min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_name = 'models/lstm-word2vec-fasttext_2012-2014-data_cat-crossentropy-2014-b-val-sc_wv_fs-trimmed_tokens.model'\n",
    "epochs = 5\n",
    "for i in xrange(0, 100 // epochs):\n",
    "    hist = model.fit(\n",
    "        {'main_input': x_train, 'wv_input': wv_train, 'fs_input': fs_train},\n",
    "        {'main_output': y_train, 'aux_output': y_train},\n",
    "        epochs=epochs, batch_size=batch_size,   # 500\n",
    "        validation_split=0.2,\n",
    "        validation_data=(\n",
    "            {'main_input': x_val, 'wv_input': wv_val, 'fs_input': fs_val},\n",
    "            {'main_output': y_val, 'aux_output': y_val}\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.save(model_name.format(i))\n",
    "    print\n",
    "    print('Done with epoch: {}'.format((i + 1) * epochs))\n",
    "    with open('lstm-word2vec-fasttext.epoch.csv', 'a') as fl:\n",
    "        fl.write(model_name + '\\n')\n",
    "        fl.write('Epoch {}\\n'.format((i + 1) * epochs))\n",
    "        fl.write('{}\\n'.format(datetime.now()))\n",
    "        fl.write('\\n'.join(['{}: {}'.format(k, v[0]) for k, v in hist.history.items()]))\n",
    "        fl.write('\\n\\n')\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.6427 - main_output_loss: 1.3490 - aux_output_loss: 1.4686 - main_output_acc: 0.7712 - main_output_f1_micro: 0.6905 - aux_output_acc: 0.7839 - aux_output_f1_micro: 0.1085 - val_loss: 1.4372 - val_main_output_loss: 1.1302 - val_aux_output_loss: 1.5348 - val_main_output_acc: 0.7941 - val_main_output_f1_micro: 0.6913 - val_aux_output_acc: 0.7884 - val_aux_output_f1_micro: 0.1086\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5833 - main_output_loss: 1.2980 - aux_output_loss: 1.4265 - main_output_acc: 0.7738 - main_output_f1_micro: 0.6921 - aux_output_acc: 0.7855 - aux_output_f1_micro: 0.1088 - val_loss: 1.4210 - val_main_output_loss: 1.1179 - val_aux_output_loss: 1.5153 - val_main_output_acc: 0.7967 - val_main_output_f1_micro: 0.6930 - val_aux_output_acc: 0.7949 - val_aux_output_f1_micro: 0.1090\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5656 - main_output_loss: 1.2841 - aux_output_loss: 1.4076 - main_output_acc: 0.7752 - main_output_f1_micro: 0.6938 - aux_output_acc: 0.7870 - aux_output_f1_micro: 0.1091 - val_loss: 1.4123 - val_main_output_loss: 1.1124 - val_aux_output_loss: 1.4995 - val_main_output_acc: 0.7930 - val_main_output_f1_micro: 0.6946 - val_aux_output_acc: 0.7916 - val_aux_output_f1_micro: 0.1093\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5551 - main_output_loss: 1.2755 - aux_output_loss: 1.3983 - main_output_acc: 0.7779 - main_output_f1_micro: 0.6955 - aux_output_acc: 0.7867 - aux_output_f1_micro: 0.1094 - val_loss: 1.4043 - val_main_output_loss: 1.1070 - val_aux_output_loss: 1.4866 - val_main_output_acc: 0.7988 - val_main_output_f1_micro: 0.6963 - val_aux_output_acc: 0.7918 - val_aux_output_f1_micro: 0.1096\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5504 - main_output_loss: 1.2725 - aux_output_loss: 1.3899 - main_output_acc: 0.7771 - main_output_f1_micro: 0.6971 - aux_output_acc: 0.7872 - aux_output_f1_micro: 0.1097 - val_loss: 1.4002 - val_main_output_loss: 1.1043 - val_aux_output_loss: 1.4796 - val_main_output_acc: 0.8088 - val_main_output_f1_micro: 0.6980 - val_aux_output_acc: 0.7916 - val_aux_output_f1_micro: 0.1099\n",
      "\n",
      "Done with epoch: 100\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5459 - main_output_loss: 1.2693 - aux_output_loss: 1.3833 - main_output_acc: 0.7773 - main_output_f1_micro: 0.6988 - aux_output_acc: 0.7896 - aux_output_f1_micro: 0.1100 - val_loss: 1.3938 - val_main_output_loss: 1.0999 - val_aux_output_loss: 1.4694 - val_main_output_acc: 0.8001 - val_main_output_f1_micro: 0.6996 - val_aux_output_acc: 0.7926 - val_aux_output_f1_micro: 0.1102\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5393 - main_output_loss: 1.2640 - aux_output_loss: 1.3764 - main_output_acc: 0.7776 - main_output_f1_micro: 0.7004 - aux_output_acc: 0.7896 - aux_output_f1_micro: 0.1103 - val_loss: 1.3912 - val_main_output_loss: 1.0979 - val_aux_output_loss: 1.4664 - val_main_output_acc: 0.7940 - val_main_output_f1_micro: 0.7012 - val_aux_output_acc: 0.7917 - val_aux_output_f1_micro: 0.1105\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5369 - main_output_loss: 1.2627 - aux_output_loss: 1.3708 - main_output_acc: 0.7815 - main_output_f1_micro: 0.7020 - aux_output_acc: 0.7890 - aux_output_f1_micro: 0.1106 - val_loss: 1.3821 - val_main_output_loss: 1.0902 - val_aux_output_loss: 1.4594 - val_main_output_acc: 0.8066 - val_main_output_f1_micro: 0.7028 - val_aux_output_acc: 0.7940 - val_aux_output_f1_micro: 0.1108\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5302 - main_output_loss: 1.2571 - aux_output_loss: 1.3656 - main_output_acc: 0.7796 - main_output_f1_micro: 0.7036 - aux_output_acc: 0.7897 - aux_output_f1_micro: 0.1109 - val_loss: 1.3878 - val_main_output_loss: 1.0954 - val_aux_output_loss: 1.4620 - val_main_output_acc: 0.7964 - val_main_output_f1_micro: 0.7044 - val_aux_output_acc: 0.7954 - val_aux_output_f1_micro: 0.1111\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5282 - main_output_loss: 1.2561 - aux_output_loss: 1.3605 - main_output_acc: 0.7775 - main_output_f1_micro: 0.7052 - aux_output_acc: 0.7913 - aux_output_f1_micro: 0.1112 - val_loss: 1.3855 - val_main_output_loss: 1.0954 - val_aux_output_loss: 1.4505 - val_main_output_acc: 0.7928 - val_main_output_f1_micro: 0.7059 - val_aux_output_acc: 0.7964 - val_aux_output_f1_micro: 0.1114\n",
      "\n",
      "Done with epoch: 105\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5262 - main_output_loss: 1.2551 - aux_output_loss: 1.3553 - main_output_acc: 0.7791 - main_output_f1_micro: 0.7067 - aux_output_acc: 0.7902 - aux_output_f1_micro: 0.1115 - val_loss: 1.3707 - val_main_output_loss: 1.0832 - val_aux_output_loss: 1.4377 - val_main_output_acc: 0.8034 - val_main_output_f1_micro: 0.7075 - val_aux_output_acc: 0.7948 - val_aux_output_f1_micro: 0.1117\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5205 - main_output_loss: 1.2508 - aux_output_loss: 1.3484 - main_output_acc: 0.7803 - main_output_f1_micro: 0.7083 - aux_output_acc: 0.7910 - aux_output_f1_micro: 0.1118 - val_loss: 1.3696 - val_main_output_loss: 1.0827 - val_aux_output_loss: 1.4348 - val_main_output_acc: 0.8018 - val_main_output_f1_micro: 0.7090 - val_aux_output_acc: 0.7929 - val_aux_output_f1_micro: 0.1120\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5220 - main_output_loss: 1.2527 - aux_output_loss: 1.3466 - main_output_acc: 0.7793 - main_output_f1_micro: 0.7098 - aux_output_acc: 0.7904 - aux_output_f1_micro: 0.1122 - val_loss: 1.3695 - val_main_output_loss: 1.0827 - val_aux_output_loss: 1.4341 - val_main_output_acc: 0.7963 - val_main_output_f1_micro: 0.7105 - val_aux_output_acc: 0.7926 - val_aux_output_f1_micro: 0.1123\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5216 - main_output_loss: 1.2530 - aux_output_loss: 1.3431 - main_output_acc: 0.7800 - main_output_f1_micro: 0.7113 - aux_output_acc: 0.7914 - aux_output_f1_micro: 0.1125 - val_loss: 1.3708 - val_main_output_loss: 1.0860 - val_aux_output_loss: 1.4240 - val_main_output_acc: 0.8011 - val_main_output_f1_micro: 0.7120 - val_aux_output_acc: 0.7966 - val_aux_output_f1_micro: 0.1126\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5163 - main_output_loss: 1.2486 - aux_output_loss: 1.3386 - main_output_acc: 0.7807 - main_output_f1_micro: 0.7128 - aux_output_acc: 0.7916 - aux_output_f1_micro: 0.1128 - val_loss: 1.3660 - val_main_output_loss: 1.0814 - val_aux_output_loss: 1.4232 - val_main_output_acc: 0.7929 - val_main_output_f1_micro: 0.7135 - val_aux_output_acc: 0.7930 - val_aux_output_f1_micro: 0.1130\n",
      "\n",
      "Done with epoch: 110\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5152 - main_output_loss: 1.2484 - aux_output_loss: 1.3341 - main_output_acc: 0.7792 - main_output_f1_micro: 0.7142 - aux_output_acc: 0.7911 - aux_output_f1_micro: 0.1131 - val_loss: 1.3651 - val_main_output_loss: 1.0816 - val_aux_output_loss: 1.4173 - val_main_output_acc: 0.7956 - val_main_output_f1_micro: 0.7149 - val_aux_output_acc: 0.7927 - val_aux_output_f1_micro: 0.1133\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5089 - main_output_loss: 1.2427 - aux_output_loss: 1.3309 - main_output_acc: 0.7803 - main_output_f1_micro: 0.7156 - aux_output_acc: 0.7912 - aux_output_f1_micro: 0.1135 - val_loss: 1.3627 - val_main_output_loss: 1.0794 - val_aux_output_loss: 1.4167 - val_main_output_acc: 0.7989 - val_main_output_f1_micro: 0.7164 - val_aux_output_acc: 0.7968 - val_aux_output_f1_micro: 0.1136\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5082 - main_output_loss: 1.2431 - aux_output_loss: 1.3254 - main_output_acc: 0.7813 - main_output_f1_micro: 0.7171 - aux_output_acc: 0.7917 - aux_output_f1_micro: 0.1138 - val_loss: 1.3610 - val_main_output_loss: 1.0787 - val_aux_output_loss: 1.4114 - val_main_output_acc: 0.8054 - val_main_output_f1_micro: 0.7178 - val_aux_output_acc: 0.7916 - val_aux_output_f1_micro: 0.1139\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5043 - main_output_loss: 1.2400 - aux_output_loss: 1.3214 - main_output_acc: 0.7788 - main_output_f1_micro: 0.7185 - aux_output_acc: 0.7905 - aux_output_f1_micro: 0.1141 - val_loss: 1.3573 - val_main_output_loss: 1.0764 - val_aux_output_loss: 1.4045 - val_main_output_acc: 0.8025 - val_main_output_f1_micro: 0.7192 - val_aux_output_acc: 0.7962 - val_aux_output_f1_micro: 0.1143\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5045 - main_output_loss: 1.2409 - aux_output_loss: 1.3181 - main_output_acc: 0.7785 - main_output_f1_micro: 0.7199 - aux_output_acc: 0.7919 - aux_output_f1_micro: 0.1145 - val_loss: 1.3638 - val_main_output_loss: 1.0828 - val_aux_output_loss: 1.4050 - val_main_output_acc: 0.7982 - val_main_output_f1_micro: 0.7205 - val_aux_output_acc: 0.7963 - val_aux_output_f1_micro: 0.1146\n",
      "\n",
      "Done with epoch: 115\n",
      "\n",
      "CPU times: user 20min 20s, sys: 1min 53s, total: 22min 14s\n",
      "Wall time: 17min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# i = 100\n",
    "# batch_size = 600\n",
    "batch_size = 1200\n",
    "for j in xrange(i, i + (20 // epochs)):\n",
    "    hist = model.fit(\n",
    "        {'main_input': x_train, 'wv_input': wv_train, 'fs_input': fs_train},\n",
    "        {'main_output': y_train, 'aux_output': y_train},\n",
    "        epochs=epochs, batch_size=batch_size,   # 500\n",
    "        validation_split=0.2,\n",
    "        validation_data=(\n",
    "            {'main_input': x_val, 'wv_input': wv_val, 'fs_input': fs_val},\n",
    "            {'main_output': y_val, 'aux_output': y_val}\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.save(model_name.format(i))\n",
    "    print\n",
    "    print('Done with epoch: {}'.format((j + 1) * epochs))\n",
    "    with open('lstm-word2vec-fasttext.epoch.csv', 'a') as fl:\n",
    "        fl.write(model_name + '\\n')\n",
    "        fl.write('Epoch {}\\n'.format((j + 1) * epochs))\n",
    "        fl.write('{}\\n'.format(datetime.now()))\n",
    "        fl.write('\\n'.join(['{}: {}'.format(k, v[0]) for k, v in hist.history.items()]))\n",
    "        fl.write('\\n\\n')\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = keras.models.load_model(\n",
    "#     'models/lstm-word2vec-fasttext_2010-2014-data_categorical-crossentropy-2014-b-val-standard_scaled_wv_fs.model',\n",
    "#     custom_objects={'f1_micro': f1_micro}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = model.predict({'main_input': x_train[:100], 'wv_input': wv_train[:100], 'fs_input': fs_train[:100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6a0eb13a90>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTej/A7CnoxRVuh1UAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6a90719690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "ix = 29\n",
    "pd.Series(g[0][ix]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f69b31a4310>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6b58459f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(g[1][ix]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([ 1, 98]),), (array([ 1, 98]),), (array([], dtype=int64),))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh = 0.5\n",
    "np.where(y_train[ix] == 1), np.where(g[0][ix] > thresh), np.where(g[1][ix] > thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wvmodel = Word2Vec.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fsmodel = fasttext.load_model('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.fasttext.model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_fasttext(tokens, stopwords=[]):\n",
    "    global fsmodel\n",
    "    # This requires fsmodel to be present in the namespace.\n",
    "    fs_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    ).map(lambda x: np.array([fsmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return fs_feature_vec\n",
    "\n",
    "\n",
    "def transform_unsupervised_sentiment_neuron(tokens, stopwords=[]):\n",
    "    # This requires fsmodel to be present in the namespace.\n",
    "    \n",
    "    usn_feature_vec = usnmodel.transform(tokens)\n",
    "\n",
    "    # usn_feature_vec = tokens.map(\n",
    "    #     lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    # ).map(lambda x: np.array([usnmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return usn_feature_vec\n",
    "\n",
    "\n",
    "def transform_word2vec(tokens, stopwords=[]):\n",
    "    global wvmodel\n",
    "    # This requires wvmodel to be present in the namespace.\n",
    "    wv_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords and w in wvmodel.wv.vocab)]\n",
    "    ).map(lambda x: np.array([wvmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return wv_feature_vec\n",
    "\n",
    "\n",
    "def parallel_generate_word_vectors(samp, transformer, stopwords, batch, num_proc):\n",
    "    with Parallel(n_jobs=num_proc) as parallel:\n",
    "        dataset = []\n",
    "        is_break = False\n",
    "        i = 0\n",
    "\n",
    "        while not is_break:\n",
    "            payload = []\n",
    "\n",
    "            for j in xrange(num_proc):\n",
    "                t_df = samp[(i + j) * batch: (i + 1 + j) * batch]\n",
    "\n",
    "                if t_df.empty:\n",
    "                    is_break = True\n",
    "                    continue\n",
    "\n",
    "                payload.append(\n",
    "                    delayed(transformer)(\n",
    "                        t_df, stopwords\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            print('Current batch in main thread: {}'.format((i + j) * batch))\n",
    "\n",
    "            if payload:\n",
    "                results = parallel(payload)\n",
    "                dataset.extend(results)\n",
    "                i += num_proc\n",
    "\n",
    "    return pd.concat(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_classes(pred, scale_param=0.75, min_thresh=0.05, thresh = 0.5):\n",
    "#     mx = pred.mean() + 3 * pred.std()\n",
    "    return np.where(pred > thresh)[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2idx_transform(word, _word2idx):\n",
    "    return _word2idx.get(word, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features_for(df, min_batch=2000, stopwords=[], num_proc=7):\n",
    "    df_tokens = transform_text(df)\n",
    "    \n",
    "    batch = min(df_tokens.shape[0] / num_proc, min_batch)\n",
    "\n",
    "    print('Computing fs features...')\n",
    "    fvec = parallel_generate_word_vectors(df_tokens, transform_fasttext, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Computing wv features...')\n",
    "    wvec = parallel_generate_word_vectors(df_tokens, transform_word2vec, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Mapping word indices...')\n",
    "    word_indices = df_tokens.map(lambda x: [word2idx_transform(i, _word2idx) for i in x.split()])\n",
    "    \n",
    "    return word_indices, wvec, fvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/TestData.json') as fl:\n",
    "    data = json.load(fl)\n",
    "    test_df = pd.DataFrame(data['TestData']).T\n",
    "    del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fs features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Computing wv features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Mapping word indices...\n",
      "CPU times: user 42.4 s, sys: 1.61 s, total: 44 s\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_word_indices,test_wvec, test_fvec = extract_features_for(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert(np.all(test_wvec[test_wvec.isnull()].index == test_fvec[test_fvec.isnull()].index))\n",
    "test_null_index = test_wvec[test_wvec.isnull()].index.union(test_fvec[test_fvec.isnull()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'TestData_02543', u'TestData_05012', u'TestData_05830'], dtype='object')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_null_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.1 s, sys: 52 ms, total: 1.15 s\n",
      "Wall time: 1.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "valid_test_index = test_word_indices.index.difference(test_null_index)\n",
    "x_test = test_word_indices.ix[valid_test_index].map(lambda x: [top_token2ind.get(i, 0) for i in x])\n",
    "\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "wv_test = np.vstack(test_wvec.ix[valid_test_index])\n",
    "fs_test = np.vstack(test_fvec.ix[valid_test_index])\n",
    "\n",
    "\n",
    "wv_test = wv_sc.transform(wv_test)\n",
    "fs_test = fs_sc.transform(fs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# batch_size = 500\n",
    "test_probas = model.predict({'main_input': x_test, 'wv_input': wv_test, 'fs_input': fs_test}, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_test_probas, aux_test_probas = test_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.82399505e-21,   3.23757599e-09,   7.85459751e-13, ...,\n",
       "          6.72522482e-10,   3.58368693e-26,   1.27524769e-24],\n",
       "       [  2.84811546e-15,   3.77687606e-08,   3.68029696e-08, ...,\n",
       "          1.26781779e-05,   1.20610622e-07,   7.77806215e-16],\n",
       "       [  3.56542727e-34,   5.66692229e-22,   3.50696145e-21, ...,\n",
       "          7.07543361e-19,   7.27817400e-27,   2.74317873e-37],\n",
       "       ..., \n",
       "       [  2.37797678e-07,   1.77524313e-02,   4.36573863e-01, ...,\n",
       "          1.08819563e-06,   1.47305923e-02,   4.24878941e-08],\n",
       "       [  1.31793128e-20,   5.88922467e-06,   4.74403450e-09, ...,\n",
       "          5.86890562e-12,   1.36047769e-20,   2.60776403e-21],\n",
       "       [  3.23153710e-16,   3.27282841e-03,   7.43957207e-05, ...,\n",
       "          8.34264657e-10,   2.53804853e-17,   3.94557939e-17]], dtype=float32)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_test_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_df.ix[test_df.index.difference(test_null_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2542, 5011, 5829]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_index = [int(s.split('_')[1]) - 1 for s in test_null_index]  # Subtract 1 since test index starts at 1 while enumerate starts at 0\n",
    "skip_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7578, 160), (7581, 3))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_test_probas.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48 ms, sys: 12 ms, total: 60 ms\n",
      "Wall time: 53.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# valid_test_feature_vec found below!\n",
    "test_values = np.zeros([main_test_probas.shape[0], len(topics)])\n",
    "for ix, pred in enumerate(main_test_probas):\n",
    "    for v in get_classes(pred, thresh=0.3):\n",
    "        test_values[ix][v] = 1\n",
    "\n",
    "test_sub_df = pd.DataFrame(\n",
    "    test_values,\n",
    "    index=test_df.ix[test_df.index.difference(test_null_index)].index,\n",
    "    columns=topics\n",
    ")\n",
    "\n",
    "null_test_df = pd.DataFrame(\n",
    "    np.zeros((len(test_null_index), len(topics))),\n",
    "    index=test_null_index,\n",
    "    columns=topics\n",
    ")\n",
    "\n",
    "test_sub_df = test_sub_df.append(null_test_df)\n",
    "test_sub_df = test_sub_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9627"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9627"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14297.0"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94731/94731 [==============================] - 51s - loss: 1.5045 - main_output_loss: 1.2409 - aux_output_loss: 1.3181 - main_output_acc: 0.7785 - main_output_f1_micro: 0.7199 - aux_output_acc: 0.7919 - aux_output_f1_micro: 0.1145 - val_loss: 1.3638 - val_main_output_loss: 1.0828 - val_aux_output_loss: 1.4050 - val_main_output_acc: 0.7982 - val_main_output_f1_micro: 0.7205 - val_aux_output_acc: 0.7963 - val_aux_output_f1_micro: 0.1146\n"
     ]
    }
   ],
   "source": [
    "print '94731/94731 [==============================] - 51s - loss: 1.5045 - main_output_loss: 1.2409 - aux_output_loss: 1.3181 - main_output_acc: 0.7785 - main_output_f1_micro: 0.7199 - aux_output_acc: 0.7919 - aux_output_f1_micro: 0.1145 - val_loss: 1.3638 - val_main_output_loss: 1.0828 - val_aux_output_loss: 1.4050 - val_main_output_acc: 0.7982 - val_main_output_f1_micro: 0.7205 - val_aux_output_acc: 0.7963 - val_aux_output_f1_micro: 0.1146'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_sub_df.astype(int).reset_index().rename(\n",
    "    columns={'index': 'id'}\n",
    ").sort_values('id').to_csv(\n",
    "    'lstm_300-word2vec_300-fasttext_300-maxlen_500-dense_128_256_128-cat_cross-epoch_115-batch_size_1200-val_main_output_f1_micro_0.7205-main_output_f1_micro_0.7199-main_output_loss_1.2409-data_2012_2014-val_data_2014-thresh_0.3-with_sc_wv_fs.csv', \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7581, 160)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TestData_04490\tThe World Health Organisation has convened an ...\t[]\t28-01-2016\n",
    "TestData_04550\tSpraying pesticides will fail to deal with the...\t[]\t02-02-2016\n",
    "TestData_05683\tViolent protests at Trump rally in California ...\t[]\t03-06-2016\n",
    "TestData_05869\tLast weekend, we saw the darkest side of human...\t[]\t17-06-2016\n",
    "TestData_06148\tAs dusk falls over Copacabana beach, Ubira San...\t[]\t16-07-2016\n",
    "TestData_06291\tIt is 3pm and yet another patient is brought t...\t[]\t27-07-2016\n",
    "TestData_06610\tHuddled around their hives, beekeepers around ...\t[]\t04-09-2016\n",
    "TestData_06708\tA United Nations high-level panel on access to...\t[]\t14-09-2016\n",
    "TestData_07263\tWHO: Zika virus is no longer a world threat Th...\t[]\t19-11-2016\n",
    "TestData_07478\t1 World Health Organisation declares a public ...\t[]\t18-12-2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "guncrime    1.0\n",
       "Name: TestData_05683, dtype: float64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = 5682\n",
    "test_sub_df.iloc[ix][test_sub_df.iloc[ix] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36 ms, sys: 0 ns, total: 36 ms\n",
      "Wall time: 32.6 ms\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# adjust_index = 0\n",
    "# # valid_test_feature_vec found below!\n",
    "# test_values = np.zeros([test_df.shape[0], len(topics)])\n",
    "# for ix, pred in enumerate(main_test_probas):\n",
    "#     if ix in skip_index:\n",
    "#         test_values[ix] = np.nan\n",
    "#         # Increment adjust index so that we have the correct index for other samples\n",
    "#         adjust_index += 1\n",
    "#         continue\n",
    "\n",
    "#     for v in get_classes(pred, thresh=0.05):\n",
    "#         test_values[ix + adjust_index][v] = 1\n",
    "\n",
    "# test_sub_df = pd.DataFrame(test_values, columns=sorted(topics), index=test_df.index)\n",
    "\n",
    "# q = test_sub_df.sum(axis=1)\n",
    "# assert(len(q[q.isnull()].index.difference(test_null_index)) == 0)\n",
    "\n",
    "# test_sub_df = test_sub_df.fillna(0)\n",
    "\n",
    "# # for i in test_feature_vec[test_feature_vec.isnull()].index:\n",
    "# #     test_sub_df.ix[i] = np.zeros(len(topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestData_02543    0.0\n",
       "TestData_05012    0.0\n",
       "TestData_05830    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.ix[test_null_index].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11656.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sub_df.astype(int).reset_index().rename(\n",
    "    columns={'index': 'id'}\n",
    ").sort_values('id').to_csv(\n",
    "    'lstm_300-word2vec_300-fasttext_300-maxlen_500-dense_64_64_64-cat_cross-epoch_210-batch_size_750-val_main_output_f1_micro_0.5760-main_output_f1_micro_0.5751-main_output_loss_0.9143-data_2010_2013-val_data_2014-thresh_0.05.csv', \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: zikavirus, dtype: float64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = test_sub_df['zikavirus']\n",
    "e[e==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14328"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_submission = pd.read_csv('basic_nn_submission_0.649_accuracy_multi_class.csv')\n",
    "top_submission.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9280"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_index_lstm_sub = pd.read_csv('lstm.2014b_training_700_maxlen_64cell_100epochs_0.0025_threshold.csv')\n",
    "wrong_index_lstm_sub.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34952"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_sub = pd.read_csv('basic_nn_submission_full_training_data_0.9958_validation_accuracy_binary_crossentropy.csv')\n",
    "some_sub.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2197, 160)\n",
      "(3957, 160)\n",
      "(12, 160)\n",
      "(1503, 160)\n"
     ]
    }
   ],
   "source": [
    "print top_submission.set_index('id')[top_submission.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print wrong_index_lstm_sub.set_index('id')[wrong_index_lstm_sub.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print some_sub.set_index('id')[some_sub.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print test_sub_df[test_sub_df.sum(axis=1) == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestData_00011     0\n",
       "TestData_00012     0\n",
       "TestData_00015     0\n",
       "TestData_00027     3\n",
       "TestData_00029     0\n",
       "TestData_00038     1\n",
       "TestData_00042     5\n",
       "TestData_00053     4\n",
       "TestData_00056     1\n",
       "TestData_00060     1\n",
       "TestData_00066     0\n",
       "TestData_00085     0\n",
       "TestData_00087     1\n",
       "TestData_00090     0\n",
       "TestData_00092     0\n",
       "TestData_00107     3\n",
       "TestData_00111     0\n",
       "TestData_00114     0\n",
       "TestData_00115     1\n",
       "TestData_00118     0\n",
       "TestData_00119     0\n",
       "TestData_00121     0\n",
       "TestData_00123     0\n",
       "TestData_00125     0\n",
       "TestData_00127     0\n",
       "TestData_00128     1\n",
       "TestData_00139     1\n",
       "TestData_00140     1\n",
       "TestData_00144     0\n",
       "TestData_00147     2\n",
       "                  ..\n",
       "TestData_07445     0\n",
       "TestData_07456     3\n",
       "TestData_07461     1\n",
       "TestData_07462     4\n",
       "TestData_07465     0\n",
       "TestData_07468     0\n",
       "TestData_07471     1\n",
       "TestData_07475     0\n",
       "TestData_07486    10\n",
       "TestData_07495     1\n",
       "TestData_07509     0\n",
       "TestData_07514     3\n",
       "TestData_07515     1\n",
       "TestData_07523     0\n",
       "TestData_07533     2\n",
       "TestData_07534     2\n",
       "TestData_07542     1\n",
       "TestData_07544     2\n",
       "TestData_07545     0\n",
       "TestData_07552     2\n",
       "TestData_07556     5\n",
       "TestData_07563     1\n",
       "TestData_07565     0\n",
       "TestData_07566     0\n",
       "TestData_07569     0\n",
       "TestData_07571     3\n",
       "TestData_07572     1\n",
       "TestData_07579     6\n",
       "TestData_07580     2\n",
       "TestData_07581     3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_submission.set_index('id').ix[q[q == 0].index].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1222,)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.sum(axis=1)\n",
    "q[q==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7581.000000\n",
       "mean        2.160929\n",
       "std         1.739411\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         2.000000\n",
       "75%         3.000000\n",
       "max        13.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = trainingY.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    236286.000000\n",
       "mean          1.392787\n",
       "std           0.762577\n",
       "min           1.000000\n",
       "25%           1.000000\n",
       "50%           1.000000\n",
       "75%           2.000000\n",
       "max          15.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bodyText</th>\n",
       "      <th>topics</th>\n",
       "      <th>webPublicationDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TestData_03241</th>\n",
       "      <td>A special British police unit was put on stand...</td>\n",
       "      <td>[]</td>\n",
       "      <td>15-11-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_04088</th>\n",
       "      <td>The youngest convict in a fatal gang-rape in N...</td>\n",
       "      <td>[]</td>\n",
       "      <td>20-12-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_06306</th>\n",
       "      <td>Former New York City mayor Rudy Giuliani has s...</td>\n",
       "      <td>[]</td>\n",
       "      <td>28-07-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_06083</th>\n",
       "      <td>John Cantlie, the British journalist who has b...</td>\n",
       "      <td>[]</td>\n",
       "      <td>13-07-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_05896</th>\n",
       "      <td>Lawyers for the companies that manufactured an...</td>\n",
       "      <td>[]</td>\n",
       "      <td>20-06-2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         bodyText topics  \\\n",
       "TestData_03241  A special British police unit was put on stand...     []   \n",
       "TestData_04088  The youngest convict in a fatal gang-rape in N...     []   \n",
       "TestData_06306  Former New York City mayor Rudy Giuliani has s...     []   \n",
       "TestData_06083  John Cantlie, the British journalist who has b...     []   \n",
       "TestData_05896  Lawyers for the companies that manufactured an...     []   \n",
       "\n",
       "               webPublicationDate  \n",
       "TestData_03241         15-11-2015  \n",
       "TestData_04088         20-12-2015  \n",
       "TestData_06306         28-07-2016  \n",
       "TestData_06083         13-07-2016  \n",
       "TestData_05896         20-06-2016  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ix = 'TestData_04088'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "humanrights    1.0\n",
       "india          1.0\n",
       "Name: TestData_04088, dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ukcrime    1\n",
       "Name: TestData_04088, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = top_submission.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "humanrights    1\n",
       "india          1\n",
       "protest        1\n",
       "ukcrime        1\n",
       "Name: TestData_04088, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = some_sub.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "humanrights    1\n",
       "Name: TestData_02924, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = wrong_index_lstm_sub.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Counter-terrorism policy\n",
    " \n",
    "Foreign policy\n",
    " \n",
    "Defence policy\n",
    " \n",
    "Islamic State\n",
    " \n",
    "Syria\n",
    " \n",
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = trainingY.sum()\n",
    "unseen_topics = s[s.isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activism',\n",
       " 'bastilledaytruckattack',\n",
       " 'berlinchristmasmarketattack',\n",
       " 'brusselsattacks',\n",
       " 'charliehebdoattack',\n",
       " 'francetrainattack',\n",
       " 'munichshooting',\n",
       " 'orlandoterrorattack',\n",
       " 'parisattacks',\n",
       " 'peaceandreconciliation',\n",
       " 'sanbernardinoshooting',\n",
       " 'tunisiaattack2015',\n",
       " 'turkeycoupattempt',\n",
       " 'zikavirus'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(topics).intersection(unseen_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activism\n",
      "afghanistan\n",
      "aid\n",
      "algerianhostagecrisis\n",
      "alqaida\n",
      "alshabaab\n",
      "antiwar\n",
      "arabandmiddleeastprotests\n",
      "armstrade\n",
      "australianguncontrol\n",
      "australiansecurityandcounterterrorism\n",
      "bastilledaytruckattack\n",
      "belgium\n",
      "berlinchristmasmarketattack\n",
      "bigdata\n",
      "biometrics\n",
      "bokoharam\n",
      "bostonmarathonbombing\n",
      "britisharmy\n",
      "brusselsattacks\n",
      "cameroon\n",
      "carers\n",
      "charliehebdoattack\n",
      "chemicalweapons\n",
      "clusterbombs\n",
      "cobra\n",
      "conflictanddevelopment\n",
      "controversy\n",
      "criminaljustice\n",
      "cybercrime\n",
      "cyberwar\n",
      "darknet\n",
      "dataprotection\n",
      "debate\n",
      "defence\n",
      "deflation\n",
      "drones\n",
      "drugs\n",
      "drugspolicy\n",
      "drugstrade\n",
      "earthquakes\n",
      "ebola\n",
      "economy\n",
      "egypt\n",
      "encryption\n",
      "energy\n",
      "espionage\n",
      "ethics\n",
      "europeanarrestwarrant\n",
      "europeancourtofhumanrights\n",
      "events\n",
      "extradition\n",
      "famine\n",
      "farright\n",
      "firefighters\n",
      "forensicscience\n",
      "france\n",
      "francetrainattack\n",
      "freedomofspeech\n",
      "genevaconventions\n",
      "germany\n",
      "guncrime\n",
      "hacking\n",
      "hashtags\n",
      "helicoptercrashes\n",
      "humanitarianresponse\n",
      "humanrights\n",
      "humanrightsact\n",
      "humantrafficking\n",
      "immigration\n",
      "india\n",
      "indonesia\n",
      "internallydisplacedpeople\n",
      "internationalcourtofjustice\n",
      "internationalcriminaljustice\n",
      "internetsafety\n",
      "iraq\n",
      "isis\n",
      "israel\n",
      "jordan\n",
      "jubilee\n",
      "judiciary\n",
      "july7\n",
      "justiceandsecurity\n",
      "kenya\n",
      "knifecrime\n",
      "lebanon\n",
      "libya\n",
      "localgovernment\n",
      "logistics\n",
      "london\n",
      "londonriots\n",
      "malaysia\n",
      "mali\n",
      "malware\n",
      "metropolitanpolice\n",
      "middleeastpeacetalks\n",
      "migration\n",
      "military\n",
      "ministryofdefence\n",
      "morocco\n",
      "mrsa\n",
      "mumbaiterrorattacks\n",
      "munichshooting\n",
      "naturaldisasters\n",
      "nigeria\n",
      "nuclearweapons\n",
      "occupy\n",
      "organisedcrime\n",
      "orlandoterrorattack\n",
      "osamabinladen\n",
      "paris\n",
      "parisattacks\n",
      "peaceandreconciliation\n",
      "philippines\n",
      "piracy\n",
      "planecrashes\n",
      "police\n",
      "protest\n",
      "refugees\n",
      "religion\n",
      "retirementage\n",
      "rio20earthsummit\n",
      "royalairforce\n",
      "royalnavy\n",
      "russia\n",
      "sanbernardinoshooting\n",
      "saudiarabia\n",
      "september11\n",
      "slavery\n",
      "somalia\n",
      "southafrica\n",
      "southchinasea\n",
      "stopandsearch\n",
      "surveillance\n",
      "sydneysiege\n",
      "syria\n",
      "taliban\n",
      "terrorism\n",
      "thailand\n",
      "torture\n",
      "traincrashes\n",
      "transport\n",
      "tunisiaattack2015\n",
      "turkey\n",
      "turkeycoupattempt\n",
      "ukcrime\n",
      "uksecurity\n",
      "uksupremecourt\n",
      "undercoverpoliceandpolicing\n",
      "unitednations\n",
      "usguncontrol\n",
      "values\n",
      "warcrimes\n",
      "warreporting\n",
      "weaponstechnology\n",
      "womeninbusiness\n",
      "woolwichattack\n",
      "worldmigration\n",
      "zikavirus\n"
     ]
    }
   ],
   "source": [
    "for i in topics:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsolatorio/ml-ai/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3445929"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(wvmodel['zika'], np.vstack(test_wvec.dropna())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsolatorio/ml-ai/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.38107796869050226"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(fsmodel['zika'], np.vstack(test_fvec.dropna())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              The World Health Organisation has convened an ...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           28-01-2016\n",
       "Name: TestData_04490, dtype: object"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[4488 + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              The United Nations security council has called...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           17-09-2016\n",
       "Name: TestData_06730, dtype: object"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[6727 + 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              We are deeply concerned that the counter-terro...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           02-02-2015\n",
       "Name: TestData_00360, dtype: object"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[359]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drugstrade    1.0\n",
       "Name: TestData_04490, dtype: float64"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.iloc[4488 + 1]\n",
    "q[q > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
