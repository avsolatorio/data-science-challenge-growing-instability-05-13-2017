{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from growing_instability_lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub = pd.read_csv('../data/sampleSubmission.csv')\n",
    "topics = sorted(set(sample_sub.columns.difference(['id'])))\n",
    "\n",
    "topic2actual = {}\n",
    "for i in sample_sub.columns:\n",
    "    if 'id' == i:\n",
    "        continue\n",
    "    topic2actual[i] = segment(i)\n",
    "    \n",
    "target_columns = sorted(topics)\n",
    "len(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.2 s, sys: 4.21 s, total: 14.4 s\n",
      "Wall time: 18.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wvec_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'wvec_trainingX')\n",
    "fvec_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'fvec_trainingX')\n",
    "\n",
    "tfidf_wvec_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'tfidf_wvec_trainingX')\n",
    "tfidf_fvec_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'tfidf_fvec_trainingX')\n",
    "tfidf_lsi_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'tfidf_lsi_trainingX')\n",
    "\n",
    "word2idx_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'word2idx_trainingX')\n",
    "_word2idx = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', '_word2idx')\n",
    "trainingY = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'trainingY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://192.168.1.25:9999/notebooks/kaggle/data-science-challenge-growing-instability-05-13-2017/src/Topic%20Modeling%20and%20Clustering.ipynb\n",
    "train_test_df = pd.read_hdf('train_test_df_3.hdf', 'train_test_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_topics(df, topics):\n",
    "    topics = sorted(topics)\n",
    "#     v = np.zeros(shape=(df.shape[0], len(topics)))\n",
    "    v = []\n",
    "    for ix, tp in enumerate(df.topics):\n",
    "        tt = []\n",
    "        for t in tp:\n",
    "            tt.append(topics.index(t))\n",
    "#             v[ix][topics.index(t)] = 1\n",
    "        v.append(tt)\n",
    "\n",
    "    return pd.Series(v, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fs features...\n",
      "Current batch in main thread: 102\n",
      "Current batch in main thread: 221\n",
      "Computing wv features...\n",
      "Current batch in main thread: 102\n",
      "Current batch in main thread: 221\n",
      "Mapping word indices...\n",
      "Computing tfidf fs features...\n",
      "Current batch in main thread: 102\n",
      "Current batch in main thread: 221\n",
      "Computing tfidf wv features...\n",
      "Current batch in main thread: 102\n",
      "Current batch in main thread: 221\n",
      "Computing tfidf lsi features...\n",
      "Current batch in main thread: 102\n",
      "Current batch in main thread: 221\n"
     ]
    }
   ],
   "source": [
    "train_test_word_indices, train_test_wvec, train_test_fvec, train_test_tfidf_wvec, train_test_tfidf_fvec, train_test_tfidf_lsi = extract_features_for(\n",
    "    train_test_df\n",
    ")\n",
    "\n",
    "train_test_y = transform_topics(train_test_df, topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.3 s, sys: 252 ms, total: 11.6 s\n",
      "Wall time: 11.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ind2word = {j:i for i, j in _word2idx.iteritems()}\n",
    "ind2class = dict(enumerate(topics))\n",
    "class2ind = {j: i for i, j in ind2class.items()}\n",
    "\n",
    "num_samples = trainingY.shape[0]\n",
    "\n",
    "# ---------------------------------\n",
    "training_X = word2idx_trainingX.head(num_samples)\n",
    "training_Y = pd.DataFrame(zip(*np.where(trainingY.head(num_samples) == 1)), columns=['iloc', 'topics'])\n",
    "\n",
    "training_WV = wvec_trainingX.head(num_samples)\n",
    "training_FS = fvec_trainingX.head(num_samples)\n",
    "\n",
    "training_tfidf_WV = tfidf_wvec_trainingX.head(num_samples)\n",
    "training_tfidf_FS = tfidf_fvec_trainingX.head(num_samples)\n",
    "training_tfidf_LSI = tfidf_lsi_trainingX.head(num_samples)\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "training_Y = training_Y.groupby('iloc')['topics'].apply(list)\n",
    "training_Y.index = trainingY.head(num_samples).index\n",
    "\n",
    "indices = sorted(training_Y.index[training_Y.index.str.contains('^201[0-9]')])\n",
    "# np.random.shuffle(indices)\n",
    "indices = pd.Index(indices)\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "training_X = training_X.ix[indices]\n",
    "training_Y = training_Y.ix[indices]\n",
    "\n",
    "training_WV = training_WV.ix[indices]\n",
    "training_FS = training_FS.ix[indices]\n",
    "\n",
    "training_tfidf_WV = training_tfidf_WV.ix[indices]\n",
    "training_tfidf_FS = training_tfidf_FS.ix[indices]\n",
    "training_tfidf_LSI = training_tfidf_LSI.ix[indices]\n",
    "# ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 9.06 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wv_sc = StandardScaler()\n",
    "fs_sc = StandardScaler()\n",
    "\n",
    "tfidf_wv_sc = StandardScaler()\n",
    "tfidf_fs_sc = StandardScaler()\n",
    "tfidf_lsi_sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.99 s, sys: 64 ms, total: 2.06 s\n",
      "Wall time: 2.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "maxlen = 500\n",
    "\n",
    "\n",
    "def build_target(y, size):\n",
    "    e = np.zeros(size)\n",
    "    e[y] = 1\n",
    "    return e\n",
    "\n",
    "\n",
    "def build_input_output_data(X, WV, FS, TWV, TFS, TLSI, Y, maxlen):\n",
    "    x = sequence.pad_sequences(X, maxlen=maxlen)\n",
    "    y = np.vstack(Y.map(lambda x: build_target(x, len(topics))))\n",
    "\n",
    "    wv = np.vstack(WV)\n",
    "    fs = np.vstack(FS)\n",
    "\n",
    "    twv = np.vstack(TWV)\n",
    "    tfs = np.vstack(TFS)\n",
    "    tlsi = np.vstack(TLSI)\n",
    "\n",
    "    return x, wv, fs, twv, tfs, tlsi, y\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "train_ix = training_Y.index.str.contains('^201[2-4]')\n",
    "val_ix = training_Y.index.str.contains('^2014[b]')\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "x_train, wv_train, fs_train, tfidf_wv_train, tfidf_fs_train, tfidf_lsi_train, y_train = build_input_output_data(\n",
    "    training_X.ix[train_ix],\n",
    "\n",
    "    training_WV.ix[train_ix],\n",
    "    training_FS.ix[train_ix],\n",
    "\n",
    "    training_tfidf_WV.ix[train_ix],\n",
    "    training_tfidf_FS.ix[train_ix],\n",
    "    training_tfidf_LSI.ix[train_ix],\n",
    "\n",
    "    training_Y.ix[train_ix],\n",
    "    maxlen=maxlen\n",
    ")\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "x_val, wv_val, fs_val, tfidf_wv_val, tfidf_fs_val, tfidf_lsi_val, y_val = build_input_output_data(\n",
    "    training_X.ix[val_ix],\n",
    "\n",
    "    training_WV.ix[val_ix],\n",
    "    training_FS.ix[val_ix],\n",
    "\n",
    "    training_tfidf_WV.ix[val_ix],\n",
    "    training_tfidf_FS.ix[val_ix],\n",
    "    training_tfidf_LSI.ix[val_ix],\n",
    "\n",
    "    training_Y.ix[val_ix],\n",
    "    maxlen=maxlen\n",
    ")\n",
    "# ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "train_test_x_train, train_test_wv_train, train_test_fs_train, train_test_tfidf_wv_train, train_test_tfidf_fs_train, train_test_tfidf_lsi_train, train_test_y_train = build_input_output_data(\n",
    "    train_test_word_indices,\n",
    "\n",
    "    train_test_wvec,\n",
    "    train_test_fvec,\n",
    "\n",
    "    train_test_tfidf_wvec,\n",
    "    train_test_tfidf_fvec,\n",
    "    train_test_tfidf_lsi,\n",
    "\n",
    "    train_test_y,\n",
    "    maxlen=maxlen\n",
    ")\n",
    "# ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def upsample(x, N=3):\n",
    "    return np.vstack([x for i in xrange(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.vstack([x_train, upsample(train_test_x_train)])\n",
    "\n",
    "wv_train = np.vstack([wv_train, upsample(train_test_wv_train)])\n",
    "fs_train = np.vstack([fs_train, upsample(train_test_fs_train)])\n",
    "\n",
    "tfidf_wv_train = np.vstack([tfidf_wv_train, upsample(train_test_tfidf_wv_train)])\n",
    "tfidf_fs_train = np.vstack([tfidf_fs_train, upsample(train_test_tfidf_fs_train)])\n",
    "tfidf_lsi_train = np.vstack([tfidf_lsi_train, upsample(train_test_tfidf_lsi_train)])\n",
    "\n",
    "y_train = np.vstack([y_train, upsample(train_test_y_train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "wv_train = wv_sc.fit_transform(wv_train)\n",
    "fs_train = fs_sc.fit_transform(fs_train)\n",
    "\n",
    "tfidf_wv_train = tfidf_wv_sc.fit_transform(tfidf_wv_train)\n",
    "tfidf_fs_train = tfidf_fs_sc.fit_transform(tfidf_fs_train)\n",
    "tfidf_lsi_train = tfidf_lsi_sc.fit_transform(tfidf_lsi_train)\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "wv_val = wv_sc.transform(wv_val)\n",
    "fs_val = fs_sc.transform(fs_val)\n",
    "\n",
    "tfidf_wv_val = tfidf_wv_sc.transform(tfidf_wv_val)\n",
    "tfidf_fs_val = tfidf_fs_sc.transform(tfidf_fs_val)\n",
    "tfidf_lsi_val = tfidf_lsi_sc.transform(tfidf_lsi_val)\n",
    "# ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((94731,), (9424,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_Y.shape, training_Y.ix[training_Y.index.str.contains('^2014[b]')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = pd.DataFrame(y_train, columns=topics).sum()  #, index=training_Y.ix[train_ix].index).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "afghanistan                              1430.0\n",
       "aid                                      1179.0\n",
       "algerianhostagecrisis                      58.0\n",
       "alqaida                                   641.0\n",
       "alshabaab                                 116.0\n",
       "antiwar                                    10.0\n",
       "arabandmiddleeastprotests                1474.0\n",
       "armstrade                                 239.0\n",
       "australianguncontrol                        3.0\n",
       "australiansecurityandcounterterrorism      92.0\n",
       "bastilledaytruckattack                     21.0\n",
       "belgium                                   118.0\n",
       "berlinchristmasmarketattack                15.0\n",
       "bigdata                                   141.0\n",
       "biometrics                                 22.0\n",
       "bokoharam                                 172.0\n",
       "bostonmarathonbombing                     178.0\n",
       "britisharmy                               226.0\n",
       "brusselsattacks                            45.0\n",
       "cameroon                                   46.0\n",
       "carers                                    135.0\n",
       "charliehebdoattack                         45.0\n",
       "chemicalweapons                           206.0\n",
       "clusterbombs                                6.0\n",
       "cobra                                      23.0\n",
       "conflictanddevelopment                    504.0\n",
       "controversy                                33.0\n",
       "criminaljustice                          1464.0\n",
       "cybercrime                                300.0\n",
       "cyberwar                                   73.0\n",
       "                                          ...  \n",
       "somalia                                   376.0\n",
       "southafrica                              1136.0\n",
       "southchinasea                              13.0\n",
       "stopandsearch                              47.0\n",
       "surveillance                             1468.0\n",
       "sydneysiege                                42.0\n",
       "syria                                    2848.0\n",
       "taliban                                   486.0\n",
       "terrorism                                 454.0\n",
       "thailand                                  269.0\n",
       "torture                                   421.0\n",
       "traincrashes                               28.0\n",
       "transport                                1687.0\n",
       "tunisiaattack2015                          45.0\n",
       "turkey                                    609.0\n",
       "turkeycoupattempt                          45.0\n",
       "ukcrime                                  3246.0\n",
       "uksecurity                               1211.0\n",
       "uksupremecourt                            145.0\n",
       "undercoverpoliceandpolicing               148.0\n",
       "unitednations                            1820.0\n",
       "usguncontrol                              401.0\n",
       "values                                     18.0\n",
       "warcrimes                                 272.0\n",
       "warreporting                              110.0\n",
       "weaponstechnology                          74.0\n",
       "womeninbusiness                           182.0\n",
       "woolwichattack                            141.0\n",
       "worldmigration                            176.0\n",
       "zikavirus                                  12.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[q > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as K\n",
    "import keras.backend as KB\n",
    "\n",
    "\n",
    "def f1_micro(y_true, y_pred):\n",
    "    TP = K.metrics.true_positives(y_true, K.round(y_pred))\n",
    "    FP = K.metrics.false_positives(y_true, K.round(y_pred))\n",
    "    FN = K.metrics.false_negatives(y_true, K.round(y_pred))\n",
    "    \n",
    "    p = K.reduce_sum(TP) / (K.reduce_sum(TP) + K.reduce_sum(FP))\n",
    "    r = K.reduce_sum(TP) / (K.reduce_sum(TP) + K.reduce_sum(FN))\n",
    "    \n",
    "    return (2.0 * p * r) / (p + r)\n",
    "\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "\n",
    "    # Count positive samples.\n",
    "    c1 = KB.sum(KB.round(KB.clip(y_true * y_pred, 0, 1)))\n",
    "    c2 = KB.sum(KB.round(KB.clip(y_pred, 0, 1)))\n",
    "    c3 = KB.sum(KB.round(KB.clip(y_true, 0, 1)))\n",
    "\n",
    "    # If there are no true samples, fix the F1 score at 0.\n",
    "    if c3 == 0:\n",
    "        return 0\n",
    "\n",
    "    # How many selected items are relevant?\n",
    "    precision = c1 / c2\n",
    "\n",
    "    # How many relevant items are selected?\n",
    "    recall = c1 / c3\n",
    "\n",
    "    # Calculate f1_score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense, Dropout, Convolution1D, MaxPooling1D, Flatten\n",
    "from keras.models import Model\n",
    "import itertools as it\n",
    "\n",
    "\n",
    "def build_deep_input_stack(input_node):\n",
    "    x = Dense(128, activation='tanh')(input_node)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(256, activation='relu')(input_node)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def entangle_inputs(input_nodes=[]):\n",
    "    assert(len(input_nodes) > 1)\n",
    "    \n",
    "    entangled_inputs = []\n",
    "\n",
    "    for n1, n2 in it.combinations(input_nodes, 2):\n",
    "        entangled_inputs.append(\n",
    "            keras.layers.dot([n1, n2], 1, normalize=True)\n",
    "        )\n",
    "    \n",
    "    return entangled_inputs\n",
    "\n",
    "\n",
    "wv_input = Input(shape=(300,), name='wv_input')\n",
    "fs_input = Input(shape=(300,), name='fs_input')\n",
    "\n",
    "tfidf_wv_input = Input(shape=(300,), name='tfidf_wv_input')\n",
    "tfidf_fs_input = Input(shape=(300,), name='tfidf_fs_input')\n",
    "tfidf_lsi_input = Input(shape=(300,), name='tfidf_lsi_input')\n",
    "\n",
    "\n",
    "wv_x = build_deep_input_stack(wv_input)\n",
    "fs_x = build_deep_input_stack(fs_input)\n",
    "tfidf_wv_x = build_deep_input_stack(tfidf_wv_input)\n",
    "tfidf_fs_x = build_deep_input_stack(tfidf_fs_input)\n",
    "tfidf_lsi_x = build_deep_input_stack(tfidf_wv_input)\n",
    "\n",
    "stacked_inputs_x = [wv_x, fs_x, tfidf_wv_x, tfidf_fs_x, tfidf_lsi_x]\n",
    "# stacked_inputs_x = [tfidf_wv_x, tfidf_fs_x, tfidf_lsi_x]\n",
    "entangled_inputs_x = entangle_inputs(stacked_inputs_x)\n",
    "\n",
    "x = keras.layers.concatenate(stacked_inputs_x + entangled_inputs_x)\n",
    "\n",
    "# We stack a deep densely-connected network on top\n",
    "x = Dense(128, activation='tanh')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "# And finally we add the main logistic regression layer\n",
    "main_output = Dense(len(class2ind), activation='sigmoid', name='main_output')(x)\n",
    "\n",
    "model = Model(\n",
    "    inputs=[\n",
    "        wv_input,\n",
    "        fs_input,\n",
    "        tfidf_wv_input,\n",
    "        tfidf_fs_input,\n",
    "        tfidf_lsi_input,\n",
    "    ],\n",
    "    outputs=[main_output]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'dot_1/ExpandDims:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'dot_2/ExpandDims:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'dot_3/ExpandDims:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'dot_4/ExpandDims:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'dot_5/ExpandDims:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'dot_6/ExpandDims:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'dot_7/ExpandDims:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'dot_8/ExpandDims:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'dot_9/ExpandDims:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'dot_10/ExpandDims:0' shape=(?, 1) dtype=float32>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entangled_inputs_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "wv_input (InputLayer)            (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "fs_input (InputLayer)            (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "tfidf_wv_input (InputLayer)      (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "tfidf_fs_input (InputLayer)      (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 256)           77056                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 256)           77056                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 256)           77056                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_11 (Dense)                 (None, 256)           77056                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_14 (Dense)                 (None, 256)           77056                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)             (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)             (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 512)           131584                                       \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 512)           131584                                       \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 512)           131584                                       \n",
      "____________________________________________________________________________________________________\n",
      "dense_12 (Dense)                 (None, 512)           131584                                       \n",
      "____________________________________________________________________________________________________\n",
      "dense_15 (Dense)                 (None, 512)           131584                                       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)             (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)             (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_1 (Dot)                      (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_2 (Dot)                      (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_3 (Dot)                      (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_4 (Dot)                      (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_5 (Dot)                      (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_6 (Dot)                      (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_7 (Dot)                      (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_8 (Dot)                      (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_9 (Dot)                      (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_10 (Dot)                     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 2570)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_16 (Dense)                 (None, 128)           329088                                       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)             (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_17 (Dense)                 (None, 256)           33024                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)             (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_18 (Dense)                 (None, 256)           65792                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)             (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_19 (Dense)                 (None, 128)           32896                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)             (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 160)           20640                                        \n",
      "====================================================================================================\n",
      "Total params: 1,524,640\n",
      "Trainable params: 1,524,640\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='rmsprop',  # keras.optimizers.RMSprop(lr=0.005),  # , rho=0.9, epsilon=1e-08, decay=0.0, clipnorm=1),\n",
    "    loss={'main_output': 'categorical_crossentropy'},\n",
    "    loss_weights={'main_output': 1.},\n",
    "    metrics=['accuracy', f1_micro]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.callbacks import EarlyStopping\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "# model.fit(X, y, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_training_inputs(wv, fs, tfidf_wv, tfidf_fs, tfidf_lsi):\n",
    "    training_inputs = {\n",
    "        'wv_input': wv,\n",
    "        'fs_input': fs,\n",
    "        'tfidf_wv_input': tfidf_wv,\n",
    "        'tfidf_fs_input': tfidf_fs,\n",
    "        'tfidf_lsi_input': tfidf_lsi,\n",
    "    }\n",
    "    \n",
    "    return training_inputs\n",
    "    \n",
    "\n",
    "training_inputs = build_training_inputs(\n",
    "    wv_train,\n",
    "    fs_train,\n",
    "    tfidf_wv_train,\n",
    "    tfidf_fs_train,\n",
    "    tfidf_lsi_train,\n",
    ")\n",
    "\n",
    "training_outputs = {\n",
    "    'main_output': y_train,\n",
    "}\n",
    "\n",
    "# train_test_shape = train_test_df.shape[0]\n",
    "# train_test_training_inputs = build_training_inputs(\n",
    "#     wv_train[-train_test_shape:],\n",
    "#     fs_train[-train_test_shape:],\n",
    "#     tfidf_wv_train[-train_test_shape:],\n",
    "#     tfidf_fs_train[-train_test_shape:],\n",
    "#     tfidf_lsi_train[-train_test_shape:],\n",
    "# )\n",
    "\n",
    "# train_test_training_outputs = {\n",
    "#     'main_output': y_train[-train_test_shape:],\n",
    "# }\n",
    "\n",
    "\n",
    "validation_data=(\n",
    "    build_training_inputs(\n",
    "        wv_val,\n",
    "        fs_val,\n",
    "        tfidf_wv_val,\n",
    "        tfidf_fs_val,\n",
    "        tfidf_lsi_val,\n",
    "    ),\n",
    "    {\n",
    "        'main_output': y_val,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/100\n",
      "56877/56877 [==============================] - 2s - loss: 5.6404 - acc: 0.1295 - f1_micro: 0.0630 - val_loss: 4.1946 - val_acc: 0.3277 - val_f1_micro: 0.0990\n",
      "Epoch 2/100\n",
      "56877/56877 [==============================] - 1s - loss: 3.7813 - acc: 0.4165 - f1_micro: 0.1261 - val_loss: 3.1512 - val_acc: 0.5209 - val_f1_micro: 0.1516\n",
      "Epoch 3/100\n",
      "56877/56877 [==============================] - 1s - loss: 3.1480 - acc: 0.5158 - f1_micro: 0.1753 - val_loss: 2.7997 - val_acc: 0.5892 - val_f1_micro: 0.1980\n",
      "Epoch 4/100\n",
      "56877/56877 [==============================] - 1s - loss: 2.8541 - acc: 0.5558 - f1_micro: 0.2187 - val_loss: 2.6495 - val_acc: 0.5999 - val_f1_micro: 0.2385\n",
      "Epoch 5/100\n",
      "56877/56877 [==============================] - 1s - loss: 2.6869 - acc: 0.5808 - f1_micro: 0.2566 - val_loss: 2.5518 - val_acc: 0.6065 - val_f1_micro: 0.2741\n",
      "Epoch 6/100\n",
      "56877/56877 [==============================] - 1s - loss: 2.5511 - acc: 0.5954 - f1_micro: 0.2900 - val_loss: 2.3708 - val_acc: 0.6306 - val_f1_micro: 0.3053\n",
      "Epoch 7/100\n",
      "56877/56877 [==============================] - 1s - loss: 2.4586 - acc: 0.6088 - f1_micro: 0.3193 - val_loss: 2.3108 - val_acc: 0.6431 - val_f1_micro: 0.3327\n",
      "Epoch 8/100\n",
      "56877/56877 [==============================] - 1s - loss: 2.3755 - acc: 0.6179 - f1_micro: 0.3452 - val_loss: 2.1896 - val_acc: 0.6567 - val_f1_micro: 0.3571\n",
      "Epoch 9/100\n",
      "56877/56877 [==============================] - 1s - loss: 2.3023 - acc: 0.6271 - f1_micro: 0.3682 - val_loss: 2.1465 - val_acc: 0.6615 - val_f1_micro: 0.3789\n",
      "Epoch 10/100\n",
      "56877/56877 [==============================] - 1s - loss: 2.2377 - acc: 0.6333 - f1_micro: 0.3891 - val_loss: 2.1382 - val_acc: 0.6708 - val_f1_micro: 0.3988\n",
      "Epoch 11/100\n",
      "56877/56877 [==============================] - 1s - loss: 2.1920 - acc: 0.6402 - f1_micro: 0.4080 - val_loss: 2.1051 - val_acc: 0.6756 - val_f1_micro: 0.4168\n",
      "Epoch 12/100\n",
      "56877/56877 [==============================] - 1s - loss: 2.1432 - acc: 0.6465 - f1_micro: 0.4251 - val_loss: 1.9697 - val_acc: 0.6837 - val_f1_micro: 0.4331\n",
      "Epoch 13/100\n",
      "56877/56877 [==============================] - 1s - loss: 2.0887 - acc: 0.6523 - f1_micro: 0.4406 - val_loss: 1.9223 - val_acc: 0.6992 - val_f1_micro: 0.4481\n",
      "Epoch 14/100\n",
      "56877/56877 [==============================] - 1s - loss: 2.0522 - acc: 0.6583 - f1_micro: 0.4551 - val_loss: 1.8829 - val_acc: 0.7047 - val_f1_micro: 0.4618\n",
      "Epoch 15/100\n",
      "56877/56877 [==============================] - 1s - loss: 2.0116 - acc: 0.6612 - f1_micro: 0.4683 - val_loss: 1.8680 - val_acc: 0.7192 - val_f1_micro: 0.4746\n",
      "Epoch 16/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.9790 - acc: 0.6668 - f1_micro: 0.4805 - val_loss: 1.8019 - val_acc: 0.7110 - val_f1_micro: 0.4863\n",
      "Epoch 17/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.9499 - acc: 0.6721 - f1_micro: 0.4918 - val_loss: 1.8239 - val_acc: 0.7089 - val_f1_micro: 0.4972\n",
      "Epoch 18/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.9208 - acc: 0.6728 - f1_micro: 0.5023 - val_loss: 1.7340 - val_acc: 0.7261 - val_f1_micro: 0.5073\n",
      "Epoch 19/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.8874 - acc: 0.6776 - f1_micro: 0.5121 - val_loss: 1.7189 - val_acc: 0.7245 - val_f1_micro: 0.5168\n",
      "Epoch 20/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.8726 - acc: 0.6796 - f1_micro: 0.5214 - val_loss: 1.6813 - val_acc: 0.7228 - val_f1_micro: 0.5258\n",
      "Epoch 21/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.8357 - acc: 0.6828 - f1_micro: 0.5301 - val_loss: 1.6496 - val_acc: 0.7271 - val_f1_micro: 0.5342\n",
      "Epoch 22/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.8160 - acc: 0.6878 - f1_micro: 0.5383 - val_loss: 1.6317 - val_acc: 0.7382 - val_f1_micro: 0.5422\n",
      "Epoch 23/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.7930 - acc: 0.6899 - f1_micro: 0.5460 - val_loss: 1.6268 - val_acc: 0.7402 - val_f1_micro: 0.5498\n",
      "Epoch 24/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.7774 - acc: 0.6911 - f1_micro: 0.5534 - val_loss: 1.5830 - val_acc: 0.7416 - val_f1_micro: 0.5570\n",
      "Epoch 25/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.7573 - acc: 0.6953 - f1_micro: 0.5604 - val_loss: 1.5704 - val_acc: 0.7396 - val_f1_micro: 0.5637\n",
      "Epoch 26/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.7369 - acc: 0.6979 - f1_micro: 0.5669 - val_loss: 1.5657 - val_acc: 0.7476 - val_f1_micro: 0.5701\n",
      "Epoch 27/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.7205 - acc: 0.6990 - f1_micro: 0.5732 - val_loss: 1.5073 - val_acc: 0.7414 - val_f1_micro: 0.5763\n",
      "Epoch 28/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.6999 - acc: 0.7019 - f1_micro: 0.5792 - val_loss: 1.5218 - val_acc: 0.7404 - val_f1_micro: 0.5821\n",
      "Epoch 29/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.6951 - acc: 0.7019 - f1_micro: 0.5849 - val_loss: 1.4885 - val_acc: 0.7524 - val_f1_micro: 0.5877\n",
      "Epoch 30/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.6787 - acc: 0.7037 - f1_micro: 0.5904 - val_loss: 1.4929 - val_acc: 0.7438 - val_f1_micro: 0.5931\n",
      "Epoch 31/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.6570 - acc: 0.7059 - f1_micro: 0.5958 - val_loss: 1.4521 - val_acc: 0.7511 - val_f1_micro: 0.5983\n",
      "Epoch 32/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.6424 - acc: 0.7092 - f1_micro: 0.6008 - val_loss: 1.4641 - val_acc: 0.7521 - val_f1_micro: 0.6033\n",
      "Epoch 33/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.6298 - acc: 0.7109 - f1_micro: 0.6057 - val_loss: 1.4521 - val_acc: 0.7514 - val_f1_micro: 0.6081\n",
      "Epoch 34/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.6208 - acc: 0.7110 - f1_micro: 0.6104 - val_loss: 1.4334 - val_acc: 0.7568 - val_f1_micro: 0.6127\n",
      "Epoch 35/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.6077 - acc: 0.7124 - f1_micro: 0.6149 - val_loss: 1.4038 - val_acc: 0.7555 - val_f1_micro: 0.6171\n",
      "Epoch 36/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.6030 - acc: 0.7131 - f1_micro: 0.6192 - val_loss: 1.3800 - val_acc: 0.7582 - val_f1_micro: 0.6213\n",
      "Epoch 37/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.5885 - acc: 0.7126 - f1_micro: 0.6234 - val_loss: 1.3864 - val_acc: 0.7496 - val_f1_micro: 0.6254\n",
      "Epoch 38/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.5760 - acc: 0.7159 - f1_micro: 0.6275 - val_loss: 1.3885 - val_acc: 0.7646 - val_f1_micro: 0.6294\n",
      "Epoch 39/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.5682 - acc: 0.7171 - f1_micro: 0.6314 - val_loss: 1.3642 - val_acc: 0.7592 - val_f1_micro: 0.6333\n",
      "Epoch 40/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.5613 - acc: 0.7180 - f1_micro: 0.6352 - val_loss: 1.3606 - val_acc: 0.7565 - val_f1_micro: 0.6370\n",
      "Epoch 41/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.5463 - acc: 0.7204 - f1_micro: 0.6388 - val_loss: 1.3740 - val_acc: 0.7575 - val_f1_micro: 0.6406\n",
      "Epoch 42/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.5443 - acc: 0.7210 - f1_micro: 0.6424 - val_loss: 1.3951 - val_acc: 0.7689 - val_f1_micro: 0.6441\n",
      "Epoch 43/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.5268 - acc: 0.7213 - f1_micro: 0.6458 - val_loss: 1.3374 - val_acc: 0.7696 - val_f1_micro: 0.6475\n",
      "Epoch 44/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.5233 - acc: 0.7232 - f1_micro: 0.6491 - val_loss: 1.3425 - val_acc: 0.7611 - val_f1_micro: 0.6508\n",
      "Epoch 45/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.5168 - acc: 0.7248 - f1_micro: 0.6524 - val_loss: 1.3392 - val_acc: 0.7650 - val_f1_micro: 0.6539\n",
      "Epoch 46/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.5109 - acc: 0.7235 - f1_micro: 0.6555 - val_loss: 1.3397 - val_acc: 0.7631 - val_f1_micro: 0.6570\n",
      "Epoch 47/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4998 - acc: 0.7247 - f1_micro: 0.6585 - val_loss: 1.3114 - val_acc: 0.7652 - val_f1_micro: 0.6600\n",
      "Epoch 48/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4930 - acc: 0.7285 - f1_micro: 0.6615 - val_loss: 1.3118 - val_acc: 0.7689 - val_f1_micro: 0.6630\n",
      "Epoch 49/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4887 - acc: 0.7296 - f1_micro: 0.6644 - val_loss: 1.2826 - val_acc: 0.7680 - val_f1_micro: 0.6658\n",
      "Epoch 50/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4791 - acc: 0.7281 - f1_micro: 0.6672 - val_loss: 1.2895 - val_acc: 0.7756 - val_f1_micro: 0.6686\n",
      "Epoch 51/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4730 - acc: 0.7298 - f1_micro: 0.6699 - val_loss: 1.2936 - val_acc: 0.7744 - val_f1_micro: 0.6713\n",
      "Epoch 52/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4653 - acc: 0.7306 - f1_micro: 0.6726 - val_loss: 1.2800 - val_acc: 0.7640 - val_f1_micro: 0.6740\n",
      "Epoch 53/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4590 - acc: 0.7289 - f1_micro: 0.6752 - val_loss: 1.2692 - val_acc: 0.7768 - val_f1_micro: 0.6765\n",
      "Epoch 54/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4517 - acc: 0.7303 - f1_micro: 0.6778 - val_loss: 1.3135 - val_acc: 0.7703 - val_f1_micro: 0.6790\n",
      "Epoch 55/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4543 - acc: 0.7304 - f1_micro: 0.6802 - val_loss: 1.2498 - val_acc: 0.7795 - val_f1_micro: 0.6815\n",
      "Epoch 56/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4456 - acc: 0.7319 - f1_micro: 0.6827 - val_loss: 1.2449 - val_acc: 0.7747 - val_f1_micro: 0.6839\n",
      "Epoch 57/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4411 - acc: 0.7336 - f1_micro: 0.6850 - val_loss: 1.2457 - val_acc: 0.7698 - val_f1_micro: 0.6862\n",
      "Epoch 58/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4376 - acc: 0.7335 - f1_micro: 0.6873 - val_loss: 1.2457 - val_acc: 0.7742 - val_f1_micro: 0.6884\n",
      "Epoch 59/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4295 - acc: 0.7349 - f1_micro: 0.6895 - val_loss: 1.2491 - val_acc: 0.7744 - val_f1_micro: 0.6906\n",
      "Epoch 60/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4228 - acc: 0.7356 - f1_micro: 0.6917 - val_loss: 1.2421 - val_acc: 0.7783 - val_f1_micro: 0.6928\n",
      "Epoch 61/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4227 - acc: 0.7354 - f1_micro: 0.6939 - val_loss: 1.2435 - val_acc: 0.7796 - val_f1_micro: 0.6950\n",
      "Epoch 62/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4155 - acc: 0.7360 - f1_micro: 0.6960 - val_loss: 1.2198 - val_acc: 0.7834 - val_f1_micro: 0.6970\n",
      "Epoch 63/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4083 - acc: 0.7358 - f1_micro: 0.6981 - val_loss: 1.2469 - val_acc: 0.7721 - val_f1_micro: 0.6991\n",
      "Epoch 64/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4036 - acc: 0.7366 - f1_micro: 0.7001 - val_loss: 1.2229 - val_acc: 0.7748 - val_f1_micro: 0.7011\n",
      "Epoch 65/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4054 - acc: 0.7383 - f1_micro: 0.7021 - val_loss: 1.2041 - val_acc: 0.7773 - val_f1_micro: 0.7031\n",
      "Epoch 66/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3998 - acc: 0.7376 - f1_micro: 0.7040 - val_loss: 1.2115 - val_acc: 0.7792 - val_f1_micro: 0.7050\n",
      "Epoch 67/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3930 - acc: 0.7404 - f1_micro: 0.7059 - val_loss: 1.2043 - val_acc: 0.7778 - val_f1_micro: 0.7068\n",
      "Epoch 68/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3895 - acc: 0.7397 - f1_micro: 0.7078 - val_loss: 1.1914 - val_acc: 0.7813 - val_f1_micro: 0.7087\n",
      "Epoch 69/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3938 - acc: 0.7393 - f1_micro: 0.7096 - val_loss: 1.1918 - val_acc: 0.7822 - val_f1_micro: 0.7105\n",
      "Epoch 70/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3857 - acc: 0.7397 - f1_micro: 0.7114 - val_loss: 1.2017 - val_acc: 0.7771 - val_f1_micro: 0.7123\n",
      "Epoch 71/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3805 - acc: 0.7413 - f1_micro: 0.7132 - val_loss: 1.1931 - val_acc: 0.7767 - val_f1_micro: 0.7140\n",
      "Epoch 72/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3809 - acc: 0.7411 - f1_micro: 0.7149 - val_loss: 1.2091 - val_acc: 0.7831 - val_f1_micro: 0.7157\n",
      "Epoch 73/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3682 - acc: 0.7403 - f1_micro: 0.7166 - val_loss: 1.1941 - val_acc: 0.7932 - val_f1_micro: 0.7174\n",
      "Epoch 74/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3683 - acc: 0.7419 - f1_micro: 0.7182 - val_loss: 1.1811 - val_acc: 0.7812 - val_f1_micro: 0.7191\n",
      "Epoch 75/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3721 - acc: 0.7426 - f1_micro: 0.7199 - val_loss: 1.1899 - val_acc: 0.7761 - val_f1_micro: 0.7207\n",
      "Epoch 76/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3683 - acc: 0.7408 - f1_micro: 0.7215 - val_loss: 1.1780 - val_acc: 0.7801 - val_f1_micro: 0.7223\n",
      "Epoch 77/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3572 - acc: 0.7437 - f1_micro: 0.7230 - val_loss: 1.1876 - val_acc: 0.7814 - val_f1_micro: 0.7238\n",
      "Epoch 78/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3595 - acc: 0.7445 - f1_micro: 0.7246 - val_loss: 1.1676 - val_acc: 0.7879 - val_f1_micro: 0.7253\n",
      "Epoch 79/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3523 - acc: 0.7445 - f1_micro: 0.7261 - val_loss: 1.1776 - val_acc: 0.7819 - val_f1_micro: 0.7268\n",
      "Epoch 80/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3525 - acc: 0.7461 - f1_micro: 0.7276 - val_loss: 1.1738 - val_acc: 0.7864 - val_f1_micro: 0.7283\n",
      "Epoch 81/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3474 - acc: 0.7418 - f1_micro: 0.7290 - val_loss: 1.1634 - val_acc: 0.7863 - val_f1_micro: 0.7298\n",
      "Epoch 82/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3495 - acc: 0.7447 - f1_micro: 0.7305 - val_loss: 1.1804 - val_acc: 0.7826 - val_f1_micro: 0.7312\n",
      "Epoch 83/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3383 - acc: 0.7443 - f1_micro: 0.7319 - val_loss: 1.1503 - val_acc: 0.7883 - val_f1_micro: 0.7326\n",
      "Epoch 84/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3386 - acc: 0.7444 - f1_micro: 0.7333 - val_loss: 1.1617 - val_acc: 0.7876 - val_f1_micro: 0.7340\n",
      "Epoch 85/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3351 - acc: 0.7448 - f1_micro: 0.7347 - val_loss: 1.1669 - val_acc: 0.7867 - val_f1_micro: 0.7354\n",
      "Epoch 86/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3314 - acc: 0.7457 - f1_micro: 0.7360 - val_loss: 1.1775 - val_acc: 0.7829 - val_f1_micro: 0.7367\n",
      "Epoch 87/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3332 - acc: 0.7452 - f1_micro: 0.7374 - val_loss: 1.1604 - val_acc: 0.7801 - val_f1_micro: 0.7380\n",
      "Epoch 88/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3254 - acc: 0.7472 - f1_micro: 0.7387 - val_loss: 1.1619 - val_acc: 0.7890 - val_f1_micro: 0.7393\n",
      "Epoch 89/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3288 - acc: 0.7457 - f1_micro: 0.7400 - val_loss: 1.1492 - val_acc: 0.7749 - val_f1_micro: 0.7406\n",
      "Epoch 90/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3286 - acc: 0.7466 - f1_micro: 0.7412 - val_loss: 1.1430 - val_acc: 0.7881 - val_f1_micro: 0.7418\n",
      "Epoch 91/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3195 - acc: 0.7482 - f1_micro: 0.7425 - val_loss: 1.1473 - val_acc: 0.7838 - val_f1_micro: 0.7431\n",
      "Epoch 92/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3193 - acc: 0.7469 - f1_micro: 0.7437 - val_loss: 1.1359 - val_acc: 0.7923 - val_f1_micro: 0.7443\n",
      "Epoch 93/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3191 - acc: 0.7494 - f1_micro: 0.7449 - val_loss: 1.1407 - val_acc: 0.7910 - val_f1_micro: 0.7455\n",
      "Epoch 94/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3190 - acc: 0.7478 - f1_micro: 0.7461 - val_loss: 1.1387 - val_acc: 0.7847 - val_f1_micro: 0.7467\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56877/56877 [==============================] - 1s - loss: 1.3139 - acc: 0.7469 - f1_micro: 0.7472 - val_loss: 1.1294 - val_acc: 0.7915 - val_f1_micro: 0.7478\n",
      "Epoch 96/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3169 - acc: 0.7473 - f1_micro: 0.7484 - val_loss: 1.1351 - val_acc: 0.7910 - val_f1_micro: 0.7489\n",
      "Epoch 97/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3075 - acc: 0.7506 - f1_micro: 0.7495 - val_loss: 1.1346 - val_acc: 0.7899 - val_f1_micro: 0.7501\n",
      "Epoch 98/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3036 - acc: 0.7492 - f1_micro: 0.7506 - val_loss: 1.1241 - val_acc: 0.7971 - val_f1_micro: 0.7512\n",
      "Epoch 99/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3050 - acc: 0.7491 - f1_micro: 0.7517 - val_loss: 1.1459 - val_acc: 0.7855 - val_f1_micro: 0.7523\n",
      "Epoch 100/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3031 - acc: 0.7482 - f1_micro: 0.7528 - val_loss: 1.1262 - val_acc: 0.7870 - val_f1_micro: 0.7534\n",
      "CPU times: user 2min 34s, sys: 25.2 s, total: 2min 59s\n",
      "Wall time: 2min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# And trained it via:\n",
    "batch_size = 1000\n",
    "epochs = 100\n",
    "\n",
    "hist = model.fit(\n",
    "    training_inputs,\n",
    "    training_outputs,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    validation_data=validation_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 57243 samples, validate on 9424 samples\n",
      "Epoch 1/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.2080 - acc: 0.7683 - f1_micro: 0.8133 - val_loss: 1.0572 - val_acc: 0.8016 - val_f1_micro: 0.8135\n",
      "Epoch 2/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.2059 - acc: 0.7668 - f1_micro: 0.8137 - val_loss: 1.0453 - val_acc: 0.8065 - val_f1_micro: 0.8139\n",
      "Epoch 3/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.2065 - acc: 0.7687 - f1_micro: 0.8141 - val_loss: 1.0555 - val_acc: 0.8072 - val_f1_micro: 0.8142\n",
      "Epoch 4/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.2085 - acc: 0.7660 - f1_micro: 0.8144 - val_loss: 1.0707 - val_acc: 0.8053 - val_f1_micro: 0.8146\n",
      "Epoch 5/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.2048 - acc: 0.7692 - f1_micro: 0.8148 - val_loss: 1.0500 - val_acc: 0.8007 - val_f1_micro: 0.8150\n",
      "Epoch 6/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.2051 - acc: 0.7678 - f1_micro: 0.8151 - val_loss: 1.0581 - val_acc: 0.7953 - val_f1_micro: 0.8153\n",
      "Epoch 7/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.2049 - acc: 0.7683 - f1_micro: 0.8155 - val_loss: 1.0535 - val_acc: 0.7980 - val_f1_micro: 0.8157\n",
      "Epoch 8/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.2004 - acc: 0.7660 - f1_micro: 0.8159 - val_loss: 1.0574 - val_acc: 0.8020 - val_f1_micro: 0.8161\n",
      "Epoch 9/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.2045 - acc: 0.7678 - f1_micro: 0.8162 - val_loss: 1.0462 - val_acc: 0.8020 - val_f1_micro: 0.8164\n",
      "Epoch 10/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.2000 - acc: 0.7675 - f1_micro: 0.8166 - val_loss: 1.0657 - val_acc: 0.7998 - val_f1_micro: 0.8168\n",
      "Epoch 11/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.2029 - acc: 0.7694 - f1_micro: 0.8169 - val_loss: 1.0571 - val_acc: 0.8088 - val_f1_micro: 0.8171\n",
      "Epoch 12/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.2018 - acc: 0.7707 - f1_micro: 0.8173 - val_loss: 1.0431 - val_acc: 0.8057 - val_f1_micro: 0.8175\n",
      "Epoch 13/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.2032 - acc: 0.7678 - f1_micro: 0.8176 - val_loss: 1.0390 - val_acc: 0.8042 - val_f1_micro: 0.8178\n",
      "Epoch 14/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.2027 - acc: 0.7685 - f1_micro: 0.8180 - val_loss: 1.0696 - val_acc: 0.8077 - val_f1_micro: 0.8182\n",
      "Epoch 15/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.2059 - acc: 0.7689 - f1_micro: 0.8183 - val_loss: 1.0454 - val_acc: 0.8067 - val_f1_micro: 0.8185\n",
      "Epoch 16/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1987 - acc: 0.7681 - f1_micro: 0.8187 - val_loss: 1.0593 - val_acc: 0.8006 - val_f1_micro: 0.8188\n",
      "Epoch 17/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.2048 - acc: 0.7679 - f1_micro: 0.8190 - val_loss: 1.0598 - val_acc: 0.8009 - val_f1_micro: 0.8192\n",
      "Epoch 18/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.2006 - acc: 0.7683 - f1_micro: 0.8193 - val_loss: 1.0493 - val_acc: 0.8041 - val_f1_micro: 0.8195\n",
      "Epoch 19/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1985 - acc: 0.7685 - f1_micro: 0.8197 - val_loss: 1.0588 - val_acc: 0.8051 - val_f1_micro: 0.8198\n",
      "Epoch 20/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1969 - acc: 0.7682 - f1_micro: 0.8200 - val_loss: 1.0418 - val_acc: 0.8019 - val_f1_micro: 0.8202\n",
      "Epoch 21/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.2010 - acc: 0.7676 - f1_micro: 0.8203 - val_loss: 1.0323 - val_acc: 0.8069 - val_f1_micro: 0.8205\n",
      "Epoch 22/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1998 - acc: 0.7697 - f1_micro: 0.8207 - val_loss: 1.0425 - val_acc: 0.7989 - val_f1_micro: 0.8208\n",
      "Epoch 23/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1993 - acc: 0.7690 - f1_micro: 0.8210 - val_loss: 1.0590 - val_acc: 0.8055 - val_f1_micro: 0.8211\n",
      "Epoch 24/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1994 - acc: 0.7705 - f1_micro: 0.8213 - val_loss: 1.0496 - val_acc: 0.8087 - val_f1_micro: 0.8215\n",
      "Epoch 25/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1987 - acc: 0.7703 - f1_micro: 0.8216 - val_loss: 1.0625 - val_acc: 0.8019 - val_f1_micro: 0.8218\n",
      "Epoch 26/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1955 - acc: 0.7694 - f1_micro: 0.8219 - val_loss: 1.0314 - val_acc: 0.8076 - val_f1_micro: 0.8221\n",
      "Epoch 27/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1962 - acc: 0.7720 - f1_micro: 0.8222 - val_loss: 1.0380 - val_acc: 0.8078 - val_f1_micro: 0.8224\n",
      "Epoch 28/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1977 - acc: 0.7717 - f1_micro: 0.8226 - val_loss: 1.0372 - val_acc: 0.8058 - val_f1_micro: 0.8227\n",
      "Epoch 29/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1999 - acc: 0.7697 - f1_micro: 0.8229 - val_loss: 1.0698 - val_acc: 0.8110 - val_f1_micro: 0.8230\n",
      "Epoch 30/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1917 - acc: 0.7701 - f1_micro: 0.8232 - val_loss: 1.0375 - val_acc: 0.8024 - val_f1_micro: 0.8233\n",
      "Epoch 31/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1942 - acc: 0.7691 - f1_micro: 0.8235 - val_loss: 1.0534 - val_acc: 0.8111 - val_f1_micro: 0.8236\n",
      "Epoch 32/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1945 - acc: 0.7698 - f1_micro: 0.8238 - val_loss: 1.0356 - val_acc: 0.8007 - val_f1_micro: 0.8239\n",
      "Epoch 33/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1939 - acc: 0.7705 - f1_micro: 0.8241 - val_loss: 1.0404 - val_acc: 0.8142 - val_f1_micro: 0.8242\n",
      "Epoch 34/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1898 - acc: 0.7701 - f1_micro: 0.8244 - val_loss: 1.0345 - val_acc: 0.8072 - val_f1_micro: 0.8245\n",
      "Epoch 35/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1924 - acc: 0.7687 - f1_micro: 0.8247 - val_loss: 1.0472 - val_acc: 0.8078 - val_f1_micro: 0.8249\n",
      "Epoch 36/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1898 - acc: 0.7680 - f1_micro: 0.8250 - val_loss: 1.0498 - val_acc: 0.8056 - val_f1_micro: 0.8251\n",
      "Epoch 37/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1894 - acc: 0.7707 - f1_micro: 0.8253 - val_loss: 1.0245 - val_acc: 0.8101 - val_f1_micro: 0.8254\n",
      "Epoch 38/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1968 - acc: 0.7700 - f1_micro: 0.8256 - val_loss: 1.0369 - val_acc: 0.8073 - val_f1_micro: 0.8257\n",
      "Epoch 39/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1976 - acc: 0.7693 - f1_micro: 0.8259 - val_loss: 1.0485 - val_acc: 0.8028 - val_f1_micro: 0.8260\n",
      "Epoch 40/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1946 - acc: 0.7706 - f1_micro: 0.8262 - val_loss: 1.0297 - val_acc: 0.8051 - val_f1_micro: 0.8263\n",
      "Epoch 41/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1908 - acc: 0.7717 - f1_micro: 0.8265 - val_loss: 1.0430 - val_acc: 0.8085 - val_f1_micro: 0.8266\n",
      "Epoch 42/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1914 - acc: 0.7728 - f1_micro: 0.8267 - val_loss: 1.0456 - val_acc: 0.8105 - val_f1_micro: 0.8269\n",
      "Epoch 43/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1903 - acc: 0.7703 - f1_micro: 0.8270 - val_loss: 1.0508 - val_acc: 0.8008 - val_f1_micro: 0.8272\n",
      "Epoch 44/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1837 - acc: 0.7695 - f1_micro: 0.8273 - val_loss: 1.0395 - val_acc: 0.8070 - val_f1_micro: 0.8274\n",
      "Epoch 45/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1900 - acc: 0.7715 - f1_micro: 0.8276 - val_loss: 1.0369 - val_acc: 0.8017 - val_f1_micro: 0.8277\n",
      "Epoch 46/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1903 - acc: 0.7712 - f1_micro: 0.8279 - val_loss: 1.0479 - val_acc: 0.8148 - val_f1_micro: 0.8280\n",
      "Epoch 47/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1897 - acc: 0.7697 - f1_micro: 0.8281 - val_loss: 1.0342 - val_acc: 0.7988 - val_f1_micro: 0.8283\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57243/57243 [==============================] - 1s - loss: 1.1954 - acc: 0.7709 - f1_micro: 0.8284 - val_loss: 1.0513 - val_acc: 0.8053 - val_f1_micro: 0.8285\n",
      "Epoch 49/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1933 - acc: 0.7710 - f1_micro: 0.8287 - val_loss: 1.0414 - val_acc: 0.8044 - val_f1_micro: 0.8288\n",
      "Epoch 50/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1954 - acc: 0.7713 - f1_micro: 0.8289 - val_loss: 1.0426 - val_acc: 0.8121 - val_f1_micro: 0.8291\n",
      "Epoch 51/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1902 - acc: 0.7701 - f1_micro: 0.8292 - val_loss: 1.0504 - val_acc: 0.8054 - val_f1_micro: 0.8293\n",
      "Epoch 52/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1941 - acc: 0.7728 - f1_micro: 0.8295 - val_loss: 1.0330 - val_acc: 0.8084 - val_f1_micro: 0.8296\n",
      "Epoch 53/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1895 - acc: 0.7703 - f1_micro: 0.8297 - val_loss: 1.0345 - val_acc: 0.8003 - val_f1_micro: 0.8299\n",
      "Epoch 54/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1917 - acc: 0.7720 - f1_micro: 0.8300 - val_loss: 1.0462 - val_acc: 0.8083 - val_f1_micro: 0.8301\n",
      "Epoch 55/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1896 - acc: 0.7717 - f1_micro: 0.8303 - val_loss: 1.0533 - val_acc: 0.8097 - val_f1_micro: 0.8304\n",
      "Epoch 56/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1923 - acc: 0.7708 - f1_micro: 0.8305 - val_loss: 1.0529 - val_acc: 0.8084 - val_f1_micro: 0.8306\n",
      "Epoch 57/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1878 - acc: 0.7694 - f1_micro: 0.8308 - val_loss: 1.0348 - val_acc: 0.8088 - val_f1_micro: 0.8309\n",
      "Epoch 58/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1913 - acc: 0.7716 - f1_micro: 0.8310 - val_loss: 1.0517 - val_acc: 0.8065 - val_f1_micro: 0.8311\n",
      "Epoch 59/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1923 - acc: 0.7698 - f1_micro: 0.8313 - val_loss: 1.0484 - val_acc: 0.8124 - val_f1_micro: 0.8314\n",
      "Epoch 60/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1870 - acc: 0.7705 - f1_micro: 0.8315 - val_loss: 1.0697 - val_acc: 0.8178 - val_f1_micro: 0.8316\n",
      "Epoch 61/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1886 - acc: 0.7716 - f1_micro: 0.8318 - val_loss: 1.0659 - val_acc: 0.8103 - val_f1_micro: 0.8319\n",
      "Epoch 62/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1886 - acc: 0.7703 - f1_micro: 0.8320 - val_loss: 1.0491 - val_acc: 0.8102 - val_f1_micro: 0.8321\n",
      "Epoch 63/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1929 - acc: 0.7732 - f1_micro: 0.8323 - val_loss: 1.0495 - val_acc: 0.8170 - val_f1_micro: 0.8324\n",
      "Epoch 64/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1920 - acc: 0.7710 - f1_micro: 0.8325 - val_loss: 1.0643 - val_acc: 0.8084 - val_f1_micro: 0.8326\n",
      "Epoch 65/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1869 - acc: 0.7726 - f1_micro: 0.8327 - val_loss: 1.0394 - val_acc: 0.8043 - val_f1_micro: 0.8328\n",
      "Epoch 66/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1888 - acc: 0.7718 - f1_micro: 0.8330 - val_loss: 1.0544 - val_acc: 0.8037 - val_f1_micro: 0.8331\n",
      "Epoch 67/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1884 - acc: 0.7732 - f1_micro: 0.8332 - val_loss: 1.0493 - val_acc: 0.8057 - val_f1_micro: 0.8333\n",
      "Epoch 68/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1934 - acc: 0.7721 - f1_micro: 0.8334 - val_loss: 1.0402 - val_acc: 0.8025 - val_f1_micro: 0.8336\n",
      "Epoch 69/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1926 - acc: 0.7723 - f1_micro: 0.8337 - val_loss: 1.0731 - val_acc: 0.8102 - val_f1_micro: 0.8338\n",
      "Epoch 70/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1868 - acc: 0.7714 - f1_micro: 0.8339 - val_loss: 1.0532 - val_acc: 0.8118 - val_f1_micro: 0.8340\n",
      "Epoch 71/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1857 - acc: 0.7711 - f1_micro: 0.8341 - val_loss: 1.0226 - val_acc: 0.8096 - val_f1_micro: 0.8343\n",
      "Epoch 72/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1916 - acc: 0.7708 - f1_micro: 0.8344 - val_loss: 1.0356 - val_acc: 0.7998 - val_f1_micro: 0.8345\n",
      "Epoch 73/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1946 - acc: 0.7701 - f1_micro: 0.8346 - val_loss: 1.0599 - val_acc: 0.8020 - val_f1_micro: 0.8347\n",
      "Epoch 74/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1860 - acc: 0.7714 - f1_micro: 0.8348 - val_loss: 1.0475 - val_acc: 0.8141 - val_f1_micro: 0.8349\n",
      "Epoch 75/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1867 - acc: 0.7708 - f1_micro: 0.8351 - val_loss: 1.0678 - val_acc: 0.8089 - val_f1_micro: 0.8352\n",
      "Epoch 76/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1868 - acc: 0.7712 - f1_micro: 0.8353 - val_loss: 1.0474 - val_acc: 0.8067 - val_f1_micro: 0.8354\n",
      "Epoch 77/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1873 - acc: 0.7759 - f1_micro: 0.8355 - val_loss: 1.0525 - val_acc: 0.8072 - val_f1_micro: 0.8356\n",
      "Epoch 78/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1886 - acc: 0.7718 - f1_micro: 0.8357 - val_loss: 1.0456 - val_acc: 0.8010 - val_f1_micro: 0.8358\n",
      "Epoch 79/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1881 - acc: 0.7702 - f1_micro: 0.8359 - val_loss: 1.0315 - val_acc: 0.8001 - val_f1_micro: 0.8361\n",
      "Epoch 80/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1806 - acc: 0.7738 - f1_micro: 0.8362 - val_loss: 1.0328 - val_acc: 0.8027 - val_f1_micro: 0.8363\n",
      "Epoch 81/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1850 - acc: 0.7713 - f1_micro: 0.8364 - val_loss: 1.0298 - val_acc: 0.7979 - val_f1_micro: 0.8365\n",
      "Epoch 82/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1864 - acc: 0.7704 - f1_micro: 0.8366 - val_loss: 1.0287 - val_acc: 0.8024 - val_f1_micro: 0.8367\n",
      "Epoch 83/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1881 - acc: 0.7726 - f1_micro: 0.8368 - val_loss: 1.0665 - val_acc: 0.8085 - val_f1_micro: 0.8369\n",
      "Epoch 84/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1899 - acc: 0.7702 - f1_micro: 0.8370 - val_loss: 1.0412 - val_acc: 0.8098 - val_f1_micro: 0.8371\n",
      "Epoch 85/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1858 - acc: 0.7712 - f1_micro: 0.8373 - val_loss: 1.0354 - val_acc: 0.8015 - val_f1_micro: 0.8374\n",
      "Epoch 86/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1898 - acc: 0.7674 - f1_micro: 0.8375 - val_loss: 1.0508 - val_acc: 0.8050 - val_f1_micro: 0.8376\n",
      "Epoch 87/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1831 - acc: 0.7721 - f1_micro: 0.8377 - val_loss: 1.0310 - val_acc: 0.8062 - val_f1_micro: 0.8378\n",
      "Epoch 88/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1845 - acc: 0.7707 - f1_micro: 0.8379 - val_loss: 1.0462 - val_acc: 0.8073 - val_f1_micro: 0.8380\n",
      "Epoch 89/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1895 - acc: 0.7705 - f1_micro: 0.8381 - val_loss: 1.0398 - val_acc: 0.8137 - val_f1_micro: 0.8382\n",
      "Epoch 90/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1813 - acc: 0.7739 - f1_micro: 0.8383 - val_loss: 1.0530 - val_acc: 0.8062 - val_f1_micro: 0.8384\n",
      "Epoch 91/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1877 - acc: 0.7705 - f1_micro: 0.8385 - val_loss: 1.0290 - val_acc: 0.8034 - val_f1_micro: 0.8386\n",
      "Epoch 92/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1885 - acc: 0.7728 - f1_micro: 0.8387 - val_loss: 1.0465 - val_acc: 0.8110 - val_f1_micro: 0.8388\n",
      "Epoch 93/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1857 - acc: 0.7712 - f1_micro: 0.8389 - val_loss: 1.0469 - val_acc: 0.8173 - val_f1_micro: 0.8390\n",
      "Epoch 94/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1855 - acc: 0.7734 - f1_micro: 0.8391 - val_loss: 1.0641 - val_acc: 0.8096 - val_f1_micro: 0.8392\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57243/57243 [==============================] - 1s - loss: 1.1912 - acc: 0.7728 - f1_micro: 0.8393 - val_loss: 1.0431 - val_acc: 0.8130 - val_f1_micro: 0.8394\n",
      "Epoch 96/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1864 - acc: 0.7742 - f1_micro: 0.8395 - val_loss: 1.0557 - val_acc: 0.8089 - val_f1_micro: 0.8396\n",
      "Epoch 97/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1904 - acc: 0.7709 - f1_micro: 0.8397 - val_loss: 1.0453 - val_acc: 0.8103 - val_f1_micro: 0.8398\n",
      "Epoch 98/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1836 - acc: 0.7731 - f1_micro: 0.8399 - val_loss: 1.0549 - val_acc: 0.8192 - val_f1_micro: 0.8400\n",
      "Epoch 99/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1900 - acc: 0.7718 - f1_micro: 0.8401 - val_loss: 1.0542 - val_acc: 0.8104 - val_f1_micro: 0.8402\n",
      "Epoch 100/100\n",
      "57243/57243 [==============================] - 1s - loss: 1.1861 - acc: 0.7720 - f1_micro: 0.8403 - val_loss: 1.0329 - val_acc: 0.8063 - val_f1_micro: 0.8404\n",
      "CPU times: user 2min 34s, sys: 26.8 s, total: 3min\n",
      "Wall time: 2min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# And trained it via:\n",
    "batch_size = 1000\n",
    "epochs = 100\n",
    "\n",
    "hist = model.fit(\n",
    "    training_inputs,\n",
    "    training_outputs,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    validation_data=validation_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # And trained it via:\n",
    "# batch_size = 10\n",
    "# epochs = 50\n",
    "\n",
    "# hist = model.fit(\n",
    "#     train_test_training_inputs,\n",
    "#     train_test_training_outputs,\n",
    "#     epochs=epochs,\n",
    "#     batch_size=batch_size,\n",
    "#     validation_split=0.2,\n",
    "#     validation_data=validation_data,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84033768880776072"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history['f1_micro'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# log_history_file = 'lstm-word2vec-fasttext-lsi.epoch.csv'\n",
    "# model_name = 'models/tfidf-wv-fs-lsi-2010-2014-data_cat-crossentropy-2014-b-val-sc_tfidf_wv_fs_lsi.model'\n",
    "# batch_size = 1200\n",
    "# epochs = 5\n",
    "# total_epochs = 100\n",
    "\n",
    "# for i in xrange(0, total_epochs // epochs):\n",
    "#     hist = model.fit(\n",
    "#         training_inputs,\n",
    "#         training_outputs,\n",
    "#         epochs=epochs,\n",
    "#         batch_size=batch_size,\n",
    "#         validation_split=0.2,\n",
    "#         validation_data=validation_data,\n",
    "#     )\n",
    "\n",
    "#     model.save(model_name.format(i))\n",
    "#     print\n",
    "#     print('Done with epoch: {}'.format((i + 1) * epochs))\n",
    "#     with open(log_history_file, 'a') as fl:\n",
    "#         fl.write(model_name + '\\n')\n",
    "#         fl.write('Epoch {}\\n'.format((i + 1) * epochs))\n",
    "#         fl.write('{}\\n'.format(datetime.now()))\n",
    "#         fl.write('\\n'.join(['{}: {}'.format(k, v[0]) for k, v in hist.history.items()]))\n",
    "#         fl.write('\\n\\n')\n",
    "#     print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# total_epochs = 100\n",
    "# for j in xrange(i, i + (total_epochs // epochs)):\n",
    "#     hist = model.fit(\n",
    "#         training_inputs,\n",
    "#         training_outputs,\n",
    "#         epochs=epochs,\n",
    "#         batch_size=batch_size,\n",
    "#         validation_split=0.2,\n",
    "#         validation_data=validation_data,\n",
    "#     )\n",
    "\n",
    "#     model.save(model_name.format(i))\n",
    "#     print\n",
    "#     print('Done with epoch: {}'.format((j + 1) * epochs))\n",
    "#     with open(log_history_file, 'a') as fl:\n",
    "#         fl.write(model_name + '\\n')\n",
    "#         fl.write('Epoch {}\\n'.format((j + 1) * epochs))\n",
    "#         fl.write('{}\\n'.format(datetime.now()))\n",
    "#         fl.write('\\n'.join(['{}: {}'.format(k, v[0]) for k, v in hist.history.items()]))\n",
    "#         fl.write('\\n\\n')\n",
    "#     print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = keras.models.load_model(\n",
    "#     'models/lstm-word2vec-fasttext_2010-2014-data_categorical-crossentropy-2014-b-val-standard_scaled_wv_fs.model',\n",
    "#     custom_objects={'f1_micro': f1_micro}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test_wv_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = model.predict(\n",
    "    build_training_inputs(\n",
    "        wv_train,\n",
    "        fs_train,\n",
    "        tfidf_wv_train,\n",
    "        tfidf_fs_train,\n",
    "        tfidf_lsi_train,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.20138209e-15,   2.42166287e-08,   1.41483841e-15, ...,\n",
       "          1.19395740e-14,   8.71162044e-22,   5.17794256e-14],\n",
       "       [  8.68130334e-21,   4.66071462e-16,   2.03802076e-22, ...,\n",
       "          3.22669669e-23,   9.73546685e-23,   1.42461977e-37],\n",
       "       [  2.24891386e-23,   1.92595978e-18,   7.91063942e-19, ...,\n",
       "          1.00835154e-21,   2.09687485e-30,   4.72186983e-36],\n",
       "       ..., \n",
       "       [  5.87631423e-18,   5.57505770e-17,   7.04986763e-11, ...,\n",
       "          5.10007049e-28,   1.99941725e-15,   7.01880515e-01],\n",
       "       [  1.73102794e-19,   3.80870466e-20,   3.55734973e-12, ...,\n",
       "          2.98159203e-29,   1.81713713e-17,   7.62282670e-01],\n",
       "       [  6.64151811e-16,   2.43986888e-16,   3.74290332e-09, ...,\n",
       "          3.50970149e-23,   2.64689902e-11,   9.47064757e-01]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score as sk_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 436 ms, sys: 36 ms, total: 472 ms\n",
      "Wall time: 472 ms\n",
      "CPU times: user 468 ms, sys: 40 ms, total: 508 ms\n",
      "Wall time: 503 ms\n",
      "CPU times: user 456 ms, sys: 40 ms, total: 496 ms\n",
      "Wall time: 494 ms\n",
      "CPU times: user 432 ms, sys: 44 ms, total: 476 ms\n",
      "Wall time: 471 ms\n",
      "CPU times: user 448 ms, sys: 44 ms, total: 492 ms\n",
      "Wall time: 490 ms\n",
      "CPU times: user 496 ms, sys: 36 ms, total: 532 ms\n",
      "Wall time: 530 ms\n",
      "CPU times: user 436 ms, sys: 64 ms, total: 500 ms\n",
      "Wall time: 499 ms\n",
      "CPU times: user 416 ms, sys: 56 ms, total: 472 ms\n",
      "Wall time: 468 ms\n",
      "CPU times: user 440 ms, sys: 36 ms, total: 476 ms\n",
      "Wall time: 469 ms\n",
      "CPU times: user 428 ms, sys: 44 ms, total: 472 ms\n",
      "Wall time: 470 ms\n",
      "CPU times: user 432 ms, sys: 44 ms, total: 476 ms\n",
      "Wall time: 470 ms\n",
      "CPU times: user 432 ms, sys: 40 ms, total: 472 ms\n",
      "Wall time: 469 ms\n",
      "CPU times: user 448 ms, sys: 24 ms, total: 472 ms\n",
      "Wall time: 469 ms\n",
      "CPU times: user 440 ms, sys: 32 ms, total: 472 ms\n",
      "Wall time: 469 ms\n",
      "CPU times: user 416 ms, sys: 56 ms, total: 472 ms\n",
      "Wall time: 469 ms\n",
      "CPU times: user 468 ms, sys: 44 ms, total: 512 ms\n",
      "Wall time: 509 ms\n",
      "CPU times: user 488 ms, sys: 44 ms, total: 532 ms\n",
      "Wall time: 531 ms\n",
      "CPU times: user 440 ms, sys: 40 ms, total: 480 ms\n",
      "Wall time: 478 ms\n",
      "CPU times: user 444 ms, sys: 28 ms, total: 472 ms\n",
      "Wall time: 469 ms\n",
      "CPU times: user 428 ms, sys: 44 ms, total: 472 ms\n",
      "Wall time: 469 ms\n",
      "CPU times: user 436 ms, sys: 36 ms, total: 472 ms\n",
      "Wall time: 468 ms\n",
      "CPU times: user 432 ms, sys: 40 ms, total: 472 ms\n",
      "Wall time: 467 ms\n",
      "CPU times: user 448 ms, sys: 24 ms, total: 472 ms\n",
      "Wall time: 468 ms\n",
      "CPU times: user 444 ms, sys: 28 ms, total: 472 ms\n",
      "Wall time: 468 ms\n",
      "CPU times: user 444 ms, sys: 28 ms, total: 472 ms\n",
      "Wall time: 468 ms\n",
      "CPU times: user 412 ms, sys: 60 ms, total: 472 ms\n",
      "Wall time: 469 ms\n",
      "CPU times: user 428 ms, sys: 40 ms, total: 468 ms\n",
      "Wall time: 468 ms\n",
      "CPU times: user 436 ms, sys: 36 ms, total: 472 ms\n",
      "Wall time: 470 ms\n",
      "CPU times: user 428 ms, sys: 44 ms, total: 472 ms\n",
      "Wall time: 468 ms\n",
      "CPU times: user 436 ms, sys: 36 ms, total: 472 ms\n",
      "Wall time: 468 ms\n",
      "CPU times: user 440 ms, sys: 36 ms, total: 476 ms\n",
      "Wall time: 469 ms\n",
      "CPU times: user 432 ms, sys: 40 ms, total: 472 ms\n",
      "Wall time: 469 ms\n",
      "CPU times: user 460 ms, sys: 40 ms, total: 500 ms\n",
      "Wall time: 496 ms\n",
      "CPU times: user 484 ms, sys: 52 ms, total: 536 ms\n",
      "Wall time: 531 ms\n",
      "CPU times: user 424 ms, sys: 52 ms, total: 476 ms\n",
      "Wall time: 471 ms\n",
      "CPU times: user 428 ms, sys: 48 ms, total: 476 ms\n",
      "Wall time: 470 ms\n",
      "CPU times: user 420 ms, sys: 52 ms, total: 472 ms\n",
      "Wall time: 469 ms\n",
      "CPU times: user 436 ms, sys: 36 ms, total: 472 ms\n",
      "Wall time: 467 ms\n",
      "CPU times: user 428 ms, sys: 44 ms, total: 472 ms\n",
      "Wall time: 468 ms\n",
      "CPU times: user 428 ms, sys: 44 ms, total: 472 ms\n",
      "Wall time: 469 ms\n",
      "CPU times: user 444 ms, sys: 60 ms, total: 504 ms\n",
      "Wall time: 498 ms\n",
      "CPU times: user 492 ms, sys: 40 ms, total: 532 ms\n",
      "Wall time: 529 ms\n",
      "CPU times: user 448 ms, sys: 40 ms, total: 488 ms\n",
      "Wall time: 487 ms\n",
      "CPU times: user 420 ms, sys: 52 ms, total: 472 ms\n",
      "Wall time: 468 ms\n",
      "CPU times: user 428 ms, sys: 44 ms, total: 472 ms\n",
      "Wall time: 469 ms\n",
      "CPU times: user 420 ms, sys: 48 ms, total: 468 ms\n",
      "Wall time: 467 ms\n",
      "CPU times: user 436 ms, sys: 36 ms, total: 472 ms\n",
      "Wall time: 467 ms\n",
      "CPU times: user 432 ms, sys: 40 ms, total: 472 ms\n",
      "Wall time: 469 ms\n",
      "CPU times: user 436 ms, sys: 36 ms, total: 472 ms\n",
      "Wall time: 469 ms\n",
      "CPU times: user 488 ms, sys: 48 ms, total: 536 ms\n",
      "Wall time: 531 ms\n",
      "CPU times: user 464 ms, sys: 40 ms, total: 504 ms\n",
      "Wall time: 502 ms\n",
      "CPU times: user 22.6 s, sys: 2.14 s, total: 24.7 s\n",
      "Wall time: 24.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dt = 0.01\n",
    "s = 0.1\n",
    "e = 0.6\n",
    "th = np.arange(s, e + dt, dt)\n",
    "mean_fscores = []\n",
    "for t in th:\n",
    "#     fscores = []\n",
    "#     for ix in range(g.shape[0]):\n",
    "#         y_a = y_train[ix]\n",
    "#         y_p = 1.0 * (g[ix] > t)\n",
    "#         fscores.append(sk_f1_score(y_a, y_p))\n",
    "#     mean_fscores.append(np.mean(fscores))\n",
    "    %time mean_fscores.append((t, sk_f1_score(y_train, 1.0 * (g > t), average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.53999999999999981, 0.95807753620730596)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh, thresh_score = sorted(mean_fscores, key=lambda x: x[1], reverse=True)[0]\n",
    "thresh, thresh_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53999999999999981"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_test_df.iloc[ix].bodyText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'charliehebdoattack'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa9b590e9d0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa9b587ff90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "ix = 13\n",
    "sd = -100\n",
    "pd.Series(g[sd:][ix]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([22]),), (array([], dtype=int64),))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# thresh = 0.5\n",
    "np.where(y_train[sd:][ix] == 1), np.where(g[sd:][ix] > thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "from gensim.models.lsimodel import LsiModel\n",
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = TfidfModel.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.dictionary')\n",
    "tfidf = TfidfModel.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.tfidf')\n",
    "lsi = LsiModel.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.lsi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wvmodel = Word2Vec.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fsmodel = fasttext.load_model('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.fasttext.model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_fsmodel_cache = {}\n",
    "def get_fsvec(word):\n",
    "    if word in _fsmodel_cache:\n",
    "        fv = _fsmodel_cache[word]\n",
    "    else:\n",
    "        fv = fsmodel[word]\n",
    "        _fsmodel_cache[word] = fv\n",
    "\n",
    "    return fv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_tfidf_word2vec(tokens, stopwords=[]):\n",
    "#     global wvmodel\n",
    "#     global tfidf\n",
    "    # This requires wvmodel to be present in the namespace.\n",
    "    wv_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords and w in wvmodel.wv.vocab)]\n",
    "    ).map(\n",
    "        lambda x: tfidf[dictionary.doc2bow(x)]\n",
    "    ).map(\n",
    "        lambda x: np.array([wvmodel[dictionary.id2token[id]] * w for id, w in x]).mean(axis=0) if len(x) > 0 else np.nan\n",
    "    )\n",
    "\n",
    "    return wv_feature_vec\n",
    "\n",
    "\n",
    "def transform_tfidf_fasttext(tokens, stopwords=[]):\n",
    "#     global fsmodel\n",
    "#     global tfidf\n",
    "    # This requires wvmodel to be present in the namespace.\n",
    "    fs_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    ).map(\n",
    "        lambda x: tfidf[dictionary.doc2bow(x)]\n",
    "    ).map(\n",
    "        lambda x: np.array([np.array(get_fsvec(dictionary.id2token[id])) * w for id, w in x]).mean(axis=0) if len(x) > 0 else np.nan\n",
    "    )\n",
    "\n",
    "    return fs_feature_vec\n",
    "\n",
    "\n",
    "def build_lsi_vector(l):\n",
    "    v = np.zeros(lsi.num_topics)\n",
    "    \n",
    "    for ix, vv in lsi[tfidf[dictionary.doc2bow(l)]]:\n",
    "        v[ix] = vv\n",
    "        \n",
    "    return v\n",
    "\n",
    "\n",
    "def transform_tfidf_lsi(tokens, stopwords=[]):\n",
    "#     global fsmodel\n",
    "#     global tfidf\n",
    "    # This requires wvmodel to be present in the namespace.\n",
    "    lsi_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    ).map(\n",
    "        lambda x: build_lsi_vector(x) if len(x) > 0 else np.nan\n",
    "    )\n",
    "\n",
    "    return lsi_feature_vec\n",
    "\n",
    "\n",
    "def transform_fasttext(tokens, stopwords=[]):\n",
    "    global fsmodel\n",
    "    # This requires fsmodel to be present in the namespace.\n",
    "    fs_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    ).map(lambda x: np.array([get_fsvec(w) for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return fs_feature_vec\n",
    "\n",
    "\n",
    "def transform_unsupervised_sentiment_neuron(tokens, stopwords=[]):\n",
    "    # This requires fsmodel to be present in the namespace.\n",
    "    \n",
    "    usn_feature_vec = usnmodel.transform(tokens)\n",
    "\n",
    "    # usn_feature_vec = tokens.map(\n",
    "    #     lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    # ).map(lambda x: np.array([usnmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return usn_feature_vec\n",
    "\n",
    "\n",
    "def transform_word2vec(tokens, stopwords=[]):\n",
    "    global wvmodel\n",
    "    # This requires wvmodel to be present in the namespace.\n",
    "    wv_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords and w in wvmodel.wv.vocab)]\n",
    "    ).map(lambda x: np.array([wvmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return wv_feature_vec\n",
    "\n",
    "\n",
    "def parallel_generate_word_vectors(samp, transformer, stopwords, batch, num_proc):\n",
    "    with Parallel(n_jobs=num_proc) as parallel:\n",
    "        dataset = []\n",
    "        is_break = False\n",
    "        i = 0\n",
    "\n",
    "        while not is_break:\n",
    "            payload = []\n",
    "\n",
    "            for j in xrange(num_proc):\n",
    "                t_df = samp[(i + j) * batch: (i + 1 + j) * batch]\n",
    "\n",
    "                if t_df.empty:\n",
    "                    is_break = True\n",
    "                    continue\n",
    "\n",
    "                payload.append(\n",
    "                    delayed(transformer)(\n",
    "                        t_df, stopwords\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            print('Current batch in main thread: {}'.format((i + j) * batch))\n",
    "\n",
    "            if payload:\n",
    "                results = parallel(payload)\n",
    "                dataset.extend(results)\n",
    "                i += num_proc\n",
    "\n",
    "    return pd.concat(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_classes(pred, scale_param=0.75, min_thresh=0.05, thresh = 0.5):\n",
    "#     mx = pred.mean() + 3 * pred.std()\n",
    "    return np.where(pred > thresh)[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2idx_transform(word, _word2idx):\n",
    "    return _word2idx.get(word, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features_for(df, min_batch=2000, stopwords=[], num_proc=7):\n",
    "    df_tokens = transform_text(df)\n",
    "    \n",
    "    batch = min(df_tokens.shape[0] / num_proc, min_batch)\n",
    "\n",
    "    print('Computing fs features...')\n",
    "    fvec = parallel_generate_word_vectors(df_tokens, transform_fasttext, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Computing wv features...')\n",
    "    wvec = parallel_generate_word_vectors(df_tokens, transform_word2vec, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Mapping word indices...')\n",
    "    word_indices = df_tokens.map(lambda x: [word2idx_transform(i, _word2idx) for i in x.split()])\n",
    "\n",
    "    print('Computing tfidf fs features...')\n",
    "    tfidf_fvec = parallel_generate_word_vectors(df_tokens, transform_tfidf_fasttext, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Computing tfidf wv features...')\n",
    "    tfidf_wvec = parallel_generate_word_vectors(df_tokens, transform_tfidf_word2vec, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Computing tfidf lsi features...')\n",
    "    tfidf_lsi = parallel_generate_word_vectors(df_tokens, transform_tfidf_lsi, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "    \n",
    "    return word_indices, wvec, fvec, tfidf_wvec, tfidf_fvec, tfidf_lsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/TestData.json') as fl:\n",
    "    data = json.load(fl)\n",
    "    test_df = pd.DataFrame(data['TestData']).T\n",
    "    del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fs features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Computing wv features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Mapping word indices...\n",
      "Computing tfidf fs features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Computing tfidf wv features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Computing tfidf lsi features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "CPU times: user 52.2 s, sys: 4.41 s, total: 56.6 s\n",
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_word_indices,test_wvec, test_fvec, test_tfidf_wvec, test_tfidf_fvec, test_tfidf_lsi = extract_features_for(\n",
    "    test_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert(np.all(test_wvec[test_wvec.isnull()].index == test_fvec[test_fvec.isnull()].index))\n",
    "test_null_index = test_wvec[test_wvec.isnull()].index.union(test_fvec[test_fvec.isnull()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'TestData_02543', u'TestData_05012', u'TestData_05830'], dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_null_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 348 ms, sys: 28 ms, total: 376 ms\n",
      "Wall time: 377 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "valid_test_index = test_word_indices.index.difference(test_null_index)\n",
    "x_test = test_word_indices.ix[valid_test_index]  # .map(lambda x: [top_token2ind.get(i, 0) for i in x])\n",
    "\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "wv_test = np.vstack(test_wvec.ix[valid_test_index])\n",
    "fs_test = np.vstack(test_fvec.ix[valid_test_index])\n",
    "\n",
    "tfidf_wv_test = np.vstack(test_tfidf_wvec.ix[valid_test_index])\n",
    "tfidf_fs_test = np.vstack(test_tfidf_fvec.ix[valid_test_index])\n",
    "tfidf_lsi_test = np.vstack(test_tfidf_lsi.ix[valid_test_index])\n",
    "\n",
    "wv_test = wv_sc.transform(wv_test)\n",
    "fs_test = fs_sc.transform(fs_test)\n",
    "\n",
    "tfidf_wv_test = tfidf_wv_sc.transform(tfidf_wv_test)\n",
    "tfidf_fs_test = tfidf_fs_sc.transform(tfidf_fs_test)\n",
    "tfidf_lsi_test = tfidf_lsi_sc.transform(tfidf_lsi_test)\n",
    "\n",
    "test_inputs = build_training_inputs(\n",
    "    wv_test,\n",
    "    fs_test,\n",
    "    tfidf_wv_test,\n",
    "    tfidf_fs_test,\n",
    "    tfidf_lsi_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_probas = model.predict(test_inputs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_test_probas = test_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8.45687097e-15,   9.60972482e-11,   6.67067823e-09, ...,\n",
       "          5.84431115e-11,   2.77209750e-29,   3.90811282e-18],\n",
       "       [  1.33567311e-13,   6.27112797e-08,   1.08719211e-09, ...,\n",
       "          1.97126437e-14,   5.12922886e-17,   1.88924263e-17],\n",
       "       [  2.43227819e-15,   3.15362669e-09,   1.88201641e-14, ...,\n",
       "          1.26029058e-15,   1.40200144e-25,   1.83297716e-23],\n",
       "       ..., \n",
       "       [  4.72065702e-16,   5.09863137e-04,   3.37027162e-02, ...,\n",
       "          1.15086081e-23,   4.50472015e-07,   6.16123784e-18],\n",
       "       [  6.01658376e-11,   7.09882588e-05,   1.47755426e-08, ...,\n",
       "          4.92415223e-12,   7.81392832e-12,   1.01341055e-14],\n",
       "       [  5.47104205e-14,   3.48044409e-07,   1.46855018e-06, ...,\n",
       "          8.50327453e-19,   3.15968544e-19,   3.32763670e-16]], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_test_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2542, 5011, 5829]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_index = [int(s.split('_')[1]) - 1 for s in test_null_index]  # Subtract 1 since test index starts at 1 while enumerate starts at 0\n",
    "skip_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7578, 160), (7581, 3))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_test_probas.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28 ms, sys: 4 ms, total: 32 ms\n",
      "Wall time: 29.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# valid_test_feature_vec found below!\n",
    "thresh = 0.5\n",
    "test_values = np.zeros([main_test_probas.shape[0], len(topics)])\n",
    "for ix, pred in enumerate(main_test_probas):\n",
    "    for v in get_classes(pred, thresh=0.5):\n",
    "        test_values[ix][v] = 1\n",
    "\n",
    "test_sub_df = pd.DataFrame(\n",
    "    test_values,\n",
    "    index=test_df.ix[test_df.index.difference(test_null_index)].index,\n",
    "    columns=topics\n",
    ")\n",
    "\n",
    "null_test_df = pd.DataFrame(\n",
    "    np.zeros((len(test_null_index), len(topics))),\n",
    "    index=test_null_index,\n",
    "    columns=topics\n",
    ")\n",
    "\n",
    "test_sub_df = test_sub_df.append(null_test_df)\n",
    "test_sub_df = test_sub_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6552, 0.5)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6552, thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 9627 (0.5), 14297 (0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12803.0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12803.0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 12803.0)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh, test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13897.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12489.0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7581.000000\n",
       "mean      882.691070\n",
       "std       621.585386\n",
       "min         0.000000\n",
       "25%       552.000000\n",
       "50%       770.000000\n",
       "75%      1026.000000\n",
       "max      8171.000000\n",
       "Name: bodyText, dtype: float64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_word_indices.map(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1382.0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_word_indices.map(len).quantile(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1223"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df.ix['TestData_04490'].bodyText.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activism                                    0.0\n",
       "afghanistan                               112.0\n",
       "aid                                        80.0\n",
       "algerianhostagecrisis                      16.0\n",
       "alqaida                                   109.0\n",
       "alshabaab                                  39.0\n",
       "antiwar                                     0.0\n",
       "arabandmiddleeastprotests                 333.0\n",
       "armstrade                                  75.0\n",
       "australianguncontrol                        0.0\n",
       "australiansecurityandcounterterrorism      63.0\n",
       "bastilledaytruckattack                     26.0\n",
       "belgium                                    11.0\n",
       "berlinchristmasmarketattack                20.0\n",
       "bigdata                                     7.0\n",
       "biometrics                                  1.0\n",
       "bokoharam                                  37.0\n",
       "bostonmarathonbombing                      61.0\n",
       "britisharmy                                 0.0\n",
       "brusselsattacks                            50.0\n",
       "cameroon                                    1.0\n",
       "carers                                      1.0\n",
       "charliehebdoattack                         52.0\n",
       "chemicalweapons                            21.0\n",
       "clusterbombs                                4.0\n",
       "cobra                                       0.0\n",
       "conflictanddevelopment                     52.0\n",
       "controversy                                 8.0\n",
       "criminaljustice                            32.0\n",
       "cybercrime                                 82.0\n",
       "                                          ...  \n",
       "somalia                                    47.0\n",
       "southafrica                                47.0\n",
       "southchinasea                               5.0\n",
       "stopandsearch                               0.0\n",
       "surveillance                              130.0\n",
       "sydneysiege                                41.0\n",
       "syria                                    1368.0\n",
       "taliban                                    48.0\n",
       "terrorism                                 215.0\n",
       "thailand                                   30.0\n",
       "torture                                    11.0\n",
       "traincrashes                                4.0\n",
       "transport                                 100.0\n",
       "tunisiaattack2015                          59.0\n",
       "turkey                                    220.0\n",
       "turkeycoupattempt                          30.0\n",
       "ukcrime                                   295.0\n",
       "uksecurity                                439.0\n",
       "uksupremecourt                              6.0\n",
       "undercoverpoliceandpolicing                 4.0\n",
       "unitednations                             196.0\n",
       "usguncontrol                              271.0\n",
       "values                                      1.0\n",
       "warcrimes                                  16.0\n",
       "warreporting                               10.0\n",
       "weaponstechnology                           4.0\n",
       "womeninbusiness                             0.0\n",
       "woolwichattack                             41.0\n",
       "worldmigration                              2.0\n",
       "zikavirus                                   3.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activism                                    0.0\n",
       "afghanistan                                95.0\n",
       "aid                                        89.0\n",
       "algerianhostagecrisis                      24.0\n",
       "alqaida                                   136.0\n",
       "alshabaab                                  38.0\n",
       "antiwar                                     0.0\n",
       "arabandmiddleeastprotests                 162.0\n",
       "armstrade                                  96.0\n",
       "australianguncontrol                        0.0\n",
       "australiansecurityandcounterterrorism      39.0\n",
       "bastilledaytruckattack                     38.0\n",
       "belgium                                     7.0\n",
       "berlinchristmasmarketattack                16.0\n",
       "bigdata                                     6.0\n",
       "biometrics                                  1.0\n",
       "bokoharam                                  37.0\n",
       "bostonmarathonbombing                      51.0\n",
       "britisharmy                                 4.0\n",
       "brusselsattacks                            71.0\n",
       "cameroon                                    0.0\n",
       "carers                                      0.0\n",
       "charliehebdoattack                         47.0\n",
       "chemicalweapons                            27.0\n",
       "clusterbombs                                1.0\n",
       "cobra                                       6.0\n",
       "conflictanddevelopment                     86.0\n",
       "controversy                                 1.0\n",
       "criminaljustice                            39.0\n",
       "cybercrime                                 66.0\n",
       "                                          ...  \n",
       "somalia                                    40.0\n",
       "southafrica                                30.0\n",
       "southchinasea                               7.0\n",
       "stopandsearch                               1.0\n",
       "surveillance                               86.0\n",
       "sydneysiege                                14.0\n",
       "syria                                    1055.0\n",
       "taliban                                    41.0\n",
       "terrorism                                 138.0\n",
       "thailand                                   34.0\n",
       "torture                                    15.0\n",
       "traincrashes                                5.0\n",
       "transport                                  86.0\n",
       "tunisiaattack2015                          43.0\n",
       "turkey                                    257.0\n",
       "turkeycoupattempt                          41.0\n",
       "ukcrime                                   188.0\n",
       "uksecurity                                366.0\n",
       "uksupremecourt                              5.0\n",
       "undercoverpoliceandpolicing                 2.0\n",
       "unitednations                             258.0\n",
       "usguncontrol                              176.0\n",
       "values                                      0.0\n",
       "warcrimes                                  10.0\n",
       "warreporting                                2.0\n",
       "weaponstechnology                          11.0\n",
       "womeninbusiness                             1.0\n",
       "woolwichattack                              8.0\n",
       "worldmigration                             13.0\n",
       "zikavirus                                   3.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activism                                    0.0\n",
       "afghanistan                                96.0\n",
       "aid                                        70.0\n",
       "algerianhostagecrisis                      31.0\n",
       "alqaida                                   151.0\n",
       "alshabaab                                  35.0\n",
       "antiwar                                     2.0\n",
       "arabandmiddleeastprotests                 239.0\n",
       "armstrade                                  78.0\n",
       "australianguncontrol                        0.0\n",
       "australiansecurityandcounterterrorism      79.0\n",
       "bastilledaytruckattack                      0.0\n",
       "belgium                                    87.0\n",
       "berlinchristmasmarketattack                 0.0\n",
       "bigdata                                     8.0\n",
       "biometrics                                  2.0\n",
       "bokoharam                                  38.0\n",
       "bostonmarathonbombing                     104.0\n",
       "britisharmy                                 4.0\n",
       "brusselsattacks                             0.0\n",
       "cameroon                                    1.0\n",
       "carers                                      3.0\n",
       "charliehebdoattack                          0.0\n",
       "chemicalweapons                            38.0\n",
       "clusterbombs                                3.0\n",
       "cobra                                       0.0\n",
       "conflictanddevelopment                     55.0\n",
       "controversy                                 4.0\n",
       "criminaljustice                            39.0\n",
       "cybercrime                                 55.0\n",
       "                                          ...  \n",
       "somalia                                    40.0\n",
       "southafrica                                36.0\n",
       "southchinasea                               6.0\n",
       "stopandsearch                               2.0\n",
       "surveillance                              129.0\n",
       "sydneysiege                                38.0\n",
       "syria                                    1399.0\n",
       "taliban                                    54.0\n",
       "terrorism                                 180.0\n",
       "thailand                                   32.0\n",
       "torture                                    12.0\n",
       "traincrashes                                3.0\n",
       "transport                                  85.0\n",
       "tunisiaattack2015                           0.0\n",
       "turkey                                    255.0\n",
       "turkeycoupattempt                           0.0\n",
       "ukcrime                                   266.0\n",
       "uksecurity                                415.0\n",
       "uksupremecourt                              9.0\n",
       "undercoverpoliceandpolicing                 3.0\n",
       "unitednations                             214.0\n",
       "usguncontrol                              263.0\n",
       "values                                      0.0\n",
       "warcrimes                                  24.0\n",
       "warreporting                               17.0\n",
       "weaponstechnology                           6.0\n",
       "womeninbusiness                             0.0\n",
       "woolwichattack                             35.0\n",
       "worldmigration                             13.0\n",
       "zikavirus                                   0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activism                                    0.0\n",
       "afghanistan                               106.0\n",
       "aid                                        95.0\n",
       "algerianhostagecrisis                      14.0\n",
       "alqaida                                   226.0\n",
       "alshabaab                                  41.0\n",
       "antiwar                                     1.0\n",
       "arabandmiddleeastprotests                 170.0\n",
       "armstrade                                  88.0\n",
       "australianguncontrol                        0.0\n",
       "australiansecurityandcounterterrorism      81.0\n",
       "bastilledaytruckattack                     22.0\n",
       "belgium                                     7.0\n",
       "berlinchristmasmarketattack                18.0\n",
       "bigdata                                     7.0\n",
       "biometrics                                  1.0\n",
       "bokoharam                                  44.0\n",
       "bostonmarathonbombing                      65.0\n",
       "britisharmy                                12.0\n",
       "brusselsattacks                            23.0\n",
       "cameroon                                    3.0\n",
       "carers                                      3.0\n",
       "charliehebdoattack                         60.0\n",
       "chemicalweapons                            56.0\n",
       "clusterbombs                                2.0\n",
       "cobra                                       2.0\n",
       "conflictanddevelopment                     85.0\n",
       "controversy                                 1.0\n",
       "criminaljustice                            31.0\n",
       "cybercrime                                 79.0\n",
       "                                          ...  \n",
       "somalia                                    54.0\n",
       "southafrica                                39.0\n",
       "southchinasea                               5.0\n",
       "stopandsearch                               2.0\n",
       "surveillance                              125.0\n",
       "sydneysiege                                16.0\n",
       "syria                                    1371.0\n",
       "taliban                                    52.0\n",
       "terrorism                                 174.0\n",
       "thailand                                   38.0\n",
       "torture                                    15.0\n",
       "traincrashes                                3.0\n",
       "transport                                  84.0\n",
       "tunisiaattack2015                          42.0\n",
       "turkey                                    225.0\n",
       "turkeycoupattempt                          33.0\n",
       "ukcrime                                   318.0\n",
       "uksecurity                                411.0\n",
       "uksupremecourt                              8.0\n",
       "undercoverpoliceandpolicing                 2.0\n",
       "unitednations                             276.0\n",
       "usguncontrol                              181.0\n",
       "values                                      0.0\n",
       "warcrimes                                  48.0\n",
       "warreporting                               16.0\n",
       "weaponstechnology                          10.0\n",
       "womeninbusiness                             0.0\n",
       "woolwichattack                             48.0\n",
       "worldmigration                             15.0\n",
       "zikavirus                                   4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activism                                    0.0\n",
       "afghanistan                               113.0\n",
       "aid                                       101.0\n",
       "algerianhostagecrisis                      14.0\n",
       "alqaida                                   254.0\n",
       "alshabaab                                  43.0\n",
       "antiwar                                     4.0\n",
       "arabandmiddleeastprotests                 204.0\n",
       "armstrade                                  93.0\n",
       "australianguncontrol                        0.0\n",
       "australiansecurityandcounterterrorism      83.0\n",
       "bastilledaytruckattack                     23.0\n",
       "belgium                                     9.0\n",
       "berlinchristmasmarketattack                18.0\n",
       "bigdata                                     8.0\n",
       "biometrics                                  1.0\n",
       "bokoharam                                  44.0\n",
       "bostonmarathonbombing                      68.0\n",
       "britisharmy                                15.0\n",
       "brusselsattacks                            24.0\n",
       "cameroon                                    3.0\n",
       "carers                                      3.0\n",
       "charliehebdoattack                         61.0\n",
       "chemicalweapons                            61.0\n",
       "clusterbombs                                2.0\n",
       "cobra                                       2.0\n",
       "conflictanddevelopment                     97.0\n",
       "controversy                                 3.0\n",
       "criminaljustice                            33.0\n",
       "cybercrime                                 82.0\n",
       "                                          ...  \n",
       "somalia                                    61.0\n",
       "southafrica                                41.0\n",
       "southchinasea                               5.0\n",
       "stopandsearch                               2.0\n",
       "surveillance                              132.0\n",
       "sydneysiege                                16.0\n",
       "syria                                    1411.0\n",
       "taliban                                    54.0\n",
       "terrorism                                 187.0\n",
       "thailand                                   39.0\n",
       "torture                                    19.0\n",
       "traincrashes                                3.0\n",
       "transport                                  86.0\n",
       "tunisiaattack2015                          44.0\n",
       "turkey                                    238.0\n",
       "turkeycoupattempt                          35.0\n",
       "ukcrime                                   330.0\n",
       "uksecurity                                430.0\n",
       "uksupremecourt                              8.0\n",
       "undercoverpoliceandpolicing                 2.0\n",
       "unitednations                             296.0\n",
       "usguncontrol                              184.0\n",
       "values                                      0.0\n",
       "warcrimes                                  50.0\n",
       "warreporting                               16.0\n",
       "weaponstechnology                          12.0\n",
       "womeninbusiness                             0.0\n",
       "woolwichattack                             51.0\n",
       "worldmigration                             18.0\n",
       "zikavirus                                   4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95811/95811 [==============================] - 2s - loss: 1.7367 - acc: 0.7069 - f1_micro: 0.5886 - val_loss: 1.4146 - val_acc: 0.7645 - val_f1_micro: 0.5889\n"
     ]
    }
   ],
   "source": [
    "print '95811/95811 [==============================] - 2s - loss: 1.7367 - acc: 0.7069 - f1_micro: 0.5886 - val_loss: 1.4146 - val_acc: 0.7645 - val_f1_micro: 0.5889'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_filename = 'tfidf_wv_300-fs_300-lsi_300-deep_stack_net-low_dropout-rmsprop-epochs_300-tanh_init_activation-f1_0.8403-data_2012_2014_test_augmented_3_upsample-val_data_2014-thresh_{}-with_sc_wv_fs_lsi.csv'.format(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_sub_df.astype(int).reset_index().rename(\n",
    "    columns={'index': 'id'}\n",
    ").sort_values('id').to_csv(\n",
    "    sub_filename, \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7581, 160)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TestData_04490\tThe World Health Organisation has convened an ...\t[]\t28-01-2016\n",
    "TestData_04550\tSpraying pesticides will fail to deal with the...\t[]\t02-02-2016\n",
    "TestData_05683\tViolent protests at Trump rally in California ...\t[]\t03-06-2016\n",
    "TestData_05869\tLast weekend, we saw the darkest side of human...\t[]\t17-06-2016\n",
    "TestData_06148\tAs dusk falls over Copacabana beach, Ubira San...\t[]\t16-07-2016\n",
    "TestData_06291\tIt is 3pm and yet another patient is brought t...\t[]\t27-07-2016\n",
    "TestData_06610\tHuddled around their hives, beekeepers around ...\t[]\t04-09-2016\n",
    "TestData_06708\tA United Nations high-level panel on access to...\t[]\t14-09-2016\n",
    "TestData_07263\tWHO: Zika virus is no longer a world threat Th...\t[]\t19-11-2016\n",
    "TestData_07478\t1 World Health Organisation declares a public ...\t[]\t18-12-2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "guncrime        1.0\n",
       "usguncontrol    1.0\n",
       "Name: TestData_05869, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = 5868\n",
    "test_sub_df.iloc[ix][test_sub_df.iloc[ix] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36 ms, sys: 0 ns, total: 36 ms\n",
      "Wall time: 32.6 ms\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# adjust_index = 0\n",
    "# # valid_test_feature_vec found below!\n",
    "# test_values = np.zeros([test_df.shape[0], len(topics)])\n",
    "# for ix, pred in enumerate(main_test_probas):\n",
    "#     if ix in skip_index:\n",
    "#         test_values[ix] = np.nan\n",
    "#         # Increment adjust index so that we have the correct index for other samples\n",
    "#         adjust_index += 1\n",
    "#         continue\n",
    "\n",
    "#     for v in get_classes(pred, thresh=0.05):\n",
    "#         test_values[ix + adjust_index][v] = 1\n",
    "\n",
    "# test_sub_df = pd.DataFrame(test_values, columns=sorted(topics), index=test_df.index)\n",
    "\n",
    "# q = test_sub_df.sum(axis=1)\n",
    "# assert(len(q[q.isnull()].index.difference(test_null_index)) == 0)\n",
    "\n",
    "# test_sub_df = test_sub_df.fillna(0)\n",
    "\n",
    "# # for i in test_feature_vec[test_feature_vec.isnull()].index:\n",
    "# #     test_sub_df.ix[i] = np.zeros(len(topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestData_02543    0.0\n",
       "TestData_05012    0.0\n",
       "TestData_05830    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.ix[test_null_index].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11656.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sub_df.astype(int).reset_index().rename(\n",
    "    columns={'index': 'id'}\n",
    ").sort_values('id').to_csv(\n",
    "    'lstm_300-word2vec_300-fasttext_300-maxlen_500-dense_64_64_64-cat_cross-epoch_210-batch_size_750-val_main_output_f1_micro_0.5760-main_output_f1_micro_0.5751-main_output_loss_0.9143-data_2010_2013-val_data_2014-thresh_0.05.csv', \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: zikavirus, dtype: float64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = test_sub_df['zikavirus']\n",
    "e[e==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14328"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_submission = pd.read_csv('basic_nn_submission_0.649_accuracy_multi_class.csv')\n",
    "top_submission.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9280"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_index_lstm_sub = pd.read_csv('lstm.2014b_training_700_maxlen_64cell_100epochs_0.0025_threshold.csv')\n",
    "wrong_index_lstm_sub.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34952"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_sub = pd.read_csv('basic_nn_submission_full_training_data_0.9958_validation_accuracy_binary_crossentropy.csv')\n",
    "some_sub.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2197, 160)\n",
      "(3957, 160)\n",
      "(12, 160)\n",
      "(1503, 160)\n"
     ]
    }
   ],
   "source": [
    "print top_submission.set_index('id')[top_submission.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print wrong_index_lstm_sub.set_index('id')[wrong_index_lstm_sub.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print some_sub.set_index('id')[some_sub.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print test_sub_df[test_sub_df.sum(axis=1) == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestData_00011     0\n",
       "TestData_00012     0\n",
       "TestData_00015     0\n",
       "TestData_00027     3\n",
       "TestData_00029     0\n",
       "TestData_00038     1\n",
       "TestData_00042     5\n",
       "TestData_00053     4\n",
       "TestData_00056     1\n",
       "TestData_00060     1\n",
       "TestData_00066     0\n",
       "TestData_00085     0\n",
       "TestData_00087     1\n",
       "TestData_00090     0\n",
       "TestData_00092     0\n",
       "TestData_00107     3\n",
       "TestData_00111     0\n",
       "TestData_00114     0\n",
       "TestData_00115     1\n",
       "TestData_00118     0\n",
       "TestData_00119     0\n",
       "TestData_00121     0\n",
       "TestData_00123     0\n",
       "TestData_00125     0\n",
       "TestData_00127     0\n",
       "TestData_00128     1\n",
       "TestData_00139     1\n",
       "TestData_00140     1\n",
       "TestData_00144     0\n",
       "TestData_00147     2\n",
       "                  ..\n",
       "TestData_07445     0\n",
       "TestData_07456     3\n",
       "TestData_07461     1\n",
       "TestData_07462     4\n",
       "TestData_07465     0\n",
       "TestData_07468     0\n",
       "TestData_07471     1\n",
       "TestData_07475     0\n",
       "TestData_07486    10\n",
       "TestData_07495     1\n",
       "TestData_07509     0\n",
       "TestData_07514     3\n",
       "TestData_07515     1\n",
       "TestData_07523     0\n",
       "TestData_07533     2\n",
       "TestData_07534     2\n",
       "TestData_07542     1\n",
       "TestData_07544     2\n",
       "TestData_07545     0\n",
       "TestData_07552     2\n",
       "TestData_07556     5\n",
       "TestData_07563     1\n",
       "TestData_07565     0\n",
       "TestData_07566     0\n",
       "TestData_07569     0\n",
       "TestData_07571     3\n",
       "TestData_07572     1\n",
       "TestData_07579     6\n",
       "TestData_07580     2\n",
       "TestData_07581     3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_submission.set_index('id').ix[q[q == 0].index].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1222,)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.sum(axis=1)\n",
    "q[q==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7581.000000\n",
       "mean        2.160929\n",
       "std         1.739411\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         2.000000\n",
       "75%         3.000000\n",
       "max        13.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = trainingY.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    236286.000000\n",
       "mean          1.392787\n",
       "std           0.762577\n",
       "min           1.000000\n",
       "25%           1.000000\n",
       "50%           1.000000\n",
       "75%           2.000000\n",
       "max          15.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bodyText</th>\n",
       "      <th>topics</th>\n",
       "      <th>webPublicationDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TestData_03241</th>\n",
       "      <td>A special British police unit was put on stand...</td>\n",
       "      <td>[]</td>\n",
       "      <td>15-11-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_04088</th>\n",
       "      <td>The youngest convict in a fatal gang-rape in N...</td>\n",
       "      <td>[]</td>\n",
       "      <td>20-12-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_06306</th>\n",
       "      <td>Former New York City mayor Rudy Giuliani has s...</td>\n",
       "      <td>[]</td>\n",
       "      <td>28-07-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_06083</th>\n",
       "      <td>John Cantlie, the British journalist who has b...</td>\n",
       "      <td>[]</td>\n",
       "      <td>13-07-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_05896</th>\n",
       "      <td>Lawyers for the companies that manufactured an...</td>\n",
       "      <td>[]</td>\n",
       "      <td>20-06-2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         bodyText topics  \\\n",
       "TestData_03241  A special British police unit was put on stand...     []   \n",
       "TestData_04088  The youngest convict in a fatal gang-rape in N...     []   \n",
       "TestData_06306  Former New York City mayor Rudy Giuliani has s...     []   \n",
       "TestData_06083  John Cantlie, the British journalist who has b...     []   \n",
       "TestData_05896  Lawyers for the companies that manufactured an...     []   \n",
       "\n",
       "               webPublicationDate  \n",
       "TestData_03241         15-11-2015  \n",
       "TestData_04088         20-12-2015  \n",
       "TestData_06306         28-07-2016  \n",
       "TestData_06083         13-07-2016  \n",
       "TestData_05896         20-06-2016  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ix = 'TestData_03241'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "london                1.0\n",
       "metropolitanpolice    1.0\n",
       "police                1.0\n",
       "uksecurity            1.0\n",
       "Name: TestData_03241, dtype: float64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ukcrime    1\n",
       "Name: TestData_04088, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = top_submission.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "humanrights    1\n",
       "india          1\n",
       "protest        1\n",
       "ukcrime        1\n",
       "Name: TestData_04088, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = some_sub.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "humanrights    1\n",
       "Name: TestData_02924, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = wrong_index_lstm_sub.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Counter-terrorism policy\n",
    " \n",
    "Foreign policy\n",
    " \n",
    "Defence policy\n",
    " \n",
    "Islamic State\n",
    " \n",
    "Syria\n",
    " \n",
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = trainingY.sum()\n",
    "unseen_topics = s[s.isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activism',\n",
       " 'bastilledaytruckattack',\n",
       " 'berlinchristmasmarketattack',\n",
       " 'brusselsattacks',\n",
       " 'charliehebdoattack',\n",
       " 'francetrainattack',\n",
       " 'munichshooting',\n",
       " 'orlandoterrorattack',\n",
       " 'parisattacks',\n",
       " 'peaceandreconciliation',\n",
       " 'sanbernardinoshooting',\n",
       " 'tunisiaattack2015',\n",
       " 'turkeycoupattempt',\n",
       " 'zikavirus'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(topics).intersection(unseen_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activism\n",
      "afghanistan\n",
      "aid\n",
      "algerianhostagecrisis\n",
      "alqaida\n",
      "alshabaab\n",
      "antiwar\n",
      "arabandmiddleeastprotests\n",
      "armstrade\n",
      "australianguncontrol\n",
      "australiansecurityandcounterterrorism\n",
      "bastilledaytruckattack\n",
      "belgium\n",
      "berlinchristmasmarketattack\n",
      "bigdata\n",
      "biometrics\n",
      "bokoharam\n",
      "bostonmarathonbombing\n",
      "britisharmy\n",
      "brusselsattacks\n",
      "cameroon\n",
      "carers\n",
      "charliehebdoattack\n",
      "chemicalweapons\n",
      "clusterbombs\n",
      "cobra\n",
      "conflictanddevelopment\n",
      "controversy\n",
      "criminaljustice\n",
      "cybercrime\n",
      "cyberwar\n",
      "darknet\n",
      "dataprotection\n",
      "debate\n",
      "defence\n",
      "deflation\n",
      "drones\n",
      "drugs\n",
      "drugspolicy\n",
      "drugstrade\n",
      "earthquakes\n",
      "ebola\n",
      "economy\n",
      "egypt\n",
      "encryption\n",
      "energy\n",
      "espionage\n",
      "ethics\n",
      "europeanarrestwarrant\n",
      "europeancourtofhumanrights\n",
      "events\n",
      "extradition\n",
      "famine\n",
      "farright\n",
      "firefighters\n",
      "forensicscience\n",
      "france\n",
      "francetrainattack\n",
      "freedomofspeech\n",
      "genevaconventions\n",
      "germany\n",
      "guncrime\n",
      "hacking\n",
      "hashtags\n",
      "helicoptercrashes\n",
      "humanitarianresponse\n",
      "humanrights\n",
      "humanrightsact\n",
      "humantrafficking\n",
      "immigration\n",
      "india\n",
      "indonesia\n",
      "internallydisplacedpeople\n",
      "internationalcourtofjustice\n",
      "internationalcriminaljustice\n",
      "internetsafety\n",
      "iraq\n",
      "isis\n",
      "israel\n",
      "jordan\n",
      "jubilee\n",
      "judiciary\n",
      "july7\n",
      "justiceandsecurity\n",
      "kenya\n",
      "knifecrime\n",
      "lebanon\n",
      "libya\n",
      "localgovernment\n",
      "logistics\n",
      "london\n",
      "londonriots\n",
      "malaysia\n",
      "mali\n",
      "malware\n",
      "metropolitanpolice\n",
      "middleeastpeacetalks\n",
      "migration\n",
      "military\n",
      "ministryofdefence\n",
      "morocco\n",
      "mrsa\n",
      "mumbaiterrorattacks\n",
      "munichshooting\n",
      "naturaldisasters\n",
      "nigeria\n",
      "nuclearweapons\n",
      "occupy\n",
      "organisedcrime\n",
      "orlandoterrorattack\n",
      "osamabinladen\n",
      "paris\n",
      "parisattacks\n",
      "peaceandreconciliation\n",
      "philippines\n",
      "piracy\n",
      "planecrashes\n",
      "police\n",
      "protest\n",
      "refugees\n",
      "religion\n",
      "retirementage\n",
      "rio20earthsummit\n",
      "royalairforce\n",
      "royalnavy\n",
      "russia\n",
      "sanbernardinoshooting\n",
      "saudiarabia\n",
      "september11\n",
      "slavery\n",
      "somalia\n",
      "southafrica\n",
      "southchinasea\n",
      "stopandsearch\n",
      "surveillance\n",
      "sydneysiege\n",
      "syria\n",
      "taliban\n",
      "terrorism\n",
      "thailand\n",
      "torture\n",
      "traincrashes\n",
      "transport\n",
      "tunisiaattack2015\n",
      "turkey\n",
      "turkeycoupattempt\n",
      "ukcrime\n",
      "uksecurity\n",
      "uksupremecourt\n",
      "undercoverpoliceandpolicing\n",
      "unitednations\n",
      "usguncontrol\n",
      "values\n",
      "warcrimes\n",
      "warreporting\n",
      "weaponstechnology\n",
      "womeninbusiness\n",
      "woolwichattack\n",
      "worldmigration\n",
      "zikavirus\n"
     ]
    }
   ],
   "source": [
    "for i in topics:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsolatorio/ml-ai/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3445929"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(wvmodel['zika'], np.vstack(test_wvec.dropna())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsolatorio/ml-ai/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.38107796869050226"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(fsmodel['zika'], np.vstack(test_fvec.dropna())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              The World Health Organisation has convened an ...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           28-01-2016\n",
       "Name: TestData_04490, dtype: object"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[4488 + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              The United Nations security council has called...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           17-09-2016\n",
       "Name: TestData_06730, dtype: object"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[6727 + 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              We are deeply concerned that the counter-terro...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           02-02-2015\n",
       "Name: TestData_00360, dtype: object"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[359]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drugstrade    1.0\n",
       "Name: TestData_04490, dtype: float64"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.iloc[4488 + 1]\n",
    "q[q > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
