{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from growing_instability_lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub = pd.read_csv('../data/sampleSubmission.csv')\n",
    "topics = sorted(set(sample_sub.columns.difference(['id'])))\n",
    "\n",
    "topic2actual = {}\n",
    "for i in sample_sub.columns:\n",
    "    if 'id' == i:\n",
    "        continue\n",
    "    topic2actual[i] = segment(i)\n",
    "    \n",
    "target_columns = sorted(topics)\n",
    "len(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.73 s, sys: 1.4 s, total: 10.1 s\n",
      "Wall time: 10.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wvec_trainingX = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', 'wvec_trainingX')\n",
    "fvec_trainingX = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', 'fvec_trainingX')\n",
    "\n",
    "tfidf_wvec_trainingX = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', 'tfidf_wvec_trainingX')\n",
    "tfidf_fvec_trainingX = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', 'tfidf_fvec_trainingX')\n",
    "tfidf_lsi_trainingX = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', 'tfidf_lsi_trainingX')\n",
    "\n",
    "word2idx_trainingX = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', 'word2idx_trainingX')\n",
    "_word2idx = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', '_word2idx')\n",
    "trainingY = pd.read_hdf('training_data_wv_fs_no_stopwords.hdf', 'trainingY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ind2class = dict(enumerate(topics))\n",
    "class2ind = {j: i for i, j in ind2class.items()}\n",
    "\n",
    "num_samples = trainingY.shape[0]\n",
    "\n",
    "# ---------------------------------\n",
    "training_X = word2idx_trainingX.head(num_samples)\n",
    "training_Y = pd.DataFrame(zip(*np.where(trainingY.head(num_samples) == 1)), columns=['iloc', 'topics'])\n",
    "\n",
    "training_WV = wvec_trainingX.head(num_samples)\n",
    "training_FS = fvec_trainingX.head(num_samples)\n",
    "\n",
    "training_tfidf_WV = tfidf_wvec_trainingX.head(num_samples)\n",
    "training_tfidf_FS = tfidf_fvec_trainingX.head(num_samples)\n",
    "training_tfidf_LSI = tfidf_lsi_trainingX.head(num_samples)\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "training_Y = training_Y.groupby('iloc')['topics'].apply(list)\n",
    "training_Y.index = trainingY.head(num_samples).index\n",
    "\n",
    "indices = sorted(training_Y.index[training_Y.index.str.contains('^201[0-9]')])\n",
    "# np.random.shuffle(indices)\n",
    "indices = pd.Index(indices)\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "training_X = training_X.ix[indices]\n",
    "training_Y = training_Y.ix[indices]\n",
    "\n",
    "training_WV = training_WV.ix[indices]\n",
    "training_FS = training_FS.ix[indices]\n",
    "\n",
    "training_tfidf_WV = tfidf_training_WV.ix[indices]\n",
    "training_tfidf_FS = tfidf_training_FS.ix[indices]\n",
    "training_tfidf_LSI = tfidf_training_LSI.ix[indices]\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "dataset = zip(training_X, training_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wv_sc = StandardScaler()\n",
    "fs_sc = StandardScaler()\n",
    "\n",
    "tfidf_wv_sc = StandardScaler()\n",
    "tfidf_fs_sc = StandardScaler()\n",
    "tfidf_lsi_sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "def build_target(y, size):\n",
    "    e = np.zeros(size)\n",
    "    e[y] = 1\n",
    "    return e\n",
    "\n",
    "def build_input_output_data(X, WV, FS, TWV, TFS, TLSI, Y, maxlen):\n",
    "\n",
    "    x = sequence.pad_sequences(X, maxlen=maxlen)\n",
    "    y = np.vstack(Y.map(lambda x: build_target(x, len(topics))))\n",
    "\n",
    "    wv = np.vstack(WV)\n",
    "    fs = np.vstack(FS)\n",
    "\n",
    "    twv = np.vstack(TWV)\n",
    "    tfs = np.vstack(TFS)\n",
    "    tlsi = np.vstack(TLSI)\n",
    "    \n",
    "    return x, wv, fs, twv, tfs, tlsi, y\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "train_ix = training_Y.index.str.contains('^201[0-4]')\n",
    "val_ix = training_Y.index.str.contains('^2014[b]')\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "x_train, wv_train, fs_train, tfidf_wv_train, tfidf_fs_train, tfidf_lsi_train, y_train = build_input_output_data(\n",
    "    training_X.ix[train_ix],\n",
    "\n",
    "    training_WV.ix[train_ix],\n",
    "    training_FS.ix[train_ix],\n",
    "\n",
    "    training_tfidf_WV.ix[train_ix],\n",
    "    training_tfidf_FS.ix[train_ix],\n",
    "    training_tfidf_LSI.ix[train_ix],\n",
    "\n",
    "    training_Y.ix[train_ix],\n",
    "    maxlen=maxlen\n",
    ")\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "x_val, wv_val, fs_val, tfidf_wv_val, tfidf_fs_val, tfidf_lsi_val, y_val = build_input_output_data(\n",
    "    training_X.ix[val_ix],\n",
    "\n",
    "    training_WV.ix[val_ix],\n",
    "    training_FS.ix[val_ix],\n",
    "\n",
    "    training_tfidf_WV.ix[val_ix],\n",
    "    training_tfidf_FS.ix[val_ix],\n",
    "    training_tfidf_LSI.ix[val_ix],\n",
    "\n",
    "    training_Y.ix[val_ix],\n",
    "    maxlen=maxlen\n",
    ")\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "wv_train = wv_sc.fit_transform(wv_train)\n",
    "fs_train = fs_sc.fit_transform(fs_train)\n",
    "\n",
    "tfidf_wv_train = tfidf_wv_sc.fit_transform(tfidf_wv_train)\n",
    "tfidf_fs_train = tfidf_fs_sc.fit_transform(tfidf_fs_train)\n",
    "tfidf_lsi_train = tfidf_lsi_sc.fit_transform(tfidf_lsi_train)\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "wv_val = wv_sc.transform(wv_val)\n",
    "fs_val = fs_sc.transform(fs_val)\n",
    "\n",
    "tfidf_wv_val = tfidf_wv_sc.transform(tfidf_wv_val)\n",
    "tfidf_fs_val = tfidf_fs_sc.transform(tfidf_fs_val)\n",
    "tfidf_lsi_val = tfidf_lsi_sc.transform(tfidf_lsi_val)\n",
    "# ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_Y.shape, training_Y.ix[training_Y.index.str.contains('^2014[b]')].shape, training_sample_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as K\n",
    "import keras.backend as KB\n",
    "\n",
    "\n",
    "def f1_micro(y_true, y_pred):\n",
    "    TP = K.metrics.true_positives(y_true, K.round(y_pred))\n",
    "    FP = K.metrics.false_positives(y_true, K.round(y_pred))\n",
    "    FN = K.metrics.false_negatives(y_true, K.round(y_pred))\n",
    "    \n",
    "    p = K.reduce_sum(TP) / (K.reduce_sum(TP) + K.reduce_sum(FP))\n",
    "    r = K.reduce_sum(TP) / (K.reduce_sum(TP) + K.reduce_sum(FN))\n",
    "    \n",
    "    return (2.0 * p * r) / (p + r)\n",
    "\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "\n",
    "    # Count positive samples.\n",
    "    c1 = KB.sum(KB.round(KB.clip(y_true * y_pred, 0, 1)))\n",
    "    c2 = KB.sum(KB.round(KB.clip(y_pred, 0, 1)))\n",
    "    c3 = KB.sum(KB.round(KB.clip(y_true, 0, 1)))\n",
    "\n",
    "    # If there are no true samples, fix the F1 score at 0.\n",
    "    if c3 == 0:\n",
    "        return 0\n",
    "\n",
    "    # How many selected items are relevant?\n",
    "    precision = c1 / c2\n",
    "\n",
    "    # How many relevant items are selected?\n",
    "    recall = c1 / c3\n",
    "\n",
    "    # Calculate f1_score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense, Dropout, Convolution1D, MaxPooling1D, Flatten\n",
    "from keras.models import Model\n",
    "import itertools as it\n",
    "\n",
    "\n",
    "def build_deep_input_stack(input_node):\n",
    "    x = Dense(128, activation='relu')(input_node)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def entangle_inputs(input_nodes=[]):\n",
    "    assert(len(input_nodes) > 1)\n",
    "    \n",
    "    entangled_inputs = []\n",
    "    \n",
    "    for n1, n2 in it.combinations(input_nodes, 2):\n",
    "        entangled_inputs.append(\n",
    "            keras.layers.dot([n1, n2], 1)\n",
    "        )\n",
    "    \n",
    "    return entangled_inputs\n",
    "\n",
    "\n",
    "wv_input = Input(shape=(300,), name='wv_input')\n",
    "fs_input = Input(shape=(300,), name='fs_input')\n",
    "\n",
    "tfidf_wv_input = Input(shape=(300,), name='tfidf_wv_input')\n",
    "tfidf_fs_input = Input(shape=(300,), name='tfidf_fs_input')\n",
    "tfidf_lsi_input = Input(shape=(300,), name='tfidf_lsi_input')\n",
    "\n",
    "\n",
    "wv_x = build_deep_input_stack(wv_input)\n",
    "fs_x = build_deep_input_stack(fs_input)\n",
    "tfidf_wv_x = build_deep_input_stack(tfidf_wv_input)\n",
    "tfidf_fs_x = build_deep_input_stack(tfidf_fs_input)\n",
    "tfidf_lsi_x = build_deep_input_stack(tfidf_wv_input)\n",
    "\n",
    "stacked_inputs_x = [wv_x, fs_x, tfidf_wv_x, tfidf_fs_x, tfidf_lsi_x]\n",
    "entangled_inputs_x = entangle_inputs(stacked_inputs_x)\n",
    "\n",
    "x = keras.layers.concatenate(stacked_inputs_x + entangled_inputs_x)\n",
    "\n",
    "# We stack a deep densely-connected network on top\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "# And finally we add the main logistic regression layer\n",
    "main_output = Dense(len(class2ind), activation='sigmoid', name='main_output')(x)\n",
    "\n",
    "model = Model(inputs=[wv_input, fs_input], outputs=[main_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={'main_output': 'categorical_crossentropy'},\n",
    "    loss_weights={'main_output': 1.},\n",
    "    metrics=['accuracy', f1_micro]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.callbacks import EarlyStopping\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "# model.fit(X, y, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_training_inputs(wv, fs, tfidf_wv, tfidf_fs, tfidf_lsi):\n",
    "    training_inputs = {\n",
    "        'wv_input': wv,\n",
    "        'fs_input': fs,\n",
    "        'tfidf_wv_input': tfidf_wv,\n",
    "        'tfidf_fs_input': tfidf_fs,\n",
    "        'tfidf_lsi_input': tfidf_lsi,\n",
    "    }\n",
    "    \n",
    "    return training_inputs\n",
    "    \n",
    "\n",
    "training_inputs = build_training_inputs(\n",
    "    wv_train,\n",
    "    fs_train,\n",
    "    tfidf_wv_train,\n",
    "    tfidf_fs_train,\n",
    "    tfidf_lsi_train,\n",
    ")\n",
    "\n",
    "training_outputs = {\n",
    "    'main_output': y_train,\n",
    "}\n",
    "\n",
    "validation_data=(\n",
    "    build_training_inputs(\n",
    "        wv_val,\n",
    "        fs_val,\n",
    "        tfidf_wv_val,\n",
    "        tfidf_fs_val,\n",
    "        tfidf_lsi_val,\n",
    "    ),\n",
    "    {\n",
    "        'main_output': y_val,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 1s - loss: 2.9674 - acc: 0.5478 - f1_micro: 0.2535 - val_loss: 2.7046 - val_acc: 0.6051 - val_f1_micro: 0.2645\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 1s - loss: 2.9033 - acc: 0.5547 - f1_micro: 0.2746 - val_loss: 2.6373 - val_acc: 0.6115 - val_f1_micro: 0.2845\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 1s - loss: 2.8473 - acc: 0.5614 - f1_micro: 0.2936 - val_loss: 2.5996 - val_acc: 0.6164 - val_f1_micro: 0.3020\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 1s - loss: 2.8051 - acc: 0.5664 - f1_micro: 0.3099 - val_loss: 2.5656 - val_acc: 0.6161 - val_f1_micro: 0.3175\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 1s - loss: 2.7725 - acc: 0.5720 - f1_micro: 0.3247 - val_loss: 2.5370 - val_acc: 0.6237 - val_f1_micro: 0.3315\n",
      "CPU times: user 7.11 s, sys: 464 ms, total: 7.57 s\n",
      "Wall time: 5.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# And trained it via:\n",
    "batch_size = 500\n",
    "epochs = 5\n",
    "\n",
    "model.fit(\n",
    "    training_inputs,\n",
    "    training_outputs,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    validation_data=validation_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9223 - acc: 0.6675 - f1_micro: 0.6154 - val_loss: 1.5412 - val_acc: 0.7377 - val_f1_micro: 0.6154\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9187 - acc: 0.6692 - f1_micro: 0.6154 - val_loss: 1.5448 - val_acc: 0.7409 - val_f1_micro: 0.6154\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9205 - acc: 0.6683 - f1_micro: 0.6155 - val_loss: 1.5374 - val_acc: 0.7429 - val_f1_micro: 0.6155\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9227 - acc: 0.6703 - f1_micro: 0.6155 - val_loss: 1.5447 - val_acc: 0.7329 - val_f1_micro: 0.6155\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9203 - acc: 0.6685 - f1_micro: 0.6155 - val_loss: 1.5355 - val_acc: 0.7364 - val_f1_micro: 0.6155\n",
      "\n",
      "Done with epoch: 5\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9157 - acc: 0.6708 - f1_micro: 0.6156 - val_loss: 1.5441 - val_acc: 0.7309 - val_f1_micro: 0.6156\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9195 - acc: 0.6718 - f1_micro: 0.6156 - val_loss: 1.5377 - val_acc: 0.7392 - val_f1_micro: 0.6156\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9227 - acc: 0.6692 - f1_micro: 0.6156 - val_loss: 1.5405 - val_acc: 0.7402 - val_f1_micro: 0.6156\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9229 - acc: 0.6687 - f1_micro: 0.6157 - val_loss: 1.5405 - val_acc: 0.7365 - val_f1_micro: 0.6157\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9125 - acc: 0.6702 - f1_micro: 0.6157 - val_loss: 1.5456 - val_acc: 0.7384 - val_f1_micro: 0.6157\n",
      "\n",
      "Done with epoch: 10\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9177 - acc: 0.6720 - f1_micro: 0.6157 - val_loss: 1.5304 - val_acc: 0.7401 - val_f1_micro: 0.6157\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9179 - acc: 0.6688 - f1_micro: 0.6158 - val_loss: 1.5427 - val_acc: 0.7348 - val_f1_micro: 0.6158\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9193 - acc: 0.6691 - f1_micro: 0.6158 - val_loss: 1.5412 - val_acc: 0.7327 - val_f1_micro: 0.6158\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9191 - acc: 0.6695 - f1_micro: 0.6158 - val_loss: 1.5363 - val_acc: 0.7391 - val_f1_micro: 0.6158\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9168 - acc: 0.6708 - f1_micro: 0.6158 - val_loss: 1.5342 - val_acc: 0.7397 - val_f1_micro: 0.6159\n",
      "\n",
      "Done with epoch: 15\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9221 - acc: 0.6693 - f1_micro: 0.6159 - val_loss: 1.5335 - val_acc: 0.7367 - val_f1_micro: 0.6159\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9162 - acc: 0.6710 - f1_micro: 0.6159 - val_loss: 1.5338 - val_acc: 0.7372 - val_f1_micro: 0.6159\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9207 - acc: 0.6691 - f1_micro: 0.6159 - val_loss: 1.5289 - val_acc: 0.7334 - val_f1_micro: 0.6159\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9201 - acc: 0.6689 - f1_micro: 0.6160 - val_loss: 1.5354 - val_acc: 0.7397 - val_f1_micro: 0.6160\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9173 - acc: 0.6686 - f1_micro: 0.6160 - val_loss: 1.5293 - val_acc: 0.7378 - val_f1_micro: 0.6160\n",
      "\n",
      "Done with epoch: 20\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9213 - acc: 0.6697 - f1_micro: 0.6160 - val_loss: 1.5390 - val_acc: 0.7385 - val_f1_micro: 0.6160\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9134 - acc: 0.6703 - f1_micro: 0.6160 - val_loss: 1.5306 - val_acc: 0.7446 - val_f1_micro: 0.6161\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9137 - acc: 0.6691 - f1_micro: 0.6161 - val_loss: 1.5293 - val_acc: 0.7324 - val_f1_micro: 0.6161\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9200 - acc: 0.6687 - f1_micro: 0.6161 - val_loss: 1.5279 - val_acc: 0.7380 - val_f1_micro: 0.6161\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9173 - acc: 0.6707 - f1_micro: 0.6161 - val_loss: 1.5320 - val_acc: 0.7384 - val_f1_micro: 0.6161\n",
      "\n",
      "Done with epoch: 25\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9218 - acc: 0.6680 - f1_micro: 0.6162 - val_loss: 1.5398 - val_acc: 0.7353 - val_f1_micro: 0.6162\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9213 - acc: 0.6706 - f1_micro: 0.6162 - val_loss: 1.5378 - val_acc: 0.7366 - val_f1_micro: 0.6162\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9178 - acc: 0.6674 - f1_micro: 0.6162 - val_loss: 1.5325 - val_acc: 0.7420 - val_f1_micro: 0.6162\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9145 - acc: 0.6706 - f1_micro: 0.6162 - val_loss: 1.5377 - val_acc: 0.7373 - val_f1_micro: 0.6163\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9217 - acc: 0.6684 - f1_micro: 0.6163 - val_loss: 1.5379 - val_acc: 0.7366 - val_f1_micro: 0.6163\n",
      "\n",
      "Done with epoch: 30\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9244 - acc: 0.6682 - f1_micro: 0.6163 - val_loss: 1.5349 - val_acc: 0.7404 - val_f1_micro: 0.6163\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9196 - acc: 0.6697 - f1_micro: 0.6163 - val_loss: 1.5400 - val_acc: 0.7365 - val_f1_micro: 0.6163\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9243 - acc: 0.6687 - f1_micro: 0.6164 - val_loss: 1.5347 - val_acc: 0.7321 - val_f1_micro: 0.6164\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9224 - acc: 0.6673 - f1_micro: 0.6164 - val_loss: 1.5369 - val_acc: 0.7340 - val_f1_micro: 0.6164\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9201 - acc: 0.6716 - f1_micro: 0.6164 - val_loss: 1.5311 - val_acc: 0.7353 - val_f1_micro: 0.6164\n",
      "\n",
      "Done with epoch: 35\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9151 - acc: 0.6704 - f1_micro: 0.6164 - val_loss: 1.5329 - val_acc: 0.7430 - val_f1_micro: 0.6165\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9166 - acc: 0.6699 - f1_micro: 0.6165 - val_loss: 1.5355 - val_acc: 0.7363 - val_f1_micro: 0.6165\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9159 - acc: 0.6695 - f1_micro: 0.6165 - val_loss: 1.5343 - val_acc: 0.7384 - val_f1_micro: 0.6165\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9203 - acc: 0.6693 - f1_micro: 0.6165 - val_loss: 1.5319 - val_acc: 0.7421 - val_f1_micro: 0.6165\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9196 - acc: 0.6695 - f1_micro: 0.6166 - val_loss: 1.5358 - val_acc: 0.7420 - val_f1_micro: 0.6166\n",
      "\n",
      "Done with epoch: 40\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9214 - acc: 0.6685 - f1_micro: 0.6166 - val_loss: 1.5326 - val_acc: 0.7331 - val_f1_micro: 0.6166\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9204 - acc: 0.6691 - f1_micro: 0.6166 - val_loss: 1.5288 - val_acc: 0.7346 - val_f1_micro: 0.6166\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9157 - acc: 0.6710 - f1_micro: 0.6166 - val_loss: 1.5351 - val_acc: 0.7412 - val_f1_micro: 0.6167\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9197 - acc: 0.6702 - f1_micro: 0.6167 - val_loss: 1.5314 - val_acc: 0.7348 - val_f1_micro: 0.6167\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9189 - acc: 0.6673 - f1_micro: 0.6167 - val_loss: 1.5315 - val_acc: 0.7330 - val_f1_micro: 0.6167\n",
      "\n",
      "Done with epoch: 45\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94731/94731 [==============================] - 0s - loss: 1.9168 - acc: 0.6684 - f1_micro: 0.6167 - val_loss: 1.5317 - val_acc: 0.7375 - val_f1_micro: 0.6167\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9138 - acc: 0.6709 - f1_micro: 0.6168 - val_loss: 1.5307 - val_acc: 0.7391 - val_f1_micro: 0.6168\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9131 - acc: 0.6717 - f1_micro: 0.6168 - val_loss: 1.5264 - val_acc: 0.7419 - val_f1_micro: 0.6168\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9199 - acc: 0.6672 - f1_micro: 0.6168 - val_loss: 1.5316 - val_acc: 0.7385 - val_f1_micro: 0.6168\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9186 - acc: 0.6696 - f1_micro: 0.6168 - val_loss: 1.5284 - val_acc: 0.7426 - val_f1_micro: 0.6169\n",
      "\n",
      "Done with epoch: 50\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9110 - acc: 0.6696 - f1_micro: 0.6169 - val_loss: 1.5327 - val_acc: 0.7442 - val_f1_micro: 0.6169\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9129 - acc: 0.6703 - f1_micro: 0.6169 - val_loss: 1.5261 - val_acc: 0.7390 - val_f1_micro: 0.6169\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9144 - acc: 0.6704 - f1_micro: 0.6169 - val_loss: 1.5295 - val_acc: 0.7461 - val_f1_micro: 0.6169\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9168 - acc: 0.6730 - f1_micro: 0.6170 - val_loss: 1.5240 - val_acc: 0.7399 - val_f1_micro: 0.6170\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9155 - acc: 0.6707 - f1_micro: 0.6170 - val_loss: 1.5344 - val_acc: 0.7353 - val_f1_micro: 0.6170\n",
      "\n",
      "Done with epoch: 55\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9163 - acc: 0.6689 - f1_micro: 0.6170 - val_loss: 1.5346 - val_acc: 0.7369 - val_f1_micro: 0.6170\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9159 - acc: 0.6714 - f1_micro: 0.6170 - val_loss: 1.5308 - val_acc: 0.7423 - val_f1_micro: 0.6171\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9163 - acc: 0.6694 - f1_micro: 0.6171 - val_loss: 1.5292 - val_acc: 0.7455 - val_f1_micro: 0.6171\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9081 - acc: 0.6707 - f1_micro: 0.6171 - val_loss: 1.5238 - val_acc: 0.7374 - val_f1_micro: 0.6171\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9140 - acc: 0.6717 - f1_micro: 0.6171 - val_loss: 1.5328 - val_acc: 0.7412 - val_f1_micro: 0.6171\n",
      "\n",
      "Done with epoch: 60\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9186 - acc: 0.6683 - f1_micro: 0.6172 - val_loss: 1.5345 - val_acc: 0.7364 - val_f1_micro: 0.6172\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9187 - acc: 0.6680 - f1_micro: 0.6172 - val_loss: 1.5311 - val_acc: 0.7355 - val_f1_micro: 0.6172\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9183 - acc: 0.6688 - f1_micro: 0.6172 - val_loss: 1.5279 - val_acc: 0.7397 - val_f1_micro: 0.6172\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9157 - acc: 0.6700 - f1_micro: 0.6172 - val_loss: 1.5268 - val_acc: 0.7419 - val_f1_micro: 0.6173\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9132 - acc: 0.6700 - f1_micro: 0.6173 - val_loss: 1.5275 - val_acc: 0.7444 - val_f1_micro: 0.6173\n",
      "\n",
      "Done with epoch: 65\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9218 - acc: 0.6701 - f1_micro: 0.6173 - val_loss: 1.5284 - val_acc: 0.7375 - val_f1_micro: 0.6173\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9176 - acc: 0.6695 - f1_micro: 0.6173 - val_loss: 1.5287 - val_acc: 0.7425 - val_f1_micro: 0.6173\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9181 - acc: 0.6697 - f1_micro: 0.6174 - val_loss: 1.5254 - val_acc: 0.7304 - val_f1_micro: 0.6174\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9161 - acc: 0.6680 - f1_micro: 0.6174 - val_loss: 1.5287 - val_acc: 0.7375 - val_f1_micro: 0.6174\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9101 - acc: 0.6701 - f1_micro: 0.6174 - val_loss: 1.5288 - val_acc: 0.7424 - val_f1_micro: 0.6174\n",
      "\n",
      "Done with epoch: 70\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9076 - acc: 0.6702 - f1_micro: 0.6174 - val_loss: 1.5222 - val_acc: 0.7496 - val_f1_micro: 0.6175\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9161 - acc: 0.6712 - f1_micro: 0.6175 - val_loss: 1.5262 - val_acc: 0.7423 - val_f1_micro: 0.6175\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9112 - acc: 0.6719 - f1_micro: 0.6175 - val_loss: 1.5292 - val_acc: 0.7428 - val_f1_micro: 0.6175\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9248 - acc: 0.6686 - f1_micro: 0.6175 - val_loss: 1.5388 - val_acc: 0.7340 - val_f1_micro: 0.6175\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9124 - acc: 0.6708 - f1_micro: 0.6175 - val_loss: 1.5288 - val_acc: 0.7438 - val_f1_micro: 0.6176\n",
      "\n",
      "Done with epoch: 75\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9127 - acc: 0.6672 - f1_micro: 0.6176 - val_loss: 1.5232 - val_acc: 0.7396 - val_f1_micro: 0.6176\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9084 - acc: 0.6717 - f1_micro: 0.6176 - val_loss: 1.5325 - val_acc: 0.7345 - val_f1_micro: 0.6176\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9156 - acc: 0.6711 - f1_micro: 0.6176 - val_loss: 1.5301 - val_acc: 0.7365 - val_f1_micro: 0.6176\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9143 - acc: 0.6719 - f1_micro: 0.6176 - val_loss: 1.5262 - val_acc: 0.7413 - val_f1_micro: 0.6177\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9228 - acc: 0.6676 - f1_micro: 0.6177 - val_loss: 1.5310 - val_acc: 0.7364 - val_f1_micro: 0.6177\n",
      "\n",
      "Done with epoch: 80\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9089 - acc: 0.6713 - f1_micro: 0.6177 - val_loss: 1.5319 - val_acc: 0.7435 - val_f1_micro: 0.6177\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9145 - acc: 0.6706 - f1_micro: 0.6177 - val_loss: 1.5279 - val_acc: 0.7416 - val_f1_micro: 0.6177\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9085 - acc: 0.6704 - f1_micro: 0.6178 - val_loss: 1.5272 - val_acc: 0.7411 - val_f1_micro: 0.6178\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9151 - acc: 0.6681 - f1_micro: 0.6178 - val_loss: 1.5379 - val_acc: 0.7383 - val_f1_micro: 0.6178\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9109 - acc: 0.6725 - f1_micro: 0.6178 - val_loss: 1.5329 - val_acc: 0.7369 - val_f1_micro: 0.6178\n",
      "\n",
      "Done with epoch: 85\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9074 - acc: 0.6688 - f1_micro: 0.6178 - val_loss: 1.5381 - val_acc: 0.7372 - val_f1_micro: 0.6179\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9080 - acc: 0.6701 - f1_micro: 0.6179 - val_loss: 1.5309 - val_acc: 0.7388 - val_f1_micro: 0.6179\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9125 - acc: 0.6695 - f1_micro: 0.6179 - val_loss: 1.5329 - val_acc: 0.7421 - val_f1_micro: 0.6179\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9118 - acc: 0.6685 - f1_micro: 0.6179 - val_loss: 1.5257 - val_acc: 0.7449 - val_f1_micro: 0.6179\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9124 - acc: 0.6714 - f1_micro: 0.6180 - val_loss: 1.5223 - val_acc: 0.7432 - val_f1_micro: 0.6180\n",
      "\n",
      "Done with epoch: 90\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94731/94731 [==============================] - 0s - loss: 1.9131 - acc: 0.6711 - f1_micro: 0.6180 - val_loss: 1.5285 - val_acc: 0.7411 - val_f1_micro: 0.6180\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9154 - acc: 0.6713 - f1_micro: 0.6180 - val_loss: 1.5232 - val_acc: 0.7392 - val_f1_micro: 0.6180\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9101 - acc: 0.6670 - f1_micro: 0.6181 - val_loss: 1.5253 - val_acc: 0.7344 - val_f1_micro: 0.6181\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9152 - acc: 0.6685 - f1_micro: 0.6181 - val_loss: 1.5293 - val_acc: 0.7348 - val_f1_micro: 0.6181\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9085 - acc: 0.6697 - f1_micro: 0.6181 - val_loss: 1.5267 - val_acc: 0.7393 - val_f1_micro: 0.6181\n",
      "\n",
      "Done with epoch: 95\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9121 - acc: 0.6704 - f1_micro: 0.6181 - val_loss: 1.5282 - val_acc: 0.7481 - val_f1_micro: 0.6182\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9227 - acc: 0.6704 - f1_micro: 0.6182 - val_loss: 1.5314 - val_acc: 0.7371 - val_f1_micro: 0.6182\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9129 - acc: 0.6697 - f1_micro: 0.6182 - val_loss: 1.5234 - val_acc: 0.7386 - val_f1_micro: 0.6182\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9084 - acc: 0.6714 - f1_micro: 0.6182 - val_loss: 1.5235 - val_acc: 0.7372 - val_f1_micro: 0.6182\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9141 - acc: 0.6703 - f1_micro: 0.6183 - val_loss: 1.5295 - val_acc: 0.7438 - val_f1_micro: 0.6183\n",
      "\n",
      "Done with epoch: 100\n",
      "\n",
      "CPU times: user 1min 45s, sys: 10.6 s, total: 1min 56s\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "log_history_file = 'lstm-word2vec-fasttext-lsi.epoch.csv'\n",
    "model_name = 'models/tfidf-wv-fs-lsi-2010-2014-data_cat-crossentropy-2014-b-val-sc_tfidf_wv_fs_lsi.model'\n",
    "batch_size = 1200\n",
    "epochs = 5\n",
    "total_epochs = 100\n",
    "\n",
    "for i in xrange(0, total_epochs // epochs):\n",
    "    hist = model.fit(\n",
    "        training_inputs,\n",
    "        training_outputs,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.2,\n",
    "        validation_data=validation_data,\n",
    "    )\n",
    "\n",
    "    model.save(model_name.format(i))\n",
    "    print\n",
    "    print('Done with epoch: {}'.format((i + 1) * epochs))\n",
    "    with open(log_history_file, 'a') as fl:\n",
    "        fl.write(model_name + '\\n')\n",
    "        fl.write('Epoch {}\\n'.format((i + 1) * epochs))\n",
    "        fl.write('{}\\n'.format(datetime.now()))\n",
    "        fl.write('\\n'.join(['{}: {}'.format(k, v[0]) for k, v in hist.history.items()]))\n",
    "        fl.write('\\n\\n')\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.6427 - main_output_loss: 1.3490 - aux_output_loss: 1.4686 - main_output_acc: 0.7712 - main_output_f1_micro: 0.6905 - aux_output_acc: 0.7839 - aux_output_f1_micro: 0.1085 - val_loss: 1.4372 - val_main_output_loss: 1.1302 - val_aux_output_loss: 1.5348 - val_main_output_acc: 0.7941 - val_main_output_f1_micro: 0.6913 - val_aux_output_acc: 0.7884 - val_aux_output_f1_micro: 0.1086\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5833 - main_output_loss: 1.2980 - aux_output_loss: 1.4265 - main_output_acc: 0.7738 - main_output_f1_micro: 0.6921 - aux_output_acc: 0.7855 - aux_output_f1_micro: 0.1088 - val_loss: 1.4210 - val_main_output_loss: 1.1179 - val_aux_output_loss: 1.5153 - val_main_output_acc: 0.7967 - val_main_output_f1_micro: 0.6930 - val_aux_output_acc: 0.7949 - val_aux_output_f1_micro: 0.1090\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5656 - main_output_loss: 1.2841 - aux_output_loss: 1.4076 - main_output_acc: 0.7752 - main_output_f1_micro: 0.6938 - aux_output_acc: 0.7870 - aux_output_f1_micro: 0.1091 - val_loss: 1.4123 - val_main_output_loss: 1.1124 - val_aux_output_loss: 1.4995 - val_main_output_acc: 0.7930 - val_main_output_f1_micro: 0.6946 - val_aux_output_acc: 0.7916 - val_aux_output_f1_micro: 0.1093\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5551 - main_output_loss: 1.2755 - aux_output_loss: 1.3983 - main_output_acc: 0.7779 - main_output_f1_micro: 0.6955 - aux_output_acc: 0.7867 - aux_output_f1_micro: 0.1094 - val_loss: 1.4043 - val_main_output_loss: 1.1070 - val_aux_output_loss: 1.4866 - val_main_output_acc: 0.7988 - val_main_output_f1_micro: 0.6963 - val_aux_output_acc: 0.7918 - val_aux_output_f1_micro: 0.1096\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5504 - main_output_loss: 1.2725 - aux_output_loss: 1.3899 - main_output_acc: 0.7771 - main_output_f1_micro: 0.6971 - aux_output_acc: 0.7872 - aux_output_f1_micro: 0.1097 - val_loss: 1.4002 - val_main_output_loss: 1.1043 - val_aux_output_loss: 1.4796 - val_main_output_acc: 0.8088 - val_main_output_f1_micro: 0.6980 - val_aux_output_acc: 0.7916 - val_aux_output_f1_micro: 0.1099\n",
      "\n",
      "Done with epoch: 100\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5459 - main_output_loss: 1.2693 - aux_output_loss: 1.3833 - main_output_acc: 0.7773 - main_output_f1_micro: 0.6988 - aux_output_acc: 0.7896 - aux_output_f1_micro: 0.1100 - val_loss: 1.3938 - val_main_output_loss: 1.0999 - val_aux_output_loss: 1.4694 - val_main_output_acc: 0.8001 - val_main_output_f1_micro: 0.6996 - val_aux_output_acc: 0.7926 - val_aux_output_f1_micro: 0.1102\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5393 - main_output_loss: 1.2640 - aux_output_loss: 1.3764 - main_output_acc: 0.7776 - main_output_f1_micro: 0.7004 - aux_output_acc: 0.7896 - aux_output_f1_micro: 0.1103 - val_loss: 1.3912 - val_main_output_loss: 1.0979 - val_aux_output_loss: 1.4664 - val_main_output_acc: 0.7940 - val_main_output_f1_micro: 0.7012 - val_aux_output_acc: 0.7917 - val_aux_output_f1_micro: 0.1105\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5369 - main_output_loss: 1.2627 - aux_output_loss: 1.3708 - main_output_acc: 0.7815 - main_output_f1_micro: 0.7020 - aux_output_acc: 0.7890 - aux_output_f1_micro: 0.1106 - val_loss: 1.3821 - val_main_output_loss: 1.0902 - val_aux_output_loss: 1.4594 - val_main_output_acc: 0.8066 - val_main_output_f1_micro: 0.7028 - val_aux_output_acc: 0.7940 - val_aux_output_f1_micro: 0.1108\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5302 - main_output_loss: 1.2571 - aux_output_loss: 1.3656 - main_output_acc: 0.7796 - main_output_f1_micro: 0.7036 - aux_output_acc: 0.7897 - aux_output_f1_micro: 0.1109 - val_loss: 1.3878 - val_main_output_loss: 1.0954 - val_aux_output_loss: 1.4620 - val_main_output_acc: 0.7964 - val_main_output_f1_micro: 0.7044 - val_aux_output_acc: 0.7954 - val_aux_output_f1_micro: 0.1111\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5282 - main_output_loss: 1.2561 - aux_output_loss: 1.3605 - main_output_acc: 0.7775 - main_output_f1_micro: 0.7052 - aux_output_acc: 0.7913 - aux_output_f1_micro: 0.1112 - val_loss: 1.3855 - val_main_output_loss: 1.0954 - val_aux_output_loss: 1.4505 - val_main_output_acc: 0.7928 - val_main_output_f1_micro: 0.7059 - val_aux_output_acc: 0.7964 - val_aux_output_f1_micro: 0.1114\n",
      "\n",
      "Done with epoch: 105\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5262 - main_output_loss: 1.2551 - aux_output_loss: 1.3553 - main_output_acc: 0.7791 - main_output_f1_micro: 0.7067 - aux_output_acc: 0.7902 - aux_output_f1_micro: 0.1115 - val_loss: 1.3707 - val_main_output_loss: 1.0832 - val_aux_output_loss: 1.4377 - val_main_output_acc: 0.8034 - val_main_output_f1_micro: 0.7075 - val_aux_output_acc: 0.7948 - val_aux_output_f1_micro: 0.1117\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5205 - main_output_loss: 1.2508 - aux_output_loss: 1.3484 - main_output_acc: 0.7803 - main_output_f1_micro: 0.7083 - aux_output_acc: 0.7910 - aux_output_f1_micro: 0.1118 - val_loss: 1.3696 - val_main_output_loss: 1.0827 - val_aux_output_loss: 1.4348 - val_main_output_acc: 0.8018 - val_main_output_f1_micro: 0.7090 - val_aux_output_acc: 0.7929 - val_aux_output_f1_micro: 0.1120\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5220 - main_output_loss: 1.2527 - aux_output_loss: 1.3466 - main_output_acc: 0.7793 - main_output_f1_micro: 0.7098 - aux_output_acc: 0.7904 - aux_output_f1_micro: 0.1122 - val_loss: 1.3695 - val_main_output_loss: 1.0827 - val_aux_output_loss: 1.4341 - val_main_output_acc: 0.7963 - val_main_output_f1_micro: 0.7105 - val_aux_output_acc: 0.7926 - val_aux_output_f1_micro: 0.1123\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5216 - main_output_loss: 1.2530 - aux_output_loss: 1.3431 - main_output_acc: 0.7800 - main_output_f1_micro: 0.7113 - aux_output_acc: 0.7914 - aux_output_f1_micro: 0.1125 - val_loss: 1.3708 - val_main_output_loss: 1.0860 - val_aux_output_loss: 1.4240 - val_main_output_acc: 0.8011 - val_main_output_f1_micro: 0.7120 - val_aux_output_acc: 0.7966 - val_aux_output_f1_micro: 0.1126\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5163 - main_output_loss: 1.2486 - aux_output_loss: 1.3386 - main_output_acc: 0.7807 - main_output_f1_micro: 0.7128 - aux_output_acc: 0.7916 - aux_output_f1_micro: 0.1128 - val_loss: 1.3660 - val_main_output_loss: 1.0814 - val_aux_output_loss: 1.4232 - val_main_output_acc: 0.7929 - val_main_output_f1_micro: 0.7135 - val_aux_output_acc: 0.7930 - val_aux_output_f1_micro: 0.1130\n",
      "\n",
      "Done with epoch: 110\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5152 - main_output_loss: 1.2484 - aux_output_loss: 1.3341 - main_output_acc: 0.7792 - main_output_f1_micro: 0.7142 - aux_output_acc: 0.7911 - aux_output_f1_micro: 0.1131 - val_loss: 1.3651 - val_main_output_loss: 1.0816 - val_aux_output_loss: 1.4173 - val_main_output_acc: 0.7956 - val_main_output_f1_micro: 0.7149 - val_aux_output_acc: 0.7927 - val_aux_output_f1_micro: 0.1133\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5089 - main_output_loss: 1.2427 - aux_output_loss: 1.3309 - main_output_acc: 0.7803 - main_output_f1_micro: 0.7156 - aux_output_acc: 0.7912 - aux_output_f1_micro: 0.1135 - val_loss: 1.3627 - val_main_output_loss: 1.0794 - val_aux_output_loss: 1.4167 - val_main_output_acc: 0.7989 - val_main_output_f1_micro: 0.7164 - val_aux_output_acc: 0.7968 - val_aux_output_f1_micro: 0.1136\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5082 - main_output_loss: 1.2431 - aux_output_loss: 1.3254 - main_output_acc: 0.7813 - main_output_f1_micro: 0.7171 - aux_output_acc: 0.7917 - aux_output_f1_micro: 0.1138 - val_loss: 1.3610 - val_main_output_loss: 1.0787 - val_aux_output_loss: 1.4114 - val_main_output_acc: 0.8054 - val_main_output_f1_micro: 0.7178 - val_aux_output_acc: 0.7916 - val_aux_output_f1_micro: 0.1139\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5043 - main_output_loss: 1.2400 - aux_output_loss: 1.3214 - main_output_acc: 0.7788 - main_output_f1_micro: 0.7185 - aux_output_acc: 0.7905 - aux_output_f1_micro: 0.1141 - val_loss: 1.3573 - val_main_output_loss: 1.0764 - val_aux_output_loss: 1.4045 - val_main_output_acc: 0.8025 - val_main_output_f1_micro: 0.7192 - val_aux_output_acc: 0.7962 - val_aux_output_f1_micro: 0.1143\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5045 - main_output_loss: 1.2409 - aux_output_loss: 1.3181 - main_output_acc: 0.7785 - main_output_f1_micro: 0.7199 - aux_output_acc: 0.7919 - aux_output_f1_micro: 0.1145 - val_loss: 1.3638 - val_main_output_loss: 1.0828 - val_aux_output_loss: 1.4050 - val_main_output_acc: 0.7982 - val_main_output_f1_micro: 0.7205 - val_aux_output_acc: 0.7963 - val_aux_output_f1_micro: 0.1146\n",
      "\n",
      "Done with epoch: 115\n",
      "\n",
      "CPU times: user 20min 20s, sys: 1min 53s, total: 22min 14s\n",
      "Wall time: 17min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total_epochs = 100\n",
    "for j in xrange(i, i + (total_epochs // epochs)):\n",
    "    hist = model.fit(\n",
    "        training_inputs,\n",
    "        training_outputs,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.2,\n",
    "        validation_data=validation_data,\n",
    "    )\n",
    "\n",
    "    model.save(model_name.format(i))\n",
    "    print\n",
    "    print('Done with epoch: {}'.format((j + 1) * epochs))\n",
    "    with open(log_history_file, 'a') as fl:\n",
    "        fl.write(model_name + '\\n')\n",
    "        fl.write('Epoch {}\\n'.format((j + 1) * epochs))\n",
    "        fl.write('{}\\n'.format(datetime.now()))\n",
    "        fl.write('\\n'.join(['{}: {}'.format(k, v[0]) for k, v in hist.history.items()]))\n",
    "        fl.write('\\n\\n')\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = keras.models.load_model(\n",
    "#     'models/lstm-word2vec-fasttext_2010-2014-data_categorical-crossentropy-2014-b-val-standard_scaled_wv_fs.model',\n",
    "#     custom_objects={'f1_micro': f1_micro}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = model.predict(\n",
    "    build_training_inputs(\n",
    "        wv_train[:100],\n",
    "        fs_train[:100],\n",
    "        tfidf_wv_train[:100],\n",
    "        tfidf_fs_train[:100],\n",
    "        tfidf_lsi_train[:100],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0af7f9e5d0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f09bd27bbd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "ix = 29\n",
    "pd.Series(g[ix]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([ 1, 98]),), (array([ 1, 98]),))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh = 0.5\n",
    "np.where(y_train[ix] == 1), np.where(g[ix] > thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.tfidfmodel import TfidfModel, LsiModel\n",
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = TfidfModel.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.dictionary')\n",
    "tfidf = TfidfModel.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.tfidf')\n",
    "lsi = LsiModel.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.lsi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wvmodel = Word2Vec.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fsmodel = fasttext.load_model('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.fasttext.model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_tfidf_word2vec(tokens, stopwords=[]):\n",
    "#     global wvmodel\n",
    "#     global tfidf\n",
    "    # This requires wvmodel to be present in the namespace.\n",
    "    wv_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords and w in wvmodel.wv.vocab)]\n",
    "    ).map(\n",
    "        lambda x: tfidf[dictionary.doc2bow(x)]\n",
    "    ).map(\n",
    "        lambda x: np.array([wvmodel[dictionary.id2token[id]] * w for id, w in x]).mean(axis=0) if len(x) > 0 else np.nan\n",
    "    )\n",
    "\n",
    "    return wv_feature_vec\n",
    "\n",
    "\n",
    "def transform_tfidf_fasttext(tokens, stopwords=[]):\n",
    "#     global fsmodel\n",
    "#     global tfidf\n",
    "    # This requires wvmodel to be present in the namespace.\n",
    "    fs_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    ).map(\n",
    "        lambda x: tfidf[dictionary.doc2bow(x)]\n",
    "    ).map(\n",
    "        lambda x: np.array([np.array(fsmodel[dictionary.id2token[id]]) * w for id, w in x]).mean(axis=0) if len(x) > 0 else np.nan\n",
    "    )\n",
    "\n",
    "    return fs_feature_vec\n",
    "\n",
    "\n",
    "def transform_tfidf_lsi(tokens, stopwords=[]):\n",
    "#     global fsmodel\n",
    "#     global tfidf\n",
    "    # This requires wvmodel to be present in the namespace.\n",
    "    lsi_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    ).map(\n",
    "        lambda x: np.array(zip(*lsi[tfidf[dictionary.doc2bow(x)]])[1]) if len(x) > 0 else np.nan\n",
    "    )\n",
    "\n",
    "    return lsi_feature_vec\n",
    "\n",
    "\n",
    "def transform_fasttext(tokens, stopwords=[]):\n",
    "    global fsmodel\n",
    "    # This requires fsmodel to be present in the namespace.\n",
    "    fs_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    ).map(lambda x: np.array([fsmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return fs_feature_vec\n",
    "\n",
    "\n",
    "def transform_unsupervised_sentiment_neuron(tokens, stopwords=[]):\n",
    "    # This requires fsmodel to be present in the namespace.\n",
    "    \n",
    "    usn_feature_vec = usnmodel.transform(tokens)\n",
    "\n",
    "    # usn_feature_vec = tokens.map(\n",
    "    #     lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    # ).map(lambda x: np.array([usnmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return usn_feature_vec\n",
    "\n",
    "\n",
    "def transform_word2vec(tokens, stopwords=[]):\n",
    "    global wvmodel\n",
    "    # This requires wvmodel to be present in the namespace.\n",
    "    wv_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords and w in wvmodel.wv.vocab)]\n",
    "    ).map(lambda x: np.array([wvmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return wv_feature_vec\n",
    "\n",
    "\n",
    "def parallel_generate_word_vectors(samp, transformer, stopwords, batch, num_proc):\n",
    "    with Parallel(n_jobs=num_proc) as parallel:\n",
    "        dataset = []\n",
    "        is_break = False\n",
    "        i = 0\n",
    "\n",
    "        while not is_break:\n",
    "            payload = []\n",
    "\n",
    "            for j in xrange(num_proc):\n",
    "                t_df = samp[(i + j) * batch: (i + 1 + j) * batch]\n",
    "\n",
    "                if t_df.empty:\n",
    "                    is_break = True\n",
    "                    continue\n",
    "\n",
    "                payload.append(\n",
    "                    delayed(transformer)(\n",
    "                        t_df, stopwords\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            print('Current batch in main thread: {}'.format((i + j) * batch))\n",
    "\n",
    "            if payload:\n",
    "                results = parallel(payload)\n",
    "                dataset.extend(results)\n",
    "                i += num_proc\n",
    "\n",
    "    return pd.concat(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_classes(pred, scale_param=0.75, min_thresh=0.05, thresh = 0.5):\n",
    "#     mx = pred.mean() + 3 * pred.std()\n",
    "    return np.where(pred > thresh)[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2idx_transform(word, _word2idx):\n",
    "    return _word2idx.get(word, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features_for(df, min_batch=2000, stopwords=[], num_proc=7):\n",
    "    df_tokens = transform_text(df)\n",
    "    \n",
    "    batch = min(df_tokens.shape[0] / num_proc, min_batch)\n",
    "\n",
    "    print('Computing fs features...')\n",
    "    fvec = parallel_generate_word_vectors(df_tokens, transform_fasttext, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Computing wv features...')\n",
    "    wvec = parallel_generate_word_vectors(df_tokens, transform_word2vec, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Mapping word indices...')\n",
    "    word_indices = df_tokens.map(lambda x: [word2idx_transform(i, _word2idx) for i in x.split()])\n",
    "\n",
    "    print('Computing tfidf fs features...')\n",
    "    tfidf_fvec = parallel_generate_word_vectors(df_tokens, transform_tfidf_fasttext, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Computing tfidf wv features...')\n",
    "    tfidf_wvec = parallel_generate_word_vectors(df_tokens, transform_tfidf_word2vec, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Computing tfidf lsi features...')\n",
    "    tfidf_lsi = parallel_generate_word_vectors(df_tokens, transform_tfidf_lsi, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "    \n",
    "    return word_indices, wvec, fvec, tfidf_wvec, tfidf_fvec, tfidf_lsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/TestData.json') as fl:\n",
    "    data = json.load(fl)\n",
    "    test_df = pd.DataFrame(data['TestData']).T\n",
    "    del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fs features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Computing wv features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Mapping word indices...\n",
      "Computing tfidf fs features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Computing tfidf wv features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "CPU times: user 50.3 s, sys: 4.88 s, total: 55.2 s\n",
      "Wall time: 2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_word_indices,test_wvec, test_fvec, test_tfidf_wvec, test_tfidf_fvec, test_tfidf_lsi = extract_features_for(\n",
    "    test_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert(np.all(test_wvec[test_wvec.isnull()].index == test_fvec[test_fvec.isnull()].index))\n",
    "test_null_index = test_wvec[test_wvec.isnull()].index.union(test_fvec[test_fvec.isnull()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'TestData_02543', u'TestData_05012', u'TestData_05830'], dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_null_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.18 s, sys: 32 ms, total: 1.21 s\n",
      "Wall time: 1.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "valid_test_index = test_word_indices.index.difference(test_null_index)\n",
    "x_test = test_word_indices.ix[valid_test_index]  # .map(lambda x: [top_token2ind.get(i, 0) for i in x])\n",
    "\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "wv_test = np.vstack(test_wvec.ix[valid_test_index])\n",
    "fs_test = np.vstack(test_fvec.ix[valid_test_index])\n",
    "\n",
    "tfidf_wv_test = np.vstack(test_tfidf_wvec.ix[valid_test_index])\n",
    "tfidf_fs_test = np.vstack(test_tfidf_fvec.ix[valid_test_index])\n",
    "tfidf_lsi_test = np.vstack(test_tfidf_lsi.ix[valid_test_index])\n",
    "\n",
    "wv_test = wv_sc.transform(wv_test)\n",
    "fs_test = fs_sc.transform(fs_test)\n",
    "\n",
    "tfidf_wv_test = tfidf_wv_sc.transform(tfidf_wv_test)\n",
    "tfidf_fs_test = tfidf_fs_sc.transform(tfidf_fs_test)\n",
    "tfidf_lsi_test = tfidf_lsi_sc.transform(tfidf_lsi_test)\n",
    "\n",
    "test_inputs = build_training_inputs(\n",
    "    wv_test,\n",
    "    fs_test,\n",
    "    tfidf_wv_test,\n",
    "    tfidf_fs_test,\n",
    "    tfidf_lsi_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_probas = model.predict(test_inputs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_test_probas = test_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   9.53572221e-11,   2.34125965e-11, ...,\n",
       "          4.58941804e-13,   7.55075030e-18,   0.00000000e+00],\n",
       "       [  7.10577062e-37,   1.95997995e-06,   6.26461588e-06, ...,\n",
       "          1.58872293e-08,   1.58961299e-07,   9.53767052e-37],\n",
       "       [  0.00000000e+00,   3.49002214e-08,   1.33569715e-08, ...,\n",
       "          7.51075777e-06,   3.19748228e-10,   0.00000000e+00],\n",
       "       ..., \n",
       "       [  6.72936563e-26,   5.19690383e-03,   1.15589380e-01, ...,\n",
       "          2.78446732e-09,   7.49666803e-03,   2.38802543e-25],\n",
       "       [  7.92818150e-29,   1.94924721e-03,   2.61581095e-04, ...,\n",
       "          8.19239574e-08,   1.91242202e-06,   4.57425551e-28],\n",
       "       [  0.00000000e+00,   6.89471854e-05,   1.37220457e-04, ...,\n",
       "          1.12836277e-11,   3.48008816e-10,   8.89052297e-38]], dtype=float32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_test_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2542, 5011, 5829]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_index = [int(s.split('_')[1]) - 1 for s in test_null_index]  # Subtract 1 since test index starts at 1 while enumerate starts at 0\n",
    "skip_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7578, 160), (7581, 3))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_test_probas.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36 ms, sys: 0 ns, total: 36 ms\n",
      "Wall time: 31.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# valid_test_feature_vec found below!\n",
    "thresh = 0.2\n",
    "test_values = np.zeros([main_test_probas.shape[0], len(topics)])\n",
    "for ix, pred in enumerate(main_test_probas):\n",
    "    for v in get_classes(pred, thresh=thresh):\n",
    "        test_values[ix][v] = 1\n",
    "\n",
    "test_sub_df = pd.DataFrame(\n",
    "    test_values,\n",
    "    index=test_df.ix[test_df.index.difference(test_null_index)].index,\n",
    "    columns=topics\n",
    ")\n",
    "\n",
    "null_test_df = pd.DataFrame(\n",
    "    np.zeros((len(test_null_index), len(topics))),\n",
    "    index=test_null_index,\n",
    "    columns=topics\n",
    ")\n",
    "\n",
    "test_sub_df = test_sub_df.append(null_test_df)\n",
    "test_sub_df = test_sub_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 9627 (0.5), 14297 (0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12622.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14432.0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7581.000000\n",
       "mean      882.691070\n",
       "std       621.585386\n",
       "min         0.000000\n",
       "25%       552.000000\n",
       "50%       770.000000\n",
       "75%      1026.000000\n",
       "max      8171.000000\n",
       "Name: bodyText, dtype: float64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_word_indices.map(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1382.0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_word_indices.map(len).quantile(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1223"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df.ix['TestData_04490'].bodyText.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94731/94731 [==============================] - 51s - loss: 1.5045 - main_output_loss: 1.2409 - aux_output_loss: 1.3181 - main_output_acc: 0.7785 - main_output_f1_micro: 0.7199 - aux_output_acc: 0.7919 - aux_output_f1_micro: 0.1145 - val_loss: 1.3638 - val_main_output_loss: 1.0828 - val_aux_output_loss: 1.4050 - val_main_output_acc: 0.7982 - val_main_output_f1_micro: 0.7205 - val_aux_output_acc: 0.7963 - val_aux_output_f1_micro: 0.1146\n"
     ]
    }
   ],
   "source": [
    "print '94731/94731 [==============================] - 51s - loss: 1.5045 - main_output_loss: 1.2409 - aux_output_loss: 1.3181 - main_output_acc: 0.7785 - main_output_f1_micro: 0.7199 - aux_output_acc: 0.7919 - aux_output_f1_micro: 0.1145 - val_loss: 1.3638 - val_main_output_loss: 1.0828 - val_aux_output_loss: 1.4050 - val_main_output_acc: 0.7982 - val_main_output_f1_micro: 0.7205 - val_aux_output_acc: 0.7963 - val_aux_output_f1_micro: 0.1146'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_filename = 'tfidf_word2vec_300-fasttext_300-deep_stack_net-epochs_800-f1_0.6183-data_2010_2014-val_data_2014-thresh_{}-with_sc_wv_fs.csv'.format(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_sub_df.astype(int).reset_index().rename(\n",
    "    columns={'index': 'id'}\n",
    ").sort_values('id').to_csv(\n",
    "    sub_filename, \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7581, 160)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TestData_04490\tThe World Health Organisation has convened an ...\t[]\t28-01-2016\n",
    "TestData_04550\tSpraying pesticides will fail to deal with the...\t[]\t02-02-2016\n",
    "TestData_05683\tViolent protests at Trump rally in California ...\t[]\t03-06-2016\n",
    "TestData_05869\tLast weekend, we saw the darkest side of human...\t[]\t17-06-2016\n",
    "TestData_06148\tAs dusk falls over Copacabana beach, Ubira San...\t[]\t16-07-2016\n",
    "TestData_06291\tIt is 3pm and yet another patient is brought t...\t[]\t27-07-2016\n",
    "TestData_06610\tHuddled around their hives, beekeepers around ...\t[]\t04-09-2016\n",
    "TestData_06708\tA United Nations high-level panel on access to...\t[]\t14-09-2016\n",
    "TestData_07263\tWHO: Zika virus is no longer a world threat Th...\t[]\t19-11-2016\n",
    "TestData_07478\t1 World Health Organisation declares a public ...\t[]\t18-12-2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "guncrime        1.0\n",
       "usguncontrol    1.0\n",
       "Name: TestData_05869, dtype: float64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = 5868\n",
    "test_sub_df.iloc[ix][test_sub_df.iloc[ix] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36 ms, sys: 0 ns, total: 36 ms\n",
      "Wall time: 32.6 ms\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# adjust_index = 0\n",
    "# # valid_test_feature_vec found below!\n",
    "# test_values = np.zeros([test_df.shape[0], len(topics)])\n",
    "# for ix, pred in enumerate(main_test_probas):\n",
    "#     if ix in skip_index:\n",
    "#         test_values[ix] = np.nan\n",
    "#         # Increment adjust index so that we have the correct index for other samples\n",
    "#         adjust_index += 1\n",
    "#         continue\n",
    "\n",
    "#     for v in get_classes(pred, thresh=0.05):\n",
    "#         test_values[ix + adjust_index][v] = 1\n",
    "\n",
    "# test_sub_df = pd.DataFrame(test_values, columns=sorted(topics), index=test_df.index)\n",
    "\n",
    "# q = test_sub_df.sum(axis=1)\n",
    "# assert(len(q[q.isnull()].index.difference(test_null_index)) == 0)\n",
    "\n",
    "# test_sub_df = test_sub_df.fillna(0)\n",
    "\n",
    "# # for i in test_feature_vec[test_feature_vec.isnull()].index:\n",
    "# #     test_sub_df.ix[i] = np.zeros(len(topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestData_02543    0.0\n",
       "TestData_05012    0.0\n",
       "TestData_05830    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.ix[test_null_index].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11656.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sub_df.astype(int).reset_index().rename(\n",
    "    columns={'index': 'id'}\n",
    ").sort_values('id').to_csv(\n",
    "    'lstm_300-word2vec_300-fasttext_300-maxlen_500-dense_64_64_64-cat_cross-epoch_210-batch_size_750-val_main_output_f1_micro_0.5760-main_output_f1_micro_0.5751-main_output_loss_0.9143-data_2010_2013-val_data_2014-thresh_0.05.csv', \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: zikavirus, dtype: float64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = test_sub_df['zikavirus']\n",
    "e[e==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14328"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_submission = pd.read_csv('basic_nn_submission_0.649_accuracy_multi_class.csv')\n",
    "top_submission.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9280"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_index_lstm_sub = pd.read_csv('lstm.2014b_training_700_maxlen_64cell_100epochs_0.0025_threshold.csv')\n",
    "wrong_index_lstm_sub.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34952"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_sub = pd.read_csv('basic_nn_submission_full_training_data_0.9958_validation_accuracy_binary_crossentropy.csv')\n",
    "some_sub.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2197, 160)\n",
      "(3957, 160)\n",
      "(12, 160)\n",
      "(1503, 160)\n"
     ]
    }
   ],
   "source": [
    "print top_submission.set_index('id')[top_submission.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print wrong_index_lstm_sub.set_index('id')[wrong_index_lstm_sub.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print some_sub.set_index('id')[some_sub.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print test_sub_df[test_sub_df.sum(axis=1) == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestData_00011     0\n",
       "TestData_00012     0\n",
       "TestData_00015     0\n",
       "TestData_00027     3\n",
       "TestData_00029     0\n",
       "TestData_00038     1\n",
       "TestData_00042     5\n",
       "TestData_00053     4\n",
       "TestData_00056     1\n",
       "TestData_00060     1\n",
       "TestData_00066     0\n",
       "TestData_00085     0\n",
       "TestData_00087     1\n",
       "TestData_00090     0\n",
       "TestData_00092     0\n",
       "TestData_00107     3\n",
       "TestData_00111     0\n",
       "TestData_00114     0\n",
       "TestData_00115     1\n",
       "TestData_00118     0\n",
       "TestData_00119     0\n",
       "TestData_00121     0\n",
       "TestData_00123     0\n",
       "TestData_00125     0\n",
       "TestData_00127     0\n",
       "TestData_00128     1\n",
       "TestData_00139     1\n",
       "TestData_00140     1\n",
       "TestData_00144     0\n",
       "TestData_00147     2\n",
       "                  ..\n",
       "TestData_07445     0\n",
       "TestData_07456     3\n",
       "TestData_07461     1\n",
       "TestData_07462     4\n",
       "TestData_07465     0\n",
       "TestData_07468     0\n",
       "TestData_07471     1\n",
       "TestData_07475     0\n",
       "TestData_07486    10\n",
       "TestData_07495     1\n",
       "TestData_07509     0\n",
       "TestData_07514     3\n",
       "TestData_07515     1\n",
       "TestData_07523     0\n",
       "TestData_07533     2\n",
       "TestData_07534     2\n",
       "TestData_07542     1\n",
       "TestData_07544     2\n",
       "TestData_07545     0\n",
       "TestData_07552     2\n",
       "TestData_07556     5\n",
       "TestData_07563     1\n",
       "TestData_07565     0\n",
       "TestData_07566     0\n",
       "TestData_07569     0\n",
       "TestData_07571     3\n",
       "TestData_07572     1\n",
       "TestData_07579     6\n",
       "TestData_07580     2\n",
       "TestData_07581     3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_submission.set_index('id').ix[q[q == 0].index].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1222,)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.sum(axis=1)\n",
    "q[q==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7581.000000\n",
       "mean        2.160929\n",
       "std         1.739411\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         2.000000\n",
       "75%         3.000000\n",
       "max        13.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = trainingY.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    236286.000000\n",
       "mean          1.392787\n",
       "std           0.762577\n",
       "min           1.000000\n",
       "25%           1.000000\n",
       "50%           1.000000\n",
       "75%           2.000000\n",
       "max          15.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bodyText</th>\n",
       "      <th>topics</th>\n",
       "      <th>webPublicationDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TestData_03241</th>\n",
       "      <td>A special British police unit was put on stand...</td>\n",
       "      <td>[]</td>\n",
       "      <td>15-11-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_04088</th>\n",
       "      <td>The youngest convict in a fatal gang-rape in N...</td>\n",
       "      <td>[]</td>\n",
       "      <td>20-12-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_06306</th>\n",
       "      <td>Former New York City mayor Rudy Giuliani has s...</td>\n",
       "      <td>[]</td>\n",
       "      <td>28-07-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_06083</th>\n",
       "      <td>John Cantlie, the British journalist who has b...</td>\n",
       "      <td>[]</td>\n",
       "      <td>13-07-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_05896</th>\n",
       "      <td>Lawyers for the companies that manufactured an...</td>\n",
       "      <td>[]</td>\n",
       "      <td>20-06-2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         bodyText topics  \\\n",
       "TestData_03241  A special British police unit was put on stand...     []   \n",
       "TestData_04088  The youngest convict in a fatal gang-rape in N...     []   \n",
       "TestData_06306  Former New York City mayor Rudy Giuliani has s...     []   \n",
       "TestData_06083  John Cantlie, the British journalist who has b...     []   \n",
       "TestData_05896  Lawyers for the companies that manufactured an...     []   \n",
       "\n",
       "               webPublicationDate  \n",
       "TestData_03241         15-11-2015  \n",
       "TestData_04088         20-12-2015  \n",
       "TestData_06306         28-07-2016  \n",
       "TestData_06083         13-07-2016  \n",
       "TestData_05896         20-06-2016  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ix = 'TestData_04088'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "humanrights    1.0\n",
       "india          1.0\n",
       "Name: TestData_04088, dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ukcrime    1\n",
       "Name: TestData_04088, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = top_submission.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "humanrights    1\n",
       "india          1\n",
       "protest        1\n",
       "ukcrime        1\n",
       "Name: TestData_04088, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = some_sub.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "humanrights    1\n",
       "Name: TestData_02924, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = wrong_index_lstm_sub.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Counter-terrorism policy\n",
    " \n",
    "Foreign policy\n",
    " \n",
    "Defence policy\n",
    " \n",
    "Islamic State\n",
    " \n",
    "Syria\n",
    " \n",
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = trainingY.sum()\n",
    "unseen_topics = s[s.isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activism',\n",
       " 'bastilledaytruckattack',\n",
       " 'berlinchristmasmarketattack',\n",
       " 'brusselsattacks',\n",
       " 'charliehebdoattack',\n",
       " 'francetrainattack',\n",
       " 'munichshooting',\n",
       " 'orlandoterrorattack',\n",
       " 'parisattacks',\n",
       " 'peaceandreconciliation',\n",
       " 'sanbernardinoshooting',\n",
       " 'tunisiaattack2015',\n",
       " 'turkeycoupattempt',\n",
       " 'zikavirus'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(topics).intersection(unseen_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activism\n",
      "afghanistan\n",
      "aid\n",
      "algerianhostagecrisis\n",
      "alqaida\n",
      "alshabaab\n",
      "antiwar\n",
      "arabandmiddleeastprotests\n",
      "armstrade\n",
      "australianguncontrol\n",
      "australiansecurityandcounterterrorism\n",
      "bastilledaytruckattack\n",
      "belgium\n",
      "berlinchristmasmarketattack\n",
      "bigdata\n",
      "biometrics\n",
      "bokoharam\n",
      "bostonmarathonbombing\n",
      "britisharmy\n",
      "brusselsattacks\n",
      "cameroon\n",
      "carers\n",
      "charliehebdoattack\n",
      "chemicalweapons\n",
      "clusterbombs\n",
      "cobra\n",
      "conflictanddevelopment\n",
      "controversy\n",
      "criminaljustice\n",
      "cybercrime\n",
      "cyberwar\n",
      "darknet\n",
      "dataprotection\n",
      "debate\n",
      "defence\n",
      "deflation\n",
      "drones\n",
      "drugs\n",
      "drugspolicy\n",
      "drugstrade\n",
      "earthquakes\n",
      "ebola\n",
      "economy\n",
      "egypt\n",
      "encryption\n",
      "energy\n",
      "espionage\n",
      "ethics\n",
      "europeanarrestwarrant\n",
      "europeancourtofhumanrights\n",
      "events\n",
      "extradition\n",
      "famine\n",
      "farright\n",
      "firefighters\n",
      "forensicscience\n",
      "france\n",
      "francetrainattack\n",
      "freedomofspeech\n",
      "genevaconventions\n",
      "germany\n",
      "guncrime\n",
      "hacking\n",
      "hashtags\n",
      "helicoptercrashes\n",
      "humanitarianresponse\n",
      "humanrights\n",
      "humanrightsact\n",
      "humantrafficking\n",
      "immigration\n",
      "india\n",
      "indonesia\n",
      "internallydisplacedpeople\n",
      "internationalcourtofjustice\n",
      "internationalcriminaljustice\n",
      "internetsafety\n",
      "iraq\n",
      "isis\n",
      "israel\n",
      "jordan\n",
      "jubilee\n",
      "judiciary\n",
      "july7\n",
      "justiceandsecurity\n",
      "kenya\n",
      "knifecrime\n",
      "lebanon\n",
      "libya\n",
      "localgovernment\n",
      "logistics\n",
      "london\n",
      "londonriots\n",
      "malaysia\n",
      "mali\n",
      "malware\n",
      "metropolitanpolice\n",
      "middleeastpeacetalks\n",
      "migration\n",
      "military\n",
      "ministryofdefence\n",
      "morocco\n",
      "mrsa\n",
      "mumbaiterrorattacks\n",
      "munichshooting\n",
      "naturaldisasters\n",
      "nigeria\n",
      "nuclearweapons\n",
      "occupy\n",
      "organisedcrime\n",
      "orlandoterrorattack\n",
      "osamabinladen\n",
      "paris\n",
      "parisattacks\n",
      "peaceandreconciliation\n",
      "philippines\n",
      "piracy\n",
      "planecrashes\n",
      "police\n",
      "protest\n",
      "refugees\n",
      "religion\n",
      "retirementage\n",
      "rio20earthsummit\n",
      "royalairforce\n",
      "royalnavy\n",
      "russia\n",
      "sanbernardinoshooting\n",
      "saudiarabia\n",
      "september11\n",
      "slavery\n",
      "somalia\n",
      "southafrica\n",
      "southchinasea\n",
      "stopandsearch\n",
      "surveillance\n",
      "sydneysiege\n",
      "syria\n",
      "taliban\n",
      "terrorism\n",
      "thailand\n",
      "torture\n",
      "traincrashes\n",
      "transport\n",
      "tunisiaattack2015\n",
      "turkey\n",
      "turkeycoupattempt\n",
      "ukcrime\n",
      "uksecurity\n",
      "uksupremecourt\n",
      "undercoverpoliceandpolicing\n",
      "unitednations\n",
      "usguncontrol\n",
      "values\n",
      "warcrimes\n",
      "warreporting\n",
      "weaponstechnology\n",
      "womeninbusiness\n",
      "woolwichattack\n",
      "worldmigration\n",
      "zikavirus\n"
     ]
    }
   ],
   "source": [
    "for i in topics:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsolatorio/ml-ai/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3445929"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(wvmodel['zika'], np.vstack(test_wvec.dropna())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsolatorio/ml-ai/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.38107796869050226"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(fsmodel['zika'], np.vstack(test_fvec.dropna())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              The World Health Organisation has convened an ...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           28-01-2016\n",
       "Name: TestData_04490, dtype: object"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[4488 + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              The United Nations security council has called...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           17-09-2016\n",
       "Name: TestData_06730, dtype: object"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[6727 + 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              We are deeply concerned that the counter-terro...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           02-02-2015\n",
       "Name: TestData_00360, dtype: object"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[359]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drugstrade    1.0\n",
       "Name: TestData_04490, dtype: float64"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.iloc[4488 + 1]\n",
    "q[q > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
