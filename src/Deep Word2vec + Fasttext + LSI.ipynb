{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from growing_instability_lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub = pd.read_csv('../data/sampleSubmission.csv')\n",
    "topics = sorted(set(sample_sub.columns.difference(['id'])))\n",
    "\n",
    "topic2actual = {}\n",
    "for i in sample_sub.columns:\n",
    "    if 'id' == i:\n",
    "        continue\n",
    "    topic2actual[i] = segment(i)\n",
    "    \n",
    "target_columns = sorted(topics)\n",
    "len(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.3 s, sys: 3.88 s, total: 14.1 s\n",
      "Wall time: 17.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wvec_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'wvec_trainingX')\n",
    "fvec_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'fvec_trainingX')\n",
    "\n",
    "tfidf_wvec_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'tfidf_wvec_trainingX')\n",
    "tfidf_fvec_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'tfidf_fvec_trainingX')\n",
    "tfidf_lsi_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'tfidf_lsi_trainingX')\n",
    "\n",
    "word2idx_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'word2idx_trainingX')\n",
    "_word2idx = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', '_word2idx')\n",
    "trainingY = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'trainingY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://192.168.1.25:9999/notebooks/kaggle/data-science-challenge-growing-instability-05-13-2017/src/Topic%20Modeling%20and%20Clustering.ipynb\n",
    "train_test_df = pd.read_hdf('train_test_df.hdf', 'train_test_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_topics(df, topics):\n",
    "    topics = sorted(topics)\n",
    "#     v = np.zeros(shape=(df.shape[0], len(topics)))\n",
    "    v = []\n",
    "    for ix, tp in enumerate(df.topics):\n",
    "        tt = []\n",
    "        for t in tp:\n",
    "            tt.append(topics.index(t))\n",
    "#             v[ix][topics.index(t)] = 1\n",
    "        v.append(tt)\n",
    "\n",
    "    return pd.Series(v, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_word_indices, train_test_wvec, train_test_fvec, train_test_tfidf_wvec, train_test_tfidf_fvec, train_test_tfidf_lsi = extract_features_for(\n",
    ")\n",
    "\n",
    "train_test_y = transform_topics(train_test_df, topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 s, sys: 288 ms, total: 11.3 s\n",
      "Wall time: 11.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ind2word = {j:i for i, j in _word2idx.iteritems()}\n",
    "ind2class = dict(enumerate(topics))\n",
    "class2ind = {j: i for i, j in ind2class.items()}\n",
    "\n",
    "num_samples = trainingY.shape[0]\n",
    "\n",
    "# ---------------------------------\n",
    "training_X = word2idx_trainingX.head(num_samples)\n",
    "training_Y = pd.DataFrame(zip(*np.where(trainingY.head(num_samples) == 1)), columns=['iloc', 'topics'])\n",
    "\n",
    "training_WV = wvec_trainingX.head(num_samples)\n",
    "training_FS = fvec_trainingX.head(num_samples)\n",
    "\n",
    "training_tfidf_WV = tfidf_wvec_trainingX.head(num_samples)\n",
    "training_tfidf_FS = tfidf_fvec_trainingX.head(num_samples)\n",
    "training_tfidf_LSI = tfidf_lsi_trainingX.head(num_samples)\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "training_Y = training_Y.groupby('iloc')['topics'].apply(list)\n",
    "training_Y.index = trainingY.head(num_samples).index\n",
    "\n",
    "indices = sorted(training_Y.index[training_Y.index.str.contains('^201[0-9]')])\n",
    "# np.random.shuffle(indices)\n",
    "indices = pd.Index(indices)\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "training_X = training_X.ix[indices]\n",
    "training_Y = training_Y.ix[indices]\n",
    "\n",
    "training_WV = training_WV.ix[indices]\n",
    "training_FS = training_FS.ix[indices]\n",
    "\n",
    "training_tfidf_WV = training_tfidf_WV.ix[indices]\n",
    "training_tfidf_FS = training_tfidf_FS.ix[indices]\n",
    "training_tfidf_LSI = training_tfidf_LSI.ix[indices]\n",
    "# ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 9.06 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wv_sc = StandardScaler()\n",
    "fs_sc = StandardScaler()\n",
    "\n",
    "tfidf_wv_sc = StandardScaler()\n",
    "tfidf_fs_sc = StandardScaler()\n",
    "tfidf_lsi_sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.7 s, sys: 268 ms, total: 2.97 s\n",
      "Wall time: 2.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "maxlen = 500\n",
    "\n",
    "\n",
    "def build_target(y, size):\n",
    "    e = np.zeros(size)\n",
    "    e[y] = 1\n",
    "    return e\n",
    "\n",
    "\n",
    "def build_input_output_data(X, WV, FS, TWV, TFS, TLSI, Y, maxlen):\n",
    "    x = sequence.pad_sequences(X, maxlen=maxlen)\n",
    "    y = np.vstack(Y.map(lambda x: build_target(x, len(topics))))\n",
    "\n",
    "    wv = np.vstack(WV)\n",
    "    fs = np.vstack(FS)\n",
    "\n",
    "    twv = np.vstack(TWV)\n",
    "    tfs = np.vstack(TFS)\n",
    "    tlsi = np.vstack(TLSI)\n",
    "\n",
    "    return x, wv, fs, twv, tfs, tlsi, y\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "train_ix = training_Y.index.str.contains('^201[0-4]')\n",
    "val_ix = training_Y.index.str.contains('^2014[b]')\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "x_train, wv_train, fs_train, tfidf_wv_train, tfidf_fs_train, tfidf_lsi_train, y_train = build_input_output_data(\n",
    "    training_X.ix[train_ix],\n",
    "\n",
    "    training_WV.ix[train_ix],\n",
    "    training_FS.ix[train_ix],\n",
    "\n",
    "    training_tfidf_WV.ix[train_ix],\n",
    "    training_tfidf_FS.ix[train_ix],\n",
    "    training_tfidf_LSI.ix[train_ix],\n",
    "\n",
    "    training_Y.ix[train_ix],\n",
    "    maxlen=maxlen\n",
    ")\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "x_val, wv_val, fs_val, tfidf_wv_val, tfidf_fs_val, tfidf_lsi_val, y_val = build_input_output_data(\n",
    "    training_X.ix[val_ix],\n",
    "\n",
    "    training_WV.ix[val_ix],\n",
    "    training_FS.ix[val_ix],\n",
    "\n",
    "    training_tfidf_WV.ix[val_ix],\n",
    "    training_tfidf_FS.ix[val_ix],\n",
    "    training_tfidf_LSI.ix[val_ix],\n",
    "\n",
    "    training_Y.ix[val_ix],\n",
    "    maxlen=maxlen\n",
    ")\n",
    "# ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "train_test_x_train, train_test_wv_train, train_test_fs_train, train_test_tfidf_wv_train, train_test_tfidf_fs_train, train_test_tfidf_lsi_train, train_test_y_train = build_input_output_data(\n",
    "    train_test_word_indices,\n",
    "\n",
    "    train_test_wvec,\n",
    "    train_test_fvec,\n",
    "\n",
    "    train_test_tfidf_wvec,\n",
    "    train_test_tfidf_fvec,\n",
    "    train_test_tfidf_lsi,\n",
    "\n",
    "    train_test_y,\n",
    "    maxlen=maxlen\n",
    ")\n",
    "# ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(x, N=10):\n",
    "    return np.vstack([x for i in xrange(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.vstack([x_train, upsample(train_test_x_train)])\n",
    "\n",
    "wv_train = np.vstack([wv_train, upsample(train_test_wv_train)])\n",
    "fs_train = np.vstack([fs_train, upsample(train_test_fs_train)])\n",
    "\n",
    "tfidf_wv_train = np.vstack([tfidf_wv_train, upsample(train_test_tfidf_wv_train)])\n",
    "tfidf_fs_train = np.vstack([tfidf_fs_train, upsample(train_test_tfidf_fs_train)])\n",
    "tfidf_lsi_train = np.vstack([tfidf_lsi_train, upsample(train_test_tfidf_lsi_train)])\n",
    "\n",
    "y_train = np.vstack([y_train, upsample(train_test_y_train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "wv_train = wv_sc.fit_transform(wv_train)\n",
    "fs_train = fs_sc.fit_transform(fs_train)\n",
    "\n",
    "tfidf_wv_train = tfidf_wv_sc.fit_transform(tfidf_wv_train)\n",
    "tfidf_fs_train = tfidf_fs_sc.fit_transform(tfidf_fs_train)\n",
    "tfidf_lsi_train = tfidf_lsi_sc.fit_transform(tfidf_lsi_train)\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "wv_val = wv_sc.transform(wv_val)\n",
    "fs_val = fs_sc.transform(fs_val)\n",
    "\n",
    "tfidf_wv_val = tfidf_wv_sc.transform(tfidf_wv_val)\n",
    "tfidf_fs_val = tfidf_fs_sc.transform(tfidf_fs_val)\n",
    "tfidf_lsi_val = tfidf_lsi_sc.transform(tfidf_lsi_val)\n",
    "# ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((94731,), (9424,))"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_Y.shape, training_Y.ix[training_Y.index.str.contains('^2014[b]')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as K\n",
    "import keras.backend as KB\n",
    "\n",
    "\n",
    "def f1_micro(y_true, y_pred):\n",
    "    TP = K.metrics.true_positives(y_true, K.round(y_pred))\n",
    "    FP = K.metrics.false_positives(y_true, K.round(y_pred))\n",
    "    FN = K.metrics.false_negatives(y_true, K.round(y_pred))\n",
    "    \n",
    "    p = K.reduce_sum(TP) / (K.reduce_sum(TP) + K.reduce_sum(FP))\n",
    "    r = K.reduce_sum(TP) / (K.reduce_sum(TP) + K.reduce_sum(FN))\n",
    "    \n",
    "    return (2.0 * p * r) / (p + r)\n",
    "\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "\n",
    "    # Count positive samples.\n",
    "    c1 = KB.sum(KB.round(KB.clip(y_true * y_pred, 0, 1)))\n",
    "    c2 = KB.sum(KB.round(KB.clip(y_pred, 0, 1)))\n",
    "    c3 = KB.sum(KB.round(KB.clip(y_true, 0, 1)))\n",
    "\n",
    "    # If there are no true samples, fix the F1 score at 0.\n",
    "    if c3 == 0:\n",
    "        return 0\n",
    "\n",
    "    # How many selected items are relevant?\n",
    "    precision = c1 / c2\n",
    "\n",
    "    # How many relevant items are selected?\n",
    "    recall = c1 / c3\n",
    "\n",
    "    # Calculate f1_score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense, Dropout, Convolution1D, MaxPooling1D, Flatten\n",
    "from keras.models import Model\n",
    "import itertools as it\n",
    "\n",
    "\n",
    "def build_deep_input_stack(input_node):\n",
    "    x = Dense(128, activation='relu')(input_node)\n",
    "    x = Dropout(0.3)(x)\n",
    "#     x = Dense(256, activation='relu')(input_node)\n",
    "#     x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def entangle_inputs(input_nodes=[]):\n",
    "    assert(len(input_nodes) > 1)\n",
    "    \n",
    "    entangled_inputs = []\n",
    "\n",
    "    for n1, n2 in it.combinations(input_nodes, 2):\n",
    "        entangled_inputs.append(\n",
    "            keras.layers.dot([n1, n2], 1, normalize=True)\n",
    "        )\n",
    "    \n",
    "    return entangled_inputs\n",
    "\n",
    "\n",
    "wv_input = Input(shape=(300,), name='wv_input')\n",
    "fs_input = Input(shape=(300,), name='fs_input')\n",
    "\n",
    "tfidf_wv_input = Input(shape=(300,), name='tfidf_wv_input')\n",
    "tfidf_fs_input = Input(shape=(300,), name='tfidf_fs_input')\n",
    "tfidf_lsi_input = Input(shape=(300,), name='tfidf_lsi_input')\n",
    "\n",
    "\n",
    "wv_x = build_deep_input_stack(wv_input)\n",
    "fs_x = build_deep_input_stack(fs_input)\n",
    "tfidf_wv_x = build_deep_input_stack(tfidf_wv_input)\n",
    "tfidf_fs_x = build_deep_input_stack(tfidf_fs_input)\n",
    "tfidf_lsi_x = build_deep_input_stack(tfidf_wv_input)\n",
    "\n",
    "stacked_inputs_x = [wv_x, fs_x, tfidf_wv_x, tfidf_fs_x, tfidf_lsi_x]\n",
    "entangled_inputs_x = entangle_inputs(stacked_inputs_x)\n",
    "\n",
    "x = keras.layers.concatenate(stacked_inputs_x + entangled_inputs_x)\n",
    "\n",
    "# We stack a deep densely-connected network on top\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "# And finally we add the main logistic regression layer\n",
    "main_output = Dense(len(class2ind), activation='sigmoid', name='main_output')(x)\n",
    "\n",
    "model = Model(\n",
    "    inputs=[\n",
    "        wv_input,\n",
    "        fs_input,\n",
    "        tfidf_wv_input,\n",
    "        tfidf_fs_input,\n",
    "        tfidf_lsi_input,\n",
    "    ],\n",
    "    outputs=[main_output]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'dot_41/ExpandDims:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'dot_42/ExpandDims:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'dot_43/ExpandDims:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'dot_44/ExpandDims:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'dot_45/ExpandDims:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'dot_46/ExpandDims:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'dot_47/ExpandDims:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'dot_48/ExpandDims:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'dot_49/ExpandDims:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'dot_50/ExpandDims:0' shape=(?, 1) dtype=float32>]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entangled_inputs_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "wv_input (InputLayer)            (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "fs_input (InputLayer)            (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "tfidf_wv_input (InputLayer)      (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "tfidf_fs_input (InputLayer)      (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_71 (Dense)                 (None, 128)           38528                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_73 (Dense)                 (None, 128)           38528                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_75 (Dense)                 (None, 128)           38528                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_77 (Dense)                 (None, 128)           38528                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_79 (Dense)                 (None, 128)           38528                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)             (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)             (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)             (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_77 (Dropout)             (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)             (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_72 (Dense)                 (None, 512)           66048                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_74 (Dense)                 (None, 512)           66048                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_76 (Dense)                 (None, 512)           66048                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_78 (Dense)                 (None, 512)           66048                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_80 (Dense)                 (None, 512)           66048                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)             (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)             (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)             (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)             (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)             (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_41 (Dot)                     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_42 (Dot)                     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_43 (Dot)                     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_44 (Dot)                     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_45 (Dot)                     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_46 (Dot)                     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_47 (Dot)                     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_48 (Dot)                     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_49 (Dot)                     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_50 (Dot)                     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)      (None, 2570)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_81 (Dense)                 (None, 128)           329088                                       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_81 (Dropout)             (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_82 (Dense)                 (None, 256)           33024                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_82 (Dropout)             (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_83 (Dense)                 (None, 256)           65792                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_83 (Dropout)             (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_84 (Dense)                 (None, 128)           32896                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_84 (Dropout)             (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 160)           20640                                        \n",
      "====================================================================================================\n",
      "Total params: 1,004,320\n",
      "Trainable params: 1,004,320\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={'main_output': 'categorical_crossentropy'},\n",
    "    loss_weights={'main_output': 1.},\n",
    "    metrics=['accuracy', f1_micro]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.callbacks import EarlyStopping\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "# model.fit(X, y, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_training_inputs(wv, fs, tfidf_wv, tfidf_fs, tfidf_lsi):\n",
    "    training_inputs = {\n",
    "        'wv_input': wv,\n",
    "        'fs_input': fs,\n",
    "        'tfidf_wv_input': tfidf_wv,\n",
    "        'tfidf_fs_input': tfidf_fs,\n",
    "        'tfidf_lsi_input': tfidf_lsi,\n",
    "    }\n",
    "    \n",
    "    return training_inputs\n",
    "    \n",
    "\n",
    "training_inputs = build_training_inputs(\n",
    "    wv_train,\n",
    "    fs_train,\n",
    "    tfidf_wv_train,\n",
    "    tfidf_fs_train,\n",
    "    tfidf_lsi_train,\n",
    ")\n",
    "\n",
    "training_outputs = {\n",
    "    'main_output': y_train,\n",
    "}\n",
    "\n",
    "# train_test_shape = train_test_df.shape[0]\n",
    "# train_test_training_inputs = build_training_inputs(\n",
    "#     wv_train[-train_test_shape:],\n",
    "#     fs_train[-train_test_shape:],\n",
    "#     tfidf_wv_train[-train_test_shape:],\n",
    "#     tfidf_fs_train[-train_test_shape:],\n",
    "#     tfidf_lsi_train[-train_test_shape:],\n",
    "# )\n",
    "\n",
    "# train_test_training_outputs = {\n",
    "#     'main_output': y_train[-train_test_shape:],\n",
    "# }\n",
    "\n",
    "\n",
    "validation_data=(\n",
    "    build_training_inputs(\n",
    "        wv_val,\n",
    "        fs_val,\n",
    "        tfidf_wv_val,\n",
    "        tfidf_fs_val,\n",
    "        tfidf_lsi_val,\n",
    "    ),\n",
    "    {\n",
    "        'main_output': y_val,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 95811 samples, validate on 9424 samples\n",
      "Epoch 1/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7525 - acc: 0.7020 - f1_micro: 0.6047 - val_loss: 1.4197 - val_acc: 0.7527 - val_f1_micro: 0.6048\n",
      "Epoch 2/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7488 - acc: 0.6993 - f1_micro: 0.6048 - val_loss: 1.4224 - val_acc: 0.7617 - val_f1_micro: 0.6049\n",
      "Epoch 3/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7550 - acc: 0.7010 - f1_micro: 0.6050 - val_loss: 1.4259 - val_acc: 0.7607 - val_f1_micro: 0.6051\n",
      "Epoch 4/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7508 - acc: 0.6998 - f1_micro: 0.6052 - val_loss: 1.4216 - val_acc: 0.7603 - val_f1_micro: 0.6053\n",
      "Epoch 5/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7516 - acc: 0.7012 - f1_micro: 0.6053 - val_loss: 1.4217 - val_acc: 0.7589 - val_f1_micro: 0.6054\n",
      "Epoch 6/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7481 - acc: 0.7026 - f1_micro: 0.6055 - val_loss: 1.4241 - val_acc: 0.7584 - val_f1_micro: 0.6056\n",
      "Epoch 7/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7462 - acc: 0.7003 - f1_micro: 0.6057 - val_loss: 1.4200 - val_acc: 0.7571 - val_f1_micro: 0.6058\n",
      "Epoch 8/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7460 - acc: 0.7014 - f1_micro: 0.6058 - val_loss: 1.4252 - val_acc: 0.7568 - val_f1_micro: 0.6059\n",
      "Epoch 9/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7446 - acc: 0.7017 - f1_micro: 0.6060 - val_loss: 1.4214 - val_acc: 0.7579 - val_f1_micro: 0.6061\n",
      "Epoch 10/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7567 - acc: 0.7006 - f1_micro: 0.6062 - val_loss: 1.4257 - val_acc: 0.7600 - val_f1_micro: 0.6062\n",
      "Epoch 11/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7502 - acc: 0.7006 - f1_micro: 0.6063 - val_loss: 1.4183 - val_acc: 0.7528 - val_f1_micro: 0.6064\n",
      "Epoch 12/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7495 - acc: 0.7013 - f1_micro: 0.6065 - val_loss: 1.4256 - val_acc: 0.7663 - val_f1_micro: 0.6066\n",
      "Epoch 13/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7503 - acc: 0.7007 - f1_micro: 0.6066 - val_loss: 1.4219 - val_acc: 0.7573 - val_f1_micro: 0.6067\n",
      "Epoch 14/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7507 - acc: 0.6968 - f1_micro: 0.6068 - val_loss: 1.4208 - val_acc: 0.7625 - val_f1_micro: 0.6069\n",
      "Epoch 15/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7458 - acc: 0.7016 - f1_micro: 0.6070 - val_loss: 1.4208 - val_acc: 0.7589 - val_f1_micro: 0.6070\n",
      "Epoch 16/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7458 - acc: 0.7022 - f1_micro: 0.6071 - val_loss: 1.4164 - val_acc: 0.7600 - val_f1_micro: 0.6072\n",
      "Epoch 17/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7398 - acc: 0.7018 - f1_micro: 0.6073 - val_loss: 1.4142 - val_acc: 0.7586 - val_f1_micro: 0.6074\n",
      "Epoch 18/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7485 - acc: 0.7023 - f1_micro: 0.6074 - val_loss: 1.4144 - val_acc: 0.7530 - val_f1_micro: 0.6075\n",
      "Epoch 19/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7519 - acc: 0.7002 - f1_micro: 0.6076 - val_loss: 1.4172 - val_acc: 0.7580 - val_f1_micro: 0.6077\n",
      "Epoch 20/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7483 - acc: 0.7018 - f1_micro: 0.6078 - val_loss: 1.4182 - val_acc: 0.7614 - val_f1_micro: 0.6078\n",
      "Epoch 21/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7455 - acc: 0.7018 - f1_micro: 0.6079 - val_loss: 1.4146 - val_acc: 0.7645 - val_f1_micro: 0.6080\n",
      "Epoch 22/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7479 - acc: 0.6999 - f1_micro: 0.6081 - val_loss: 1.4119 - val_acc: 0.7582 - val_f1_micro: 0.6082\n",
      "Epoch 23/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7457 - acc: 0.7002 - f1_micro: 0.6082 - val_loss: 1.4199 - val_acc: 0.7581 - val_f1_micro: 0.6083\n",
      "Epoch 24/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7426 - acc: 0.7010 - f1_micro: 0.6084 - val_loss: 1.4211 - val_acc: 0.7529 - val_f1_micro: 0.6085\n",
      "Epoch 25/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7454 - acc: 0.6990 - f1_micro: 0.6086 - val_loss: 1.4170 - val_acc: 0.7593 - val_f1_micro: 0.6086\n",
      "Epoch 26/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7453 - acc: 0.7020 - f1_micro: 0.6087 - val_loss: 1.4142 - val_acc: 0.7663 - val_f1_micro: 0.6088\n",
      "Epoch 27/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7414 - acc: 0.7040 - f1_micro: 0.6089 - val_loss: 1.4114 - val_acc: 0.7652 - val_f1_micro: 0.6090\n",
      "Epoch 28/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7445 - acc: 0.7013 - f1_micro: 0.6090 - val_loss: 1.4108 - val_acc: 0.7633 - val_f1_micro: 0.6091\n",
      "Epoch 29/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7397 - acc: 0.7013 - f1_micro: 0.6092 - val_loss: 1.4174 - val_acc: 0.7562 - val_f1_micro: 0.6093\n",
      "Epoch 30/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7353 - acc: 0.7020 - f1_micro: 0.6094 - val_loss: 1.4091 - val_acc: 0.7591 - val_f1_micro: 0.6094\n",
      "Epoch 31/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7440 - acc: 0.7034 - f1_micro: 0.6095 - val_loss: 1.4152 - val_acc: 0.7690 - val_f1_micro: 0.6096\n",
      "Epoch 32/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7405 - acc: 0.7012 - f1_micro: 0.6097 - val_loss: 1.4086 - val_acc: 0.7633 - val_f1_micro: 0.6097\n",
      "Epoch 33/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7440 - acc: 0.7015 - f1_micro: 0.6098 - val_loss: 1.4113 - val_acc: 0.7637 - val_f1_micro: 0.6099\n",
      "Epoch 34/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7464 - acc: 0.7030 - f1_micro: 0.6100 - val_loss: 1.4142 - val_acc: 0.7654 - val_f1_micro: 0.6100\n",
      "Epoch 35/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7383 - acc: 0.7030 - f1_micro: 0.6101 - val_loss: 1.4088 - val_acc: 0.7584 - val_f1_micro: 0.6102\n",
      "Epoch 36/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7371 - acc: 0.7020 - f1_micro: 0.6102 - val_loss: 1.4141 - val_acc: 0.7616 - val_f1_micro: 0.6103\n",
      "Epoch 37/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7449 - acc: 0.7009 - f1_micro: 0.6104 - val_loss: 1.4083 - val_acc: 0.7568 - val_f1_micro: 0.6105\n",
      "Epoch 38/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7389 - acc: 0.7020 - f1_micro: 0.6106 - val_loss: 1.4116 - val_acc: 0.7599 - val_f1_micro: 0.6106\n",
      "Epoch 39/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7423 - acc: 0.7017 - f1_micro: 0.6107 - val_loss: 1.4080 - val_acc: 0.7698 - val_f1_micro: 0.6108\n",
      "Epoch 40/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7396 - acc: 0.7036 - f1_micro: 0.6108 - val_loss: 1.4059 - val_acc: 0.7629 - val_f1_micro: 0.6109\n",
      "Epoch 41/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7423 - acc: 0.7017 - f1_micro: 0.6110 - val_loss: 1.4123 - val_acc: 0.7588 - val_f1_micro: 0.6111\n",
      "Epoch 42/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7404 - acc: 0.7005 - f1_micro: 0.6111 - val_loss: 1.4067 - val_acc: 0.7609 - val_f1_micro: 0.6112\n",
      "Epoch 43/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7415 - acc: 0.7017 - f1_micro: 0.6113 - val_loss: 1.4081 - val_acc: 0.7636 - val_f1_micro: 0.6114\n",
      "Epoch 44/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7373 - acc: 0.7019 - f1_micro: 0.6114 - val_loss: 1.4083 - val_acc: 0.7600 - val_f1_micro: 0.6115\n",
      "Epoch 45/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7355 - acc: 0.7037 - f1_micro: 0.6116 - val_loss: 1.4049 - val_acc: 0.7637 - val_f1_micro: 0.6117\n",
      "Epoch 46/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7368 - acc: 0.7037 - f1_micro: 0.6118 - val_loss: 1.4082 - val_acc: 0.7629 - val_f1_micro: 0.6119\n",
      "Epoch 47/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7423 - acc: 0.7000 - f1_micro: 0.6119 - val_loss: 1.4101 - val_acc: 0.7672 - val_f1_micro: 0.6120\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95811/95811 [==============================] - 2s - loss: 1.7389 - acc: 0.7029 - f1_micro: 0.6121 - val_loss: 1.4051 - val_acc: 0.7639 - val_f1_micro: 0.6122\n",
      "Epoch 49/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7354 - acc: 0.7028 - f1_micro: 0.6123 - val_loss: 1.4095 - val_acc: 0.7597 - val_f1_micro: 0.6123\n",
      "Epoch 50/50\n",
      "95811/95811 [==============================] - 2s - loss: 1.7352 - acc: 0.7014 - f1_micro: 0.6124 - val_loss: 1.4088 - val_acc: 0.7591 - val_f1_micro: 0.6125\n",
      "CPU times: user 1min 31s, sys: 13.4 s, total: 1min 44s\n",
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# And trained it via:\n",
    "batch_size = 2000\n",
    "epochs = 50\n",
    "\n",
    "hist = model.fit(\n",
    "    training_inputs,\n",
    "    training_outputs,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    validation_data=validation_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # And trained it via:\n",
    "# batch_size = 10\n",
    "# epochs = 50\n",
    "\n",
    "# hist = model.fit(\n",
    "#     train_test_training_inputs,\n",
    "#     train_test_training_outputs,\n",
    "#     epochs=epochs,\n",
    "#     batch_size=batch_size,\n",
    "#     validation_split=0.2,\n",
    "#     validation_data=validation_data,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63482992056972509"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history['f1_micro'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# log_history_file = 'lstm-word2vec-fasttext-lsi.epoch.csv'\n",
    "# model_name = 'models/tfidf-wv-fs-lsi-2010-2014-data_cat-crossentropy-2014-b-val-sc_tfidf_wv_fs_lsi.model'\n",
    "# batch_size = 1200\n",
    "# epochs = 5\n",
    "# total_epochs = 100\n",
    "\n",
    "# for i in xrange(0, total_epochs // epochs):\n",
    "#     hist = model.fit(\n",
    "#         training_inputs,\n",
    "#         training_outputs,\n",
    "#         epochs=epochs,\n",
    "#         batch_size=batch_size,\n",
    "#         validation_split=0.2,\n",
    "#         validation_data=validation_data,\n",
    "#     )\n",
    "\n",
    "#     model.save(model_name.format(i))\n",
    "#     print\n",
    "#     print('Done with epoch: {}'.format((i + 1) * epochs))\n",
    "#     with open(log_history_file, 'a') as fl:\n",
    "#         fl.write(model_name + '\\n')\n",
    "#         fl.write('Epoch {}\\n'.format((i + 1) * epochs))\n",
    "#         fl.write('{}\\n'.format(datetime.now()))\n",
    "#         fl.write('\\n'.join(['{}: {}'.format(k, v[0]) for k, v in hist.history.items()]))\n",
    "#         fl.write('\\n\\n')\n",
    "#     print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# total_epochs = 100\n",
    "# for j in xrange(i, i + (total_epochs // epochs)):\n",
    "#     hist = model.fit(\n",
    "#         training_inputs,\n",
    "#         training_outputs,\n",
    "#         epochs=epochs,\n",
    "#         batch_size=batch_size,\n",
    "#         validation_split=0.2,\n",
    "#         validation_data=validation_data,\n",
    "#     )\n",
    "\n",
    "#     model.save(model_name.format(i))\n",
    "#     print\n",
    "#     print('Done with epoch: {}'.format((j + 1) * epochs))\n",
    "#     with open(log_history_file, 'a') as fl:\n",
    "#         fl.write(model_name + '\\n')\n",
    "#         fl.write('Epoch {}\\n'.format((j + 1) * epochs))\n",
    "#         fl.write('{}\\n'.format(datetime.now()))\n",
    "#         fl.write('\\n'.join(['{}: {}'.format(k, v[0]) for k, v in hist.history.items()]))\n",
    "#         fl.write('\\n\\n')\n",
    "#     print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = keras.models.load_model(\n",
    "#     'models/lstm-word2vec-fasttext_2010-2014-data_categorical-crossentropy-2014-b-val-standard_scaled_wv_fs.model',\n",
    "#     custom_objects={'f1_micro': f1_micro}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test_wv_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = model.predict(\n",
    "    build_training_inputs(\n",
    "        wv_train,\n",
    "        fs_train,\n",
    "        tfidf_wv_train,\n",
    "        tfidf_fs_train,\n",
    "        tfidf_lsi_train,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       ..., \n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan]], dtype=float32)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score as sk_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 724 ms, sys: 24 ms, total: 748 ms\n",
      "Wall time: 744 ms\n",
      "CPU times: user 736 ms, sys: 8 ms, total: 744 ms\n",
      "Wall time: 743 ms\n",
      "CPU times: user 728 ms, sys: 16 ms, total: 744 ms\n",
      "Wall time: 742 ms\n",
      "CPU times: user 732 ms, sys: 16 ms, total: 748 ms\n",
      "Wall time: 743 ms\n",
      "CPU times: user 784 ms, sys: 16 ms, total: 800 ms\n",
      "Wall time: 798 ms\n",
      "CPU times: user 772 ms, sys: 16 ms, total: 788 ms\n",
      "Wall time: 784 ms\n",
      "CPU times: user 728 ms, sys: 16 ms, total: 744 ms\n",
      "Wall time: 740 ms\n",
      "CPU times: user 724 ms, sys: 24 ms, total: 748 ms\n",
      "Wall time: 744 ms\n",
      "CPU times: user 716 ms, sys: 28 ms, total: 744 ms\n",
      "Wall time: 741 ms\n",
      "CPU times: user 740 ms, sys: 8 ms, total: 748 ms\n",
      "Wall time: 741 ms\n",
      "CPU times: user 724 ms, sys: 20 ms, total: 744 ms\n",
      "Wall time: 742 ms\n",
      "CPU times: user 720 ms, sys: 28 ms, total: 748 ms\n",
      "Wall time: 745 ms\n",
      "CPU times: user 728 ms, sys: 20 ms, total: 748 ms\n",
      "Wall time: 742 ms\n",
      "CPU times: user 724 ms, sys: 24 ms, total: 748 ms\n",
      "Wall time: 741 ms\n",
      "CPU times: user 728 ms, sys: 16 ms, total: 744 ms\n",
      "Wall time: 740 ms\n",
      "CPU times: user 712 ms, sys: 32 ms, total: 744 ms\n",
      "Wall time: 739 ms\n",
      "CPU times: user 736 ms, sys: 12 ms, total: 748 ms\n",
      "Wall time: 743 ms\n",
      "CPU times: user 736 ms, sys: 8 ms, total: 744 ms\n",
      "Wall time: 739 ms\n",
      "CPU times: user 716 ms, sys: 28 ms, total: 744 ms\n",
      "Wall time: 740 ms\n",
      "CPU times: user 732 ms, sys: 12 ms, total: 744 ms\n",
      "Wall time: 740 ms\n",
      "CPU times: user 724 ms, sys: 20 ms, total: 744 ms\n",
      "Wall time: 737 ms\n",
      "CPU times: user 700 ms, sys: 40 ms, total: 740 ms\n",
      "Wall time: 737 ms\n",
      "CPU times: user 732 ms, sys: 12 ms, total: 744 ms\n",
      "Wall time: 737 ms\n",
      "CPU times: user 712 ms, sys: 28 ms, total: 740 ms\n",
      "Wall time: 737 ms\n",
      "CPU times: user 728 ms, sys: 12 ms, total: 740 ms\n",
      "Wall time: 736 ms\n",
      "CPU times: user 740 ms, sys: 4 ms, total: 744 ms\n",
      "Wall time: 740 ms\n",
      "CPU times: user 724 ms, sys: 16 ms, total: 740 ms\n",
      "Wall time: 738 ms\n",
      "CPU times: user 732 ms, sys: 12 ms, total: 744 ms\n",
      "Wall time: 739 ms\n",
      "CPU times: user 724 ms, sys: 16 ms, total: 740 ms\n",
      "Wall time: 737 ms\n",
      "CPU times: user 728 ms, sys: 16 ms, total: 744 ms\n",
      "Wall time: 738 ms\n",
      "CPU times: user 720 ms, sys: 20 ms, total: 740 ms\n",
      "Wall time: 735 ms\n",
      "CPU times: user 736 ms, sys: 8 ms, total: 744 ms\n",
      "Wall time: 736 ms\n",
      "CPU times: user 23.4 s, sys: 584 ms, total: 24 s\n",
      "Wall time: 23.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dt = 0.01\n",
    "s = 0.1\n",
    "e = 0.4\n",
    "th = np.arange(s, e + dt, dt)\n",
    "mean_fscores = []\n",
    "for t in th:\n",
    "#     fscores = []\n",
    "#     for ix in range(g.shape[0]):\n",
    "#         y_a = y_train[ix]\n",
    "#         y_p = 1.0 * (g[ix] > t)\n",
    "#         fscores.append(sk_f1_score(y_a, y_p))\n",
    "#     mean_fscores.append(np.mean(fscores))\n",
    "    %time mean_fscores.append((t, sk_f1_score(y_train, 1.0 * (g > t), average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.27999999999999992, 0.85864787299742062)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh, thresh_score = sorted(mean_fscores, key=lambda x: x[1], reverse=True)[0]\n",
    "thresh, thresh_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'When Angela Merkel addressed a press conference in Berlin yesterday morning, only hours after the attack on the Christmas market and not far distant from it, she was unflinching. She took head-on the hardest question of how the country would feel if the perpetrator turned out to be one of the million refugees to whom she had offered protection not much more than a year ago. It would be hard to bear, she said \\u2013 in one version of a German phrase that has been variously translated as \\u201cparticularly repugnant\\u201d and \\u201csickening\\u201d \\u2013 if it were a refugee. It would be an insult to all those who had helped refugees and all those who needed Germany\\u2019s protection. And that was it. Christmas markets are as much a part of German national life as the 14 July festivities are French (in Nice nearly 100 people died in a similar attack). That makes Monday\\u2019s attack seem like an unmistakable act of terror, apparently motivated by jihadism. It may well turn out to be someone who had come to the country as an asylum seeker. But Merkel\\u2019s appeal at that subdued press conference was for the country to distinguish between terrorists and refugees, and to keep faith with her version of what it is to be German. \\u201cWe will find strength for the life we want to live in Germany \\u2013 free, united and open.\\u201d In one sense, everything the chancellor said was intensely political. She faces elections next September, and her fate is a preoccupation for all of Europe. Yet there is a difference between conveying a potent political message and politicking; and not so much as a zephyr of politicking appeared to ruffle the trademark Merkel demeanour \\u2013 reassuringly impassive as a dumpling, as always. There was no overt concession to those colleagues who fear that her refugee policy, the subject of so much criticism on the right, is likely to eat savagely into her \\u2013 and their \\u2013 majority. Nothing explicitly betrayed the challenge she will face from her partners in government, the Bavarian Christian Social Union (CSU), who are ramping up the pressure on her. There was certainly no nod in the direction of the far right\\u2019s charge that the casualties of Monday night\\u2019s attack were \\u201cMerkel\\u2019s dead\\u201d. Merkel has established herself as the best and strongest voice of the values of a liberal Europe, and her steadfastness under pressure \\u2013 at least her rhetorical steadfastness, for her policies have been modified to accommodate some of her critics\\u2019 concerns \\u2013 is a beacon in a continent that is increasingly inward turning, nativist and afraid. And every time she stands up for what postwar Europe represents, she consolidates Germany\\u2019s rebirth. When in her summer press conference, on 31 August last year, as thousands of refugees trekked northwards into Hungary, she told the world \\u201cWe can do it\\u201d, and when a few days later she announced that no one would be stopped from seeking asylum, and when a few days after that she posed for a selfie with one of the refugees from the first train to draw into Munich station, for millions of people around the world she reset the image of her country. Only months earlier, the Greeks had portrayed Merkel in a stormtrooper helmet. In September she seemed to banish the faint but lingering stench of 20th-century history for good. In its place came what Merkel called Germany\\u2019s \\u201cfriendly, beautiful face\\u201d. It has not been an easy 15 months, and Merkel has been forced into making concessions to her critics. But that merely makes her calm, mostly endorsed by other politicians, the more admirable yesterday. As important, it was reflected in the actions of authority everywhere \\u2013 in, for example, how quickly the police acknowledged they had picked up the wrong person. How tempting it must have been to hang on to the appearance of having speedily apprehended at least one of the perpetrators, and how attractive to the security forces who had, after all, failed in the most devastating way imaginable to try to redeem themselves. It was there in the strong clear message that there would always be soft targets that could not be protected, and in the refusal to panic and shut down the hundreds of other Christmas fairs across the country. Of course security will be tighter; understandably some cities are erecting concrete blocks at the entrance to their shopping areas. Naturally there will be a more visible police presence. Yet out of the bloody carnage of violence and hate of Berlin on the Monday before Christmas comes the enviable impression of a country that is true to the values of liberal Europe.'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_df.iloc[ix].bodyText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'munichshooting'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics[103]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f085cea1850>"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f085b360ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "ix = 125\n",
    "sd = -0\n",
    "pd.Series(g[sd:][ix]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([78]),), (array([78]),))"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# thresh = 0.5\n",
    "np.where(y_train[sd:][ix] == 1), np.where(g[sd:][ix] > thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "from gensim.models.lsimodel import LsiModel\n",
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = TfidfModel.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.dictionary')\n",
    "tfidf = TfidfModel.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.tfidf')\n",
    "lsi = LsiModel.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.lsi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wvmodel = Word2Vec.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fsmodel = fasttext.load_model('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.fasttext.model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_tfidf_word2vec(tokens, stopwords=[]):\n",
    "#     global wvmodel\n",
    "#     global tfidf\n",
    "    # This requires wvmodel to be present in the namespace.\n",
    "    wv_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords and w in wvmodel.wv.vocab)]\n",
    "    ).map(\n",
    "        lambda x: tfidf[dictionary.doc2bow(x)]\n",
    "    ).map(\n",
    "        lambda x: np.array([wvmodel[dictionary.id2token[id]] * w for id, w in x]).mean(axis=0) if len(x) > 0 else np.nan\n",
    "    )\n",
    "\n",
    "    return wv_feature_vec\n",
    "\n",
    "\n",
    "def transform_tfidf_fasttext(tokens, stopwords=[]):\n",
    "#     global fsmodel\n",
    "#     global tfidf\n",
    "    # This requires wvmodel to be present in the namespace.\n",
    "    fs_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    ).map(\n",
    "        lambda x: tfidf[dictionary.doc2bow(x)]\n",
    "    ).map(\n",
    "        lambda x: np.array([np.array(fsmodel[dictionary.id2token[id]]) * w for id, w in x]).mean(axis=0) if len(x) > 0 else np.nan\n",
    "    )\n",
    "\n",
    "    return fs_feature_vec\n",
    "\n",
    "\n",
    "def build_lsi_vector(l):\n",
    "    v = np.zeros(lsi.num_topics)\n",
    "    \n",
    "    for ix, vv in lsi[tfidf[dictionary.doc2bow(l)]]:\n",
    "        v[ix] = vv\n",
    "        \n",
    "    return v\n",
    "\n",
    "\n",
    "def transform_tfidf_lsi(tokens, stopwords=[]):\n",
    "#     global fsmodel\n",
    "#     global tfidf\n",
    "    # This requires wvmodel to be present in the namespace.\n",
    "    lsi_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    ).map(\n",
    "        lambda x: build_lsi_vector(x) if len(x) > 0 else np.nan\n",
    "    )\n",
    "\n",
    "    return lsi_feature_vec\n",
    "\n",
    "\n",
    "def transform_fasttext(tokens, stopwords=[]):\n",
    "    global fsmodel\n",
    "    # This requires fsmodel to be present in the namespace.\n",
    "    fs_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    ).map(lambda x: np.array([fsmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return fs_feature_vec\n",
    "\n",
    "\n",
    "def transform_unsupervised_sentiment_neuron(tokens, stopwords=[]):\n",
    "    # This requires fsmodel to be present in the namespace.\n",
    "    \n",
    "    usn_feature_vec = usnmodel.transform(tokens)\n",
    "\n",
    "    # usn_feature_vec = tokens.map(\n",
    "    #     lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    # ).map(lambda x: np.array([usnmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return usn_feature_vec\n",
    "\n",
    "\n",
    "def transform_word2vec(tokens, stopwords=[]):\n",
    "    global wvmodel\n",
    "    # This requires wvmodel to be present in the namespace.\n",
    "    wv_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords and w in wvmodel.wv.vocab)]\n",
    "    ).map(lambda x: np.array([wvmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return wv_feature_vec\n",
    "\n",
    "\n",
    "def parallel_generate_word_vectors(samp, transformer, stopwords, batch, num_proc):\n",
    "    with Parallel(n_jobs=num_proc) as parallel:\n",
    "        dataset = []\n",
    "        is_break = False\n",
    "        i = 0\n",
    "\n",
    "        while not is_break:\n",
    "            payload = []\n",
    "\n",
    "            for j in xrange(num_proc):\n",
    "                t_df = samp[(i + j) * batch: (i + 1 + j) * batch]\n",
    "\n",
    "                if t_df.empty:\n",
    "                    is_break = True\n",
    "                    continue\n",
    "\n",
    "                payload.append(\n",
    "                    delayed(transformer)(\n",
    "                        t_df, stopwords\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            print('Current batch in main thread: {}'.format((i + j) * batch))\n",
    "\n",
    "            if payload:\n",
    "                results = parallel(payload)\n",
    "                dataset.extend(results)\n",
    "                i += num_proc\n",
    "\n",
    "    return pd.concat(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_classes(pred, scale_param=0.75, min_thresh=0.05, thresh = 0.5):\n",
    "#     mx = pred.mean() + 3 * pred.std()\n",
    "    return np.where(pred > thresh)[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2idx_transform(word, _word2idx):\n",
    "    return _word2idx.get(word, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features_for(df, min_batch=2000, stopwords=[], num_proc=7):\n",
    "    df_tokens = transform_text(df)\n",
    "    \n",
    "    batch = min(df_tokens.shape[0] / num_proc, min_batch)\n",
    "\n",
    "    print('Computing fs features...')\n",
    "    fvec = parallel_generate_word_vectors(df_tokens, transform_fasttext, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Computing wv features...')\n",
    "    wvec = parallel_generate_word_vectors(df_tokens, transform_word2vec, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Mapping word indices...')\n",
    "    word_indices = df_tokens.map(lambda x: [word2idx_transform(i, _word2idx) for i in x.split()])\n",
    "\n",
    "    print('Computing tfidf fs features...')\n",
    "    tfidf_fvec = parallel_generate_word_vectors(df_tokens, transform_tfidf_fasttext, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Computing tfidf wv features...')\n",
    "    tfidf_wvec = parallel_generate_word_vectors(df_tokens, transform_tfidf_word2vec, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Computing tfidf lsi features...')\n",
    "    tfidf_lsi = parallel_generate_word_vectors(df_tokens, transform_tfidf_lsi, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "    \n",
    "    return word_indices, wvec, fvec, tfidf_wvec, tfidf_fvec, tfidf_lsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/TestData.json') as fl:\n",
    "    data = json.load(fl)\n",
    "    test_df = pd.DataFrame(data['TestData']).T\n",
    "    del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fs features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Computing wv features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Mapping word indices...\n",
      "Computing tfidf fs features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Computing tfidf wv features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Computing tfidf lsi features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "CPU times: user 48.4 s, sys: 8.48 s, total: 56.8 s\n",
      "Wall time: 3min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_word_indices,test_wvec, test_fvec, test_tfidf_wvec, test_tfidf_fvec, test_tfidf_lsi = extract_features_for(\n",
    "    test_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert(np.all(test_wvec[test_wvec.isnull()].index == test_fvec[test_fvec.isnull()].index))\n",
    "test_null_index = test_wvec[test_wvec.isnull()].index.union(test_fvec[test_fvec.isnull()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'TestData_02543', u'TestData_05012', u'TestData_05830'], dtype='object')"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_null_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 376 ms, sys: 20 ms, total: 396 ms\n",
      "Wall time: 398 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "valid_test_index = test_word_indices.index.difference(test_null_index)\n",
    "x_test = test_word_indices.ix[valid_test_index]  # .map(lambda x: [top_token2ind.get(i, 0) for i in x])\n",
    "\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "wv_test = np.vstack(test_wvec.ix[valid_test_index])\n",
    "fs_test = np.vstack(test_fvec.ix[valid_test_index])\n",
    "\n",
    "tfidf_wv_test = np.vstack(test_tfidf_wvec.ix[valid_test_index])\n",
    "tfidf_fs_test = np.vstack(test_tfidf_fvec.ix[valid_test_index])\n",
    "tfidf_lsi_test = np.vstack(test_tfidf_lsi.ix[valid_test_index])\n",
    "\n",
    "wv_test = wv_sc.transform(wv_test)\n",
    "fs_test = fs_sc.transform(fs_test)\n",
    "\n",
    "tfidf_wv_test = tfidf_wv_sc.transform(tfidf_wv_test)\n",
    "tfidf_fs_test = tfidf_fs_sc.transform(tfidf_fs_test)\n",
    "tfidf_lsi_test = tfidf_lsi_sc.transform(tfidf_lsi_test)\n",
    "\n",
    "test_inputs = build_training_inputs(\n",
    "    wv_test,\n",
    "    fs_test,\n",
    "    tfidf_wv_test,\n",
    "    tfidf_fs_test,\n",
    "    tfidf_lsi_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_probas = model.predict(test_inputs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_test_probas = test_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   2.56437514e-12,   1.68488877e-12, ...,\n",
       "          1.01288488e-14,   3.99726008e-29,   7.43145001e-32],\n",
       "       [  1.99439271e-27,   5.81497588e-08,   8.58239446e-07, ...,\n",
       "          6.88081953e-11,   2.10295314e-09,   5.28252447e-26],\n",
       "       [  4.04533639e-36,   1.38322175e-11,   4.44929439e-13, ...,\n",
       "          2.49850962e-09,   1.87614074e-12,   1.75152270e-23],\n",
       "       ..., \n",
       "       [  1.15240699e-16,   3.85989319e-03,   2.55611897e-01, ...,\n",
       "          2.99304560e-07,   1.25287310e-03,   4.16126940e-21],\n",
       "       [  2.74920797e-18,   1.59700902e-03,   5.88278403e-04, ...,\n",
       "          1.80582717e-07,   9.86770843e-09,   8.52394027e-24],\n",
       "       [  6.98238584e-21,   2.06221812e-04,   9.87412757e-04, ...,\n",
       "          1.54710555e-08,   3.28320038e-10,   2.07271847e-26]], dtype=float32)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_test_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2542, 5011, 5829]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_index = [int(s.split('_')[1]) - 1 for s in test_null_index]  # Subtract 1 since test index starts at 1 while enumerate starts at 0\n",
    "skip_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7578, 160), (7581, 3))"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_test_probas.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24 ms, sys: 8 ms, total: 32 ms\n",
      "Wall time: 29.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# valid_test_feature_vec found below!\n",
    "# thresh = 0.3\n",
    "test_values = np.zeros([main_test_probas.shape[0], len(topics)])\n",
    "for ix, pred in enumerate(main_test_probas):\n",
    "    for v in get_classes(pred, thresh=thresh):\n",
    "        test_values[ix][v] = 1\n",
    "\n",
    "test_sub_df = pd.DataFrame(\n",
    "    test_values,\n",
    "    index=test_df.ix[test_df.index.difference(test_null_index)].index,\n",
    "    columns=topics\n",
    ")\n",
    "\n",
    "null_test_df = pd.DataFrame(\n",
    "    np.zeros((len(test_null_index), len(topics))),\n",
    "    index=test_null_index,\n",
    "    columns=topics\n",
    ")\n",
    "\n",
    "test_sub_df = test_sub_df.append(null_test_df)\n",
    "test_sub_df = test_sub_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 9627 (0.5), 14297 (0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12141.0"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13866.0"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.375, 10524.0)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh, test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13897.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12489.0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7581.000000\n",
       "mean      882.691070\n",
       "std       621.585386\n",
       "min         0.000000\n",
       "25%       552.000000\n",
       "50%       770.000000\n",
       "75%      1026.000000\n",
       "max      8171.000000\n",
       "Name: bodyText, dtype: float64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_word_indices.map(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1382.0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_word_indices.map(len).quantile(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1223"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df.ix['TestData_04490'].bodyText.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activism                                    0.0\n",
       "afghanistan                               111.0\n",
       "aid                                        78.0\n",
       "algerianhostagecrisis                      10.0\n",
       "alqaida                                   101.0\n",
       "alshabaab                                  38.0\n",
       "antiwar                                     0.0\n",
       "arabandmiddleeastprotests                 321.0\n",
       "armstrade                                  77.0\n",
       "australianguncontrol                        0.0\n",
       "australiansecurityandcounterterrorism      84.0\n",
       "bastilledaytruckattack                     27.0\n",
       "belgium                                     9.0\n",
       "berlinchristmasmarketattack                40.0\n",
       "bigdata                                     7.0\n",
       "biometrics                                  0.0\n",
       "bokoharam                                  41.0\n",
       "bostonmarathonbombing                      61.0\n",
       "britisharmy                                 2.0\n",
       "brusselsattacks                            98.0\n",
       "cameroon                                    2.0\n",
       "carers                                      1.0\n",
       "charliehebdoattack                         82.0\n",
       "chemicalweapons                            17.0\n",
       "clusterbombs                                4.0\n",
       "cobra                                       0.0\n",
       "conflictanddevelopment                     43.0\n",
       "controversy                                 3.0\n",
       "criminaljustice                            28.0\n",
       "cybercrime                                 81.0\n",
       "                                          ...  \n",
       "somalia                                    44.0\n",
       "southafrica                                41.0\n",
       "southchinasea                               3.0\n",
       "stopandsearch                               2.0\n",
       "surveillance                              151.0\n",
       "sydneysiege                                41.0\n",
       "syria                                    1476.0\n",
       "taliban                                    57.0\n",
       "terrorism                                 280.0\n",
       "thailand                                   35.0\n",
       "torture                                    15.0\n",
       "traincrashes                                4.0\n",
       "transport                                  93.0\n",
       "tunisiaattack2015                          79.0\n",
       "turkey                                    202.0\n",
       "turkeycoupattempt                          46.0\n",
       "ukcrime                                   309.0\n",
       "uksecurity                                538.0\n",
       "uksupremecourt                             10.0\n",
       "undercoverpoliceandpolicing                 4.0\n",
       "unitednations                             187.0\n",
       "usguncontrol                              259.0\n",
       "values                                      0.0\n",
       "warcrimes                                  18.0\n",
       "warreporting                                4.0\n",
       "weaponstechnology                           3.0\n",
       "womeninbusiness                             1.0\n",
       "woolwichattack                             17.0\n",
       "worldmigration                              6.0\n",
       "zikavirus                                   3.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95811/95811 [==============================] - 2s - loss: 1.7367 - acc: 0.7069 - f1_micro: 0.5886 - val_loss: 1.4146 - val_acc: 0.7645 - val_f1_micro: 0.5889\n"
     ]
    }
   ],
   "source": [
    "print '95811/95811 [==============================] - 2s - loss: 1.7367 - acc: 0.7069 - f1_micro: 0.5886 - val_loss: 1.4146 - val_acc: 0.7645 - val_f1_micro: 0.5889'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_filename = 'tfidf_wv_300-fs_300-lsi_300-deep_stack_net-epochs_260-f1_0.6124-data_2010_2014_test_augmented_10_upsample-val_data_2014-thresh_{}-with_sc_wv_fs_lsi.csv'.format(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_sub_df.astype(int).reset_index().rename(\n",
    "    columns={'index': 'id'}\n",
    ").sort_values('id').to_csv(\n",
    "    sub_filename, \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7581, 160)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TestData_04490\tThe World Health Organisation has convened an ...\t[]\t28-01-2016\n",
    "TestData_04550\tSpraying pesticides will fail to deal with the...\t[]\t02-02-2016\n",
    "TestData_05683\tViolent protests at Trump rally in California ...\t[]\t03-06-2016\n",
    "TestData_05869\tLast weekend, we saw the darkest side of human...\t[]\t17-06-2016\n",
    "TestData_06148\tAs dusk falls over Copacabana beach, Ubira San...\t[]\t16-07-2016\n",
    "TestData_06291\tIt is 3pm and yet another patient is brought t...\t[]\t27-07-2016\n",
    "TestData_06610\tHuddled around their hives, beekeepers around ...\t[]\t04-09-2016\n",
    "TestData_06708\tA United Nations high-level panel on access to...\t[]\t14-09-2016\n",
    "TestData_07263\tWHO: Zika virus is no longer a world threat Th...\t[]\t19-11-2016\n",
    "TestData_07478\t1 World Health Organisation declares a public ...\t[]\t18-12-2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "guncrime        1.0\n",
       "usguncontrol    1.0\n",
       "Name: TestData_05869, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = 5868\n",
    "test_sub_df.iloc[ix][test_sub_df.iloc[ix] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36 ms, sys: 0 ns, total: 36 ms\n",
      "Wall time: 32.6 ms\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# adjust_index = 0\n",
    "# # valid_test_feature_vec found below!\n",
    "# test_values = np.zeros([test_df.shape[0], len(topics)])\n",
    "# for ix, pred in enumerate(main_test_probas):\n",
    "#     if ix in skip_index:\n",
    "#         test_values[ix] = np.nan\n",
    "#         # Increment adjust index so that we have the correct index for other samples\n",
    "#         adjust_index += 1\n",
    "#         continue\n",
    "\n",
    "#     for v in get_classes(pred, thresh=0.05):\n",
    "#         test_values[ix + adjust_index][v] = 1\n",
    "\n",
    "# test_sub_df = pd.DataFrame(test_values, columns=sorted(topics), index=test_df.index)\n",
    "\n",
    "# q = test_sub_df.sum(axis=1)\n",
    "# assert(len(q[q.isnull()].index.difference(test_null_index)) == 0)\n",
    "\n",
    "# test_sub_df = test_sub_df.fillna(0)\n",
    "\n",
    "# # for i in test_feature_vec[test_feature_vec.isnull()].index:\n",
    "# #     test_sub_df.ix[i] = np.zeros(len(topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestData_02543    0.0\n",
       "TestData_05012    0.0\n",
       "TestData_05830    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.ix[test_null_index].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11656.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sub_df.astype(int).reset_index().rename(\n",
    "    columns={'index': 'id'}\n",
    ").sort_values('id').to_csv(\n",
    "    'lstm_300-word2vec_300-fasttext_300-maxlen_500-dense_64_64_64-cat_cross-epoch_210-batch_size_750-val_main_output_f1_micro_0.5760-main_output_f1_micro_0.5751-main_output_loss_0.9143-data_2010_2013-val_data_2014-thresh_0.05.csv', \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: zikavirus, dtype: float64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = test_sub_df['zikavirus']\n",
    "e[e==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14328"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_submission = pd.read_csv('basic_nn_submission_0.649_accuracy_multi_class.csv')\n",
    "top_submission.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9280"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_index_lstm_sub = pd.read_csv('lstm.2014b_training_700_maxlen_64cell_100epochs_0.0025_threshold.csv')\n",
    "wrong_index_lstm_sub.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34952"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_sub = pd.read_csv('basic_nn_submission_full_training_data_0.9958_validation_accuracy_binary_crossentropy.csv')\n",
    "some_sub.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2197, 160)\n",
      "(3957, 160)\n",
      "(12, 160)\n",
      "(1503, 160)\n"
     ]
    }
   ],
   "source": [
    "print top_submission.set_index('id')[top_submission.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print wrong_index_lstm_sub.set_index('id')[wrong_index_lstm_sub.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print some_sub.set_index('id')[some_sub.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print test_sub_df[test_sub_df.sum(axis=1) == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestData_00011     0\n",
       "TestData_00012     0\n",
       "TestData_00015     0\n",
       "TestData_00027     3\n",
       "TestData_00029     0\n",
       "TestData_00038     1\n",
       "TestData_00042     5\n",
       "TestData_00053     4\n",
       "TestData_00056     1\n",
       "TestData_00060     1\n",
       "TestData_00066     0\n",
       "TestData_00085     0\n",
       "TestData_00087     1\n",
       "TestData_00090     0\n",
       "TestData_00092     0\n",
       "TestData_00107     3\n",
       "TestData_00111     0\n",
       "TestData_00114     0\n",
       "TestData_00115     1\n",
       "TestData_00118     0\n",
       "TestData_00119     0\n",
       "TestData_00121     0\n",
       "TestData_00123     0\n",
       "TestData_00125     0\n",
       "TestData_00127     0\n",
       "TestData_00128     1\n",
       "TestData_00139     1\n",
       "TestData_00140     1\n",
       "TestData_00144     0\n",
       "TestData_00147     2\n",
       "                  ..\n",
       "TestData_07445     0\n",
       "TestData_07456     3\n",
       "TestData_07461     1\n",
       "TestData_07462     4\n",
       "TestData_07465     0\n",
       "TestData_07468     0\n",
       "TestData_07471     1\n",
       "TestData_07475     0\n",
       "TestData_07486    10\n",
       "TestData_07495     1\n",
       "TestData_07509     0\n",
       "TestData_07514     3\n",
       "TestData_07515     1\n",
       "TestData_07523     0\n",
       "TestData_07533     2\n",
       "TestData_07534     2\n",
       "TestData_07542     1\n",
       "TestData_07544     2\n",
       "TestData_07545     0\n",
       "TestData_07552     2\n",
       "TestData_07556     5\n",
       "TestData_07563     1\n",
       "TestData_07565     0\n",
       "TestData_07566     0\n",
       "TestData_07569     0\n",
       "TestData_07571     3\n",
       "TestData_07572     1\n",
       "TestData_07579     6\n",
       "TestData_07580     2\n",
       "TestData_07581     3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_submission.set_index('id').ix[q[q == 0].index].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1222,)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.sum(axis=1)\n",
    "q[q==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7581.000000\n",
       "mean        2.160929\n",
       "std         1.739411\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         2.000000\n",
       "75%         3.000000\n",
       "max        13.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = trainingY.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    236286.000000\n",
       "mean          1.392787\n",
       "std           0.762577\n",
       "min           1.000000\n",
       "25%           1.000000\n",
       "50%           1.000000\n",
       "75%           2.000000\n",
       "max          15.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bodyText</th>\n",
       "      <th>topics</th>\n",
       "      <th>webPublicationDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TestData_03241</th>\n",
       "      <td>A special British police unit was put on stand...</td>\n",
       "      <td>[]</td>\n",
       "      <td>15-11-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_04088</th>\n",
       "      <td>The youngest convict in a fatal gang-rape in N...</td>\n",
       "      <td>[]</td>\n",
       "      <td>20-12-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_06306</th>\n",
       "      <td>Former New York City mayor Rudy Giuliani has s...</td>\n",
       "      <td>[]</td>\n",
       "      <td>28-07-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_06083</th>\n",
       "      <td>John Cantlie, the British journalist who has b...</td>\n",
       "      <td>[]</td>\n",
       "      <td>13-07-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_05896</th>\n",
       "      <td>Lawyers for the companies that manufactured an...</td>\n",
       "      <td>[]</td>\n",
       "      <td>20-06-2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         bodyText topics  \\\n",
       "TestData_03241  A special British police unit was put on stand...     []   \n",
       "TestData_04088  The youngest convict in a fatal gang-rape in N...     []   \n",
       "TestData_06306  Former New York City mayor Rudy Giuliani has s...     []   \n",
       "TestData_06083  John Cantlie, the British journalist who has b...     []   \n",
       "TestData_05896  Lawyers for the companies that manufactured an...     []   \n",
       "\n",
       "               webPublicationDate  \n",
       "TestData_03241         15-11-2015  \n",
       "TestData_04088         20-12-2015  \n",
       "TestData_06306         28-07-2016  \n",
       "TestData_06083         13-07-2016  \n",
       "TestData_05896         20-06-2016  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ix = 'TestData_03241'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "london                1.0\n",
       "metropolitanpolice    1.0\n",
       "police                1.0\n",
       "uksecurity            1.0\n",
       "Name: TestData_03241, dtype: float64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ukcrime    1\n",
       "Name: TestData_04088, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = top_submission.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "humanrights    1\n",
       "india          1\n",
       "protest        1\n",
       "ukcrime        1\n",
       "Name: TestData_04088, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = some_sub.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "humanrights    1\n",
       "Name: TestData_02924, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = wrong_index_lstm_sub.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Counter-terrorism policy\n",
    " \n",
    "Foreign policy\n",
    " \n",
    "Defence policy\n",
    " \n",
    "Islamic State\n",
    " \n",
    "Syria\n",
    " \n",
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = trainingY.sum()\n",
    "unseen_topics = s[s.isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activism',\n",
       " 'bastilledaytruckattack',\n",
       " 'berlinchristmasmarketattack',\n",
       " 'brusselsattacks',\n",
       " 'charliehebdoattack',\n",
       " 'francetrainattack',\n",
       " 'munichshooting',\n",
       " 'orlandoterrorattack',\n",
       " 'parisattacks',\n",
       " 'peaceandreconciliation',\n",
       " 'sanbernardinoshooting',\n",
       " 'tunisiaattack2015',\n",
       " 'turkeycoupattempt',\n",
       " 'zikavirus'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(topics).intersection(unseen_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activism\n",
      "afghanistan\n",
      "aid\n",
      "algerianhostagecrisis\n",
      "alqaida\n",
      "alshabaab\n",
      "antiwar\n",
      "arabandmiddleeastprotests\n",
      "armstrade\n",
      "australianguncontrol\n",
      "australiansecurityandcounterterrorism\n",
      "bastilledaytruckattack\n",
      "belgium\n",
      "berlinchristmasmarketattack\n",
      "bigdata\n",
      "biometrics\n",
      "bokoharam\n",
      "bostonmarathonbombing\n",
      "britisharmy\n",
      "brusselsattacks\n",
      "cameroon\n",
      "carers\n",
      "charliehebdoattack\n",
      "chemicalweapons\n",
      "clusterbombs\n",
      "cobra\n",
      "conflictanddevelopment\n",
      "controversy\n",
      "criminaljustice\n",
      "cybercrime\n",
      "cyberwar\n",
      "darknet\n",
      "dataprotection\n",
      "debate\n",
      "defence\n",
      "deflation\n",
      "drones\n",
      "drugs\n",
      "drugspolicy\n",
      "drugstrade\n",
      "earthquakes\n",
      "ebola\n",
      "economy\n",
      "egypt\n",
      "encryption\n",
      "energy\n",
      "espionage\n",
      "ethics\n",
      "europeanarrestwarrant\n",
      "europeancourtofhumanrights\n",
      "events\n",
      "extradition\n",
      "famine\n",
      "farright\n",
      "firefighters\n",
      "forensicscience\n",
      "france\n",
      "francetrainattack\n",
      "freedomofspeech\n",
      "genevaconventions\n",
      "germany\n",
      "guncrime\n",
      "hacking\n",
      "hashtags\n",
      "helicoptercrashes\n",
      "humanitarianresponse\n",
      "humanrights\n",
      "humanrightsact\n",
      "humantrafficking\n",
      "immigration\n",
      "india\n",
      "indonesia\n",
      "internallydisplacedpeople\n",
      "internationalcourtofjustice\n",
      "internationalcriminaljustice\n",
      "internetsafety\n",
      "iraq\n",
      "isis\n",
      "israel\n",
      "jordan\n",
      "jubilee\n",
      "judiciary\n",
      "july7\n",
      "justiceandsecurity\n",
      "kenya\n",
      "knifecrime\n",
      "lebanon\n",
      "libya\n",
      "localgovernment\n",
      "logistics\n",
      "london\n",
      "londonriots\n",
      "malaysia\n",
      "mali\n",
      "malware\n",
      "metropolitanpolice\n",
      "middleeastpeacetalks\n",
      "migration\n",
      "military\n",
      "ministryofdefence\n",
      "morocco\n",
      "mrsa\n",
      "mumbaiterrorattacks\n",
      "munichshooting\n",
      "naturaldisasters\n",
      "nigeria\n",
      "nuclearweapons\n",
      "occupy\n",
      "organisedcrime\n",
      "orlandoterrorattack\n",
      "osamabinladen\n",
      "paris\n",
      "parisattacks\n",
      "peaceandreconciliation\n",
      "philippines\n",
      "piracy\n",
      "planecrashes\n",
      "police\n",
      "protest\n",
      "refugees\n",
      "religion\n",
      "retirementage\n",
      "rio20earthsummit\n",
      "royalairforce\n",
      "royalnavy\n",
      "russia\n",
      "sanbernardinoshooting\n",
      "saudiarabia\n",
      "september11\n",
      "slavery\n",
      "somalia\n",
      "southafrica\n",
      "southchinasea\n",
      "stopandsearch\n",
      "surveillance\n",
      "sydneysiege\n",
      "syria\n",
      "taliban\n",
      "terrorism\n",
      "thailand\n",
      "torture\n",
      "traincrashes\n",
      "transport\n",
      "tunisiaattack2015\n",
      "turkey\n",
      "turkeycoupattempt\n",
      "ukcrime\n",
      "uksecurity\n",
      "uksupremecourt\n",
      "undercoverpoliceandpolicing\n",
      "unitednations\n",
      "usguncontrol\n",
      "values\n",
      "warcrimes\n",
      "warreporting\n",
      "weaponstechnology\n",
      "womeninbusiness\n",
      "woolwichattack\n",
      "worldmigration\n",
      "zikavirus\n"
     ]
    }
   ],
   "source": [
    "for i in topics:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsolatorio/ml-ai/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3445929"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(wvmodel['zika'], np.vstack(test_wvec.dropna())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsolatorio/ml-ai/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.38107796869050226"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(fsmodel['zika'], np.vstack(test_fvec.dropna())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              The World Health Organisation has convened an ...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           28-01-2016\n",
       "Name: TestData_04490, dtype: object"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[4488 + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              The United Nations security council has called...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           17-09-2016\n",
       "Name: TestData_06730, dtype: object"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[6727 + 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              We are deeply concerned that the counter-terro...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           02-02-2015\n",
       "Name: TestData_00360, dtype: object"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[359]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drugstrade    1.0\n",
       "Name: TestData_04490, dtype: float64"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.iloc[4488 + 1]\n",
    "q[q > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
