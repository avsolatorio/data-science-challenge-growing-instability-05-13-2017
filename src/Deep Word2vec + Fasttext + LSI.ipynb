{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from growing_instability_lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub = pd.read_csv('../data/sampleSubmission.csv')\n",
    "topics = sorted(set(sample_sub.columns.difference(['id'])))\n",
    "\n",
    "topic2actual = {}\n",
    "for i in sample_sub.columns:\n",
    "    if 'id' == i:\n",
    "        continue\n",
    "    topic2actual[i] = segment(i)\n",
    "    \n",
    "target_columns = sorted(topics)\n",
    "len(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.3 s, sys: 3.83 s, total: 14.1 s\n",
      "Wall time: 17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wvec_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'wvec_trainingX')\n",
    "fvec_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'fvec_trainingX')\n",
    "\n",
    "tfidf_wvec_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'tfidf_wvec_trainingX')\n",
    "tfidf_fvec_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'tfidf_fvec_trainingX')\n",
    "tfidf_lsi_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'tfidf_lsi_trainingX')\n",
    "\n",
    "word2idx_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'word2idx_trainingX')\n",
    "_word2idx = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', '_word2idx')\n",
    "trainingY = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'trainingY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://192.168.1.25:9999/notebooks/kaggle/data-science-challenge-growing-instability-05-13-2017/src/Topic%20Modeling%20and%20Clustering.ipynb\n",
    "train_test_df = pd.read_hdf('train_test_df.hdf', 'train_test_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_topics(df, topics):\n",
    "    topics = sorted(topics)\n",
    "#     v = np.zeros(shape=(df.shape[0], len(topics)))\n",
    "    v = []\n",
    "    for ix, tp in enumerate(df.topics):\n",
    "        tt = []\n",
    "        for t in tp:\n",
    "            tt.append(topics.index(t))\n",
    "#             v[ix][topics.index(t)] = 1\n",
    "        v.append(tt)\n",
    "\n",
    "    return pd.Series(v, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fs features...\n",
      "Current batch in main thread: 90\n",
      "Current batch in main thread: 195\n",
      "Computing wv features...\n",
      "Current batch in main thread: 90\n",
      "Current batch in main thread: 195\n",
      "Mapping word indices...\n",
      "Computing tfidf fs features...\n",
      "Current batch in main thread: 90\n",
      "Current batch in main thread: 195\n",
      "Computing tfidf wv features...\n",
      "Current batch in main thread: 90\n",
      "Current batch in main thread: 195\n",
      "Computing tfidf lsi features...\n",
      "Current batch in main thread: 90\n",
      "Current batch in main thread: 195\n"
     ]
    }
   ],
   "source": [
    "train_test_word_indices, train_test_wvec, train_test_fvec, train_test_tfidf_wvec, train_test_tfidf_fvec, train_test_tfidf_lsi = extract_features_for(\n",
    "    train_test_df\n",
    ")\n",
    "\n",
    "train_test_y = transform_topics(train_test_df, topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 s, sys: 64 ms, total: 12.1 s\n",
      "Wall time: 12.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ind2word = {j:i for i, j in _word2idx.iteritems()}\n",
    "ind2class = dict(enumerate(topics))\n",
    "class2ind = {j: i for i, j in ind2class.items()}\n",
    "\n",
    "num_samples = trainingY.shape[0]\n",
    "\n",
    "# ---------------------------------\n",
    "training_X = word2idx_trainingX.head(num_samples)\n",
    "training_Y = pd.DataFrame(zip(*np.where(trainingY.head(num_samples) == 1)), columns=['iloc', 'topics'])\n",
    "\n",
    "training_WV = wvec_trainingX.head(num_samples)\n",
    "training_FS = fvec_trainingX.head(num_samples)\n",
    "\n",
    "training_tfidf_WV = tfidf_wvec_trainingX.head(num_samples)\n",
    "training_tfidf_FS = tfidf_fvec_trainingX.head(num_samples)\n",
    "training_tfidf_LSI = tfidf_lsi_trainingX.head(num_samples)\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "training_Y = training_Y.groupby('iloc')['topics'].apply(list)\n",
    "training_Y.index = trainingY.head(num_samples).index\n",
    "\n",
    "indices = sorted(training_Y.index[training_Y.index.str.contains('^201[0-9]')])\n",
    "# np.random.shuffle(indices)\n",
    "indices = pd.Index(indices)\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "training_X = training_X.ix[indices]\n",
    "training_Y = training_Y.ix[indices]\n",
    "\n",
    "training_WV = training_WV.ix[indices]\n",
    "training_FS = training_FS.ix[indices]\n",
    "\n",
    "training_tfidf_WV = training_tfidf_WV.ix[indices]\n",
    "training_tfidf_FS = training_tfidf_FS.ix[indices]\n",
    "training_tfidf_LSI = training_tfidf_LSI.ix[indices]\n",
    "# ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 6.2 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wv_sc = StandardScaler()\n",
    "fs_sc = StandardScaler()\n",
    "\n",
    "tfidf_wv_sc = StandardScaler()\n",
    "tfidf_fs_sc = StandardScaler()\n",
    "tfidf_lsi_sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.87 s, sys: 84 ms, total: 1.95 s\n",
      "Wall time: 1.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "maxlen = 500\n",
    "\n",
    "\n",
    "def build_target(y, size):\n",
    "    e = np.zeros(size)\n",
    "    e[y] = 1\n",
    "    return e\n",
    "\n",
    "\n",
    "def build_input_output_data(X, WV, FS, TWV, TFS, TLSI, Y, maxlen):\n",
    "    x = sequence.pad_sequences(X, maxlen=maxlen)\n",
    "    y = np.vstack(Y.map(lambda x: build_target(x, len(topics))))\n",
    "\n",
    "    wv = np.vstack(WV)\n",
    "    fs = np.vstack(FS)\n",
    "\n",
    "    twv = np.vstack(TWV)\n",
    "    tfs = np.vstack(TFS)\n",
    "    tlsi = np.vstack(TLSI)\n",
    "\n",
    "    return x, wv, fs, twv, tfs, tlsi, y\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "train_ix = training_Y.index.str.contains('^201[2-4]')\n",
    "val_ix = training_Y.index.str.contains('^2014[b]')\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "x_train, wv_train, fs_train, tfidf_wv_train, tfidf_fs_train, tfidf_lsi_train, y_train = build_input_output_data(\n",
    "    training_X.ix[train_ix],\n",
    "\n",
    "    training_WV.ix[train_ix],\n",
    "    training_FS.ix[train_ix],\n",
    "\n",
    "    training_tfidf_WV.ix[train_ix],\n",
    "    training_tfidf_FS.ix[train_ix],\n",
    "    training_tfidf_LSI.ix[train_ix],\n",
    "\n",
    "    training_Y.ix[train_ix],\n",
    "    maxlen=maxlen\n",
    ")\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "x_val, wv_val, fs_val, tfidf_wv_val, tfidf_fs_val, tfidf_lsi_val, y_val = build_input_output_data(\n",
    "    training_X.ix[val_ix],\n",
    "\n",
    "    training_WV.ix[val_ix],\n",
    "    training_FS.ix[val_ix],\n",
    "\n",
    "    training_tfidf_WV.ix[val_ix],\n",
    "    training_tfidf_FS.ix[val_ix],\n",
    "    training_tfidf_LSI.ix[val_ix],\n",
    "\n",
    "    training_Y.ix[val_ix],\n",
    "    maxlen=maxlen\n",
    ")\n",
    "# ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "train_test_x_train, train_test_wv_train, train_test_fs_train, train_test_tfidf_wv_train, train_test_tfidf_fs_train, train_test_tfidf_lsi_train, train_test_y_train = build_input_output_data(\n",
    "    train_test_word_indices,\n",
    "\n",
    "    train_test_wvec,\n",
    "    train_test_fvec,\n",
    "\n",
    "    train_test_tfidf_wvec,\n",
    "    train_test_tfidf_fvec,\n",
    "    train_test_tfidf_lsi,\n",
    "\n",
    "    train_test_y,\n",
    "    maxlen=maxlen\n",
    ")\n",
    "# ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def upsample(x, N=5):\n",
    "    return np.vstack([x for i in xrange(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.vstack([x_train, upsample(train_test_x_train)])\n",
    "\n",
    "wv_train = np.vstack([wv_train, upsample(train_test_wv_train)])\n",
    "fs_train = np.vstack([fs_train, upsample(train_test_fs_train)])\n",
    "\n",
    "tfidf_wv_train = np.vstack([tfidf_wv_train, upsample(train_test_tfidf_wv_train)])\n",
    "tfidf_fs_train = np.vstack([tfidf_fs_train, upsample(train_test_tfidf_fs_train)])\n",
    "tfidf_lsi_train = np.vstack([tfidf_lsi_train, upsample(train_test_tfidf_lsi_train)])\n",
    "\n",
    "y_train = np.vstack([y_train, upsample(train_test_y_train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "wv_train = wv_sc.fit_transform(wv_train)\n",
    "fs_train = fs_sc.fit_transform(fs_train)\n",
    "\n",
    "tfidf_wv_train = tfidf_wv_sc.fit_transform(tfidf_wv_train)\n",
    "tfidf_fs_train = tfidf_fs_sc.fit_transform(tfidf_fs_train)\n",
    "tfidf_lsi_train = tfidf_lsi_sc.fit_transform(tfidf_lsi_train)\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "wv_val = wv_sc.transform(wv_val)\n",
    "fs_val = fs_sc.transform(fs_val)\n",
    "\n",
    "tfidf_wv_val = tfidf_wv_sc.transform(tfidf_wv_val)\n",
    "tfidf_fs_val = tfidf_fs_sc.transform(tfidf_fs_val)\n",
    "tfidf_lsi_val = tfidf_lsi_sc.transform(tfidf_lsi_val)\n",
    "# ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((94731,), (9424,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_Y.shape, training_Y.ix[training_Y.index.str.contains('^2014[b]')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as K\n",
    "import keras.backend as KB\n",
    "\n",
    "\n",
    "def f1_micro(y_true, y_pred):\n",
    "    TP = K.metrics.true_positives(y_true, K.round(y_pred))\n",
    "    FP = K.metrics.false_positives(y_true, K.round(y_pred))\n",
    "    FN = K.metrics.false_negatives(y_true, K.round(y_pred))\n",
    "    \n",
    "    p = K.reduce_sum(TP) / (K.reduce_sum(TP) + K.reduce_sum(FP))\n",
    "    r = K.reduce_sum(TP) / (K.reduce_sum(TP) + K.reduce_sum(FN))\n",
    "    \n",
    "    return (2.0 * p * r) / (p + r)\n",
    "\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "\n",
    "    # Count positive samples.\n",
    "    c1 = KB.sum(KB.round(KB.clip(y_true * y_pred, 0, 1)))\n",
    "    c2 = KB.sum(KB.round(KB.clip(y_pred, 0, 1)))\n",
    "    c3 = KB.sum(KB.round(KB.clip(y_true, 0, 1)))\n",
    "\n",
    "    # If there are no true samples, fix the F1 score at 0.\n",
    "    if c3 == 0:\n",
    "        return 0\n",
    "\n",
    "    # How many selected items are relevant?\n",
    "    precision = c1 / c2\n",
    "\n",
    "    # How many relevant items are selected?\n",
    "    recall = c1 / c3\n",
    "\n",
    "    # Calculate f1_score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense, Dropout, Convolution1D, MaxPooling1D, Flatten\n",
    "from keras.models import Model\n",
    "import itertools as it\n",
    "\n",
    "\n",
    "def build_deep_input_stack(input_node):\n",
    "    x = Dense(128, activation='tanh')(input_node)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(256, activation='relu')(input_node)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def entangle_inputs(input_nodes=[]):\n",
    "    assert(len(input_nodes) > 1)\n",
    "    \n",
    "    entangled_inputs = []\n",
    "\n",
    "    for n1, n2 in it.combinations(input_nodes, 2):\n",
    "        entangled_inputs.append(\n",
    "            keras.layers.dot([n1, n2], 1, normalize=True)\n",
    "        )\n",
    "    \n",
    "    return entangled_inputs\n",
    "\n",
    "\n",
    "wv_input = Input(shape=(300,), name='wv_input')\n",
    "fs_input = Input(shape=(300,), name='fs_input')\n",
    "\n",
    "tfidf_wv_input = Input(shape=(300,), name='tfidf_wv_input')\n",
    "tfidf_fs_input = Input(shape=(300,), name='tfidf_fs_input')\n",
    "tfidf_lsi_input = Input(shape=(300,), name='tfidf_lsi_input')\n",
    "\n",
    "\n",
    "wv_x = build_deep_input_stack(wv_input)\n",
    "fs_x = build_deep_input_stack(fs_input)\n",
    "tfidf_wv_x = build_deep_input_stack(tfidf_wv_input)\n",
    "tfidf_fs_x = build_deep_input_stack(tfidf_fs_input)\n",
    "tfidf_lsi_x = build_deep_input_stack(tfidf_wv_input)\n",
    "\n",
    "stacked_inputs_x = [wv_x, fs_x, tfidf_wv_x, tfidf_fs_x, tfidf_lsi_x]\n",
    "# stacked_inputs_x = [tfidf_wv_x, tfidf_fs_x, tfidf_lsi_x]\n",
    "entangled_inputs_x = entangle_inputs(stacked_inputs_x)\n",
    "\n",
    "x = keras.layers.concatenate(stacked_inputs_x + entangled_inputs_x)\n",
    "\n",
    "# We stack a deep densely-connected network on top\n",
    "x = Dense(128, activation='tanh')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "# And finally we add the main logistic regression layer\n",
    "main_output = Dense(len(class2ind), activation='sigmoid', name='main_output')(x)\n",
    "\n",
    "model = Model(\n",
    "    inputs=[\n",
    "        wv_input,\n",
    "        fs_input,\n",
    "        tfidf_wv_input,\n",
    "        tfidf_fs_input,\n",
    "        tfidf_lsi_input,\n",
    "    ],\n",
    "    outputs=[main_output]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'dot_21/ExpandDims:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'dot_22/ExpandDims:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'dot_23/ExpandDims:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'dot_24/ExpandDims:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'dot_25/ExpandDims:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'dot_26/ExpandDims:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'dot_27/ExpandDims:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'dot_28/ExpandDims:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'dot_29/ExpandDims:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'dot_30/ExpandDims:0' shape=(?, 1) dtype=float32>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entangled_inputs_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "wv_input (InputLayer)            (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "fs_input (InputLayer)            (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "tfidf_wv_input (InputLayer)      (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "tfidf_fs_input (InputLayer)      (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_40 (Dense)                 (None, 256)           77056                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_43 (Dense)                 (None, 256)           77056                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_46 (Dense)                 (None, 256)           77056                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_49 (Dense)                 (None, 256)           77056                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_52 (Dense)                 (None, 256)           77056                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)             (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)             (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)             (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)             (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)             (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_41 (Dense)                 (None, 512)           131584                                       \n",
      "____________________________________________________________________________________________________\n",
      "dense_44 (Dense)                 (None, 512)           131584                                       \n",
      "____________________________________________________________________________________________________\n",
      "dense_47 (Dense)                 (None, 512)           131584                                       \n",
      "____________________________________________________________________________________________________\n",
      "dense_50 (Dense)                 (None, 512)           131584                                       \n",
      "____________________________________________________________________________________________________\n",
      "dense_53 (Dense)                 (None, 512)           131584                                       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)             (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)             (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)             (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)             (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)             (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_21 (Dot)                     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_22 (Dot)                     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_23 (Dot)                     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_24 (Dot)                     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_25 (Dot)                     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_26 (Dot)                     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_27 (Dot)                     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_28 (Dot)                     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_29 (Dot)                     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dot_30 (Dot)                     (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 2570)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_54 (Dense)                 (None, 128)           329088                                       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)             (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_55 (Dense)                 (None, 256)           33024                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)             (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_56 (Dense)                 (None, 256)           65792                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)             (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_57 (Dense)                 (None, 128)           32896                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)             (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 160)           20640                                        \n",
      "====================================================================================================\n",
      "Total params: 1,524,640\n",
      "Trainable params: 1,524,640\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='rmsprop',  # keras.optimizers.RMSprop(lr=0.005),  # , rho=0.9, epsilon=1e-08, decay=0.0, clipnorm=1),\n",
    "    loss={'main_output': 'categorical_crossentropy'},\n",
    "    loss_weights={'main_output': 1.},\n",
    "    metrics=['accuracy', f1_micro]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.callbacks import EarlyStopping\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "# model.fit(X, y, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_training_inputs(wv, fs, tfidf_wv, tfidf_fs, tfidf_lsi):\n",
    "    training_inputs = {\n",
    "        'wv_input': wv,\n",
    "        'fs_input': fs,\n",
    "        'tfidf_wv_input': tfidf_wv,\n",
    "        'tfidf_fs_input': tfidf_fs,\n",
    "        'tfidf_lsi_input': tfidf_lsi,\n",
    "    }\n",
    "    \n",
    "    return training_inputs\n",
    "    \n",
    "\n",
    "training_inputs = build_training_inputs(\n",
    "    wv_train,\n",
    "    fs_train,\n",
    "    tfidf_wv_train,\n",
    "    tfidf_fs_train,\n",
    "    tfidf_lsi_train,\n",
    ")\n",
    "\n",
    "training_outputs = {\n",
    "    'main_output': y_train,\n",
    "}\n",
    "\n",
    "# train_test_shape = train_test_df.shape[0]\n",
    "# train_test_training_inputs = build_training_inputs(\n",
    "#     wv_train[-train_test_shape:],\n",
    "#     fs_train[-train_test_shape:],\n",
    "#     tfidf_wv_train[-train_test_shape:],\n",
    "#     tfidf_fs_train[-train_test_shape:],\n",
    "#     tfidf_lsi_train[-train_test_shape:],\n",
    "# )\n",
    "\n",
    "# train_test_training_outputs = {\n",
    "#     'main_output': y_train[-train_test_shape:],\n",
    "# }\n",
    "\n",
    "\n",
    "validation_data=(\n",
    "    build_training_inputs(\n",
    "        wv_val,\n",
    "        fs_val,\n",
    "        tfidf_wv_val,\n",
    "        tfidf_fs_val,\n",
    "        tfidf_lsi_val,\n",
    "    ),\n",
    "    {\n",
    "        'main_output': y_val,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 56877 samples, validate on 9424 samples\n",
      "Epoch 1/100\n",
      "56877/56877 [==============================] - 2s - loss: 5.6404 - acc: 0.1295 - f1_micro: 0.0630 - val_loss: 4.1946 - val_acc: 0.3277 - val_f1_micro: 0.0990\n",
      "Epoch 2/100\n",
      "56877/56877 [==============================] - 1s - loss: 3.7813 - acc: 0.4165 - f1_micro: 0.1261 - val_loss: 3.1512 - val_acc: 0.5209 - val_f1_micro: 0.1516\n",
      "Epoch 3/100\n",
      "56877/56877 [==============================] - 1s - loss: 3.1480 - acc: 0.5158 - f1_micro: 0.1753 - val_loss: 2.7997 - val_acc: 0.5892 - val_f1_micro: 0.1980\n",
      "Epoch 4/100\n",
      "56877/56877 [==============================] - 1s - loss: 2.8541 - acc: 0.5558 - f1_micro: 0.2187 - val_loss: 2.6495 - val_acc: 0.5999 - val_f1_micro: 0.2385\n",
      "Epoch 5/100\n",
      "56877/56877 [==============================] - 1s - loss: 2.6869 - acc: 0.5808 - f1_micro: 0.2566 - val_loss: 2.5518 - val_acc: 0.6065 - val_f1_micro: 0.2741\n",
      "Epoch 6/100\n",
      "56877/56877 [==============================] - 1s - loss: 2.5511 - acc: 0.5954 - f1_micro: 0.2900 - val_loss: 2.3708 - val_acc: 0.6306 - val_f1_micro: 0.3053\n",
      "Epoch 7/100\n",
      "56877/56877 [==============================] - 1s - loss: 2.4586 - acc: 0.6088 - f1_micro: 0.3193 - val_loss: 2.3108 - val_acc: 0.6431 - val_f1_micro: 0.3327\n",
      "Epoch 8/100\n",
      "56877/56877 [==============================] - 1s - loss: 2.3755 - acc: 0.6179 - f1_micro: 0.3452 - val_loss: 2.1896 - val_acc: 0.6567 - val_f1_micro: 0.3571\n",
      "Epoch 9/100\n",
      "56877/56877 [==============================] - 1s - loss: 2.3023 - acc: 0.6271 - f1_micro: 0.3682 - val_loss: 2.1465 - val_acc: 0.6615 - val_f1_micro: 0.3789\n",
      "Epoch 10/100\n",
      "56877/56877 [==============================] - 1s - loss: 2.2377 - acc: 0.6333 - f1_micro: 0.3891 - val_loss: 2.1382 - val_acc: 0.6708 - val_f1_micro: 0.3988\n",
      "Epoch 11/100\n",
      "56877/56877 [==============================] - 1s - loss: 2.1920 - acc: 0.6402 - f1_micro: 0.4080 - val_loss: 2.1051 - val_acc: 0.6756 - val_f1_micro: 0.4168\n",
      "Epoch 12/100\n",
      "56877/56877 [==============================] - 1s - loss: 2.1432 - acc: 0.6465 - f1_micro: 0.4251 - val_loss: 1.9697 - val_acc: 0.6837 - val_f1_micro: 0.4331\n",
      "Epoch 13/100\n",
      "56877/56877 [==============================] - 1s - loss: 2.0887 - acc: 0.6523 - f1_micro: 0.4406 - val_loss: 1.9223 - val_acc: 0.6992 - val_f1_micro: 0.4481\n",
      "Epoch 14/100\n",
      "56877/56877 [==============================] - 1s - loss: 2.0522 - acc: 0.6583 - f1_micro: 0.4551 - val_loss: 1.8829 - val_acc: 0.7047 - val_f1_micro: 0.4618\n",
      "Epoch 15/100\n",
      "56877/56877 [==============================] - 1s - loss: 2.0116 - acc: 0.6612 - f1_micro: 0.4683 - val_loss: 1.8680 - val_acc: 0.7192 - val_f1_micro: 0.4746\n",
      "Epoch 16/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.9790 - acc: 0.6668 - f1_micro: 0.4805 - val_loss: 1.8019 - val_acc: 0.7110 - val_f1_micro: 0.4863\n",
      "Epoch 17/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.9499 - acc: 0.6721 - f1_micro: 0.4918 - val_loss: 1.8239 - val_acc: 0.7089 - val_f1_micro: 0.4972\n",
      "Epoch 18/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.9208 - acc: 0.6728 - f1_micro: 0.5023 - val_loss: 1.7340 - val_acc: 0.7261 - val_f1_micro: 0.5073\n",
      "Epoch 19/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.8874 - acc: 0.6776 - f1_micro: 0.5121 - val_loss: 1.7189 - val_acc: 0.7245 - val_f1_micro: 0.5168\n",
      "Epoch 20/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.8726 - acc: 0.6796 - f1_micro: 0.5214 - val_loss: 1.6813 - val_acc: 0.7228 - val_f1_micro: 0.5258\n",
      "Epoch 21/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.8357 - acc: 0.6828 - f1_micro: 0.5301 - val_loss: 1.6496 - val_acc: 0.7271 - val_f1_micro: 0.5342\n",
      "Epoch 22/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.8160 - acc: 0.6878 - f1_micro: 0.5383 - val_loss: 1.6317 - val_acc: 0.7382 - val_f1_micro: 0.5422\n",
      "Epoch 23/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.7930 - acc: 0.6899 - f1_micro: 0.5460 - val_loss: 1.6268 - val_acc: 0.7402 - val_f1_micro: 0.5498\n",
      "Epoch 24/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.7774 - acc: 0.6911 - f1_micro: 0.5534 - val_loss: 1.5830 - val_acc: 0.7416 - val_f1_micro: 0.5570\n",
      "Epoch 25/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.7573 - acc: 0.6953 - f1_micro: 0.5604 - val_loss: 1.5704 - val_acc: 0.7396 - val_f1_micro: 0.5637\n",
      "Epoch 26/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.7369 - acc: 0.6979 - f1_micro: 0.5669 - val_loss: 1.5657 - val_acc: 0.7476 - val_f1_micro: 0.5701\n",
      "Epoch 27/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.7205 - acc: 0.6990 - f1_micro: 0.5732 - val_loss: 1.5073 - val_acc: 0.7414 - val_f1_micro: 0.5763\n",
      "Epoch 28/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.6999 - acc: 0.7019 - f1_micro: 0.5792 - val_loss: 1.5218 - val_acc: 0.7404 - val_f1_micro: 0.5821\n",
      "Epoch 29/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.6951 - acc: 0.7019 - f1_micro: 0.5849 - val_loss: 1.4885 - val_acc: 0.7524 - val_f1_micro: 0.5877\n",
      "Epoch 30/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.6787 - acc: 0.7037 - f1_micro: 0.5904 - val_loss: 1.4929 - val_acc: 0.7438 - val_f1_micro: 0.5931\n",
      "Epoch 31/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.6570 - acc: 0.7059 - f1_micro: 0.5958 - val_loss: 1.4521 - val_acc: 0.7511 - val_f1_micro: 0.5983\n",
      "Epoch 32/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.6424 - acc: 0.7092 - f1_micro: 0.6008 - val_loss: 1.4641 - val_acc: 0.7521 - val_f1_micro: 0.6033\n",
      "Epoch 33/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.6298 - acc: 0.7109 - f1_micro: 0.6057 - val_loss: 1.4521 - val_acc: 0.7514 - val_f1_micro: 0.6081\n",
      "Epoch 34/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.6208 - acc: 0.7110 - f1_micro: 0.6104 - val_loss: 1.4334 - val_acc: 0.7568 - val_f1_micro: 0.6127\n",
      "Epoch 35/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.6077 - acc: 0.7124 - f1_micro: 0.6149 - val_loss: 1.4038 - val_acc: 0.7555 - val_f1_micro: 0.6171\n",
      "Epoch 36/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.6030 - acc: 0.7131 - f1_micro: 0.6192 - val_loss: 1.3800 - val_acc: 0.7582 - val_f1_micro: 0.6213\n",
      "Epoch 37/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.5885 - acc: 0.7126 - f1_micro: 0.6234 - val_loss: 1.3864 - val_acc: 0.7496 - val_f1_micro: 0.6254\n",
      "Epoch 38/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.5760 - acc: 0.7159 - f1_micro: 0.6275 - val_loss: 1.3885 - val_acc: 0.7646 - val_f1_micro: 0.6294\n",
      "Epoch 39/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.5682 - acc: 0.7171 - f1_micro: 0.6314 - val_loss: 1.3642 - val_acc: 0.7592 - val_f1_micro: 0.6333\n",
      "Epoch 40/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.5613 - acc: 0.7180 - f1_micro: 0.6352 - val_loss: 1.3606 - val_acc: 0.7565 - val_f1_micro: 0.6370\n",
      "Epoch 41/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.5463 - acc: 0.7204 - f1_micro: 0.6388 - val_loss: 1.3740 - val_acc: 0.7575 - val_f1_micro: 0.6406\n",
      "Epoch 42/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.5443 - acc: 0.7210 - f1_micro: 0.6424 - val_loss: 1.3951 - val_acc: 0.7689 - val_f1_micro: 0.6441\n",
      "Epoch 43/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.5268 - acc: 0.7213 - f1_micro: 0.6458 - val_loss: 1.3374 - val_acc: 0.7696 - val_f1_micro: 0.6475\n",
      "Epoch 44/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.5233 - acc: 0.7232 - f1_micro: 0.6491 - val_loss: 1.3425 - val_acc: 0.7611 - val_f1_micro: 0.6508\n",
      "Epoch 45/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.5168 - acc: 0.7248 - f1_micro: 0.6524 - val_loss: 1.3392 - val_acc: 0.7650 - val_f1_micro: 0.6539\n",
      "Epoch 46/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.5109 - acc: 0.7235 - f1_micro: 0.6555 - val_loss: 1.3397 - val_acc: 0.7631 - val_f1_micro: 0.6570\n",
      "Epoch 47/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4998 - acc: 0.7247 - f1_micro: 0.6585 - val_loss: 1.3114 - val_acc: 0.7652 - val_f1_micro: 0.6600\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56877/56877 [==============================] - 1s - loss: 1.4930 - acc: 0.7285 - f1_micro: 0.6615 - val_loss: 1.3118 - val_acc: 0.7689 - val_f1_micro: 0.6630\n",
      "Epoch 49/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4887 - acc: 0.7296 - f1_micro: 0.6644 - val_loss: 1.2826 - val_acc: 0.7680 - val_f1_micro: 0.6658\n",
      "Epoch 50/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4791 - acc: 0.7281 - f1_micro: 0.6672 - val_loss: 1.2895 - val_acc: 0.7756 - val_f1_micro: 0.6686\n",
      "Epoch 51/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4730 - acc: 0.7298 - f1_micro: 0.6699 - val_loss: 1.2936 - val_acc: 0.7744 - val_f1_micro: 0.6713\n",
      "Epoch 52/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4653 - acc: 0.7306 - f1_micro: 0.6726 - val_loss: 1.2800 - val_acc: 0.7640 - val_f1_micro: 0.6740\n",
      "Epoch 53/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4590 - acc: 0.7289 - f1_micro: 0.6752 - val_loss: 1.2692 - val_acc: 0.7768 - val_f1_micro: 0.6765\n",
      "Epoch 54/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4517 - acc: 0.7303 - f1_micro: 0.6778 - val_loss: 1.3135 - val_acc: 0.7703 - val_f1_micro: 0.6790\n",
      "Epoch 55/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4543 - acc: 0.7304 - f1_micro: 0.6802 - val_loss: 1.2498 - val_acc: 0.7795 - val_f1_micro: 0.6815\n",
      "Epoch 56/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4456 - acc: 0.7319 - f1_micro: 0.6827 - val_loss: 1.2449 - val_acc: 0.7747 - val_f1_micro: 0.6839\n",
      "Epoch 57/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4411 - acc: 0.7336 - f1_micro: 0.6850 - val_loss: 1.2457 - val_acc: 0.7698 - val_f1_micro: 0.6862\n",
      "Epoch 58/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4376 - acc: 0.7335 - f1_micro: 0.6873 - val_loss: 1.2457 - val_acc: 0.7742 - val_f1_micro: 0.6884\n",
      "Epoch 59/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4295 - acc: 0.7349 - f1_micro: 0.6895 - val_loss: 1.2491 - val_acc: 0.7744 - val_f1_micro: 0.6906\n",
      "Epoch 60/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4228 - acc: 0.7356 - f1_micro: 0.6917 - val_loss: 1.2421 - val_acc: 0.7783 - val_f1_micro: 0.6928\n",
      "Epoch 61/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4227 - acc: 0.7354 - f1_micro: 0.6939 - val_loss: 1.2435 - val_acc: 0.7796 - val_f1_micro: 0.6950\n",
      "Epoch 62/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4155 - acc: 0.7360 - f1_micro: 0.6960 - val_loss: 1.2198 - val_acc: 0.7834 - val_f1_micro: 0.6970\n",
      "Epoch 63/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4083 - acc: 0.7358 - f1_micro: 0.6981 - val_loss: 1.2469 - val_acc: 0.7721 - val_f1_micro: 0.6991\n",
      "Epoch 64/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4036 - acc: 0.7366 - f1_micro: 0.7001 - val_loss: 1.2229 - val_acc: 0.7748 - val_f1_micro: 0.7011\n",
      "Epoch 65/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.4054 - acc: 0.7383 - f1_micro: 0.7021 - val_loss: 1.2041 - val_acc: 0.7773 - val_f1_micro: 0.7031\n",
      "Epoch 66/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3998 - acc: 0.7376 - f1_micro: 0.7040 - val_loss: 1.2115 - val_acc: 0.7792 - val_f1_micro: 0.7050\n",
      "Epoch 67/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3930 - acc: 0.7404 - f1_micro: 0.7059 - val_loss: 1.2043 - val_acc: 0.7778 - val_f1_micro: 0.7068\n",
      "Epoch 68/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3895 - acc: 0.7397 - f1_micro: 0.7078 - val_loss: 1.1914 - val_acc: 0.7813 - val_f1_micro: 0.7087\n",
      "Epoch 69/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3938 - acc: 0.7393 - f1_micro: 0.7096 - val_loss: 1.1918 - val_acc: 0.7822 - val_f1_micro: 0.7105\n",
      "Epoch 70/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3857 - acc: 0.7397 - f1_micro: 0.7114 - val_loss: 1.2017 - val_acc: 0.7771 - val_f1_micro: 0.7123\n",
      "Epoch 71/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3805 - acc: 0.7413 - f1_micro: 0.7132 - val_loss: 1.1931 - val_acc: 0.7767 - val_f1_micro: 0.7140\n",
      "Epoch 72/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3809 - acc: 0.7411 - f1_micro: 0.7149 - val_loss: 1.2091 - val_acc: 0.7831 - val_f1_micro: 0.7157\n",
      "Epoch 73/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3682 - acc: 0.7403 - f1_micro: 0.7166 - val_loss: 1.1941 - val_acc: 0.7932 - val_f1_micro: 0.7174\n",
      "Epoch 74/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3683 - acc: 0.7419 - f1_micro: 0.7182 - val_loss: 1.1811 - val_acc: 0.7812 - val_f1_micro: 0.7191\n",
      "Epoch 75/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3721 - acc: 0.7426 - f1_micro: 0.7199 - val_loss: 1.1899 - val_acc: 0.7761 - val_f1_micro: 0.7207\n",
      "Epoch 76/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3683 - acc: 0.7408 - f1_micro: 0.7215 - val_loss: 1.1780 - val_acc: 0.7801 - val_f1_micro: 0.7223\n",
      "Epoch 77/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3572 - acc: 0.7437 - f1_micro: 0.7230 - val_loss: 1.1876 - val_acc: 0.7814 - val_f1_micro: 0.7238\n",
      "Epoch 78/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3595 - acc: 0.7445 - f1_micro: 0.7246 - val_loss: 1.1676 - val_acc: 0.7879 - val_f1_micro: 0.7253\n",
      "Epoch 79/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3523 - acc: 0.7445 - f1_micro: 0.7261 - val_loss: 1.1776 - val_acc: 0.7819 - val_f1_micro: 0.7268\n",
      "Epoch 80/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3525 - acc: 0.7461 - f1_micro: 0.7276 - val_loss: 1.1738 - val_acc: 0.7864 - val_f1_micro: 0.7283\n",
      "Epoch 81/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3474 - acc: 0.7418 - f1_micro: 0.7290 - val_loss: 1.1634 - val_acc: 0.7863 - val_f1_micro: 0.7298\n",
      "Epoch 82/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3495 - acc: 0.7447 - f1_micro: 0.7305 - val_loss: 1.1804 - val_acc: 0.7826 - val_f1_micro: 0.7312\n",
      "Epoch 83/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3383 - acc: 0.7443 - f1_micro: 0.7319 - val_loss: 1.1503 - val_acc: 0.7883 - val_f1_micro: 0.7326\n",
      "Epoch 84/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3386 - acc: 0.7444 - f1_micro: 0.7333 - val_loss: 1.1617 - val_acc: 0.7876 - val_f1_micro: 0.7340\n",
      "Epoch 85/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3351 - acc: 0.7448 - f1_micro: 0.7347 - val_loss: 1.1669 - val_acc: 0.7867 - val_f1_micro: 0.7354\n",
      "Epoch 86/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3314 - acc: 0.7457 - f1_micro: 0.7360 - val_loss: 1.1775 - val_acc: 0.7829 - val_f1_micro: 0.7367\n",
      "Epoch 87/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3332 - acc: 0.7452 - f1_micro: 0.7374 - val_loss: 1.1604 - val_acc: 0.7801 - val_f1_micro: 0.7380\n",
      "Epoch 88/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3254 - acc: 0.7472 - f1_micro: 0.7387 - val_loss: 1.1619 - val_acc: 0.7890 - val_f1_micro: 0.7393\n",
      "Epoch 89/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3288 - acc: 0.7457 - f1_micro: 0.7400 - val_loss: 1.1492 - val_acc: 0.7749 - val_f1_micro: 0.7406\n",
      "Epoch 90/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3286 - acc: 0.7466 - f1_micro: 0.7412 - val_loss: 1.1430 - val_acc: 0.7881 - val_f1_micro: 0.7418\n",
      "Epoch 91/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3195 - acc: 0.7482 - f1_micro: 0.7425 - val_loss: 1.1473 - val_acc: 0.7838 - val_f1_micro: 0.7431\n",
      "Epoch 92/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3193 - acc: 0.7469 - f1_micro: 0.7437 - val_loss: 1.1359 - val_acc: 0.7923 - val_f1_micro: 0.7443\n",
      "Epoch 93/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3191 - acc: 0.7494 - f1_micro: 0.7449 - val_loss: 1.1407 - val_acc: 0.7910 - val_f1_micro: 0.7455\n",
      "Epoch 94/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3190 - acc: 0.7478 - f1_micro: 0.7461 - val_loss: 1.1387 - val_acc: 0.7847 - val_f1_micro: 0.7467\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56877/56877 [==============================] - 1s - loss: 1.3139 - acc: 0.7469 - f1_micro: 0.7472 - val_loss: 1.1294 - val_acc: 0.7915 - val_f1_micro: 0.7478\n",
      "Epoch 96/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3169 - acc: 0.7473 - f1_micro: 0.7484 - val_loss: 1.1351 - val_acc: 0.7910 - val_f1_micro: 0.7489\n",
      "Epoch 97/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3075 - acc: 0.7506 - f1_micro: 0.7495 - val_loss: 1.1346 - val_acc: 0.7899 - val_f1_micro: 0.7501\n",
      "Epoch 98/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3036 - acc: 0.7492 - f1_micro: 0.7506 - val_loss: 1.1241 - val_acc: 0.7971 - val_f1_micro: 0.7512\n",
      "Epoch 99/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3050 - acc: 0.7491 - f1_micro: 0.7517 - val_loss: 1.1459 - val_acc: 0.7855 - val_f1_micro: 0.7523\n",
      "Epoch 100/100\n",
      "56877/56877 [==============================] - 1s - loss: 1.3031 - acc: 0.7482 - f1_micro: 0.7528 - val_loss: 1.1262 - val_acc: 0.7870 - val_f1_micro: 0.7534\n",
      "CPU times: user 2min 34s, sys: 25.2 s, total: 2min 59s\n",
      "Wall time: 2min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# And trained it via:\n",
    "batch_size = 1000\n",
    "epochs = 100\n",
    "\n",
    "hist = model.fit(\n",
    "    training_inputs,\n",
    "    training_outputs,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    validation_data=validation_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # And trained it via:\n",
    "# batch_size = 10\n",
    "# epochs = 50\n",
    "\n",
    "# hist = model.fit(\n",
    "#     train_test_training_inputs,\n",
    "#     train_test_training_outputs,\n",
    "#     epochs=epochs,\n",
    "#     batch_size=batch_size,\n",
    "#     validation_split=0.2,\n",
    "#     validation_data=validation_data,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75280707705374483"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history['f1_micro'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# log_history_file = 'lstm-word2vec-fasttext-lsi.epoch.csv'\n",
    "# model_name = 'models/tfidf-wv-fs-lsi-2010-2014-data_cat-crossentropy-2014-b-val-sc_tfidf_wv_fs_lsi.model'\n",
    "# batch_size = 1200\n",
    "# epochs = 5\n",
    "# total_epochs = 100\n",
    "\n",
    "# for i in xrange(0, total_epochs // epochs):\n",
    "#     hist = model.fit(\n",
    "#         training_inputs,\n",
    "#         training_outputs,\n",
    "#         epochs=epochs,\n",
    "#         batch_size=batch_size,\n",
    "#         validation_split=0.2,\n",
    "#         validation_data=validation_data,\n",
    "#     )\n",
    "\n",
    "#     model.save(model_name.format(i))\n",
    "#     print\n",
    "#     print('Done with epoch: {}'.format((i + 1) * epochs))\n",
    "#     with open(log_history_file, 'a') as fl:\n",
    "#         fl.write(model_name + '\\n')\n",
    "#         fl.write('Epoch {}\\n'.format((i + 1) * epochs))\n",
    "#         fl.write('{}\\n'.format(datetime.now()))\n",
    "#         fl.write('\\n'.join(['{}: {}'.format(k, v[0]) for k, v in hist.history.items()]))\n",
    "#         fl.write('\\n\\n')\n",
    "#     print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# total_epochs = 100\n",
    "# for j in xrange(i, i + (total_epochs // epochs)):\n",
    "#     hist = model.fit(\n",
    "#         training_inputs,\n",
    "#         training_outputs,\n",
    "#         epochs=epochs,\n",
    "#         batch_size=batch_size,\n",
    "#         validation_split=0.2,\n",
    "#         validation_data=validation_data,\n",
    "#     )\n",
    "\n",
    "#     model.save(model_name.format(i))\n",
    "#     print\n",
    "#     print('Done with epoch: {}'.format((j + 1) * epochs))\n",
    "#     with open(log_history_file, 'a') as fl:\n",
    "#         fl.write(model_name + '\\n')\n",
    "#         fl.write('Epoch {}\\n'.format((j + 1) * epochs))\n",
    "#         fl.write('{}\\n'.format(datetime.now()))\n",
    "#         fl.write('\\n'.join(['{}: {}'.format(k, v[0]) for k, v in hist.history.items()]))\n",
    "#         fl.write('\\n\\n')\n",
    "#     print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = keras.models.load_model(\n",
    "#     'models/lstm-word2vec-fasttext_2010-2014-data_categorical-crossentropy-2014-b-val-standard_scaled_wv_fs.model',\n",
    "#     custom_objects={'f1_micro': f1_micro}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test_wv_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = model.predict(\n",
    "    build_training_inputs(\n",
    "        wv_train,\n",
    "        fs_train,\n",
    "        tfidf_wv_train,\n",
    "        tfidf_fs_train,\n",
    "        tfidf_lsi_train,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.63195959e-13,   8.24948074e-05,   6.47014531e-07, ...,\n",
       "          7.38081679e-11,   5.84325227e-11,   7.67876593e-13],\n",
       "       [  3.32635901e-21,   2.33425584e-10,   1.30406634e-12, ...,\n",
       "          1.42055082e-13,   2.92154195e-18,   1.97574157e-20],\n",
       "       [  3.89963753e-19,   1.96359443e-10,   2.39966198e-08, ...,\n",
       "          9.10092557e-11,   1.74331188e-14,   1.12240013e-18],\n",
       "       ..., \n",
       "       [  9.10560863e-12,   7.72679299e-02,   3.29533243e-04, ...,\n",
       "          7.46723256e-12,   7.13891226e-16,   6.85447315e-12],\n",
       "       [  1.11707954e-15,   4.03552633e-07,   3.34899797e-09, ...,\n",
       "          1.15479679e-08,   1.03178681e-11,   4.92145624e-16],\n",
       "       [  7.10842585e-15,   8.85631598e-05,   5.57425395e-08, ...,\n",
       "          2.27470642e-09,   1.78172500e-14,   4.16072663e-15]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score as sk_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 412 ms, sys: 24 ms, total: 436 ms\n",
      "Wall time: 431 ms\n",
      "CPU times: user 416 ms, sys: 16 ms, total: 432 ms\n",
      "Wall time: 430 ms\n",
      "CPU times: user 432 ms, sys: 4 ms, total: 436 ms\n",
      "Wall time: 431 ms\n",
      "CPU times: user 416 ms, sys: 20 ms, total: 436 ms\n",
      "Wall time: 431 ms\n",
      "CPU times: user 420 ms, sys: 12 ms, total: 432 ms\n",
      "Wall time: 429 ms\n",
      "CPU times: user 416 ms, sys: 16 ms, total: 432 ms\n",
      "Wall time: 430 ms\n",
      "CPU times: user 432 ms, sys: 0 ns, total: 432 ms\n",
      "Wall time: 431 ms\n",
      "CPU times: user 436 ms, sys: 0 ns, total: 436 ms\n",
      "Wall time: 430 ms\n",
      "CPU times: user 424 ms, sys: 8 ms, total: 432 ms\n",
      "Wall time: 431 ms\n",
      "CPU times: user 424 ms, sys: 8 ms, total: 432 ms\n",
      "Wall time: 430 ms\n",
      "CPU times: user 424 ms, sys: 12 ms, total: 436 ms\n",
      "Wall time: 431 ms\n",
      "CPU times: user 424 ms, sys: 8 ms, total: 432 ms\n",
      "Wall time: 431 ms\n",
      "CPU times: user 428 ms, sys: 4 ms, total: 432 ms\n",
      "Wall time: 432 ms\n",
      "CPU times: user 424 ms, sys: 12 ms, total: 436 ms\n",
      "Wall time: 429 ms\n",
      "CPU times: user 436 ms, sys: 0 ns, total: 436 ms\n",
      "Wall time: 435 ms\n",
      "CPU times: user 428 ms, sys: 4 ms, total: 432 ms\n",
      "Wall time: 430 ms\n",
      "CPU times: user 432 ms, sys: 4 ms, total: 436 ms\n",
      "Wall time: 431 ms\n",
      "CPU times: user 424 ms, sys: 8 ms, total: 432 ms\n",
      "Wall time: 431 ms\n",
      "CPU times: user 432 ms, sys: 0 ns, total: 432 ms\n",
      "Wall time: 431 ms\n",
      "CPU times: user 424 ms, sys: 12 ms, total: 436 ms\n",
      "Wall time: 432 ms\n",
      "CPU times: user 420 ms, sys: 16 ms, total: 436 ms\n",
      "Wall time: 431 ms\n",
      "CPU times: user 420 ms, sys: 16 ms, total: 436 ms\n",
      "Wall time: 430 ms\n",
      "CPU times: user 424 ms, sys: 8 ms, total: 432 ms\n",
      "Wall time: 430 ms\n",
      "CPU times: user 424 ms, sys: 8 ms, total: 432 ms\n",
      "Wall time: 429 ms\n",
      "CPU times: user 428 ms, sys: 4 ms, total: 432 ms\n",
      "Wall time: 429 ms\n",
      "CPU times: user 428 ms, sys: 4 ms, total: 432 ms\n",
      "Wall time: 430 ms\n",
      "CPU times: user 428 ms, sys: 4 ms, total: 432 ms\n",
      "Wall time: 431 ms\n",
      "CPU times: user 412 ms, sys: 20 ms, total: 432 ms\n",
      "Wall time: 429 ms\n",
      "CPU times: user 432 ms, sys: 0 ns, total: 432 ms\n",
      "Wall time: 431 ms\n",
      "CPU times: user 432 ms, sys: 4 ms, total: 436 ms\n",
      "Wall time: 430 ms\n",
      "CPU times: user 424 ms, sys: 8 ms, total: 432 ms\n",
      "Wall time: 430 ms\n",
      "CPU times: user 432 ms, sys: 4 ms, total: 436 ms\n",
      "Wall time: 429 ms\n",
      "CPU times: user 424 ms, sys: 8 ms, total: 432 ms\n",
      "Wall time: 430 ms\n",
      "CPU times: user 428 ms, sys: 8 ms, total: 436 ms\n",
      "Wall time: 431 ms\n",
      "CPU times: user 428 ms, sys: 8 ms, total: 436 ms\n",
      "Wall time: 432 ms\n",
      "CPU times: user 432 ms, sys: 4 ms, total: 436 ms\n",
      "Wall time: 432 ms\n",
      "CPU times: user 428 ms, sys: 4 ms, total: 432 ms\n",
      "Wall time: 429 ms\n",
      "CPU times: user 420 ms, sys: 12 ms, total: 432 ms\n",
      "Wall time: 430 ms\n",
      "CPU times: user 428 ms, sys: 4 ms, total: 432 ms\n",
      "Wall time: 430 ms\n",
      "CPU times: user 428 ms, sys: 8 ms, total: 436 ms\n",
      "Wall time: 430 ms\n",
      "CPU times: user 428 ms, sys: 4 ms, total: 432 ms\n",
      "Wall time: 430 ms\n",
      "CPU times: user 424 ms, sys: 8 ms, total: 432 ms\n",
      "Wall time: 430 ms\n",
      "CPU times: user 424 ms, sys: 8 ms, total: 432 ms\n",
      "Wall time: 430 ms\n",
      "CPU times: user 416 ms, sys: 16 ms, total: 432 ms\n",
      "Wall time: 429 ms\n",
      "CPU times: user 424 ms, sys: 8 ms, total: 432 ms\n",
      "Wall time: 431 ms\n",
      "CPU times: user 424 ms, sys: 12 ms, total: 436 ms\n",
      "Wall time: 431 ms\n",
      "CPU times: user 424 ms, sys: 8 ms, total: 432 ms\n",
      "Wall time: 430 ms\n",
      "CPU times: user 428 ms, sys: 8 ms, total: 436 ms\n",
      "Wall time: 432 ms\n",
      "CPU times: user 420 ms, sys: 16 ms, total: 436 ms\n",
      "Wall time: 429 ms\n",
      "CPU times: user 428 ms, sys: 8 ms, total: 436 ms\n",
      "Wall time: 432 ms\n",
      "CPU times: user 424 ms, sys: 8 ms, total: 432 ms\n",
      "Wall time: 430 ms\n",
      "CPU times: user 21.7 s, sys: 436 ms, total: 22.2 s\n",
      "Wall time: 22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dt = 0.01\n",
    "s = 0.1\n",
    "e = 0.6\n",
    "th = np.arange(s, e + dt, dt)\n",
    "mean_fscores = []\n",
    "for t in th:\n",
    "#     fscores = []\n",
    "#     for ix in range(g.shape[0]):\n",
    "#         y_a = y_train[ix]\n",
    "#         y_p = 1.0 * (g[ix] > t)\n",
    "#         fscores.append(sk_f1_score(y_a, y_p))\n",
    "#     mean_fscores.append(np.mean(fscores))\n",
    "    %time mean_fscores.append((t, sk_f1_score(y_train, 1.0 * (g > t), average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.47999999999999976, 0.9293903353691203)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh, thresh_score = sorted(mean_fscores, key=lambda x: x[1], reverse=True)[0]\n",
    "thresh, thresh_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40999999999999981"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-99ec802a7769>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_test_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbodyText\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/avsolatorio/ml-ai/local/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1310\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1312\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avsolatorio/ml-ai/local/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1627\u001b[0m                 \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1628\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_valid_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/avsolatorio/ml-ai/local/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_is_valid_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1540\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1541\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1542\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1543\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "train_test_df.iloc[ix].bodyText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nuclearweapons'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics[106]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fba2866d490>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fba28697c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "ix = 93\n",
    "sd = -0\n",
    "pd.Series(g[sd:][ix]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([  1, 137]),), (array([  1, 137]),))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# thresh = 0.5\n",
    "np.where(y_train[sd:][ix] == 1), np.where(g[sd:][ix] > thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "from gensim.models.lsimodel import LsiModel\n",
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = TfidfModel.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.dictionary')\n",
    "tfidf = TfidfModel.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.tfidf')\n",
    "lsi = LsiModel.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.lsi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wvmodel = Word2Vec.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fsmodel = fasttext.load_model('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.fasttext.model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_fsmodel_cache = {}\n",
    "def get_fsvec(word):\n",
    "    if word in _fsmodel_cache:\n",
    "        fv = _fsmodel_cache[word]\n",
    "    else:\n",
    "        fv = fsmodel[word]\n",
    "        _fsmodel_cache[word] = fv\n",
    "\n",
    "    return fv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_tfidf_word2vec(tokens, stopwords=[]):\n",
    "#     global wvmodel\n",
    "#     global tfidf\n",
    "    # This requires wvmodel to be present in the namespace.\n",
    "    wv_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords and w in wvmodel.wv.vocab)]\n",
    "    ).map(\n",
    "        lambda x: tfidf[dictionary.doc2bow(x)]\n",
    "    ).map(\n",
    "        lambda x: np.array([wvmodel[dictionary.id2token[id]] * w for id, w in x]).mean(axis=0) if len(x) > 0 else np.nan\n",
    "    )\n",
    "\n",
    "    return wv_feature_vec\n",
    "\n",
    "\n",
    "def transform_tfidf_fasttext(tokens, stopwords=[]):\n",
    "#     global fsmodel\n",
    "#     global tfidf\n",
    "    # This requires wvmodel to be present in the namespace.\n",
    "    fs_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    ).map(\n",
    "        lambda x: tfidf[dictionary.doc2bow(x)]\n",
    "    ).map(\n",
    "        lambda x: np.array([np.array(get_fsvec(dictionary.id2token[id])) * w for id, w in x]).mean(axis=0) if len(x) > 0 else np.nan\n",
    "    )\n",
    "\n",
    "    return fs_feature_vec\n",
    "\n",
    "\n",
    "def build_lsi_vector(l):\n",
    "    v = np.zeros(lsi.num_topics)\n",
    "    \n",
    "    for ix, vv in lsi[tfidf[dictionary.doc2bow(l)]]:\n",
    "        v[ix] = vv\n",
    "        \n",
    "    return v\n",
    "\n",
    "\n",
    "def transform_tfidf_lsi(tokens, stopwords=[]):\n",
    "#     global fsmodel\n",
    "#     global tfidf\n",
    "    # This requires wvmodel to be present in the namespace.\n",
    "    lsi_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    ).map(\n",
    "        lambda x: build_lsi_vector(x) if len(x) > 0 else np.nan\n",
    "    )\n",
    "\n",
    "    return lsi_feature_vec\n",
    "\n",
    "\n",
    "def transform_fasttext(tokens, stopwords=[]):\n",
    "    global fsmodel\n",
    "    # This requires fsmodel to be present in the namespace.\n",
    "    fs_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    ).map(lambda x: np.array([get_fsvec(w) for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return fs_feature_vec\n",
    "\n",
    "\n",
    "def transform_unsupervised_sentiment_neuron(tokens, stopwords=[]):\n",
    "    # This requires fsmodel to be present in the namespace.\n",
    "    \n",
    "    usn_feature_vec = usnmodel.transform(tokens)\n",
    "\n",
    "    # usn_feature_vec = tokens.map(\n",
    "    #     lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    # ).map(lambda x: np.array([usnmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return usn_feature_vec\n",
    "\n",
    "\n",
    "def transform_word2vec(tokens, stopwords=[]):\n",
    "    global wvmodel\n",
    "    # This requires wvmodel to be present in the namespace.\n",
    "    wv_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords and w in wvmodel.wv.vocab)]\n",
    "    ).map(lambda x: np.array([wvmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return wv_feature_vec\n",
    "\n",
    "\n",
    "def parallel_generate_word_vectors(samp, transformer, stopwords, batch, num_proc):\n",
    "    with Parallel(n_jobs=num_proc) as parallel:\n",
    "        dataset = []\n",
    "        is_break = False\n",
    "        i = 0\n",
    "\n",
    "        while not is_break:\n",
    "            payload = []\n",
    "\n",
    "            for j in xrange(num_proc):\n",
    "                t_df = samp[(i + j) * batch: (i + 1 + j) * batch]\n",
    "\n",
    "                if t_df.empty:\n",
    "                    is_break = True\n",
    "                    continue\n",
    "\n",
    "                payload.append(\n",
    "                    delayed(transformer)(\n",
    "                        t_df, stopwords\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            print('Current batch in main thread: {}'.format((i + j) * batch))\n",
    "\n",
    "            if payload:\n",
    "                results = parallel(payload)\n",
    "                dataset.extend(results)\n",
    "                i += num_proc\n",
    "\n",
    "    return pd.concat(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_classes(pred, scale_param=0.75, min_thresh=0.05, thresh = 0.5):\n",
    "#     mx = pred.mean() + 3 * pred.std()\n",
    "    return np.where(pred > thresh)[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2idx_transform(word, _word2idx):\n",
    "    return _word2idx.get(word, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features_for(df, min_batch=2000, stopwords=[], num_proc=7):\n",
    "    df_tokens = transform_text(df)\n",
    "    \n",
    "    batch = min(df_tokens.shape[0] / num_proc, min_batch)\n",
    "\n",
    "    print('Computing fs features...')\n",
    "    fvec = parallel_generate_word_vectors(df_tokens, transform_fasttext, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Computing wv features...')\n",
    "    wvec = parallel_generate_word_vectors(df_tokens, transform_word2vec, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Mapping word indices...')\n",
    "    word_indices = df_tokens.map(lambda x: [word2idx_transform(i, _word2idx) for i in x.split()])\n",
    "\n",
    "    print('Computing tfidf fs features...')\n",
    "    tfidf_fvec = parallel_generate_word_vectors(df_tokens, transform_tfidf_fasttext, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Computing tfidf wv features...')\n",
    "    tfidf_wvec = parallel_generate_word_vectors(df_tokens, transform_tfidf_word2vec, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Computing tfidf lsi features...')\n",
    "    tfidf_lsi = parallel_generate_word_vectors(df_tokens, transform_tfidf_lsi, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "    \n",
    "    return word_indices, wvec, fvec, tfidf_wvec, tfidf_fvec, tfidf_lsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/TestData.json') as fl:\n",
    "    data = json.load(fl)\n",
    "    test_df = pd.DataFrame(data['TestData']).T\n",
    "    del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fs features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Computing wv features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Mapping word indices...\n",
      "Computing tfidf fs features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Computing tfidf wv features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Computing tfidf lsi features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "CPU times: user 46.6 s, sys: 3.52 s, total: 50.1 s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_word_indices,test_wvec, test_fvec, test_tfidf_wvec, test_tfidf_fvec, test_tfidf_lsi = extract_features_for(\n",
    "    test_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert(np.all(test_wvec[test_wvec.isnull()].index == test_fvec[test_fvec.isnull()].index))\n",
    "test_null_index = test_wvec[test_wvec.isnull()].index.union(test_fvec[test_fvec.isnull()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'TestData_02543', u'TestData_05012', u'TestData_05830'], dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_null_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 364 ms, sys: 12 ms, total: 376 ms\n",
      "Wall time: 373 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "valid_test_index = test_word_indices.index.difference(test_null_index)\n",
    "x_test = test_word_indices.ix[valid_test_index]  # .map(lambda x: [top_token2ind.get(i, 0) for i in x])\n",
    "\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "wv_test = np.vstack(test_wvec.ix[valid_test_index])\n",
    "fs_test = np.vstack(test_fvec.ix[valid_test_index])\n",
    "\n",
    "tfidf_wv_test = np.vstack(test_tfidf_wvec.ix[valid_test_index])\n",
    "tfidf_fs_test = np.vstack(test_tfidf_fvec.ix[valid_test_index])\n",
    "tfidf_lsi_test = np.vstack(test_tfidf_lsi.ix[valid_test_index])\n",
    "\n",
    "wv_test = wv_sc.transform(wv_test)\n",
    "fs_test = fs_sc.transform(fs_test)\n",
    "\n",
    "tfidf_wv_test = tfidf_wv_sc.transform(tfidf_wv_test)\n",
    "tfidf_fs_test = tfidf_fs_sc.transform(tfidf_fs_test)\n",
    "tfidf_lsi_test = tfidf_lsi_sc.transform(tfidf_lsi_test)\n",
    "\n",
    "test_inputs = build_training_inputs(\n",
    "    wv_test,\n",
    "    fs_test,\n",
    "    tfidf_wv_test,\n",
    "    tfidf_fs_test,\n",
    "    tfidf_lsi_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_probas = model.predict(test_inputs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_test_probas = test_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7.51515902e-22,   1.30638913e-12,   1.14752912e-12, ...,\n",
       "          3.04366983e-11,   1.93785443e-18,   1.01716770e-21],\n",
       "       [  7.03673035e-18,   1.43606826e-07,   2.70513354e-08, ...,\n",
       "          2.73566642e-10,   5.52554638e-13,   5.09166022e-18],\n",
       "       [  2.01525970e-12,   1.38701432e-06,   2.92521167e-06, ...,\n",
       "          3.76850062e-06,   3.97919375e-14,   1.37272648e-12],\n",
       "       ..., \n",
       "       [  2.64981509e-10,   4.99996881e-04,   3.52071583e-01, ...,\n",
       "          1.63022753e-12,   7.85089069e-05,   1.16256373e-10],\n",
       "       [  1.22002712e-12,   6.17719721e-03,   1.11735080e-05, ...,\n",
       "          3.63131996e-08,   1.53687111e-07,   1.63743541e-12],\n",
       "       [  9.95421939e-15,   1.17369927e-06,   3.88167857e-04, ...,\n",
       "          9.96607588e-11,   8.85952683e-12,   3.78818206e-15]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_test_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2542, 5011, 5829]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_index = [int(s.split('_')[1]) - 1 for s in test_null_index]  # Subtract 1 since test index starts at 1 while enumerate starts at 0\n",
    "skip_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7578, 160), (7581, 3))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_test_probas.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32 ms, sys: 4 ms, total: 36 ms\n",
      "Wall time: 32.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# valid_test_feature_vec found below!\n",
    "# thresh = 0.3\n",
    "test_values = np.zeros([main_test_probas.shape[0], len(topics)])\n",
    "for ix, pred in enumerate(main_test_probas):\n",
    "    for v in get_classes(pred, thresh=thresh):\n",
    "        test_values[ix][v] = 1\n",
    "\n",
    "test_sub_df = pd.DataFrame(\n",
    "    test_values,\n",
    "    index=test_df.ix[test_df.index.difference(test_null_index)].index,\n",
    "    columns=topics\n",
    ")\n",
    "\n",
    "null_test_df = pd.DataFrame(\n",
    "    np.zeros((len(test_null_index), len(topics))),\n",
    "    index=test_null_index,\n",
    "    columns=topics\n",
    ")\n",
    "\n",
    "test_sub_df = test_sub_df.append(null_test_df)\n",
    "test_sub_df = test_sub_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6552, 0.47999999999999976)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6552, thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 9627 (0.5), 14297 (0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12282.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12656.0"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.375, 10524.0)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh, test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13897.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12489.0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7581.000000\n",
       "mean      882.691070\n",
       "std       621.585386\n",
       "min         0.000000\n",
       "25%       552.000000\n",
       "50%       770.000000\n",
       "75%      1026.000000\n",
       "max      8171.000000\n",
       "Name: bodyText, dtype: float64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_word_indices.map(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1382.0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_word_indices.map(len).quantile(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1223"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df.ix['TestData_04490'].bodyText.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activism                                    0.0\n",
       "afghanistan                               112.0\n",
       "aid                                        80.0\n",
       "algerianhostagecrisis                      16.0\n",
       "alqaida                                   109.0\n",
       "alshabaab                                  39.0\n",
       "antiwar                                     0.0\n",
       "arabandmiddleeastprotests                 333.0\n",
       "armstrade                                  75.0\n",
       "australianguncontrol                        0.0\n",
       "australiansecurityandcounterterrorism      63.0\n",
       "bastilledaytruckattack                     26.0\n",
       "belgium                                    11.0\n",
       "berlinchristmasmarketattack                20.0\n",
       "bigdata                                     7.0\n",
       "biometrics                                  1.0\n",
       "bokoharam                                  37.0\n",
       "bostonmarathonbombing                      61.0\n",
       "britisharmy                                 0.0\n",
       "brusselsattacks                            50.0\n",
       "cameroon                                    1.0\n",
       "carers                                      1.0\n",
       "charliehebdoattack                         52.0\n",
       "chemicalweapons                            21.0\n",
       "clusterbombs                                4.0\n",
       "cobra                                       0.0\n",
       "conflictanddevelopment                     52.0\n",
       "controversy                                 8.0\n",
       "criminaljustice                            32.0\n",
       "cybercrime                                 82.0\n",
       "                                          ...  \n",
       "somalia                                    47.0\n",
       "southafrica                                47.0\n",
       "southchinasea                               5.0\n",
       "stopandsearch                               0.0\n",
       "surveillance                              130.0\n",
       "sydneysiege                                41.0\n",
       "syria                                    1368.0\n",
       "taliban                                    48.0\n",
       "terrorism                                 215.0\n",
       "thailand                                   30.0\n",
       "torture                                    11.0\n",
       "traincrashes                                4.0\n",
       "transport                                 100.0\n",
       "tunisiaattack2015                          59.0\n",
       "turkey                                    220.0\n",
       "turkeycoupattempt                          30.0\n",
       "ukcrime                                   295.0\n",
       "uksecurity                                439.0\n",
       "uksupremecourt                              6.0\n",
       "undercoverpoliceandpolicing                 4.0\n",
       "unitednations                             196.0\n",
       "usguncontrol                              271.0\n",
       "values                                      1.0\n",
       "warcrimes                                  16.0\n",
       "warreporting                               10.0\n",
       "weaponstechnology                           4.0\n",
       "womeninbusiness                             0.0\n",
       "woolwichattack                             41.0\n",
       "worldmigration                              2.0\n",
       "zikavirus                                   3.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activism                                    0.0\n",
       "afghanistan                                95.0\n",
       "aid                                        89.0\n",
       "algerianhostagecrisis                      24.0\n",
       "alqaida                                   136.0\n",
       "alshabaab                                  38.0\n",
       "antiwar                                     0.0\n",
       "arabandmiddleeastprotests                 162.0\n",
       "armstrade                                  96.0\n",
       "australianguncontrol                        0.0\n",
       "australiansecurityandcounterterrorism      39.0\n",
       "bastilledaytruckattack                     38.0\n",
       "belgium                                     7.0\n",
       "berlinchristmasmarketattack                16.0\n",
       "bigdata                                     6.0\n",
       "biometrics                                  1.0\n",
       "bokoharam                                  37.0\n",
       "bostonmarathonbombing                      51.0\n",
       "britisharmy                                 4.0\n",
       "brusselsattacks                            71.0\n",
       "cameroon                                    0.0\n",
       "carers                                      0.0\n",
       "charliehebdoattack                         47.0\n",
       "chemicalweapons                            27.0\n",
       "clusterbombs                                1.0\n",
       "cobra                                       6.0\n",
       "conflictanddevelopment                     86.0\n",
       "controversy                                 1.0\n",
       "criminaljustice                            39.0\n",
       "cybercrime                                 66.0\n",
       "                                          ...  \n",
       "somalia                                    40.0\n",
       "southafrica                                30.0\n",
       "southchinasea                               7.0\n",
       "stopandsearch                               1.0\n",
       "surveillance                               86.0\n",
       "sydneysiege                                14.0\n",
       "syria                                    1055.0\n",
       "taliban                                    41.0\n",
       "terrorism                                 138.0\n",
       "thailand                                   34.0\n",
       "torture                                    15.0\n",
       "traincrashes                                5.0\n",
       "transport                                  86.0\n",
       "tunisiaattack2015                          43.0\n",
       "turkey                                    257.0\n",
       "turkeycoupattempt                          41.0\n",
       "ukcrime                                   188.0\n",
       "uksecurity                                366.0\n",
       "uksupremecourt                              5.0\n",
       "undercoverpoliceandpolicing                 2.0\n",
       "unitednations                             258.0\n",
       "usguncontrol                              176.0\n",
       "values                                      0.0\n",
       "warcrimes                                  10.0\n",
       "warreporting                                2.0\n",
       "weaponstechnology                          11.0\n",
       "womeninbusiness                             1.0\n",
       "woolwichattack                              8.0\n",
       "worldmigration                             13.0\n",
       "zikavirus                                   3.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activism                                    0.0\n",
       "afghanistan                                96.0\n",
       "aid                                        70.0\n",
       "algerianhostagecrisis                      31.0\n",
       "alqaida                                   151.0\n",
       "alshabaab                                  35.0\n",
       "antiwar                                     2.0\n",
       "arabandmiddleeastprotests                 239.0\n",
       "armstrade                                  78.0\n",
       "australianguncontrol                        0.0\n",
       "australiansecurityandcounterterrorism      79.0\n",
       "bastilledaytruckattack                      0.0\n",
       "belgium                                    87.0\n",
       "berlinchristmasmarketattack                 0.0\n",
       "bigdata                                     8.0\n",
       "biometrics                                  2.0\n",
       "bokoharam                                  38.0\n",
       "bostonmarathonbombing                     104.0\n",
       "britisharmy                                 4.0\n",
       "brusselsattacks                             0.0\n",
       "cameroon                                    1.0\n",
       "carers                                      3.0\n",
       "charliehebdoattack                          0.0\n",
       "chemicalweapons                            38.0\n",
       "clusterbombs                                3.0\n",
       "cobra                                       0.0\n",
       "conflictanddevelopment                     55.0\n",
       "controversy                                 4.0\n",
       "criminaljustice                            39.0\n",
       "cybercrime                                 55.0\n",
       "                                          ...  \n",
       "somalia                                    40.0\n",
       "southafrica                                36.0\n",
       "southchinasea                               6.0\n",
       "stopandsearch                               2.0\n",
       "surveillance                              129.0\n",
       "sydneysiege                                38.0\n",
       "syria                                    1399.0\n",
       "taliban                                    54.0\n",
       "terrorism                                 180.0\n",
       "thailand                                   32.0\n",
       "torture                                    12.0\n",
       "traincrashes                                3.0\n",
       "transport                                  85.0\n",
       "tunisiaattack2015                           0.0\n",
       "turkey                                    255.0\n",
       "turkeycoupattempt                           0.0\n",
       "ukcrime                                   266.0\n",
       "uksecurity                                415.0\n",
       "uksupremecourt                              9.0\n",
       "undercoverpoliceandpolicing                 3.0\n",
       "unitednations                             214.0\n",
       "usguncontrol                              263.0\n",
       "values                                      0.0\n",
       "warcrimes                                  24.0\n",
       "warreporting                               17.0\n",
       "weaponstechnology                           6.0\n",
       "womeninbusiness                             0.0\n",
       "woolwichattack                             35.0\n",
       "worldmigration                             13.0\n",
       "zikavirus                                   0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95811/95811 [==============================] - 2s - loss: 1.7367 - acc: 0.7069 - f1_micro: 0.5886 - val_loss: 1.4146 - val_acc: 0.7645 - val_f1_micro: 0.5889\n"
     ]
    }
   ],
   "source": [
    "print '95811/95811 [==============================] - 2s - loss: 1.7367 - acc: 0.7069 - f1_micro: 0.5886 - val_loss: 1.4146 - val_acc: 0.7645 - val_f1_micro: 0.5889'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_filename = 'tfidf_wv_300-fs_300-lsi_300-deep_stack_net-low_dropout-rmsprop-epochs_110-tanh_init_activation-f1_0.7528-data_2012_2014_test_augmented_10_upsample-val_data_2014-thresh_{}-with_sc_wv_fs_lsi.csv'.format(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_sub_df.astype(int).reset_index().rename(\n",
    "    columns={'index': 'id'}\n",
    ").sort_values('id').to_csv(\n",
    "    sub_filename, \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7581, 160)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TestData_04490\tThe World Health Organisation has convened an ...\t[]\t28-01-2016\n",
    "TestData_04550\tSpraying pesticides will fail to deal with the...\t[]\t02-02-2016\n",
    "TestData_05683\tViolent protests at Trump rally in California ...\t[]\t03-06-2016\n",
    "TestData_05869\tLast weekend, we saw the darkest side of human...\t[]\t17-06-2016\n",
    "TestData_06148\tAs dusk falls over Copacabana beach, Ubira San...\t[]\t16-07-2016\n",
    "TestData_06291\tIt is 3pm and yet another patient is brought t...\t[]\t27-07-2016\n",
    "TestData_06610\tHuddled around their hives, beekeepers around ...\t[]\t04-09-2016\n",
    "TestData_06708\tA United Nations high-level panel on access to...\t[]\t14-09-2016\n",
    "TestData_07263\tWHO: Zika virus is no longer a world threat Th...\t[]\t19-11-2016\n",
    "TestData_07478\t1 World Health Organisation declares a public ...\t[]\t18-12-2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "guncrime        1.0\n",
       "usguncontrol    1.0\n",
       "Name: TestData_05869, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = 5868\n",
    "test_sub_df.iloc[ix][test_sub_df.iloc[ix] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36 ms, sys: 0 ns, total: 36 ms\n",
      "Wall time: 32.6 ms\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# adjust_index = 0\n",
    "# # valid_test_feature_vec found below!\n",
    "# test_values = np.zeros([test_df.shape[0], len(topics)])\n",
    "# for ix, pred in enumerate(main_test_probas):\n",
    "#     if ix in skip_index:\n",
    "#         test_values[ix] = np.nan\n",
    "#         # Increment adjust index so that we have the correct index for other samples\n",
    "#         adjust_index += 1\n",
    "#         continue\n",
    "\n",
    "#     for v in get_classes(pred, thresh=0.05):\n",
    "#         test_values[ix + adjust_index][v] = 1\n",
    "\n",
    "# test_sub_df = pd.DataFrame(test_values, columns=sorted(topics), index=test_df.index)\n",
    "\n",
    "# q = test_sub_df.sum(axis=1)\n",
    "# assert(len(q[q.isnull()].index.difference(test_null_index)) == 0)\n",
    "\n",
    "# test_sub_df = test_sub_df.fillna(0)\n",
    "\n",
    "# # for i in test_feature_vec[test_feature_vec.isnull()].index:\n",
    "# #     test_sub_df.ix[i] = np.zeros(len(topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestData_02543    0.0\n",
       "TestData_05012    0.0\n",
       "TestData_05830    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.ix[test_null_index].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11656.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sub_df.astype(int).reset_index().rename(\n",
    "    columns={'index': 'id'}\n",
    ").sort_values('id').to_csv(\n",
    "    'lstm_300-word2vec_300-fasttext_300-maxlen_500-dense_64_64_64-cat_cross-epoch_210-batch_size_750-val_main_output_f1_micro_0.5760-main_output_f1_micro_0.5751-main_output_loss_0.9143-data_2010_2013-val_data_2014-thresh_0.05.csv', \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: zikavirus, dtype: float64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = test_sub_df['zikavirus']\n",
    "e[e==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14328"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_submission = pd.read_csv('basic_nn_submission_0.649_accuracy_multi_class.csv')\n",
    "top_submission.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9280"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_index_lstm_sub = pd.read_csv('lstm.2014b_training_700_maxlen_64cell_100epochs_0.0025_threshold.csv')\n",
    "wrong_index_lstm_sub.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34952"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_sub = pd.read_csv('basic_nn_submission_full_training_data_0.9958_validation_accuracy_binary_crossentropy.csv')\n",
    "some_sub.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2197, 160)\n",
      "(3957, 160)\n",
      "(12, 160)\n",
      "(1503, 160)\n"
     ]
    }
   ],
   "source": [
    "print top_submission.set_index('id')[top_submission.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print wrong_index_lstm_sub.set_index('id')[wrong_index_lstm_sub.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print some_sub.set_index('id')[some_sub.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print test_sub_df[test_sub_df.sum(axis=1) == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestData_00011     0\n",
       "TestData_00012     0\n",
       "TestData_00015     0\n",
       "TestData_00027     3\n",
       "TestData_00029     0\n",
       "TestData_00038     1\n",
       "TestData_00042     5\n",
       "TestData_00053     4\n",
       "TestData_00056     1\n",
       "TestData_00060     1\n",
       "TestData_00066     0\n",
       "TestData_00085     0\n",
       "TestData_00087     1\n",
       "TestData_00090     0\n",
       "TestData_00092     0\n",
       "TestData_00107     3\n",
       "TestData_00111     0\n",
       "TestData_00114     0\n",
       "TestData_00115     1\n",
       "TestData_00118     0\n",
       "TestData_00119     0\n",
       "TestData_00121     0\n",
       "TestData_00123     0\n",
       "TestData_00125     0\n",
       "TestData_00127     0\n",
       "TestData_00128     1\n",
       "TestData_00139     1\n",
       "TestData_00140     1\n",
       "TestData_00144     0\n",
       "TestData_00147     2\n",
       "                  ..\n",
       "TestData_07445     0\n",
       "TestData_07456     3\n",
       "TestData_07461     1\n",
       "TestData_07462     4\n",
       "TestData_07465     0\n",
       "TestData_07468     0\n",
       "TestData_07471     1\n",
       "TestData_07475     0\n",
       "TestData_07486    10\n",
       "TestData_07495     1\n",
       "TestData_07509     0\n",
       "TestData_07514     3\n",
       "TestData_07515     1\n",
       "TestData_07523     0\n",
       "TestData_07533     2\n",
       "TestData_07534     2\n",
       "TestData_07542     1\n",
       "TestData_07544     2\n",
       "TestData_07545     0\n",
       "TestData_07552     2\n",
       "TestData_07556     5\n",
       "TestData_07563     1\n",
       "TestData_07565     0\n",
       "TestData_07566     0\n",
       "TestData_07569     0\n",
       "TestData_07571     3\n",
       "TestData_07572     1\n",
       "TestData_07579     6\n",
       "TestData_07580     2\n",
       "TestData_07581     3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_submission.set_index('id').ix[q[q == 0].index].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1222,)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.sum(axis=1)\n",
    "q[q==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7581.000000\n",
       "mean        2.160929\n",
       "std         1.739411\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         2.000000\n",
       "75%         3.000000\n",
       "max        13.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = trainingY.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    236286.000000\n",
       "mean          1.392787\n",
       "std           0.762577\n",
       "min           1.000000\n",
       "25%           1.000000\n",
       "50%           1.000000\n",
       "75%           2.000000\n",
       "max          15.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bodyText</th>\n",
       "      <th>topics</th>\n",
       "      <th>webPublicationDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TestData_03241</th>\n",
       "      <td>A special British police unit was put on stand...</td>\n",
       "      <td>[]</td>\n",
       "      <td>15-11-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_04088</th>\n",
       "      <td>The youngest convict in a fatal gang-rape in N...</td>\n",
       "      <td>[]</td>\n",
       "      <td>20-12-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_06306</th>\n",
       "      <td>Former New York City mayor Rudy Giuliani has s...</td>\n",
       "      <td>[]</td>\n",
       "      <td>28-07-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_06083</th>\n",
       "      <td>John Cantlie, the British journalist who has b...</td>\n",
       "      <td>[]</td>\n",
       "      <td>13-07-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_05896</th>\n",
       "      <td>Lawyers for the companies that manufactured an...</td>\n",
       "      <td>[]</td>\n",
       "      <td>20-06-2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         bodyText topics  \\\n",
       "TestData_03241  A special British police unit was put on stand...     []   \n",
       "TestData_04088  The youngest convict in a fatal gang-rape in N...     []   \n",
       "TestData_06306  Former New York City mayor Rudy Giuliani has s...     []   \n",
       "TestData_06083  John Cantlie, the British journalist who has b...     []   \n",
       "TestData_05896  Lawyers for the companies that manufactured an...     []   \n",
       "\n",
       "               webPublicationDate  \n",
       "TestData_03241         15-11-2015  \n",
       "TestData_04088         20-12-2015  \n",
       "TestData_06306         28-07-2016  \n",
       "TestData_06083         13-07-2016  \n",
       "TestData_05896         20-06-2016  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ix = 'TestData_03241'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "london                1.0\n",
       "metropolitanpolice    1.0\n",
       "police                1.0\n",
       "uksecurity            1.0\n",
       "Name: TestData_03241, dtype: float64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ukcrime    1\n",
       "Name: TestData_04088, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = top_submission.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "humanrights    1\n",
       "india          1\n",
       "protest        1\n",
       "ukcrime        1\n",
       "Name: TestData_04088, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = some_sub.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "humanrights    1\n",
       "Name: TestData_02924, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = wrong_index_lstm_sub.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Counter-terrorism policy\n",
    " \n",
    "Foreign policy\n",
    " \n",
    "Defence policy\n",
    " \n",
    "Islamic State\n",
    " \n",
    "Syria\n",
    " \n",
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = trainingY.sum()\n",
    "unseen_topics = s[s.isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activism',\n",
       " 'bastilledaytruckattack',\n",
       " 'berlinchristmasmarketattack',\n",
       " 'brusselsattacks',\n",
       " 'charliehebdoattack',\n",
       " 'francetrainattack',\n",
       " 'munichshooting',\n",
       " 'orlandoterrorattack',\n",
       " 'parisattacks',\n",
       " 'peaceandreconciliation',\n",
       " 'sanbernardinoshooting',\n",
       " 'tunisiaattack2015',\n",
       " 'turkeycoupattempt',\n",
       " 'zikavirus'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(topics).intersection(unseen_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activism\n",
      "afghanistan\n",
      "aid\n",
      "algerianhostagecrisis\n",
      "alqaida\n",
      "alshabaab\n",
      "antiwar\n",
      "arabandmiddleeastprotests\n",
      "armstrade\n",
      "australianguncontrol\n",
      "australiansecurityandcounterterrorism\n",
      "bastilledaytruckattack\n",
      "belgium\n",
      "berlinchristmasmarketattack\n",
      "bigdata\n",
      "biometrics\n",
      "bokoharam\n",
      "bostonmarathonbombing\n",
      "britisharmy\n",
      "brusselsattacks\n",
      "cameroon\n",
      "carers\n",
      "charliehebdoattack\n",
      "chemicalweapons\n",
      "clusterbombs\n",
      "cobra\n",
      "conflictanddevelopment\n",
      "controversy\n",
      "criminaljustice\n",
      "cybercrime\n",
      "cyberwar\n",
      "darknet\n",
      "dataprotection\n",
      "debate\n",
      "defence\n",
      "deflation\n",
      "drones\n",
      "drugs\n",
      "drugspolicy\n",
      "drugstrade\n",
      "earthquakes\n",
      "ebola\n",
      "economy\n",
      "egypt\n",
      "encryption\n",
      "energy\n",
      "espionage\n",
      "ethics\n",
      "europeanarrestwarrant\n",
      "europeancourtofhumanrights\n",
      "events\n",
      "extradition\n",
      "famine\n",
      "farright\n",
      "firefighters\n",
      "forensicscience\n",
      "france\n",
      "francetrainattack\n",
      "freedomofspeech\n",
      "genevaconventions\n",
      "germany\n",
      "guncrime\n",
      "hacking\n",
      "hashtags\n",
      "helicoptercrashes\n",
      "humanitarianresponse\n",
      "humanrights\n",
      "humanrightsact\n",
      "humantrafficking\n",
      "immigration\n",
      "india\n",
      "indonesia\n",
      "internallydisplacedpeople\n",
      "internationalcourtofjustice\n",
      "internationalcriminaljustice\n",
      "internetsafety\n",
      "iraq\n",
      "isis\n",
      "israel\n",
      "jordan\n",
      "jubilee\n",
      "judiciary\n",
      "july7\n",
      "justiceandsecurity\n",
      "kenya\n",
      "knifecrime\n",
      "lebanon\n",
      "libya\n",
      "localgovernment\n",
      "logistics\n",
      "london\n",
      "londonriots\n",
      "malaysia\n",
      "mali\n",
      "malware\n",
      "metropolitanpolice\n",
      "middleeastpeacetalks\n",
      "migration\n",
      "military\n",
      "ministryofdefence\n",
      "morocco\n",
      "mrsa\n",
      "mumbaiterrorattacks\n",
      "munichshooting\n",
      "naturaldisasters\n",
      "nigeria\n",
      "nuclearweapons\n",
      "occupy\n",
      "organisedcrime\n",
      "orlandoterrorattack\n",
      "osamabinladen\n",
      "paris\n",
      "parisattacks\n",
      "peaceandreconciliation\n",
      "philippines\n",
      "piracy\n",
      "planecrashes\n",
      "police\n",
      "protest\n",
      "refugees\n",
      "religion\n",
      "retirementage\n",
      "rio20earthsummit\n",
      "royalairforce\n",
      "royalnavy\n",
      "russia\n",
      "sanbernardinoshooting\n",
      "saudiarabia\n",
      "september11\n",
      "slavery\n",
      "somalia\n",
      "southafrica\n",
      "southchinasea\n",
      "stopandsearch\n",
      "surveillance\n",
      "sydneysiege\n",
      "syria\n",
      "taliban\n",
      "terrorism\n",
      "thailand\n",
      "torture\n",
      "traincrashes\n",
      "transport\n",
      "tunisiaattack2015\n",
      "turkey\n",
      "turkeycoupattempt\n",
      "ukcrime\n",
      "uksecurity\n",
      "uksupremecourt\n",
      "undercoverpoliceandpolicing\n",
      "unitednations\n",
      "usguncontrol\n",
      "values\n",
      "warcrimes\n",
      "warreporting\n",
      "weaponstechnology\n",
      "womeninbusiness\n",
      "woolwichattack\n",
      "worldmigration\n",
      "zikavirus\n"
     ]
    }
   ],
   "source": [
    "for i in topics:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsolatorio/ml-ai/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3445929"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(wvmodel['zika'], np.vstack(test_wvec.dropna())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsolatorio/ml-ai/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.38107796869050226"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(fsmodel['zika'], np.vstack(test_fvec.dropna())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              The World Health Organisation has convened an ...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           28-01-2016\n",
       "Name: TestData_04490, dtype: object"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[4488 + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              The United Nations security council has called...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           17-09-2016\n",
       "Name: TestData_06730, dtype: object"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[6727 + 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              We are deeply concerned that the counter-terro...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           02-02-2015\n",
       "Name: TestData_00360, dtype: object"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[359]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drugstrade    1.0\n",
       "Name: TestData_04490, dtype: float64"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.iloc[4488 + 1]\n",
    "q[q > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
