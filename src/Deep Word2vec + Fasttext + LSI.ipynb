{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from growing_instability_lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub = pd.read_csv('../data/sampleSubmission.csv')\n",
    "topics = sorted(set(sample_sub.columns.difference(['id'])))\n",
    "\n",
    "topic2actual = {}\n",
    "for i in sample_sub.columns:\n",
    "    if 'id' == i:\n",
    "        continue\n",
    "    topic2actual[i] = segment(i)\n",
    "    \n",
    "target_columns = sorted(topics)\n",
    "len(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.97 s, sys: 2.36 s, total: 12.3 s\n",
      "Wall time: 12.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wvec_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'wvec_trainingX')\n",
    "fvec_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'fvec_trainingX')\n",
    "\n",
    "tfidf_wvec_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'tfidf_wvec_trainingX')\n",
    "tfidf_fvec_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'tfidf_fvec_trainingX')\n",
    "tfidf_lsi_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'tfidf_lsi_trainingX')\n",
    "\n",
    "word2idx_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'word2idx_trainingX')\n",
    "_word2idx = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', '_word2idx')\n",
    "trainingY = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'trainingY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.1 s, sys: 84 ms, total: 12.2 s\n",
      "Wall time: 12.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ind2word = {j:i for i, j in _word2idx.iteritems()}\n",
    "ind2class = dict(enumerate(topics))\n",
    "class2ind = {j: i for i, j in ind2class.items()}\n",
    "\n",
    "num_samples = trainingY.shape[0]\n",
    "\n",
    "# ---------------------------------\n",
    "training_X = word2idx_trainingX.head(num_samples)\n",
    "training_Y = pd.DataFrame(zip(*np.where(trainingY.head(num_samples) == 1)), columns=['iloc', 'topics'])\n",
    "\n",
    "training_WV = wvec_trainingX.head(num_samples)\n",
    "training_FS = fvec_trainingX.head(num_samples)\n",
    "\n",
    "training_tfidf_WV = tfidf_wvec_trainingX.head(num_samples)\n",
    "training_tfidf_FS = tfidf_fvec_trainingX.head(num_samples)\n",
    "training_tfidf_LSI = tfidf_lsi_trainingX.head(num_samples)\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "training_Y = training_Y.groupby('iloc')['topics'].apply(list)\n",
    "training_Y.index = trainingY.head(num_samples).index\n",
    "\n",
    "indices = sorted(training_Y.index[training_Y.index.str.contains('^201[0-9]')])\n",
    "# np.random.shuffle(indices)\n",
    "indices = pd.Index(indices)\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "training_X = training_X.ix[indices]\n",
    "training_Y = training_Y.ix[indices]\n",
    "\n",
    "training_WV = training_WV.ix[indices]\n",
    "training_FS = training_FS.ix[indices]\n",
    "\n",
    "training_tfidf_WV = training_tfidf_WV.ix[indices]\n",
    "training_tfidf_FS = training_tfidf_FS.ix[indices]\n",
    "training_tfidf_LSI = training_tfidf_LSI.ix[indices]\n",
    "# ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 7.15 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wv_sc = StandardScaler()\n",
    "fs_sc = StandardScaler()\n",
    "\n",
    "tfidf_wv_sc = StandardScaler()\n",
    "tfidf_fs_sc = StandardScaler()\n",
    "tfidf_lsi_sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.72 s, sys: 268 ms, total: 3.99 s\n",
      "Wall time: 3.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "maxlen = 500\n",
    "\n",
    "\n",
    "def build_target(y, size):\n",
    "    e = np.zeros(size)\n",
    "    e[y] = 1\n",
    "    return e\n",
    "\n",
    "\n",
    "def build_input_output_data(X, WV, FS, TWV, TFS, TLSI, Y, maxlen):\n",
    "    x = sequence.pad_sequences(X, maxlen=maxlen)\n",
    "    y = np.vstack(Y.map(lambda x: build_target(x, len(topics))))\n",
    "\n",
    "    wv = np.vstack(WV)\n",
    "    fs = np.vstack(FS)\n",
    "\n",
    "    twv = np.vstack(TWV)\n",
    "    tfs = np.vstack(TFS)\n",
    "    tlsi = np.vstack(TLSI)\n",
    "\n",
    "    return x, wv, fs, twv, tfs, tlsi, y\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "train_ix = training_Y.index.str.contains('^201[0-4]')\n",
    "val_ix = training_Y.index.str.contains('^2014[b]')\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "x_train, wv_train, fs_train, tfidf_wv_train, tfidf_fs_train, tfidf_lsi_train, y_train = build_input_output_data(\n",
    "    training_X.ix[train_ix],\n",
    "\n",
    "    training_WV.ix[train_ix],\n",
    "    training_FS.ix[train_ix],\n",
    "\n",
    "    training_tfidf_WV.ix[train_ix],\n",
    "    training_tfidf_FS.ix[train_ix],\n",
    "    training_tfidf_LSI.ix[train_ix],\n",
    "\n",
    "    training_Y.ix[train_ix],\n",
    "    maxlen=maxlen\n",
    ")\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "x_val, wv_val, fs_val, tfidf_wv_val, tfidf_fs_val, tfidf_lsi_val, y_val = build_input_output_data(\n",
    "    training_X.ix[val_ix],\n",
    "\n",
    "    training_WV.ix[val_ix],\n",
    "    training_FS.ix[val_ix],\n",
    "\n",
    "    training_tfidf_WV.ix[val_ix],\n",
    "    training_tfidf_FS.ix[val_ix],\n",
    "    training_tfidf_LSI.ix[val_ix],\n",
    "\n",
    "    training_Y.ix[val_ix],\n",
    "    maxlen=maxlen\n",
    ")\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "wv_train = wv_sc.fit_transform(wv_train)\n",
    "fs_train = fs_sc.fit_transform(fs_train)\n",
    "\n",
    "tfidf_wv_train = tfidf_wv_sc.fit_transform(tfidf_wv_train)\n",
    "tfidf_fs_train = tfidf_fs_sc.fit_transform(tfidf_fs_train)\n",
    "tfidf_lsi_train = tfidf_lsi_sc.fit_transform(tfidf_lsi_train)\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "wv_val = wv_sc.transform(wv_val)\n",
    "fs_val = fs_sc.transform(fs_val)\n",
    "\n",
    "tfidf_wv_val = tfidf_wv_sc.transform(tfidf_wv_val)\n",
    "tfidf_fs_val = tfidf_fs_sc.transform(tfidf_fs_val)\n",
    "tfidf_lsi_val = tfidf_lsi_sc.transform(tfidf_lsi_val)\n",
    "# ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((94731,), (9424,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_Y.shape, training_Y.ix[training_Y.index.str.contains('^2014[b]')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: bodyText, dtype: int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = training_tfidf_LSI.ix[train_ix].map(len)\n",
    "v[v != 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as K\n",
    "import keras.backend as KB\n",
    "\n",
    "\n",
    "def f1_micro(y_true, y_pred):\n",
    "    TP = K.metrics.true_positives(y_true, K.round(y_pred))\n",
    "    FP = K.metrics.false_positives(y_true, K.round(y_pred))\n",
    "    FN = K.metrics.false_negatives(y_true, K.round(y_pred))\n",
    "    \n",
    "    p = K.reduce_sum(TP) / (K.reduce_sum(TP) + K.reduce_sum(FP))\n",
    "    r = K.reduce_sum(TP) / (K.reduce_sum(TP) + K.reduce_sum(FN))\n",
    "    \n",
    "    return (2.0 * p * r) / (p + r)\n",
    "\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "\n",
    "    # Count positive samples.\n",
    "    c1 = KB.sum(KB.round(KB.clip(y_true * y_pred, 0, 1)))\n",
    "    c2 = KB.sum(KB.round(KB.clip(y_pred, 0, 1)))\n",
    "    c3 = KB.sum(KB.round(KB.clip(y_true, 0, 1)))\n",
    "\n",
    "    # If there are no true samples, fix the F1 score at 0.\n",
    "    if c3 == 0:\n",
    "        return 0\n",
    "\n",
    "    # How many selected items are relevant?\n",
    "    precision = c1 / c2\n",
    "\n",
    "    # How many relevant items are selected?\n",
    "    recall = c1 / c3\n",
    "\n",
    "    # Calculate f1_score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense, Dropout, Convolution1D, MaxPooling1D, Flatten\n",
    "from keras.models import Model\n",
    "import itertools as it\n",
    "\n",
    "\n",
    "def build_deep_input_stack(input_node):\n",
    "    x = Dense(128, activation='relu')(input_node)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def entangle_inputs(input_nodes=[]):\n",
    "    assert(len(input_nodes) > 1)\n",
    "    \n",
    "    entangled_inputs = []\n",
    "\n",
    "    for n1, n2 in it.combinations(input_nodes, 2):\n",
    "        entangled_inputs.append(\n",
    "            keras.layers.dot([n1, n2], 1)\n",
    "        )\n",
    "    \n",
    "    return entangled_inputs\n",
    "\n",
    "\n",
    "wv_input = Input(shape=(300,), name='wv_input')\n",
    "fs_input = Input(shape=(300,), name='fs_input')\n",
    "\n",
    "tfidf_wv_input = Input(shape=(300,), name='tfidf_wv_input')\n",
    "tfidf_fs_input = Input(shape=(300,), name='tfidf_fs_input')\n",
    "tfidf_lsi_input = Input(shape=(300,), name='tfidf_lsi_input')\n",
    "\n",
    "\n",
    "wv_x = build_deep_input_stack(wv_input)\n",
    "fs_x = build_deep_input_stack(fs_input)\n",
    "tfidf_wv_x = build_deep_input_stack(tfidf_wv_input)\n",
    "tfidf_fs_x = build_deep_input_stack(tfidf_fs_input)\n",
    "tfidf_lsi_x = build_deep_input_stack(tfidf_wv_input)\n",
    "\n",
    "stacked_inputs_x = [wv_x, fs_x, tfidf_wv_x, tfidf_fs_x, tfidf_lsi_x]\n",
    "# entangled_inputs_x = entangle_inputs(stacked_inputs_x)\n",
    "\n",
    "x = keras.layers.concatenate(stacked_inputs_x)  # + entangled_inputs_x)\n",
    "\n",
    "# We stack a deep densely-connected network on top\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "# And finally we add the main logistic regression layer\n",
    "main_output = Dense(len(class2ind), activation='sigmoid', name='main_output')(x)\n",
    "\n",
    "model = Model(\n",
    "    inputs=[\n",
    "        wv_input,\n",
    "        fs_input,\n",
    "        tfidf_wv_input,\n",
    "        tfidf_fs_input,\n",
    "        tfidf_lsi_input,\n",
    "    ],\n",
    "    outputs=[main_output]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "wv_input (InputLayer)            (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "fs_input (InputLayer)            (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "tfidf_wv_input (InputLayer)      (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "tfidf_fs_input (InputLayer)      (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_53 (Dense)                 (None, 128)           38528                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_55 (Dense)                 (None, 128)           38528                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_57 (Dense)                 (None, 128)           38528                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_59 (Dense)                 (None, 128)           38528                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_61 (Dense)                 (None, 128)           38528                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)             (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)             (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)             (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)             (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)             (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_54 (Dense)                 (None, 512)           66048                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_56 (Dense)                 (None, 512)           66048                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_58 (Dense)                 (None, 512)           66048                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_60 (Dense)                 (None, 512)           66048                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_62 (Dense)                 (None, 512)           66048                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)             (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)             (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)             (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_60 (Dropout)             (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)             (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)      (None, 2560)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_63 (Dense)                 (None, 128)           327808                                       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)             (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_64 (Dense)                 (None, 256)           33024                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)             (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_65 (Dense)                 (None, 128)           32896                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)             (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 160)           20640                                        \n",
      "====================================================================================================\n",
      "Total params: 937,248\n",
      "Trainable params: 937,248\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={'main_output': 'categorical_crossentropy'},\n",
    "    loss_weights={'main_output': 1.},\n",
    "    metrics=['accuracy', f1_micro]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.callbacks import EarlyStopping\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "# model.fit(X, y, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_training_inputs(wv, fs, tfidf_wv, tfidf_fs, tfidf_lsi):\n",
    "    training_inputs = {\n",
    "        'wv_input': wv,\n",
    "        'fs_input': fs,\n",
    "        'tfidf_wv_input': tfidf_wv,\n",
    "        'tfidf_fs_input': tfidf_fs,\n",
    "        'tfidf_lsi_input': tfidf_lsi,\n",
    "    }\n",
    "    \n",
    "    return training_inputs\n",
    "    \n",
    "\n",
    "training_inputs = build_training_inputs(\n",
    "    wv_train,\n",
    "    fs_train,\n",
    "    tfidf_wv_train,\n",
    "    tfidf_fs_train,\n",
    "    tfidf_lsi_train,\n",
    ")\n",
    "\n",
    "training_outputs = {\n",
    "    'main_output': y_train,\n",
    "}\n",
    "\n",
    "validation_data=(\n",
    "    build_training_inputs(\n",
    "        wv_val,\n",
    "        fs_val,\n",
    "        tfidf_wv_val,\n",
    "        tfidf_fs_val,\n",
    "        tfidf_lsi_val,\n",
    "    ),\n",
    "    {\n",
    "        'main_output': y_val,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/50\n",
      "94731/94731 [==============================] - 2s - loss: 1.9306 - acc: 0.6728 - f1_micro: 0.6354 - val_loss: 1.5606 - val_acc: 0.7409 - val_f1_micro: 0.6356\n",
      "Epoch 2/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.9350 - acc: 0.6721 - f1_micro: 0.6359 - val_loss: 1.5592 - val_acc: 0.7415 - val_f1_micro: 0.6361\n",
      "Epoch 3/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.9248 - acc: 0.6722 - f1_micro: 0.6363 - val_loss: 1.5557 - val_acc: 0.7367 - val_f1_micro: 0.6365\n",
      "Epoch 4/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.9217 - acc: 0.6717 - f1_micro: 0.6367 - val_loss: 1.5616 - val_acc: 0.7436 - val_f1_micro: 0.6369\n",
      "Epoch 5/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.9235 - acc: 0.6729 - f1_micro: 0.6372 - val_loss: 1.5555 - val_acc: 0.7411 - val_f1_micro: 0.6374\n",
      "Epoch 6/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.9239 - acc: 0.6724 - f1_micro: 0.6376 - val_loss: 1.5537 - val_acc: 0.7276 - val_f1_micro: 0.6378\n",
      "Epoch 7/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.9231 - acc: 0.6715 - f1_micro: 0.6380 - val_loss: 1.5450 - val_acc: 0.7382 - val_f1_micro: 0.6382\n",
      "Epoch 8/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.9241 - acc: 0.6724 - f1_micro: 0.6384 - val_loss: 1.5554 - val_acc: 0.7285 - val_f1_micro: 0.6387\n",
      "Epoch 9/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.9197 - acc: 0.6726 - f1_micro: 0.6389 - val_loss: 1.5484 - val_acc: 0.7377 - val_f1_micro: 0.6391\n",
      "Epoch 10/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.9244 - acc: 0.6745 - f1_micro: 0.6392 - val_loss: 1.5502 - val_acc: 0.7456 - val_f1_micro: 0.6394\n",
      "Epoch 11/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.9227 - acc: 0.6717 - f1_micro: 0.6396 - val_loss: 1.5476 - val_acc: 0.7361 - val_f1_micro: 0.6398\n",
      "Epoch 12/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.9171 - acc: 0.6716 - f1_micro: 0.6401 - val_loss: 1.5397 - val_acc: 0.7386 - val_f1_micro: 0.6403\n",
      "Epoch 13/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.9140 - acc: 0.6748 - f1_micro: 0.6405 - val_loss: 1.5409 - val_acc: 0.7346 - val_f1_micro: 0.6407\n",
      "Epoch 14/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.9148 - acc: 0.6741 - f1_micro: 0.6409 - val_loss: 1.5441 - val_acc: 0.7421 - val_f1_micro: 0.6411\n",
      "Epoch 15/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.9115 - acc: 0.6739 - f1_micro: 0.6413 - val_loss: 1.5389 - val_acc: 0.7404 - val_f1_micro: 0.6415\n",
      "Epoch 16/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.9159 - acc: 0.6738 - f1_micro: 0.6417 - val_loss: 1.5432 - val_acc: 0.7378 - val_f1_micro: 0.6419\n",
      "Epoch 17/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.9098 - acc: 0.6747 - f1_micro: 0.6421 - val_loss: 1.5326 - val_acc: 0.7423 - val_f1_micro: 0.6423\n",
      "Epoch 18/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.9073 - acc: 0.6738 - f1_micro: 0.6425 - val_loss: 1.5318 - val_acc: 0.7384 - val_f1_micro: 0.6427\n",
      "Epoch 19/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.9133 - acc: 0.6748 - f1_micro: 0.6429 - val_loss: 1.5315 - val_acc: 0.7464 - val_f1_micro: 0.6431\n",
      "Epoch 20/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.9097 - acc: 0.6747 - f1_micro: 0.6433 - val_loss: 1.5360 - val_acc: 0.7397 - val_f1_micro: 0.6435\n",
      "Epoch 21/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.9075 - acc: 0.6752 - f1_micro: 0.6437 - val_loss: 1.5372 - val_acc: 0.7469 - val_f1_micro: 0.6439\n",
      "Epoch 22/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.9087 - acc: 0.6750 - f1_micro: 0.6441 - val_loss: 1.5210 - val_acc: 0.7435 - val_f1_micro: 0.6443\n",
      "Epoch 23/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.9014 - acc: 0.6744 - f1_micro: 0.6445 - val_loss: 1.5296 - val_acc: 0.7399 - val_f1_micro: 0.6447\n",
      "Epoch 24/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.9002 - acc: 0.6748 - f1_micro: 0.6449 - val_loss: 1.5217 - val_acc: 0.7311 - val_f1_micro: 0.6450\n",
      "Epoch 25/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.9049 - acc: 0.6748 - f1_micro: 0.6452 - val_loss: 1.5258 - val_acc: 0.7308 - val_f1_micro: 0.6454\n",
      "Epoch 26/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.8980 - acc: 0.6732 - f1_micro: 0.6456 - val_loss: 1.5132 - val_acc: 0.7443 - val_f1_micro: 0.6458\n",
      "Epoch 27/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.9024 - acc: 0.6772 - f1_micro: 0.6460 - val_loss: 1.5211 - val_acc: 0.7343 - val_f1_micro: 0.6461\n",
      "Epoch 28/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.9027 - acc: 0.6753 - f1_micro: 0.6463 - val_loss: 1.5247 - val_acc: 0.7353 - val_f1_micro: 0.6465\n",
      "Epoch 29/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.9061 - acc: 0.6733 - f1_micro: 0.6467 - val_loss: 1.5191 - val_acc: 0.7357 - val_f1_micro: 0.6469\n",
      "Epoch 30/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.9039 - acc: 0.6769 - f1_micro: 0.6471 - val_loss: 1.5160 - val_acc: 0.7475 - val_f1_micro: 0.6472\n",
      "Epoch 31/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.8873 - acc: 0.6757 - f1_micro: 0.6474 - val_loss: 1.5153 - val_acc: 0.7378 - val_f1_micro: 0.6476\n",
      "Epoch 32/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.8890 - acc: 0.6771 - f1_micro: 0.6478 - val_loss: 1.5219 - val_acc: 0.7330 - val_f1_micro: 0.6480\n",
      "Epoch 33/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.8930 - acc: 0.6770 - f1_micro: 0.6481 - val_loss: 1.5126 - val_acc: 0.7341 - val_f1_micro: 0.6483\n",
      "Epoch 34/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.8921 - acc: 0.6775 - f1_micro: 0.6485 - val_loss: 1.5171 - val_acc: 0.7444 - val_f1_micro: 0.6487\n",
      "Epoch 35/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.8970 - acc: 0.6766 - f1_micro: 0.6488 - val_loss: 1.5132 - val_acc: 0.7480 - val_f1_micro: 0.6490\n",
      "Epoch 36/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.8934 - acc: 0.6752 - f1_micro: 0.6492 - val_loss: 1.5167 - val_acc: 0.7489 - val_f1_micro: 0.6494\n",
      "Epoch 37/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.8890 - acc: 0.6775 - f1_micro: 0.6495 - val_loss: 1.5129 - val_acc: 0.7508 - val_f1_micro: 0.6497\n",
      "Epoch 38/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.8880 - acc: 0.6770 - f1_micro: 0.6499 - val_loss: 1.5103 - val_acc: 0.7440 - val_f1_micro: 0.6500\n",
      "Epoch 39/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.8878 - acc: 0.6785 - f1_micro: 0.6502 - val_loss: 1.5135 - val_acc: 0.7450 - val_f1_micro: 0.6504\n",
      "Epoch 40/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.8914 - acc: 0.6772 - f1_micro: 0.6505 - val_loss: 1.5145 - val_acc: 0.7390 - val_f1_micro: 0.6507\n",
      "Epoch 41/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.8829 - acc: 0.6767 - f1_micro: 0.6509 - val_loss: 1.5082 - val_acc: 0.7410 - val_f1_micro: 0.6510\n",
      "Epoch 42/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.8821 - acc: 0.6773 - f1_micro: 0.6512 - val_loss: 1.5077 - val_acc: 0.7452 - val_f1_micro: 0.6514\n",
      "Epoch 43/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.8842 - acc: 0.6761 - f1_micro: 0.6515 - val_loss: 1.5067 - val_acc: 0.7500 - val_f1_micro: 0.6517\n",
      "Epoch 44/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.8810 - acc: 0.6766 - f1_micro: 0.6519 - val_loss: 1.5065 - val_acc: 0.7443 - val_f1_micro: 0.6520\n",
      "Epoch 45/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.8817 - acc: 0.6759 - f1_micro: 0.6522 - val_loss: 1.5083 - val_acc: 0.7446 - val_f1_micro: 0.6523\n",
      "Epoch 46/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.8830 - acc: 0.6793 - f1_micro: 0.6525 - val_loss: 1.5082 - val_acc: 0.7494 - val_f1_micro: 0.6527\n",
      "Epoch 47/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.8847 - acc: 0.6768 - f1_micro: 0.6528 - val_loss: 1.5045 - val_acc: 0.7413 - val_f1_micro: 0.6530\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94731/94731 [==============================] - 1s - loss: 1.8817 - acc: 0.6772 - f1_micro: 0.6531 - val_loss: 1.5097 - val_acc: 0.7344 - val_f1_micro: 0.6533\n",
      "Epoch 49/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.8838 - acc: 0.6760 - f1_micro: 0.6534 - val_loss: 1.5022 - val_acc: 0.7362 - val_f1_micro: 0.6536\n",
      "Epoch 50/50\n",
      "94731/94731 [==============================] - 1s - loss: 1.8792 - acc: 0.6781 - f1_micro: 0.6537 - val_loss: 1.5039 - val_acc: 0.7408 - val_f1_micro: 0.6539\n",
      "CPU times: user 1min 56s, sys: 12.9 s, total: 2min 9s\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# And trained it via:\n",
    "batch_size = 500\n",
    "epochs = 50\n",
    "\n",
    "hist = model.fit(\n",
    "    training_inputs,\n",
    "    training_outputs,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    validation_data=validation_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': [0.0],\n",
       " 'f1_micro': [0.022502759915887773],\n",
       " 'loss': [1.8220217678544056e-07],\n",
       " 'val_acc': [0.0],\n",
       " 'val_f1_micro': [0.022132802858999306],\n",
       " 'val_loss': [1.8207752097591942e-07]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9223 - acc: 0.6675 - f1_micro: 0.6154 - val_loss: 1.5412 - val_acc: 0.7377 - val_f1_micro: 0.6154\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9187 - acc: 0.6692 - f1_micro: 0.6154 - val_loss: 1.5448 - val_acc: 0.7409 - val_f1_micro: 0.6154\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9205 - acc: 0.6683 - f1_micro: 0.6155 - val_loss: 1.5374 - val_acc: 0.7429 - val_f1_micro: 0.6155\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9227 - acc: 0.6703 - f1_micro: 0.6155 - val_loss: 1.5447 - val_acc: 0.7329 - val_f1_micro: 0.6155\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9203 - acc: 0.6685 - f1_micro: 0.6155 - val_loss: 1.5355 - val_acc: 0.7364 - val_f1_micro: 0.6155\n",
      "\n",
      "Done with epoch: 5\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9157 - acc: 0.6708 - f1_micro: 0.6156 - val_loss: 1.5441 - val_acc: 0.7309 - val_f1_micro: 0.6156\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9195 - acc: 0.6718 - f1_micro: 0.6156 - val_loss: 1.5377 - val_acc: 0.7392 - val_f1_micro: 0.6156\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9227 - acc: 0.6692 - f1_micro: 0.6156 - val_loss: 1.5405 - val_acc: 0.7402 - val_f1_micro: 0.6156\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9229 - acc: 0.6687 - f1_micro: 0.6157 - val_loss: 1.5405 - val_acc: 0.7365 - val_f1_micro: 0.6157\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9125 - acc: 0.6702 - f1_micro: 0.6157 - val_loss: 1.5456 - val_acc: 0.7384 - val_f1_micro: 0.6157\n",
      "\n",
      "Done with epoch: 10\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9177 - acc: 0.6720 - f1_micro: 0.6157 - val_loss: 1.5304 - val_acc: 0.7401 - val_f1_micro: 0.6157\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9179 - acc: 0.6688 - f1_micro: 0.6158 - val_loss: 1.5427 - val_acc: 0.7348 - val_f1_micro: 0.6158\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9193 - acc: 0.6691 - f1_micro: 0.6158 - val_loss: 1.5412 - val_acc: 0.7327 - val_f1_micro: 0.6158\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9191 - acc: 0.6695 - f1_micro: 0.6158 - val_loss: 1.5363 - val_acc: 0.7391 - val_f1_micro: 0.6158\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9168 - acc: 0.6708 - f1_micro: 0.6158 - val_loss: 1.5342 - val_acc: 0.7397 - val_f1_micro: 0.6159\n",
      "\n",
      "Done with epoch: 15\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9221 - acc: 0.6693 - f1_micro: 0.6159 - val_loss: 1.5335 - val_acc: 0.7367 - val_f1_micro: 0.6159\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9162 - acc: 0.6710 - f1_micro: 0.6159 - val_loss: 1.5338 - val_acc: 0.7372 - val_f1_micro: 0.6159\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9207 - acc: 0.6691 - f1_micro: 0.6159 - val_loss: 1.5289 - val_acc: 0.7334 - val_f1_micro: 0.6159\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9201 - acc: 0.6689 - f1_micro: 0.6160 - val_loss: 1.5354 - val_acc: 0.7397 - val_f1_micro: 0.6160\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9173 - acc: 0.6686 - f1_micro: 0.6160 - val_loss: 1.5293 - val_acc: 0.7378 - val_f1_micro: 0.6160\n",
      "\n",
      "Done with epoch: 20\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9213 - acc: 0.6697 - f1_micro: 0.6160 - val_loss: 1.5390 - val_acc: 0.7385 - val_f1_micro: 0.6160\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9134 - acc: 0.6703 - f1_micro: 0.6160 - val_loss: 1.5306 - val_acc: 0.7446 - val_f1_micro: 0.6161\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9137 - acc: 0.6691 - f1_micro: 0.6161 - val_loss: 1.5293 - val_acc: 0.7324 - val_f1_micro: 0.6161\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9200 - acc: 0.6687 - f1_micro: 0.6161 - val_loss: 1.5279 - val_acc: 0.7380 - val_f1_micro: 0.6161\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9173 - acc: 0.6707 - f1_micro: 0.6161 - val_loss: 1.5320 - val_acc: 0.7384 - val_f1_micro: 0.6161\n",
      "\n",
      "Done with epoch: 25\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9218 - acc: 0.6680 - f1_micro: 0.6162 - val_loss: 1.5398 - val_acc: 0.7353 - val_f1_micro: 0.6162\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9213 - acc: 0.6706 - f1_micro: 0.6162 - val_loss: 1.5378 - val_acc: 0.7366 - val_f1_micro: 0.6162\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9178 - acc: 0.6674 - f1_micro: 0.6162 - val_loss: 1.5325 - val_acc: 0.7420 - val_f1_micro: 0.6162\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9145 - acc: 0.6706 - f1_micro: 0.6162 - val_loss: 1.5377 - val_acc: 0.7373 - val_f1_micro: 0.6163\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9217 - acc: 0.6684 - f1_micro: 0.6163 - val_loss: 1.5379 - val_acc: 0.7366 - val_f1_micro: 0.6163\n",
      "\n",
      "Done with epoch: 30\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9244 - acc: 0.6682 - f1_micro: 0.6163 - val_loss: 1.5349 - val_acc: 0.7404 - val_f1_micro: 0.6163\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9196 - acc: 0.6697 - f1_micro: 0.6163 - val_loss: 1.5400 - val_acc: 0.7365 - val_f1_micro: 0.6163\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9243 - acc: 0.6687 - f1_micro: 0.6164 - val_loss: 1.5347 - val_acc: 0.7321 - val_f1_micro: 0.6164\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9224 - acc: 0.6673 - f1_micro: 0.6164 - val_loss: 1.5369 - val_acc: 0.7340 - val_f1_micro: 0.6164\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9201 - acc: 0.6716 - f1_micro: 0.6164 - val_loss: 1.5311 - val_acc: 0.7353 - val_f1_micro: 0.6164\n",
      "\n",
      "Done with epoch: 35\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9151 - acc: 0.6704 - f1_micro: 0.6164 - val_loss: 1.5329 - val_acc: 0.7430 - val_f1_micro: 0.6165\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9166 - acc: 0.6699 - f1_micro: 0.6165 - val_loss: 1.5355 - val_acc: 0.7363 - val_f1_micro: 0.6165\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9159 - acc: 0.6695 - f1_micro: 0.6165 - val_loss: 1.5343 - val_acc: 0.7384 - val_f1_micro: 0.6165\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9203 - acc: 0.6693 - f1_micro: 0.6165 - val_loss: 1.5319 - val_acc: 0.7421 - val_f1_micro: 0.6165\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9196 - acc: 0.6695 - f1_micro: 0.6166 - val_loss: 1.5358 - val_acc: 0.7420 - val_f1_micro: 0.6166\n",
      "\n",
      "Done with epoch: 40\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9214 - acc: 0.6685 - f1_micro: 0.6166 - val_loss: 1.5326 - val_acc: 0.7331 - val_f1_micro: 0.6166\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9204 - acc: 0.6691 - f1_micro: 0.6166 - val_loss: 1.5288 - val_acc: 0.7346 - val_f1_micro: 0.6166\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9157 - acc: 0.6710 - f1_micro: 0.6166 - val_loss: 1.5351 - val_acc: 0.7412 - val_f1_micro: 0.6167\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9197 - acc: 0.6702 - f1_micro: 0.6167 - val_loss: 1.5314 - val_acc: 0.7348 - val_f1_micro: 0.6167\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9189 - acc: 0.6673 - f1_micro: 0.6167 - val_loss: 1.5315 - val_acc: 0.7330 - val_f1_micro: 0.6167\n",
      "\n",
      "Done with epoch: 45\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94731/94731 [==============================] - 0s - loss: 1.9168 - acc: 0.6684 - f1_micro: 0.6167 - val_loss: 1.5317 - val_acc: 0.7375 - val_f1_micro: 0.6167\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9138 - acc: 0.6709 - f1_micro: 0.6168 - val_loss: 1.5307 - val_acc: 0.7391 - val_f1_micro: 0.6168\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9131 - acc: 0.6717 - f1_micro: 0.6168 - val_loss: 1.5264 - val_acc: 0.7419 - val_f1_micro: 0.6168\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9199 - acc: 0.6672 - f1_micro: 0.6168 - val_loss: 1.5316 - val_acc: 0.7385 - val_f1_micro: 0.6168\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9186 - acc: 0.6696 - f1_micro: 0.6168 - val_loss: 1.5284 - val_acc: 0.7426 - val_f1_micro: 0.6169\n",
      "\n",
      "Done with epoch: 50\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9110 - acc: 0.6696 - f1_micro: 0.6169 - val_loss: 1.5327 - val_acc: 0.7442 - val_f1_micro: 0.6169\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9129 - acc: 0.6703 - f1_micro: 0.6169 - val_loss: 1.5261 - val_acc: 0.7390 - val_f1_micro: 0.6169\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9144 - acc: 0.6704 - f1_micro: 0.6169 - val_loss: 1.5295 - val_acc: 0.7461 - val_f1_micro: 0.6169\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9168 - acc: 0.6730 - f1_micro: 0.6170 - val_loss: 1.5240 - val_acc: 0.7399 - val_f1_micro: 0.6170\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9155 - acc: 0.6707 - f1_micro: 0.6170 - val_loss: 1.5344 - val_acc: 0.7353 - val_f1_micro: 0.6170\n",
      "\n",
      "Done with epoch: 55\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9163 - acc: 0.6689 - f1_micro: 0.6170 - val_loss: 1.5346 - val_acc: 0.7369 - val_f1_micro: 0.6170\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9159 - acc: 0.6714 - f1_micro: 0.6170 - val_loss: 1.5308 - val_acc: 0.7423 - val_f1_micro: 0.6171\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9163 - acc: 0.6694 - f1_micro: 0.6171 - val_loss: 1.5292 - val_acc: 0.7455 - val_f1_micro: 0.6171\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9081 - acc: 0.6707 - f1_micro: 0.6171 - val_loss: 1.5238 - val_acc: 0.7374 - val_f1_micro: 0.6171\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9140 - acc: 0.6717 - f1_micro: 0.6171 - val_loss: 1.5328 - val_acc: 0.7412 - val_f1_micro: 0.6171\n",
      "\n",
      "Done with epoch: 60\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9186 - acc: 0.6683 - f1_micro: 0.6172 - val_loss: 1.5345 - val_acc: 0.7364 - val_f1_micro: 0.6172\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9187 - acc: 0.6680 - f1_micro: 0.6172 - val_loss: 1.5311 - val_acc: 0.7355 - val_f1_micro: 0.6172\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9183 - acc: 0.6688 - f1_micro: 0.6172 - val_loss: 1.5279 - val_acc: 0.7397 - val_f1_micro: 0.6172\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9157 - acc: 0.6700 - f1_micro: 0.6172 - val_loss: 1.5268 - val_acc: 0.7419 - val_f1_micro: 0.6173\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9132 - acc: 0.6700 - f1_micro: 0.6173 - val_loss: 1.5275 - val_acc: 0.7444 - val_f1_micro: 0.6173\n",
      "\n",
      "Done with epoch: 65\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9218 - acc: 0.6701 - f1_micro: 0.6173 - val_loss: 1.5284 - val_acc: 0.7375 - val_f1_micro: 0.6173\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9176 - acc: 0.6695 - f1_micro: 0.6173 - val_loss: 1.5287 - val_acc: 0.7425 - val_f1_micro: 0.6173\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9181 - acc: 0.6697 - f1_micro: 0.6174 - val_loss: 1.5254 - val_acc: 0.7304 - val_f1_micro: 0.6174\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9161 - acc: 0.6680 - f1_micro: 0.6174 - val_loss: 1.5287 - val_acc: 0.7375 - val_f1_micro: 0.6174\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9101 - acc: 0.6701 - f1_micro: 0.6174 - val_loss: 1.5288 - val_acc: 0.7424 - val_f1_micro: 0.6174\n",
      "\n",
      "Done with epoch: 70\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9076 - acc: 0.6702 - f1_micro: 0.6174 - val_loss: 1.5222 - val_acc: 0.7496 - val_f1_micro: 0.6175\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9161 - acc: 0.6712 - f1_micro: 0.6175 - val_loss: 1.5262 - val_acc: 0.7423 - val_f1_micro: 0.6175\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9112 - acc: 0.6719 - f1_micro: 0.6175 - val_loss: 1.5292 - val_acc: 0.7428 - val_f1_micro: 0.6175\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9248 - acc: 0.6686 - f1_micro: 0.6175 - val_loss: 1.5388 - val_acc: 0.7340 - val_f1_micro: 0.6175\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9124 - acc: 0.6708 - f1_micro: 0.6175 - val_loss: 1.5288 - val_acc: 0.7438 - val_f1_micro: 0.6176\n",
      "\n",
      "Done with epoch: 75\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9127 - acc: 0.6672 - f1_micro: 0.6176 - val_loss: 1.5232 - val_acc: 0.7396 - val_f1_micro: 0.6176\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9084 - acc: 0.6717 - f1_micro: 0.6176 - val_loss: 1.5325 - val_acc: 0.7345 - val_f1_micro: 0.6176\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9156 - acc: 0.6711 - f1_micro: 0.6176 - val_loss: 1.5301 - val_acc: 0.7365 - val_f1_micro: 0.6176\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9143 - acc: 0.6719 - f1_micro: 0.6176 - val_loss: 1.5262 - val_acc: 0.7413 - val_f1_micro: 0.6177\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9228 - acc: 0.6676 - f1_micro: 0.6177 - val_loss: 1.5310 - val_acc: 0.7364 - val_f1_micro: 0.6177\n",
      "\n",
      "Done with epoch: 80\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9089 - acc: 0.6713 - f1_micro: 0.6177 - val_loss: 1.5319 - val_acc: 0.7435 - val_f1_micro: 0.6177\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9145 - acc: 0.6706 - f1_micro: 0.6177 - val_loss: 1.5279 - val_acc: 0.7416 - val_f1_micro: 0.6177\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9085 - acc: 0.6704 - f1_micro: 0.6178 - val_loss: 1.5272 - val_acc: 0.7411 - val_f1_micro: 0.6178\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9151 - acc: 0.6681 - f1_micro: 0.6178 - val_loss: 1.5379 - val_acc: 0.7383 - val_f1_micro: 0.6178\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9109 - acc: 0.6725 - f1_micro: 0.6178 - val_loss: 1.5329 - val_acc: 0.7369 - val_f1_micro: 0.6178\n",
      "\n",
      "Done with epoch: 85\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9074 - acc: 0.6688 - f1_micro: 0.6178 - val_loss: 1.5381 - val_acc: 0.7372 - val_f1_micro: 0.6179\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9080 - acc: 0.6701 - f1_micro: 0.6179 - val_loss: 1.5309 - val_acc: 0.7388 - val_f1_micro: 0.6179\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9125 - acc: 0.6695 - f1_micro: 0.6179 - val_loss: 1.5329 - val_acc: 0.7421 - val_f1_micro: 0.6179\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9118 - acc: 0.6685 - f1_micro: 0.6179 - val_loss: 1.5257 - val_acc: 0.7449 - val_f1_micro: 0.6179\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9124 - acc: 0.6714 - f1_micro: 0.6180 - val_loss: 1.5223 - val_acc: 0.7432 - val_f1_micro: 0.6180\n",
      "\n",
      "Done with epoch: 90\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94731/94731 [==============================] - 0s - loss: 1.9131 - acc: 0.6711 - f1_micro: 0.6180 - val_loss: 1.5285 - val_acc: 0.7411 - val_f1_micro: 0.6180\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9154 - acc: 0.6713 - f1_micro: 0.6180 - val_loss: 1.5232 - val_acc: 0.7392 - val_f1_micro: 0.6180\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9101 - acc: 0.6670 - f1_micro: 0.6181 - val_loss: 1.5253 - val_acc: 0.7344 - val_f1_micro: 0.6181\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9152 - acc: 0.6685 - f1_micro: 0.6181 - val_loss: 1.5293 - val_acc: 0.7348 - val_f1_micro: 0.6181\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9085 - acc: 0.6697 - f1_micro: 0.6181 - val_loss: 1.5267 - val_acc: 0.7393 - val_f1_micro: 0.6181\n",
      "\n",
      "Done with epoch: 95\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9121 - acc: 0.6704 - f1_micro: 0.6181 - val_loss: 1.5282 - val_acc: 0.7481 - val_f1_micro: 0.6182\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9227 - acc: 0.6704 - f1_micro: 0.6182 - val_loss: 1.5314 - val_acc: 0.7371 - val_f1_micro: 0.6182\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9129 - acc: 0.6697 - f1_micro: 0.6182 - val_loss: 1.5234 - val_acc: 0.7386 - val_f1_micro: 0.6182\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9084 - acc: 0.6714 - f1_micro: 0.6182 - val_loss: 1.5235 - val_acc: 0.7372 - val_f1_micro: 0.6182\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9141 - acc: 0.6703 - f1_micro: 0.6183 - val_loss: 1.5295 - val_acc: 0.7438 - val_f1_micro: 0.6183\n",
      "\n",
      "Done with epoch: 100\n",
      "\n",
      "CPU times: user 1min 45s, sys: 10.6 s, total: 1min 56s\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "log_history_file = 'lstm-word2vec-fasttext-lsi.epoch.csv'\n",
    "model_name = 'models/tfidf-wv-fs-lsi-2010-2014-data_cat-crossentropy-2014-b-val-sc_tfidf_wv_fs_lsi.model'\n",
    "batch_size = 1200\n",
    "epochs = 5\n",
    "total_epochs = 100\n",
    "\n",
    "for i in xrange(0, total_epochs // epochs):\n",
    "    hist = model.fit(\n",
    "        training_inputs,\n",
    "        training_outputs,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.2,\n",
    "        validation_data=validation_data,\n",
    "    )\n",
    "\n",
    "    model.save(model_name.format(i))\n",
    "    print\n",
    "    print('Done with epoch: {}'.format((i + 1) * epochs))\n",
    "    with open(log_history_file, 'a') as fl:\n",
    "        fl.write(model_name + '\\n')\n",
    "        fl.write('Epoch {}\\n'.format((i + 1) * epochs))\n",
    "        fl.write('{}\\n'.format(datetime.now()))\n",
    "        fl.write('\\n'.join(['{}: {}'.format(k, v[0]) for k, v in hist.history.items()]))\n",
    "        fl.write('\\n\\n')\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.6427 - main_output_loss: 1.3490 - aux_output_loss: 1.4686 - main_output_acc: 0.7712 - main_output_f1_micro: 0.6905 - aux_output_acc: 0.7839 - aux_output_f1_micro: 0.1085 - val_loss: 1.4372 - val_main_output_loss: 1.1302 - val_aux_output_loss: 1.5348 - val_main_output_acc: 0.7941 - val_main_output_f1_micro: 0.6913 - val_aux_output_acc: 0.7884 - val_aux_output_f1_micro: 0.1086\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5833 - main_output_loss: 1.2980 - aux_output_loss: 1.4265 - main_output_acc: 0.7738 - main_output_f1_micro: 0.6921 - aux_output_acc: 0.7855 - aux_output_f1_micro: 0.1088 - val_loss: 1.4210 - val_main_output_loss: 1.1179 - val_aux_output_loss: 1.5153 - val_main_output_acc: 0.7967 - val_main_output_f1_micro: 0.6930 - val_aux_output_acc: 0.7949 - val_aux_output_f1_micro: 0.1090\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5656 - main_output_loss: 1.2841 - aux_output_loss: 1.4076 - main_output_acc: 0.7752 - main_output_f1_micro: 0.6938 - aux_output_acc: 0.7870 - aux_output_f1_micro: 0.1091 - val_loss: 1.4123 - val_main_output_loss: 1.1124 - val_aux_output_loss: 1.4995 - val_main_output_acc: 0.7930 - val_main_output_f1_micro: 0.6946 - val_aux_output_acc: 0.7916 - val_aux_output_f1_micro: 0.1093\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5551 - main_output_loss: 1.2755 - aux_output_loss: 1.3983 - main_output_acc: 0.7779 - main_output_f1_micro: 0.6955 - aux_output_acc: 0.7867 - aux_output_f1_micro: 0.1094 - val_loss: 1.4043 - val_main_output_loss: 1.1070 - val_aux_output_loss: 1.4866 - val_main_output_acc: 0.7988 - val_main_output_f1_micro: 0.6963 - val_aux_output_acc: 0.7918 - val_aux_output_f1_micro: 0.1096\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5504 - main_output_loss: 1.2725 - aux_output_loss: 1.3899 - main_output_acc: 0.7771 - main_output_f1_micro: 0.6971 - aux_output_acc: 0.7872 - aux_output_f1_micro: 0.1097 - val_loss: 1.4002 - val_main_output_loss: 1.1043 - val_aux_output_loss: 1.4796 - val_main_output_acc: 0.8088 - val_main_output_f1_micro: 0.6980 - val_aux_output_acc: 0.7916 - val_aux_output_f1_micro: 0.1099\n",
      "\n",
      "Done with epoch: 100\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5459 - main_output_loss: 1.2693 - aux_output_loss: 1.3833 - main_output_acc: 0.7773 - main_output_f1_micro: 0.6988 - aux_output_acc: 0.7896 - aux_output_f1_micro: 0.1100 - val_loss: 1.3938 - val_main_output_loss: 1.0999 - val_aux_output_loss: 1.4694 - val_main_output_acc: 0.8001 - val_main_output_f1_micro: 0.6996 - val_aux_output_acc: 0.7926 - val_aux_output_f1_micro: 0.1102\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5393 - main_output_loss: 1.2640 - aux_output_loss: 1.3764 - main_output_acc: 0.7776 - main_output_f1_micro: 0.7004 - aux_output_acc: 0.7896 - aux_output_f1_micro: 0.1103 - val_loss: 1.3912 - val_main_output_loss: 1.0979 - val_aux_output_loss: 1.4664 - val_main_output_acc: 0.7940 - val_main_output_f1_micro: 0.7012 - val_aux_output_acc: 0.7917 - val_aux_output_f1_micro: 0.1105\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5369 - main_output_loss: 1.2627 - aux_output_loss: 1.3708 - main_output_acc: 0.7815 - main_output_f1_micro: 0.7020 - aux_output_acc: 0.7890 - aux_output_f1_micro: 0.1106 - val_loss: 1.3821 - val_main_output_loss: 1.0902 - val_aux_output_loss: 1.4594 - val_main_output_acc: 0.8066 - val_main_output_f1_micro: 0.7028 - val_aux_output_acc: 0.7940 - val_aux_output_f1_micro: 0.1108\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5302 - main_output_loss: 1.2571 - aux_output_loss: 1.3656 - main_output_acc: 0.7796 - main_output_f1_micro: 0.7036 - aux_output_acc: 0.7897 - aux_output_f1_micro: 0.1109 - val_loss: 1.3878 - val_main_output_loss: 1.0954 - val_aux_output_loss: 1.4620 - val_main_output_acc: 0.7964 - val_main_output_f1_micro: 0.7044 - val_aux_output_acc: 0.7954 - val_aux_output_f1_micro: 0.1111\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5282 - main_output_loss: 1.2561 - aux_output_loss: 1.3605 - main_output_acc: 0.7775 - main_output_f1_micro: 0.7052 - aux_output_acc: 0.7913 - aux_output_f1_micro: 0.1112 - val_loss: 1.3855 - val_main_output_loss: 1.0954 - val_aux_output_loss: 1.4505 - val_main_output_acc: 0.7928 - val_main_output_f1_micro: 0.7059 - val_aux_output_acc: 0.7964 - val_aux_output_f1_micro: 0.1114\n",
      "\n",
      "Done with epoch: 105\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5262 - main_output_loss: 1.2551 - aux_output_loss: 1.3553 - main_output_acc: 0.7791 - main_output_f1_micro: 0.7067 - aux_output_acc: 0.7902 - aux_output_f1_micro: 0.1115 - val_loss: 1.3707 - val_main_output_loss: 1.0832 - val_aux_output_loss: 1.4377 - val_main_output_acc: 0.8034 - val_main_output_f1_micro: 0.7075 - val_aux_output_acc: 0.7948 - val_aux_output_f1_micro: 0.1117\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5205 - main_output_loss: 1.2508 - aux_output_loss: 1.3484 - main_output_acc: 0.7803 - main_output_f1_micro: 0.7083 - aux_output_acc: 0.7910 - aux_output_f1_micro: 0.1118 - val_loss: 1.3696 - val_main_output_loss: 1.0827 - val_aux_output_loss: 1.4348 - val_main_output_acc: 0.8018 - val_main_output_f1_micro: 0.7090 - val_aux_output_acc: 0.7929 - val_aux_output_f1_micro: 0.1120\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5220 - main_output_loss: 1.2527 - aux_output_loss: 1.3466 - main_output_acc: 0.7793 - main_output_f1_micro: 0.7098 - aux_output_acc: 0.7904 - aux_output_f1_micro: 0.1122 - val_loss: 1.3695 - val_main_output_loss: 1.0827 - val_aux_output_loss: 1.4341 - val_main_output_acc: 0.7963 - val_main_output_f1_micro: 0.7105 - val_aux_output_acc: 0.7926 - val_aux_output_f1_micro: 0.1123\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5216 - main_output_loss: 1.2530 - aux_output_loss: 1.3431 - main_output_acc: 0.7800 - main_output_f1_micro: 0.7113 - aux_output_acc: 0.7914 - aux_output_f1_micro: 0.1125 - val_loss: 1.3708 - val_main_output_loss: 1.0860 - val_aux_output_loss: 1.4240 - val_main_output_acc: 0.8011 - val_main_output_f1_micro: 0.7120 - val_aux_output_acc: 0.7966 - val_aux_output_f1_micro: 0.1126\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5163 - main_output_loss: 1.2486 - aux_output_loss: 1.3386 - main_output_acc: 0.7807 - main_output_f1_micro: 0.7128 - aux_output_acc: 0.7916 - aux_output_f1_micro: 0.1128 - val_loss: 1.3660 - val_main_output_loss: 1.0814 - val_aux_output_loss: 1.4232 - val_main_output_acc: 0.7929 - val_main_output_f1_micro: 0.7135 - val_aux_output_acc: 0.7930 - val_aux_output_f1_micro: 0.1130\n",
      "\n",
      "Done with epoch: 110\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5152 - main_output_loss: 1.2484 - aux_output_loss: 1.3341 - main_output_acc: 0.7792 - main_output_f1_micro: 0.7142 - aux_output_acc: 0.7911 - aux_output_f1_micro: 0.1131 - val_loss: 1.3651 - val_main_output_loss: 1.0816 - val_aux_output_loss: 1.4173 - val_main_output_acc: 0.7956 - val_main_output_f1_micro: 0.7149 - val_aux_output_acc: 0.7927 - val_aux_output_f1_micro: 0.1133\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5089 - main_output_loss: 1.2427 - aux_output_loss: 1.3309 - main_output_acc: 0.7803 - main_output_f1_micro: 0.7156 - aux_output_acc: 0.7912 - aux_output_f1_micro: 0.1135 - val_loss: 1.3627 - val_main_output_loss: 1.0794 - val_aux_output_loss: 1.4167 - val_main_output_acc: 0.7989 - val_main_output_f1_micro: 0.7164 - val_aux_output_acc: 0.7968 - val_aux_output_f1_micro: 0.1136\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5082 - main_output_loss: 1.2431 - aux_output_loss: 1.3254 - main_output_acc: 0.7813 - main_output_f1_micro: 0.7171 - aux_output_acc: 0.7917 - aux_output_f1_micro: 0.1138 - val_loss: 1.3610 - val_main_output_loss: 1.0787 - val_aux_output_loss: 1.4114 - val_main_output_acc: 0.8054 - val_main_output_f1_micro: 0.7178 - val_aux_output_acc: 0.7916 - val_aux_output_f1_micro: 0.1139\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5043 - main_output_loss: 1.2400 - aux_output_loss: 1.3214 - main_output_acc: 0.7788 - main_output_f1_micro: 0.7185 - aux_output_acc: 0.7905 - aux_output_f1_micro: 0.1141 - val_loss: 1.3573 - val_main_output_loss: 1.0764 - val_aux_output_loss: 1.4045 - val_main_output_acc: 0.8025 - val_main_output_f1_micro: 0.7192 - val_aux_output_acc: 0.7962 - val_aux_output_f1_micro: 0.1143\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5045 - main_output_loss: 1.2409 - aux_output_loss: 1.3181 - main_output_acc: 0.7785 - main_output_f1_micro: 0.7199 - aux_output_acc: 0.7919 - aux_output_f1_micro: 0.1145 - val_loss: 1.3638 - val_main_output_loss: 1.0828 - val_aux_output_loss: 1.4050 - val_main_output_acc: 0.7982 - val_main_output_f1_micro: 0.7205 - val_aux_output_acc: 0.7963 - val_aux_output_f1_micro: 0.1146\n",
      "\n",
      "Done with epoch: 115\n",
      "\n",
      "CPU times: user 20min 20s, sys: 1min 53s, total: 22min 14s\n",
      "Wall time: 17min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total_epochs = 100\n",
    "for j in xrange(i, i + (total_epochs // epochs)):\n",
    "    hist = model.fit(\n",
    "        training_inputs,\n",
    "        training_outputs,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.2,\n",
    "        validation_data=validation_data,\n",
    "    )\n",
    "\n",
    "    model.save(model_name.format(i))\n",
    "    print\n",
    "    print('Done with epoch: {}'.format((j + 1) * epochs))\n",
    "    with open(log_history_file, 'a') as fl:\n",
    "        fl.write(model_name + '\\n')\n",
    "        fl.write('Epoch {}\\n'.format((j + 1) * epochs))\n",
    "        fl.write('{}\\n'.format(datetime.now()))\n",
    "        fl.write('\\n'.join(['{}: {}'.format(k, v[0]) for k, v in hist.history.items()]))\n",
    "        fl.write('\\n\\n')\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = keras.models.load_model(\n",
    "#     'models/lstm-word2vec-fasttext_2010-2014-data_categorical-crossentropy-2014-b-val-standard_scaled_wv_fs.model',\n",
    "#     custom_objects={'f1_micro': f1_micro}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = model.predict(\n",
    "    build_training_inputs(\n",
    "        wv_train[:100],\n",
    "        fs_train[:100],\n",
    "        tfidf_wv_train[:100],\n",
    "        tfidf_fs_train[:100],\n",
    "        tfidf_lsi_train[:100],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f69e029c0d0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f69e0eddfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "ix = 29\n",
    "pd.Series(g[ix]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([ 1, 98]),), (array([ 1, 98]),))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh = 0.5\n",
    "np.where(y_train[ix] == 1), np.where(g[ix] > thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "from gensim.models.lsimodel import LsiModel\n",
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = TfidfModel.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.dictionary')\n",
    "tfidf = TfidfModel.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.tfidf')\n",
    "lsi = LsiModel.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.lsi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wvmodel = Word2Vec.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fsmodel = fasttext.load_model('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.fasttext.model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_tfidf_word2vec(tokens, stopwords=[]):\n",
    "#     global wvmodel\n",
    "#     global tfidf\n",
    "    # This requires wvmodel to be present in the namespace.\n",
    "    wv_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords and w in wvmodel.wv.vocab)]\n",
    "    ).map(\n",
    "        lambda x: tfidf[dictionary.doc2bow(x)]\n",
    "    ).map(\n",
    "        lambda x: np.array([wvmodel[dictionary.id2token[id]] * w for id, w in x]).mean(axis=0) if len(x) > 0 else np.nan\n",
    "    )\n",
    "\n",
    "    return wv_feature_vec\n",
    "\n",
    "\n",
    "def transform_tfidf_fasttext(tokens, stopwords=[]):\n",
    "#     global fsmodel\n",
    "#     global tfidf\n",
    "    # This requires wvmodel to be present in the namespace.\n",
    "    fs_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    ).map(\n",
    "        lambda x: tfidf[dictionary.doc2bow(x)]\n",
    "    ).map(\n",
    "        lambda x: np.array([np.array(fsmodel[dictionary.id2token[id]]) * w for id, w in x]).mean(axis=0) if len(x) > 0 else np.nan\n",
    "    )\n",
    "\n",
    "    return fs_feature_vec\n",
    "\n",
    "\n",
    "def build_lsi_vector(l):\n",
    "    v = np.zeros(lsi.num_topics)\n",
    "    \n",
    "    for ix, vv in lsi[tfidf[dictionary.doc2bow(l)]]:\n",
    "        v[ix] = vv\n",
    "        \n",
    "    return v\n",
    "\n",
    "\n",
    "def transform_tfidf_lsi(tokens, stopwords=[]):\n",
    "#     global fsmodel\n",
    "#     global tfidf\n",
    "    # This requires wvmodel to be present in the namespace.\n",
    "    lsi_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    ).map(\n",
    "        lambda x: build_lsi_vector(x) if len(x) > 0 else np.nan\n",
    "    )\n",
    "\n",
    "    return lsi_feature_vec\n",
    "\n",
    "\n",
    "def transform_fasttext(tokens, stopwords=[]):\n",
    "    global fsmodel\n",
    "    # This requires fsmodel to be present in the namespace.\n",
    "    fs_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    ).map(lambda x: np.array([fsmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return fs_feature_vec\n",
    "\n",
    "\n",
    "def transform_unsupervised_sentiment_neuron(tokens, stopwords=[]):\n",
    "    # This requires fsmodel to be present in the namespace.\n",
    "    \n",
    "    usn_feature_vec = usnmodel.transform(tokens)\n",
    "\n",
    "    # usn_feature_vec = tokens.map(\n",
    "    #     lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    # ).map(lambda x: np.array([usnmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return usn_feature_vec\n",
    "\n",
    "\n",
    "def transform_word2vec(tokens, stopwords=[]):\n",
    "    global wvmodel\n",
    "    # This requires wvmodel to be present in the namespace.\n",
    "    wv_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords and w in wvmodel.wv.vocab)]\n",
    "    ).map(lambda x: np.array([wvmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return wv_feature_vec\n",
    "\n",
    "\n",
    "def parallel_generate_word_vectors(samp, transformer, stopwords, batch, num_proc):\n",
    "    with Parallel(n_jobs=num_proc) as parallel:\n",
    "        dataset = []\n",
    "        is_break = False\n",
    "        i = 0\n",
    "\n",
    "        while not is_break:\n",
    "            payload = []\n",
    "\n",
    "            for j in xrange(num_proc):\n",
    "                t_df = samp[(i + j) * batch: (i + 1 + j) * batch]\n",
    "\n",
    "                if t_df.empty:\n",
    "                    is_break = True\n",
    "                    continue\n",
    "\n",
    "                payload.append(\n",
    "                    delayed(transformer)(\n",
    "                        t_df, stopwords\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            print('Current batch in main thread: {}'.format((i + j) * batch))\n",
    "\n",
    "            if payload:\n",
    "                results = parallel(payload)\n",
    "                dataset.extend(results)\n",
    "                i += num_proc\n",
    "\n",
    "    return pd.concat(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_classes(pred, scale_param=0.75, min_thresh=0.05, thresh = 0.5):\n",
    "#     mx = pred.mean() + 3 * pred.std()\n",
    "    return np.where(pred > thresh)[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2idx_transform(word, _word2idx):\n",
    "    return _word2idx.get(word, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features_for(df, min_batch=2000, stopwords=[], num_proc=7):\n",
    "    df_tokens = transform_text(df)\n",
    "    \n",
    "    batch = min(df_tokens.shape[0] / num_proc, min_batch)\n",
    "\n",
    "    print('Computing fs features...')\n",
    "    fvec = parallel_generate_word_vectors(df_tokens, transform_fasttext, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Computing wv features...')\n",
    "    wvec = parallel_generate_word_vectors(df_tokens, transform_word2vec, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Mapping word indices...')\n",
    "    word_indices = df_tokens.map(lambda x: [word2idx_transform(i, _word2idx) for i in x.split()])\n",
    "\n",
    "    print('Computing tfidf fs features...')\n",
    "    tfidf_fvec = parallel_generate_word_vectors(df_tokens, transform_tfidf_fasttext, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Computing tfidf wv features...')\n",
    "    tfidf_wvec = parallel_generate_word_vectors(df_tokens, transform_tfidf_word2vec, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Computing tfidf lsi features...')\n",
    "    tfidf_lsi = parallel_generate_word_vectors(df_tokens, transform_tfidf_lsi, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "    \n",
    "    return word_indices, wvec, fvec, tfidf_wvec, tfidf_fvec, tfidf_lsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/TestData.json') as fl:\n",
    "    data = json.load(fl)\n",
    "    test_df = pd.DataFrame(data['TestData']).T\n",
    "    del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fs features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Computing wv features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Mapping word indices...\n",
      "Computing tfidf fs features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Computing tfidf wv features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Computing tfidf lsi features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "CPU times: user 50.1 s, sys: 6.48 s, total: 56.6 s\n",
      "Wall time: 2min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_word_indices,test_wvec, test_fvec, test_tfidf_wvec, test_tfidf_fvec, test_tfidf_lsi = extract_features_for(\n",
    "    test_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert(np.all(test_wvec[test_wvec.isnull()].index == test_fvec[test_fvec.isnull()].index))\n",
    "test_null_index = test_wvec[test_wvec.isnull()].index.union(test_fvec[test_fvec.isnull()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'TestData_02543', u'TestData_05012', u'TestData_05830'], dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_null_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 344 ms, sys: 36 ms, total: 380 ms\n",
      "Wall time: 383 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "valid_test_index = test_word_indices.index.difference(test_null_index)\n",
    "x_test = test_word_indices.ix[valid_test_index]  # .map(lambda x: [top_token2ind.get(i, 0) for i in x])\n",
    "\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "wv_test = np.vstack(test_wvec.ix[valid_test_index])\n",
    "fs_test = np.vstack(test_fvec.ix[valid_test_index])\n",
    "\n",
    "tfidf_wv_test = np.vstack(test_tfidf_wvec.ix[valid_test_index])\n",
    "tfidf_fs_test = np.vstack(test_tfidf_fvec.ix[valid_test_index])\n",
    "tfidf_lsi_test = np.vstack(test_tfidf_lsi.ix[valid_test_index])\n",
    "\n",
    "wv_test = wv_sc.transform(wv_test)\n",
    "fs_test = fs_sc.transform(fs_test)\n",
    "\n",
    "tfidf_wv_test = tfidf_wv_sc.transform(tfidf_wv_test)\n",
    "tfidf_fs_test = tfidf_fs_sc.transform(tfidf_fs_test)\n",
    "tfidf_lsi_test = tfidf_lsi_sc.transform(tfidf_lsi_test)\n",
    "\n",
    "test_inputs = build_training_inputs(\n",
    "    wv_test,\n",
    "    fs_test,\n",
    "    tfidf_wv_test,\n",
    "    tfidf_fs_test,\n",
    "    tfidf_lsi_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_probas = model.predict(test_inputs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_test_probas = test_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   3.51521989e-09,   3.23756189e-10, ...,\n",
       "          5.97743299e-10,   1.83255998e-13,   0.00000000e+00],\n",
       "       [  6.50782562e-29,   1.56475357e-06,   3.82902817e-06, ...,\n",
       "          1.69156135e-06,   4.58016647e-09,   1.05622823e-27],\n",
       "       [  0.00000000e+00,   6.99282132e-10,   1.03787148e-08, ...,\n",
       "          1.18757149e-09,   2.83694548e-16,   0.00000000e+00],\n",
       "       ..., \n",
       "       [  1.39064109e-16,   5.45442244e-03,   3.08843195e-01, ...,\n",
       "          6.54218226e-08,   1.21962780e-03,   1.13630343e-16],\n",
       "       [  3.10283707e-22,   1.89735810e-03,   2.62519025e-04, ...,\n",
       "          4.38363259e-06,   2.97837602e-07,   4.08869687e-22],\n",
       "       [  3.73695219e-25,   1.48586929e-04,   4.95965534e-04, ...,\n",
       "          8.57271687e-07,   2.35180209e-09,   7.00528846e-25]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_test_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2542, 5011, 5829]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_index = [int(s.split('_')[1]) - 1 for s in test_null_index]  # Subtract 1 since test index starts at 1 while enumerate starts at 0\n",
    "skip_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7578, 160), (7581, 3))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_test_probas.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36 ms, sys: 4 ms, total: 40 ms\n",
      "Wall time: 33.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# valid_test_feature_vec found below!\n",
    "thresh = 0.25\n",
    "test_values = np.zeros([main_test_probas.shape[0], len(topics)])\n",
    "for ix, pred in enumerate(main_test_probas):\n",
    "    for v in get_classes(pred, thresh=thresh):\n",
    "        test_values[ix][v] = 1\n",
    "\n",
    "test_sub_df = pd.DataFrame(\n",
    "    test_values,\n",
    "    index=test_df.ix[test_df.index.difference(test_null_index)].index,\n",
    "    columns=topics\n",
    ")\n",
    "\n",
    "null_test_df = pd.DataFrame(\n",
    "    np.zeros((len(test_null_index), len(topics))),\n",
    "    index=test_null_index,\n",
    "    columns=topics\n",
    ")\n",
    "\n",
    "test_sub_df = test_sub_df.append(null_test_df)\n",
    "test_sub_df = test_sub_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 9627 (0.5), 14297 (0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12622.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14432.0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13897.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7581.000000\n",
       "mean      882.691070\n",
       "std       621.585386\n",
       "min         0.000000\n",
       "25%       552.000000\n",
       "50%       770.000000\n",
       "75%      1026.000000\n",
       "max      8171.000000\n",
       "Name: bodyText, dtype: float64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_word_indices.map(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1382.0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_word_indices.map(len).quantile(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1223"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df.ix['TestData_04490'].bodyText.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'main_output_f1_micro'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-db68406f0e0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'main_output_f1_micro'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'main_output_f1_micro'"
     ]
    }
   ],
   "source": [
    "hist.history['main_output_f1_micro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94731/94731 [==============================] - 1s - loss: 1.8792 - acc: 0.6781 - f1_micro: 0.6537 - val_loss: 1.5039 - val_acc: 0.7408 - val_f1_micro: 0.6539\n"
     ]
    }
   ],
   "source": [
    "print '94731/94731 [==============================] - 1s - loss: 1.8792 - acc: 0.6781 - f1_micro: 0.6537 - val_loss: 1.5039 - val_acc: 0.7408 - val_f1_micro: 0.6539'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_filename = 'tfidf_wv_300-fs_300-lsi_300-deep_stack_net-epochs_160-f1_0.6537-data_2010_2014-val_data_2014-thresh_{}-with_sc_wv_fs_lsi.csv'.format(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_sub_df.astype(int).reset_index().rename(\n",
    "    columns={'index': 'id'}\n",
    ").sort_values('id').to_csv(\n",
    "    sub_filename, \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7581, 160)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TestData_04490\tThe World Health Organisation has convened an ...\t[]\t28-01-2016\n",
    "TestData_04550\tSpraying pesticides will fail to deal with the...\t[]\t02-02-2016\n",
    "TestData_05683\tViolent protests at Trump rally in California ...\t[]\t03-06-2016\n",
    "TestData_05869\tLast weekend, we saw the darkest side of human...\t[]\t17-06-2016\n",
    "TestData_06148\tAs dusk falls over Copacabana beach, Ubira San...\t[]\t16-07-2016\n",
    "TestData_06291\tIt is 3pm and yet another patient is brought t...\t[]\t27-07-2016\n",
    "TestData_06610\tHuddled around their hives, beekeepers around ...\t[]\t04-09-2016\n",
    "TestData_06708\tA United Nations high-level panel on access to...\t[]\t14-09-2016\n",
    "TestData_07263\tWHO: Zika virus is no longer a world threat Th...\t[]\t19-11-2016\n",
    "TestData_07478\t1 World Health Organisation declares a public ...\t[]\t18-12-2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "guncrime        1.0\n",
       "usguncontrol    1.0\n",
       "Name: TestData_05869, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = 5868\n",
    "test_sub_df.iloc[ix][test_sub_df.iloc[ix] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36 ms, sys: 0 ns, total: 36 ms\n",
      "Wall time: 32.6 ms\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# adjust_index = 0\n",
    "# # valid_test_feature_vec found below!\n",
    "# test_values = np.zeros([test_df.shape[0], len(topics)])\n",
    "# for ix, pred in enumerate(main_test_probas):\n",
    "#     if ix in skip_index:\n",
    "#         test_values[ix] = np.nan\n",
    "#         # Increment adjust index so that we have the correct index for other samples\n",
    "#         adjust_index += 1\n",
    "#         continue\n",
    "\n",
    "#     for v in get_classes(pred, thresh=0.05):\n",
    "#         test_values[ix + adjust_index][v] = 1\n",
    "\n",
    "# test_sub_df = pd.DataFrame(test_values, columns=sorted(topics), index=test_df.index)\n",
    "\n",
    "# q = test_sub_df.sum(axis=1)\n",
    "# assert(len(q[q.isnull()].index.difference(test_null_index)) == 0)\n",
    "\n",
    "# test_sub_df = test_sub_df.fillna(0)\n",
    "\n",
    "# # for i in test_feature_vec[test_feature_vec.isnull()].index:\n",
    "# #     test_sub_df.ix[i] = np.zeros(len(topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestData_02543    0.0\n",
       "TestData_05012    0.0\n",
       "TestData_05830    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.ix[test_null_index].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11656.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sub_df.astype(int).reset_index().rename(\n",
    "    columns={'index': 'id'}\n",
    ").sort_values('id').to_csv(\n",
    "    'lstm_300-word2vec_300-fasttext_300-maxlen_500-dense_64_64_64-cat_cross-epoch_210-batch_size_750-val_main_output_f1_micro_0.5760-main_output_f1_micro_0.5751-main_output_loss_0.9143-data_2010_2013-val_data_2014-thresh_0.05.csv', \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: zikavirus, dtype: float64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = test_sub_df['zikavirus']\n",
    "e[e==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14328"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_submission = pd.read_csv('basic_nn_submission_0.649_accuracy_multi_class.csv')\n",
    "top_submission.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9280"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_index_lstm_sub = pd.read_csv('lstm.2014b_training_700_maxlen_64cell_100epochs_0.0025_threshold.csv')\n",
    "wrong_index_lstm_sub.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34952"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_sub = pd.read_csv('basic_nn_submission_full_training_data_0.9958_validation_accuracy_binary_crossentropy.csv')\n",
    "some_sub.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2197, 160)\n",
      "(3957, 160)\n",
      "(12, 160)\n",
      "(1503, 160)\n"
     ]
    }
   ],
   "source": [
    "print top_submission.set_index('id')[top_submission.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print wrong_index_lstm_sub.set_index('id')[wrong_index_lstm_sub.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print some_sub.set_index('id')[some_sub.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print test_sub_df[test_sub_df.sum(axis=1) == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestData_00011     0\n",
       "TestData_00012     0\n",
       "TestData_00015     0\n",
       "TestData_00027     3\n",
       "TestData_00029     0\n",
       "TestData_00038     1\n",
       "TestData_00042     5\n",
       "TestData_00053     4\n",
       "TestData_00056     1\n",
       "TestData_00060     1\n",
       "TestData_00066     0\n",
       "TestData_00085     0\n",
       "TestData_00087     1\n",
       "TestData_00090     0\n",
       "TestData_00092     0\n",
       "TestData_00107     3\n",
       "TestData_00111     0\n",
       "TestData_00114     0\n",
       "TestData_00115     1\n",
       "TestData_00118     0\n",
       "TestData_00119     0\n",
       "TestData_00121     0\n",
       "TestData_00123     0\n",
       "TestData_00125     0\n",
       "TestData_00127     0\n",
       "TestData_00128     1\n",
       "TestData_00139     1\n",
       "TestData_00140     1\n",
       "TestData_00144     0\n",
       "TestData_00147     2\n",
       "                  ..\n",
       "TestData_07445     0\n",
       "TestData_07456     3\n",
       "TestData_07461     1\n",
       "TestData_07462     4\n",
       "TestData_07465     0\n",
       "TestData_07468     0\n",
       "TestData_07471     1\n",
       "TestData_07475     0\n",
       "TestData_07486    10\n",
       "TestData_07495     1\n",
       "TestData_07509     0\n",
       "TestData_07514     3\n",
       "TestData_07515     1\n",
       "TestData_07523     0\n",
       "TestData_07533     2\n",
       "TestData_07534     2\n",
       "TestData_07542     1\n",
       "TestData_07544     2\n",
       "TestData_07545     0\n",
       "TestData_07552     2\n",
       "TestData_07556     5\n",
       "TestData_07563     1\n",
       "TestData_07565     0\n",
       "TestData_07566     0\n",
       "TestData_07569     0\n",
       "TestData_07571     3\n",
       "TestData_07572     1\n",
       "TestData_07579     6\n",
       "TestData_07580     2\n",
       "TestData_07581     3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_submission.set_index('id').ix[q[q == 0].index].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1222,)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.sum(axis=1)\n",
    "q[q==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7581.000000\n",
       "mean        2.160929\n",
       "std         1.739411\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         2.000000\n",
       "75%         3.000000\n",
       "max        13.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = trainingY.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    236286.000000\n",
       "mean          1.392787\n",
       "std           0.762577\n",
       "min           1.000000\n",
       "25%           1.000000\n",
       "50%           1.000000\n",
       "75%           2.000000\n",
       "max          15.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bodyText</th>\n",
       "      <th>topics</th>\n",
       "      <th>webPublicationDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TestData_03241</th>\n",
       "      <td>A special British police unit was put on stand...</td>\n",
       "      <td>[]</td>\n",
       "      <td>15-11-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_04088</th>\n",
       "      <td>The youngest convict in a fatal gang-rape in N...</td>\n",
       "      <td>[]</td>\n",
       "      <td>20-12-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_06306</th>\n",
       "      <td>Former New York City mayor Rudy Giuliani has s...</td>\n",
       "      <td>[]</td>\n",
       "      <td>28-07-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_06083</th>\n",
       "      <td>John Cantlie, the British journalist who has b...</td>\n",
       "      <td>[]</td>\n",
       "      <td>13-07-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_05896</th>\n",
       "      <td>Lawyers for the companies that manufactured an...</td>\n",
       "      <td>[]</td>\n",
       "      <td>20-06-2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         bodyText topics  \\\n",
       "TestData_03241  A special British police unit was put on stand...     []   \n",
       "TestData_04088  The youngest convict in a fatal gang-rape in N...     []   \n",
       "TestData_06306  Former New York City mayor Rudy Giuliani has s...     []   \n",
       "TestData_06083  John Cantlie, the British journalist who has b...     []   \n",
       "TestData_05896  Lawyers for the companies that manufactured an...     []   \n",
       "\n",
       "               webPublicationDate  \n",
       "TestData_03241         15-11-2015  \n",
       "TestData_04088         20-12-2015  \n",
       "TestData_06306         28-07-2016  \n",
       "TestData_06083         13-07-2016  \n",
       "TestData_05896         20-06-2016  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ix = 'TestData_03241'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "london                1.0\n",
       "metropolitanpolice    1.0\n",
       "police                1.0\n",
       "uksecurity            1.0\n",
       "Name: TestData_03241, dtype: float64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ukcrime    1\n",
       "Name: TestData_04088, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = top_submission.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "humanrights    1\n",
       "india          1\n",
       "protest        1\n",
       "ukcrime        1\n",
       "Name: TestData_04088, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = some_sub.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "humanrights    1\n",
       "Name: TestData_02924, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = wrong_index_lstm_sub.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Counter-terrorism policy\n",
    " \n",
    "Foreign policy\n",
    " \n",
    "Defence policy\n",
    " \n",
    "Islamic State\n",
    " \n",
    "Syria\n",
    " \n",
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = trainingY.sum()\n",
    "unseen_topics = s[s.isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activism',\n",
       " 'bastilledaytruckattack',\n",
       " 'berlinchristmasmarketattack',\n",
       " 'brusselsattacks',\n",
       " 'charliehebdoattack',\n",
       " 'francetrainattack',\n",
       " 'munichshooting',\n",
       " 'orlandoterrorattack',\n",
       " 'parisattacks',\n",
       " 'peaceandreconciliation',\n",
       " 'sanbernardinoshooting',\n",
       " 'tunisiaattack2015',\n",
       " 'turkeycoupattempt',\n",
       " 'zikavirus'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(topics).intersection(unseen_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activism\n",
      "afghanistan\n",
      "aid\n",
      "algerianhostagecrisis\n",
      "alqaida\n",
      "alshabaab\n",
      "antiwar\n",
      "arabandmiddleeastprotests\n",
      "armstrade\n",
      "australianguncontrol\n",
      "australiansecurityandcounterterrorism\n",
      "bastilledaytruckattack\n",
      "belgium\n",
      "berlinchristmasmarketattack\n",
      "bigdata\n",
      "biometrics\n",
      "bokoharam\n",
      "bostonmarathonbombing\n",
      "britisharmy\n",
      "brusselsattacks\n",
      "cameroon\n",
      "carers\n",
      "charliehebdoattack\n",
      "chemicalweapons\n",
      "clusterbombs\n",
      "cobra\n",
      "conflictanddevelopment\n",
      "controversy\n",
      "criminaljustice\n",
      "cybercrime\n",
      "cyberwar\n",
      "darknet\n",
      "dataprotection\n",
      "debate\n",
      "defence\n",
      "deflation\n",
      "drones\n",
      "drugs\n",
      "drugspolicy\n",
      "drugstrade\n",
      "earthquakes\n",
      "ebola\n",
      "economy\n",
      "egypt\n",
      "encryption\n",
      "energy\n",
      "espionage\n",
      "ethics\n",
      "europeanarrestwarrant\n",
      "europeancourtofhumanrights\n",
      "events\n",
      "extradition\n",
      "famine\n",
      "farright\n",
      "firefighters\n",
      "forensicscience\n",
      "france\n",
      "francetrainattack\n",
      "freedomofspeech\n",
      "genevaconventions\n",
      "germany\n",
      "guncrime\n",
      "hacking\n",
      "hashtags\n",
      "helicoptercrashes\n",
      "humanitarianresponse\n",
      "humanrights\n",
      "humanrightsact\n",
      "humantrafficking\n",
      "immigration\n",
      "india\n",
      "indonesia\n",
      "internallydisplacedpeople\n",
      "internationalcourtofjustice\n",
      "internationalcriminaljustice\n",
      "internetsafety\n",
      "iraq\n",
      "isis\n",
      "israel\n",
      "jordan\n",
      "jubilee\n",
      "judiciary\n",
      "july7\n",
      "justiceandsecurity\n",
      "kenya\n",
      "knifecrime\n",
      "lebanon\n",
      "libya\n",
      "localgovernment\n",
      "logistics\n",
      "london\n",
      "londonriots\n",
      "malaysia\n",
      "mali\n",
      "malware\n",
      "metropolitanpolice\n",
      "middleeastpeacetalks\n",
      "migration\n",
      "military\n",
      "ministryofdefence\n",
      "morocco\n",
      "mrsa\n",
      "mumbaiterrorattacks\n",
      "munichshooting\n",
      "naturaldisasters\n",
      "nigeria\n",
      "nuclearweapons\n",
      "occupy\n",
      "organisedcrime\n",
      "orlandoterrorattack\n",
      "osamabinladen\n",
      "paris\n",
      "parisattacks\n",
      "peaceandreconciliation\n",
      "philippines\n",
      "piracy\n",
      "planecrashes\n",
      "police\n",
      "protest\n",
      "refugees\n",
      "religion\n",
      "retirementage\n",
      "rio20earthsummit\n",
      "royalairforce\n",
      "royalnavy\n",
      "russia\n",
      "sanbernardinoshooting\n",
      "saudiarabia\n",
      "september11\n",
      "slavery\n",
      "somalia\n",
      "southafrica\n",
      "southchinasea\n",
      "stopandsearch\n",
      "surveillance\n",
      "sydneysiege\n",
      "syria\n",
      "taliban\n",
      "terrorism\n",
      "thailand\n",
      "torture\n",
      "traincrashes\n",
      "transport\n",
      "tunisiaattack2015\n",
      "turkey\n",
      "turkeycoupattempt\n",
      "ukcrime\n",
      "uksecurity\n",
      "uksupremecourt\n",
      "undercoverpoliceandpolicing\n",
      "unitednations\n",
      "usguncontrol\n",
      "values\n",
      "warcrimes\n",
      "warreporting\n",
      "weaponstechnology\n",
      "womeninbusiness\n",
      "woolwichattack\n",
      "worldmigration\n",
      "zikavirus\n"
     ]
    }
   ],
   "source": [
    "for i in topics:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsolatorio/ml-ai/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3445929"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(wvmodel['zika'], np.vstack(test_wvec.dropna())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsolatorio/ml-ai/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.38107796869050226"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(fsmodel['zika'], np.vstack(test_fvec.dropna())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              The World Health Organisation has convened an ...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           28-01-2016\n",
       "Name: TestData_04490, dtype: object"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[4488 + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              The United Nations security council has called...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           17-09-2016\n",
       "Name: TestData_06730, dtype: object"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[6727 + 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              We are deeply concerned that the counter-terro...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           02-02-2015\n",
       "Name: TestData_00360, dtype: object"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[359]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drugstrade    1.0\n",
       "Name: TestData_04490, dtype: float64"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.iloc[4488 + 1]\n",
    "q[q > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
