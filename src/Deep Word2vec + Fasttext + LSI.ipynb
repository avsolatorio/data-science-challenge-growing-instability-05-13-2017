{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from growing_instability_lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub = pd.read_csv('../data/sampleSubmission.csv')\n",
    "topics = sorted(set(sample_sub.columns.difference(['id'])))\n",
    "\n",
    "topic2actual = {}\n",
    "for i in sample_sub.columns:\n",
    "    if 'id' == i:\n",
    "        continue\n",
    "    topic2actual[i] = segment(i)\n",
    "    \n",
    "target_columns = sorted(topics)\n",
    "len(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.97 s, sys: 2.36 s, total: 12.3 s\n",
      "Wall time: 12.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wvec_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'wvec_trainingX')\n",
    "fvec_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'fvec_trainingX')\n",
    "\n",
    "tfidf_wvec_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'tfidf_wvec_trainingX')\n",
    "tfidf_fvec_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'tfidf_fvec_trainingX')\n",
    "tfidf_lsi_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'tfidf_lsi_trainingX')\n",
    "\n",
    "word2idx_trainingX = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'word2idx_trainingX')\n",
    "_word2idx = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', '_word2idx')\n",
    "trainingY = pd.read_hdf('training_data_wv_fs_lsi_no_stopwords.hdf', 'trainingY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.1 s, sys: 84 ms, total: 12.2 s\n",
      "Wall time: 12.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ind2word = {j:i for i, j in _word2idx.iteritems()}\n",
    "ind2class = dict(enumerate(topics))\n",
    "class2ind = {j: i for i, j in ind2class.items()}\n",
    "\n",
    "num_samples = trainingY.shape[0]\n",
    "\n",
    "# ---------------------------------\n",
    "training_X = word2idx_trainingX.head(num_samples)\n",
    "training_Y = pd.DataFrame(zip(*np.where(trainingY.head(num_samples) == 1)), columns=['iloc', 'topics'])\n",
    "\n",
    "training_WV = wvec_trainingX.head(num_samples)\n",
    "training_FS = fvec_trainingX.head(num_samples)\n",
    "\n",
    "training_tfidf_WV = tfidf_wvec_trainingX.head(num_samples)\n",
    "training_tfidf_FS = tfidf_fvec_trainingX.head(num_samples)\n",
    "training_tfidf_LSI = tfidf_lsi_trainingX.head(num_samples)\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "training_Y = training_Y.groupby('iloc')['topics'].apply(list)\n",
    "training_Y.index = trainingY.head(num_samples).index\n",
    "\n",
    "indices = sorted(training_Y.index[training_Y.index.str.contains('^201[0-9]')])\n",
    "# np.random.shuffle(indices)\n",
    "indices = pd.Index(indices)\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "training_X = training_X.ix[indices]\n",
    "training_Y = training_Y.ix[indices]\n",
    "\n",
    "training_WV = training_WV.ix[indices]\n",
    "training_FS = training_FS.ix[indices]\n",
    "\n",
    "training_tfidf_WV = training_tfidf_WV.ix[indices]\n",
    "training_tfidf_FS = training_tfidf_FS.ix[indices]\n",
    "training_tfidf_LSI = training_tfidf_LSI.ix[indices]\n",
    "# ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 7.15 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wv_sc = StandardScaler()\n",
    "fs_sc = StandardScaler()\n",
    "\n",
    "tfidf_wv_sc = StandardScaler()\n",
    "tfidf_fs_sc = StandardScaler()\n",
    "tfidf_lsi_sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.72 s, sys: 268 ms, total: 3.99 s\n",
      "Wall time: 3.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "maxlen = 500\n",
    "\n",
    "\n",
    "def build_target(y, size):\n",
    "    e = np.zeros(size)\n",
    "    e[y] = 1\n",
    "    return e\n",
    "\n",
    "\n",
    "def build_input_output_data(X, WV, FS, TWV, TFS, TLSI, Y, maxlen):\n",
    "    x = sequence.pad_sequences(X, maxlen=maxlen)\n",
    "    y = np.vstack(Y.map(lambda x: build_target(x, len(topics))))\n",
    "\n",
    "    wv = np.vstack(WV)\n",
    "    fs = np.vstack(FS)\n",
    "\n",
    "    twv = np.vstack(TWV)\n",
    "    tfs = np.vstack(TFS)\n",
    "    tlsi = np.vstack(TLSI)\n",
    "\n",
    "    return x, wv, fs, twv, tfs, tlsi, y\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "train_ix = training_Y.index.str.contains('^201[0-4]')\n",
    "val_ix = training_Y.index.str.contains('^2014[b]')\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "x_train, wv_train, fs_train, tfidf_wv_train, tfidf_fs_train, tfidf_lsi_train, y_train = build_input_output_data(\n",
    "    training_X.ix[train_ix],\n",
    "\n",
    "    training_WV.ix[train_ix],\n",
    "    training_FS.ix[train_ix],\n",
    "\n",
    "    training_tfidf_WV.ix[train_ix],\n",
    "    training_tfidf_FS.ix[train_ix],\n",
    "    training_tfidf_LSI.ix[train_ix],\n",
    "\n",
    "    training_Y.ix[train_ix],\n",
    "    maxlen=maxlen\n",
    ")\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "x_val, wv_val, fs_val, tfidf_wv_val, tfidf_fs_val, tfidf_lsi_val, y_val = build_input_output_data(\n",
    "    training_X.ix[val_ix],\n",
    "\n",
    "    training_WV.ix[val_ix],\n",
    "    training_FS.ix[val_ix],\n",
    "\n",
    "    training_tfidf_WV.ix[val_ix],\n",
    "    training_tfidf_FS.ix[val_ix],\n",
    "    training_tfidf_LSI.ix[val_ix],\n",
    "\n",
    "    training_Y.ix[val_ix],\n",
    "    maxlen=maxlen\n",
    ")\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "wv_train = wv_sc.fit_transform(wv_train)\n",
    "fs_train = fs_sc.fit_transform(fs_train)\n",
    "\n",
    "tfidf_wv_train = tfidf_wv_sc.fit_transform(tfidf_wv_train)\n",
    "tfidf_fs_train = tfidf_fs_sc.fit_transform(tfidf_fs_train)\n",
    "tfidf_lsi_train = tfidf_lsi_sc.fit_transform(tfidf_lsi_train)\n",
    "# ---------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "wv_val = wv_sc.transform(wv_val)\n",
    "fs_val = fs_sc.transform(fs_val)\n",
    "\n",
    "tfidf_wv_val = tfidf_wv_sc.transform(tfidf_wv_val)\n",
    "tfidf_fs_val = tfidf_fs_sc.transform(tfidf_fs_val)\n",
    "tfidf_lsi_val = tfidf_lsi_sc.transform(tfidf_lsi_val)\n",
    "# ---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((94731,), (9424,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_Y.shape, training_Y.ix[training_Y.index.str.contains('^2014[b]')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: bodyText, dtype: int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = training_tfidf_LSI.ix[train_ix].map(len)\n",
    "v[v != 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as K\n",
    "import keras.backend as KB\n",
    "\n",
    "\n",
    "def f1_micro(y_true, y_pred):\n",
    "    TP = K.metrics.true_positives(y_true, K.round(y_pred))\n",
    "    FP = K.metrics.false_positives(y_true, K.round(y_pred))\n",
    "    FN = K.metrics.false_negatives(y_true, K.round(y_pred))\n",
    "    \n",
    "    p = K.reduce_sum(TP) / (K.reduce_sum(TP) + K.reduce_sum(FP))\n",
    "    r = K.reduce_sum(TP) / (K.reduce_sum(TP) + K.reduce_sum(FN))\n",
    "    \n",
    "    return (2.0 * p * r) / (p + r)\n",
    "\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "\n",
    "    # Count positive samples.\n",
    "    c1 = KB.sum(KB.round(KB.clip(y_true * y_pred, 0, 1)))\n",
    "    c2 = KB.sum(KB.round(KB.clip(y_pred, 0, 1)))\n",
    "    c3 = KB.sum(KB.round(KB.clip(y_true, 0, 1)))\n",
    "\n",
    "    # If there are no true samples, fix the F1 score at 0.\n",
    "    if c3 == 0:\n",
    "        return 0\n",
    "\n",
    "    # How many selected items are relevant?\n",
    "    precision = c1 / c2\n",
    "\n",
    "    # How many relevant items are selected?\n",
    "    recall = c1 / c3\n",
    "\n",
    "    # Calculate f1_score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense, Dropout, Convolution1D, MaxPooling1D, Flatten\n",
    "from keras.models import Model\n",
    "import itertools as it\n",
    "\n",
    "\n",
    "def build_deep_input_stack(input_node):\n",
    "    x = Dense(128, activation='relu')(input_node)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def entangle_inputs(input_nodes=[]):\n",
    "    assert(len(input_nodes) > 1)\n",
    "    \n",
    "    entangled_inputs = []\n",
    "\n",
    "    for n1, n2 in it.combinations(input_nodes, 2):\n",
    "        entangled_inputs.append(\n",
    "            keras.layers.dot([n1, n2], 1)\n",
    "        )\n",
    "    \n",
    "    return entangled_inputs\n",
    "\n",
    "\n",
    "wv_input = Input(shape=(300,), name='wv_input')\n",
    "fs_input = Input(shape=(300,), name='fs_input')\n",
    "\n",
    "tfidf_wv_input = Input(shape=(300,), name='tfidf_wv_input')\n",
    "tfidf_fs_input = Input(shape=(300,), name='tfidf_fs_input')\n",
    "tfidf_lsi_input = Input(shape=(300,), name='tfidf_lsi_input')\n",
    "\n",
    "\n",
    "wv_x = build_deep_input_stack(wv_input)\n",
    "fs_x = build_deep_input_stack(fs_input)\n",
    "tfidf_wv_x = build_deep_input_stack(tfidf_wv_input)\n",
    "tfidf_fs_x = build_deep_input_stack(tfidf_fs_input)\n",
    "tfidf_lsi_x = build_deep_input_stack(tfidf_wv_input)\n",
    "\n",
    "stacked_inputs_x = [wv_x, fs_x, tfidf_wv_x, tfidf_fs_x, tfidf_lsi_x]\n",
    "# entangled_inputs_x = entangle_inputs(stacked_inputs_x)\n",
    "\n",
    "x = keras.layers.concatenate(stacked_inputs_x)  # + entangled_inputs_x)\n",
    "\n",
    "# We stack a deep densely-connected network on top\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "# And finally we add the main logistic regression layer\n",
    "main_output = Dense(len(class2ind), activation='sigmoid', name='main_output')(x)\n",
    "\n",
    "model = Model(\n",
    "    inputs=[\n",
    "        wv_input,\n",
    "        fs_input,\n",
    "        tfidf_wv_input,\n",
    "        tfidf_fs_input,\n",
    "        tfidf_lsi_input,\n",
    "    ],\n",
    "    outputs=[main_output]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "wv_input (InputLayer)            (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "fs_input (InputLayer)            (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "tfidf_wv_input (InputLayer)      (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "tfidf_fs_input (InputLayer)      (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_53 (Dense)                 (None, 128)           38528                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_55 (Dense)                 (None, 128)           38528                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_57 (Dense)                 (None, 128)           38528                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_59 (Dense)                 (None, 128)           38528                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_61 (Dense)                 (None, 128)           38528                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)             (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)             (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)             (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)             (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)             (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_54 (Dense)                 (None, 512)           66048                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_56 (Dense)                 (None, 512)           66048                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_58 (Dense)                 (None, 512)           66048                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_60 (Dense)                 (None, 512)           66048                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_62 (Dense)                 (None, 512)           66048                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)             (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)             (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)             (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_60 (Dropout)             (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)             (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)      (None, 2560)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_63 (Dense)                 (None, 128)           327808                                       \n",
      "____________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)             (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_64 (Dense)                 (None, 256)           33024                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)             (None, 256)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_65 (Dense)                 (None, 128)           32896                                        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)             (None, 128)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "main_output (Dense)              (None, 160)           20640                                        \n",
      "====================================================================================================\n",
      "Total params: 937,248\n",
      "Trainable params: 937,248\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={'main_output': 'categorical_crossentropy'},\n",
    "    loss_weights={'main_output': 1.},\n",
    "    metrics=['accuracy', f1_micro]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.callbacks import EarlyStopping\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "# model.fit(X, y, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_training_inputs(wv, fs, tfidf_wv, tfidf_fs, tfidf_lsi):\n",
    "    training_inputs = {\n",
    "        'wv_input': wv,\n",
    "        'fs_input': fs,\n",
    "        'tfidf_wv_input': tfidf_wv,\n",
    "        'tfidf_fs_input': tfidf_fs,\n",
    "        'tfidf_lsi_input': tfidf_lsi,\n",
    "    }\n",
    "    \n",
    "    return training_inputs\n",
    "    \n",
    "\n",
    "training_inputs = build_training_inputs(\n",
    "    wv_train,\n",
    "    fs_train,\n",
    "    tfidf_wv_train,\n",
    "    tfidf_fs_train,\n",
    "    tfidf_lsi_train,\n",
    ")\n",
    "\n",
    "training_outputs = {\n",
    "    'main_output': y_train,\n",
    "}\n",
    "\n",
    "validation_data=(\n",
    "    build_training_inputs(\n",
    "        wv_val,\n",
    "        fs_val,\n",
    "        tfidf_wv_val,\n",
    "        tfidf_fs_val,\n",
    "        tfidf_lsi_val,\n",
    "    ),\n",
    "    {\n",
    "        'main_output': y_val,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/100\n",
      "94731/94731 [==============================] - 2s - loss: 1.8748 - acc: 0.6773 - f1_micro: 0.6541 - val_loss: 1.4968 - val_acc: 0.7454 - val_f1_micro: 0.6542\n",
      "Epoch 2/100\n",
      "94731/94731 [==============================] - 2s - loss: 1.8718 - acc: 0.6780 - f1_micro: 0.6544 - val_loss: 1.4974 - val_acc: 0.7366 - val_f1_micro: 0.6545\n",
      "Epoch 3/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8809 - acc: 0.6768 - f1_micro: 0.6547 - val_loss: 1.5022 - val_acc: 0.7398 - val_f1_micro: 0.6548\n",
      "Epoch 4/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8741 - acc: 0.6792 - f1_micro: 0.6550 - val_loss: 1.5025 - val_acc: 0.7423 - val_f1_micro: 0.6551\n",
      "Epoch 5/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8734 - acc: 0.6759 - f1_micro: 0.6552 - val_loss: 1.4876 - val_acc: 0.7466 - val_f1_micro: 0.6554\n",
      "Epoch 6/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8768 - acc: 0.6768 - f1_micro: 0.6555 - val_loss: 1.4991 - val_acc: 0.7359 - val_f1_micro: 0.6557\n",
      "Epoch 7/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8701 - acc: 0.6780 - f1_micro: 0.6559 - val_loss: 1.4979 - val_acc: 0.7440 - val_f1_micro: 0.6560\n",
      "Epoch 8/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8780 - acc: 0.6770 - f1_micro: 0.6562 - val_loss: 1.4995 - val_acc: 0.7449 - val_f1_micro: 0.6563\n",
      "Epoch 9/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8717 - acc: 0.6783 - f1_micro: 0.6565 - val_loss: 1.4993 - val_acc: 0.7420 - val_f1_micro: 0.6566\n",
      "Epoch 10/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8801 - acc: 0.6772 - f1_micro: 0.6567 - val_loss: 1.4926 - val_acc: 0.7388 - val_f1_micro: 0.6569\n",
      "Epoch 11/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8615 - acc: 0.6776 - f1_micro: 0.6570 - val_loss: 1.4879 - val_acc: 0.7502 - val_f1_micro: 0.6572\n",
      "Epoch 12/100\n",
      "94731/94731 [==============================] - 2s - loss: 1.8705 - acc: 0.6792 - f1_micro: 0.6573 - val_loss: 1.4796 - val_acc: 0.7447 - val_f1_micro: 0.6575\n",
      "Epoch 13/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8670 - acc: 0.6771 - f1_micro: 0.6576 - val_loss: 1.4898 - val_acc: 0.7445 - val_f1_micro: 0.6578\n",
      "Epoch 14/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8650 - acc: 0.6804 - f1_micro: 0.6579 - val_loss: 1.4911 - val_acc: 0.7342 - val_f1_micro: 0.6581\n",
      "Epoch 15/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8640 - acc: 0.6781 - f1_micro: 0.6582 - val_loss: 1.4801 - val_acc: 0.7442 - val_f1_micro: 0.6584\n",
      "Epoch 16/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8594 - acc: 0.6786 - f1_micro: 0.6585 - val_loss: 1.4878 - val_acc: 0.7486 - val_f1_micro: 0.6587\n",
      "Epoch 17/100\n",
      "94731/94731 [==============================] - 2s - loss: 1.8691 - acc: 0.6756 - f1_micro: 0.6588 - val_loss: 1.4866 - val_acc: 0.7381 - val_f1_micro: 0.6589\n",
      "Epoch 18/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8654 - acc: 0.6772 - f1_micro: 0.6591 - val_loss: 1.4910 - val_acc: 0.7525 - val_f1_micro: 0.6592\n",
      "Epoch 19/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8673 - acc: 0.6798 - f1_micro: 0.6594 - val_loss: 1.4768 - val_acc: 0.7490 - val_f1_micro: 0.6595\n",
      "Epoch 20/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8559 - acc: 0.6790 - f1_micro: 0.6597 - val_loss: 1.4766 - val_acc: 0.7479 - val_f1_micro: 0.6598\n",
      "Epoch 21/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8534 - acc: 0.6789 - f1_micro: 0.6600 - val_loss: 1.4794 - val_acc: 0.7482 - val_f1_micro: 0.6601\n",
      "Epoch 22/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8607 - acc: 0.6785 - f1_micro: 0.6602 - val_loss: 1.4783 - val_acc: 0.7501 - val_f1_micro: 0.6604\n",
      "Epoch 23/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8566 - acc: 0.6810 - f1_micro: 0.6605 - val_loss: 1.4821 - val_acc: 0.7488 - val_f1_micro: 0.6606\n",
      "Epoch 24/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8540 - acc: 0.6807 - f1_micro: 0.6608 - val_loss: 1.4740 - val_acc: 0.7492 - val_f1_micro: 0.6609\n",
      "Epoch 25/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8608 - acc: 0.6790 - f1_micro: 0.6610 - val_loss: 1.4731 - val_acc: 0.7506 - val_f1_micro: 0.6612\n",
      "Epoch 26/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8508 - acc: 0.6804 - f1_micro: 0.6613 - val_loss: 1.4746 - val_acc: 0.7480 - val_f1_micro: 0.6615\n",
      "Epoch 27/100\n",
      "94731/94731 [==============================] - 2s - loss: 1.8575 - acc: 0.6800 - f1_micro: 0.6616 - val_loss: 1.4738 - val_acc: 0.7501 - val_f1_micro: 0.6617\n",
      "Epoch 28/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8547 - acc: 0.6801 - f1_micro: 0.6619 - val_loss: 1.4742 - val_acc: 0.7501 - val_f1_micro: 0.6620\n",
      "Epoch 29/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8438 - acc: 0.6822 - f1_micro: 0.6621 - val_loss: 1.4745 - val_acc: 0.7411 - val_f1_micro: 0.6623\n",
      "Epoch 30/100\n",
      "94731/94731 [==============================] - 2s - loss: 1.8538 - acc: 0.6809 - f1_micro: 0.6624 - val_loss: 1.4771 - val_acc: 0.7459 - val_f1_micro: 0.6625\n",
      "Epoch 31/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8534 - acc: 0.6804 - f1_micro: 0.6627 - val_loss: 1.4731 - val_acc: 0.7418 - val_f1_micro: 0.6628\n",
      "Epoch 32/100\n",
      "94731/94731 [==============================] - 2s - loss: 1.8591 - acc: 0.6781 - f1_micro: 0.6629 - val_loss: 1.4716 - val_acc: 0.7465 - val_f1_micro: 0.6631\n",
      "Epoch 33/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8451 - acc: 0.6809 - f1_micro: 0.6632 - val_loss: 1.4763 - val_acc: 0.7472 - val_f1_micro: 0.6633\n",
      "Epoch 34/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8467 - acc: 0.6804 - f1_micro: 0.6634 - val_loss: 1.4722 - val_acc: 0.7494 - val_f1_micro: 0.6636\n",
      "Epoch 35/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8498 - acc: 0.6822 - f1_micro: 0.6637 - val_loss: 1.4686 - val_acc: 0.7508 - val_f1_micro: 0.6638\n",
      "Epoch 36/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8499 - acc: 0.6817 - f1_micro: 0.6639 - val_loss: 1.4630 - val_acc: 0.7427 - val_f1_micro: 0.6641\n",
      "Epoch 37/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8467 - acc: 0.6802 - f1_micro: 0.6642 - val_loss: 1.4650 - val_acc: 0.7454 - val_f1_micro: 0.6643\n",
      "Epoch 38/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8489 - acc: 0.6814 - f1_micro: 0.6644 - val_loss: 1.4656 - val_acc: 0.7413 - val_f1_micro: 0.6645\n",
      "Epoch 39/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8549 - acc: 0.6811 - f1_micro: 0.6647 - val_loss: 1.4630 - val_acc: 0.7471 - val_f1_micro: 0.6648\n",
      "Epoch 40/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8418 - acc: 0.6817 - f1_micro: 0.6649 - val_loss: 1.4561 - val_acc: 0.7415 - val_f1_micro: 0.6650\n",
      "Epoch 41/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8419 - acc: 0.6807 - f1_micro: 0.6652 - val_loss: 1.4673 - val_acc: 0.7486 - val_f1_micro: 0.6653\n",
      "Epoch 42/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8380 - acc: 0.6833 - f1_micro: 0.6654 - val_loss: 1.4620 - val_acc: 0.7453 - val_f1_micro: 0.6655\n",
      "Epoch 43/100\n",
      "94731/94731 [==============================] - 2s - loss: 1.8385 - acc: 0.6831 - f1_micro: 0.6657 - val_loss: 1.4588 - val_acc: 0.7484 - val_f1_micro: 0.6658\n",
      "Epoch 44/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8447 - acc: 0.6805 - f1_micro: 0.6659 - val_loss: 1.4627 - val_acc: 0.7429 - val_f1_micro: 0.6660\n",
      "Epoch 45/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8428 - acc: 0.6819 - f1_micro: 0.6661 - val_loss: 1.4564 - val_acc: 0.7445 - val_f1_micro: 0.6662\n",
      "Epoch 46/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8447 - acc: 0.6828 - f1_micro: 0.6664 - val_loss: 1.4623 - val_acc: 0.7448 - val_f1_micro: 0.6665\n",
      "Epoch 47/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8467 - acc: 0.6821 - f1_micro: 0.6666 - val_loss: 1.4655 - val_acc: 0.7399 - val_f1_micro: 0.6667\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94731/94731 [==============================] - 1s - loss: 1.8308 - acc: 0.6842 - f1_micro: 0.6668 - val_loss: 1.4526 - val_acc: 0.7412 - val_f1_micro: 0.6670\n",
      "Epoch 49/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8403 - acc: 0.6817 - f1_micro: 0.6671 - val_loss: 1.4619 - val_acc: 0.7440 - val_f1_micro: 0.6672\n",
      "Epoch 50/100\n",
      "94731/94731 [==============================] - 2s - loss: 1.8411 - acc: 0.6822 - f1_micro: 0.6673 - val_loss: 1.4598 - val_acc: 0.7421 - val_f1_micro: 0.6674\n",
      "Epoch 51/100\n",
      "94731/94731 [==============================] - 2s - loss: 1.8315 - acc: 0.6821 - f1_micro: 0.6676 - val_loss: 1.4610 - val_acc: 0.7388 - val_f1_micro: 0.6677\n",
      "Epoch 52/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8366 - acc: 0.6816 - f1_micro: 0.6678 - val_loss: 1.4579 - val_acc: 0.7488 - val_f1_micro: 0.6679\n",
      "Epoch 53/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8399 - acc: 0.6819 - f1_micro: 0.6680 - val_loss: 1.4588 - val_acc: 0.7542 - val_f1_micro: 0.6681\n",
      "Epoch 54/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8390 - acc: 0.6826 - f1_micro: 0.6682 - val_loss: 1.4640 - val_acc: 0.7427 - val_f1_micro: 0.6683\n",
      "Epoch 55/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8277 - acc: 0.6842 - f1_micro: 0.6685 - val_loss: 1.4610 - val_acc: 0.7498 - val_f1_micro: 0.6686\n",
      "Epoch 56/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8313 - acc: 0.6828 - f1_micro: 0.6687 - val_loss: 1.4564 - val_acc: 0.7480 - val_f1_micro: 0.6688\n",
      "Epoch 57/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8389 - acc: 0.6818 - f1_micro: 0.6689 - val_loss: 1.4557 - val_acc: 0.7483 - val_f1_micro: 0.6690\n",
      "Epoch 58/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8344 - acc: 0.6815 - f1_micro: 0.6691 - val_loss: 1.4540 - val_acc: 0.7435 - val_f1_micro: 0.6693\n",
      "Epoch 59/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8395 - acc: 0.6819 - f1_micro: 0.6694 - val_loss: 1.4516 - val_acc: 0.7467 - val_f1_micro: 0.6695\n",
      "Epoch 60/100\n",
      "94731/94731 [==============================] - 2s - loss: 1.8321 - acc: 0.6824 - f1_micro: 0.6696 - val_loss: 1.4459 - val_acc: 0.7497 - val_f1_micro: 0.6697\n",
      "Epoch 61/100\n",
      "94731/94731 [==============================] - 2s - loss: 1.8333 - acc: 0.6843 - f1_micro: 0.6698 - val_loss: 1.4530 - val_acc: 0.7494 - val_f1_micro: 0.6699\n",
      "Epoch 62/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8291 - acc: 0.6843 - f1_micro: 0.6700 - val_loss: 1.4537 - val_acc: 0.7455 - val_f1_micro: 0.6701\n",
      "Epoch 63/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8261 - acc: 0.6829 - f1_micro: 0.6702 - val_loss: 1.4569 - val_acc: 0.7396 - val_f1_micro: 0.6703\n",
      "Epoch 64/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8281 - acc: 0.6828 - f1_micro: 0.6705 - val_loss: 1.4545 - val_acc: 0.7455 - val_f1_micro: 0.6706\n",
      "Epoch 65/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8267 - acc: 0.6839 - f1_micro: 0.6707 - val_loss: 1.4586 - val_acc: 0.7378 - val_f1_micro: 0.6708\n",
      "Epoch 66/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8290 - acc: 0.6833 - f1_micro: 0.6709 - val_loss: 1.4520 - val_acc: 0.7414 - val_f1_micro: 0.6710\n",
      "Epoch 67/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8255 - acc: 0.6830 - f1_micro: 0.6711 - val_loss: 1.4526 - val_acc: 0.7511 - val_f1_micro: 0.6712\n",
      "Epoch 68/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8304 - acc: 0.6845 - f1_micro: 0.6713 - val_loss: 1.4482 - val_acc: 0.7446 - val_f1_micro: 0.6714\n",
      "Epoch 69/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8286 - acc: 0.6842 - f1_micro: 0.6715 - val_loss: 1.4507 - val_acc: 0.7385 - val_f1_micro: 0.6716\n",
      "Epoch 70/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8283 - acc: 0.6827 - f1_micro: 0.6717 - val_loss: 1.4449 - val_acc: 0.7339 - val_f1_micro: 0.6718\n",
      "Epoch 71/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8294 - acc: 0.6826 - f1_micro: 0.6719 - val_loss: 1.4477 - val_acc: 0.7505 - val_f1_micro: 0.6720\n",
      "Epoch 72/100\n",
      "94731/94731 [==============================] - 2s - loss: 1.8247 - acc: 0.6834 - f1_micro: 0.6722 - val_loss: 1.4406 - val_acc: 0.7416 - val_f1_micro: 0.6723\n",
      "Epoch 73/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8201 - acc: 0.6838 - f1_micro: 0.6724 - val_loss: 1.4411 - val_acc: 0.7412 - val_f1_micro: 0.6725\n",
      "Epoch 74/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8265 - acc: 0.6810 - f1_micro: 0.6726 - val_loss: 1.4398 - val_acc: 0.7368 - val_f1_micro: 0.6727\n",
      "Epoch 75/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8298 - acc: 0.6814 - f1_micro: 0.6728 - val_loss: 1.4411 - val_acc: 0.7511 - val_f1_micro: 0.6729\n",
      "Epoch 76/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8227 - acc: 0.6840 - f1_micro: 0.6730 - val_loss: 1.4417 - val_acc: 0.7512 - val_f1_micro: 0.6731\n",
      "Epoch 77/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8207 - acc: 0.6823 - f1_micro: 0.6732 - val_loss: 1.4406 - val_acc: 0.7332 - val_f1_micro: 0.6733\n",
      "Epoch 78/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8255 - acc: 0.6845 - f1_micro: 0.6734 - val_loss: 1.4510 - val_acc: 0.7406 - val_f1_micro: 0.6735\n",
      "Epoch 79/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8220 - acc: 0.6839 - f1_micro: 0.6736 - val_loss: 1.4407 - val_acc: 0.7498 - val_f1_micro: 0.6737\n",
      "Epoch 80/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8239 - acc: 0.6845 - f1_micro: 0.6738 - val_loss: 1.4464 - val_acc: 0.7443 - val_f1_micro: 0.6739\n",
      "Epoch 81/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8161 - acc: 0.6852 - f1_micro: 0.6740 - val_loss: 1.4398 - val_acc: 0.7609 - val_f1_micro: 0.6741\n",
      "Epoch 82/100\n",
      "94731/94731 [==============================] - ETA: 0s - loss: 1.8197 - acc: 0.6848 - f1_micro: 0.67 - 1s - loss: 1.8194 - acc: 0.6851 - f1_micro: 0.6742 - val_loss: 1.4396 - val_acc: 0.7496 - val_f1_micro: 0.6743\n",
      "Epoch 83/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8215 - acc: 0.6819 - f1_micro: 0.6744 - val_loss: 1.4388 - val_acc: 0.7540 - val_f1_micro: 0.6745\n",
      "Epoch 84/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8111 - acc: 0.6848 - f1_micro: 0.6746 - val_loss: 1.4364 - val_acc: 0.7487 - val_f1_micro: 0.6747\n",
      "Epoch 85/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8156 - acc: 0.6847 - f1_micro: 0.6748 - val_loss: 1.4361 - val_acc: 0.7466 - val_f1_micro: 0.6749\n",
      "Epoch 86/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8149 - acc: 0.6844 - f1_micro: 0.6750 - val_loss: 1.4290 - val_acc: 0.7464 - val_f1_micro: 0.6751\n",
      "Epoch 87/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8142 - acc: 0.6845 - f1_micro: 0.6752 - val_loss: 1.4417 - val_acc: 0.7495 - val_f1_micro: 0.6753\n",
      "Epoch 88/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8184 - acc: 0.6854 - f1_micro: 0.6754 - val_loss: 1.4387 - val_acc: 0.7547 - val_f1_micro: 0.6755\n",
      "Epoch 89/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8178 - acc: 0.6827 - f1_micro: 0.6756 - val_loss: 1.4330 - val_acc: 0.7494 - val_f1_micro: 0.6757\n",
      "Epoch 90/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8177 - acc: 0.6852 - f1_micro: 0.6758 - val_loss: 1.4399 - val_acc: 0.7463 - val_f1_micro: 0.6759\n",
      "Epoch 91/100\n",
      "94731/94731 [==============================] - 2s - loss: 1.8107 - acc: 0.6855 - f1_micro: 0.6760 - val_loss: 1.4308 - val_acc: 0.7511 - val_f1_micro: 0.6761\n",
      "Epoch 92/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8172 - acc: 0.6851 - f1_micro: 0.6761 - val_loss: 1.4335 - val_acc: 0.7542 - val_f1_micro: 0.6762\n",
      "Epoch 93/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8104 - acc: 0.6854 - f1_micro: 0.6763 - val_loss: 1.4369 - val_acc: 0.7512 - val_f1_micro: 0.6764\n",
      "Epoch 94/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8100 - acc: 0.6857 - f1_micro: 0.6765 - val_loss: 1.4330 - val_acc: 0.7512 - val_f1_micro: 0.6766\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94731/94731 [==============================] - 1s - loss: 1.8054 - acc: 0.6866 - f1_micro: 0.6767 - val_loss: 1.4297 - val_acc: 0.7435 - val_f1_micro: 0.6768\n",
      "Epoch 96/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8147 - acc: 0.6857 - f1_micro: 0.6769 - val_loss: 1.4288 - val_acc: 0.7500 - val_f1_micro: 0.6770\n",
      "Epoch 97/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8103 - acc: 0.6856 - f1_micro: 0.6771 - val_loss: 1.4238 - val_acc: 0.7517 - val_f1_micro: 0.6772\n",
      "Epoch 98/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8116 - acc: 0.6840 - f1_micro: 0.6773 - val_loss: 1.4278 - val_acc: 0.7525 - val_f1_micro: 0.6774\n",
      "Epoch 99/100\n",
      "94731/94731 [==============================] - 2s - loss: 1.8133 - acc: 0.6868 - f1_micro: 0.6774 - val_loss: 1.4312 - val_acc: 0.7605 - val_f1_micro: 0.6775\n",
      "Epoch 100/100\n",
      "94731/94731 [==============================] - 1s - loss: 1.8059 - acc: 0.6847 - f1_micro: 0.6776 - val_loss: 1.4254 - val_acc: 0.7536 - val_f1_micro: 0.6777\n",
      "CPU times: user 3min 57s, sys: 26.4 s, total: 4min 23s\n",
      "Wall time: 3min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# And trained it via:\n",
    "batch_size = 500\n",
    "epochs = 100\n",
    "\n",
    "hist = model.fit(\n",
    "    training_inputs,\n",
    "    training_outputs,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    validation_data=validation_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': [0.0],\n",
       " 'f1_micro': [0.022502759915887773],\n",
       " 'loss': [1.8220217678544056e-07],\n",
       " 'val_acc': [0.0],\n",
       " 'val_f1_micro': [0.022132802858999306],\n",
       " 'val_loss': [1.8207752097591942e-07]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9223 - acc: 0.6675 - f1_micro: 0.6154 - val_loss: 1.5412 - val_acc: 0.7377 - val_f1_micro: 0.6154\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9187 - acc: 0.6692 - f1_micro: 0.6154 - val_loss: 1.5448 - val_acc: 0.7409 - val_f1_micro: 0.6154\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9205 - acc: 0.6683 - f1_micro: 0.6155 - val_loss: 1.5374 - val_acc: 0.7429 - val_f1_micro: 0.6155\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9227 - acc: 0.6703 - f1_micro: 0.6155 - val_loss: 1.5447 - val_acc: 0.7329 - val_f1_micro: 0.6155\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9203 - acc: 0.6685 - f1_micro: 0.6155 - val_loss: 1.5355 - val_acc: 0.7364 - val_f1_micro: 0.6155\n",
      "\n",
      "Done with epoch: 5\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9157 - acc: 0.6708 - f1_micro: 0.6156 - val_loss: 1.5441 - val_acc: 0.7309 - val_f1_micro: 0.6156\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9195 - acc: 0.6718 - f1_micro: 0.6156 - val_loss: 1.5377 - val_acc: 0.7392 - val_f1_micro: 0.6156\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9227 - acc: 0.6692 - f1_micro: 0.6156 - val_loss: 1.5405 - val_acc: 0.7402 - val_f1_micro: 0.6156\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9229 - acc: 0.6687 - f1_micro: 0.6157 - val_loss: 1.5405 - val_acc: 0.7365 - val_f1_micro: 0.6157\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9125 - acc: 0.6702 - f1_micro: 0.6157 - val_loss: 1.5456 - val_acc: 0.7384 - val_f1_micro: 0.6157\n",
      "\n",
      "Done with epoch: 10\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9177 - acc: 0.6720 - f1_micro: 0.6157 - val_loss: 1.5304 - val_acc: 0.7401 - val_f1_micro: 0.6157\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9179 - acc: 0.6688 - f1_micro: 0.6158 - val_loss: 1.5427 - val_acc: 0.7348 - val_f1_micro: 0.6158\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9193 - acc: 0.6691 - f1_micro: 0.6158 - val_loss: 1.5412 - val_acc: 0.7327 - val_f1_micro: 0.6158\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9191 - acc: 0.6695 - f1_micro: 0.6158 - val_loss: 1.5363 - val_acc: 0.7391 - val_f1_micro: 0.6158\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9168 - acc: 0.6708 - f1_micro: 0.6158 - val_loss: 1.5342 - val_acc: 0.7397 - val_f1_micro: 0.6159\n",
      "\n",
      "Done with epoch: 15\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9221 - acc: 0.6693 - f1_micro: 0.6159 - val_loss: 1.5335 - val_acc: 0.7367 - val_f1_micro: 0.6159\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9162 - acc: 0.6710 - f1_micro: 0.6159 - val_loss: 1.5338 - val_acc: 0.7372 - val_f1_micro: 0.6159\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9207 - acc: 0.6691 - f1_micro: 0.6159 - val_loss: 1.5289 - val_acc: 0.7334 - val_f1_micro: 0.6159\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9201 - acc: 0.6689 - f1_micro: 0.6160 - val_loss: 1.5354 - val_acc: 0.7397 - val_f1_micro: 0.6160\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9173 - acc: 0.6686 - f1_micro: 0.6160 - val_loss: 1.5293 - val_acc: 0.7378 - val_f1_micro: 0.6160\n",
      "\n",
      "Done with epoch: 20\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9213 - acc: 0.6697 - f1_micro: 0.6160 - val_loss: 1.5390 - val_acc: 0.7385 - val_f1_micro: 0.6160\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9134 - acc: 0.6703 - f1_micro: 0.6160 - val_loss: 1.5306 - val_acc: 0.7446 - val_f1_micro: 0.6161\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9137 - acc: 0.6691 - f1_micro: 0.6161 - val_loss: 1.5293 - val_acc: 0.7324 - val_f1_micro: 0.6161\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9200 - acc: 0.6687 - f1_micro: 0.6161 - val_loss: 1.5279 - val_acc: 0.7380 - val_f1_micro: 0.6161\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9173 - acc: 0.6707 - f1_micro: 0.6161 - val_loss: 1.5320 - val_acc: 0.7384 - val_f1_micro: 0.6161\n",
      "\n",
      "Done with epoch: 25\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9218 - acc: 0.6680 - f1_micro: 0.6162 - val_loss: 1.5398 - val_acc: 0.7353 - val_f1_micro: 0.6162\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9213 - acc: 0.6706 - f1_micro: 0.6162 - val_loss: 1.5378 - val_acc: 0.7366 - val_f1_micro: 0.6162\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9178 - acc: 0.6674 - f1_micro: 0.6162 - val_loss: 1.5325 - val_acc: 0.7420 - val_f1_micro: 0.6162\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9145 - acc: 0.6706 - f1_micro: 0.6162 - val_loss: 1.5377 - val_acc: 0.7373 - val_f1_micro: 0.6163\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9217 - acc: 0.6684 - f1_micro: 0.6163 - val_loss: 1.5379 - val_acc: 0.7366 - val_f1_micro: 0.6163\n",
      "\n",
      "Done with epoch: 30\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9244 - acc: 0.6682 - f1_micro: 0.6163 - val_loss: 1.5349 - val_acc: 0.7404 - val_f1_micro: 0.6163\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9196 - acc: 0.6697 - f1_micro: 0.6163 - val_loss: 1.5400 - val_acc: 0.7365 - val_f1_micro: 0.6163\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9243 - acc: 0.6687 - f1_micro: 0.6164 - val_loss: 1.5347 - val_acc: 0.7321 - val_f1_micro: 0.6164\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9224 - acc: 0.6673 - f1_micro: 0.6164 - val_loss: 1.5369 - val_acc: 0.7340 - val_f1_micro: 0.6164\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9201 - acc: 0.6716 - f1_micro: 0.6164 - val_loss: 1.5311 - val_acc: 0.7353 - val_f1_micro: 0.6164\n",
      "\n",
      "Done with epoch: 35\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9151 - acc: 0.6704 - f1_micro: 0.6164 - val_loss: 1.5329 - val_acc: 0.7430 - val_f1_micro: 0.6165\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9166 - acc: 0.6699 - f1_micro: 0.6165 - val_loss: 1.5355 - val_acc: 0.7363 - val_f1_micro: 0.6165\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9159 - acc: 0.6695 - f1_micro: 0.6165 - val_loss: 1.5343 - val_acc: 0.7384 - val_f1_micro: 0.6165\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9203 - acc: 0.6693 - f1_micro: 0.6165 - val_loss: 1.5319 - val_acc: 0.7421 - val_f1_micro: 0.6165\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9196 - acc: 0.6695 - f1_micro: 0.6166 - val_loss: 1.5358 - val_acc: 0.7420 - val_f1_micro: 0.6166\n",
      "\n",
      "Done with epoch: 40\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9214 - acc: 0.6685 - f1_micro: 0.6166 - val_loss: 1.5326 - val_acc: 0.7331 - val_f1_micro: 0.6166\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9204 - acc: 0.6691 - f1_micro: 0.6166 - val_loss: 1.5288 - val_acc: 0.7346 - val_f1_micro: 0.6166\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9157 - acc: 0.6710 - f1_micro: 0.6166 - val_loss: 1.5351 - val_acc: 0.7412 - val_f1_micro: 0.6167\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9197 - acc: 0.6702 - f1_micro: 0.6167 - val_loss: 1.5314 - val_acc: 0.7348 - val_f1_micro: 0.6167\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9189 - acc: 0.6673 - f1_micro: 0.6167 - val_loss: 1.5315 - val_acc: 0.7330 - val_f1_micro: 0.6167\n",
      "\n",
      "Done with epoch: 45\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94731/94731 [==============================] - 0s - loss: 1.9168 - acc: 0.6684 - f1_micro: 0.6167 - val_loss: 1.5317 - val_acc: 0.7375 - val_f1_micro: 0.6167\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9138 - acc: 0.6709 - f1_micro: 0.6168 - val_loss: 1.5307 - val_acc: 0.7391 - val_f1_micro: 0.6168\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9131 - acc: 0.6717 - f1_micro: 0.6168 - val_loss: 1.5264 - val_acc: 0.7419 - val_f1_micro: 0.6168\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9199 - acc: 0.6672 - f1_micro: 0.6168 - val_loss: 1.5316 - val_acc: 0.7385 - val_f1_micro: 0.6168\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9186 - acc: 0.6696 - f1_micro: 0.6168 - val_loss: 1.5284 - val_acc: 0.7426 - val_f1_micro: 0.6169\n",
      "\n",
      "Done with epoch: 50\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9110 - acc: 0.6696 - f1_micro: 0.6169 - val_loss: 1.5327 - val_acc: 0.7442 - val_f1_micro: 0.6169\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9129 - acc: 0.6703 - f1_micro: 0.6169 - val_loss: 1.5261 - val_acc: 0.7390 - val_f1_micro: 0.6169\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9144 - acc: 0.6704 - f1_micro: 0.6169 - val_loss: 1.5295 - val_acc: 0.7461 - val_f1_micro: 0.6169\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9168 - acc: 0.6730 - f1_micro: 0.6170 - val_loss: 1.5240 - val_acc: 0.7399 - val_f1_micro: 0.6170\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9155 - acc: 0.6707 - f1_micro: 0.6170 - val_loss: 1.5344 - val_acc: 0.7353 - val_f1_micro: 0.6170\n",
      "\n",
      "Done with epoch: 55\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9163 - acc: 0.6689 - f1_micro: 0.6170 - val_loss: 1.5346 - val_acc: 0.7369 - val_f1_micro: 0.6170\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9159 - acc: 0.6714 - f1_micro: 0.6170 - val_loss: 1.5308 - val_acc: 0.7423 - val_f1_micro: 0.6171\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9163 - acc: 0.6694 - f1_micro: 0.6171 - val_loss: 1.5292 - val_acc: 0.7455 - val_f1_micro: 0.6171\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9081 - acc: 0.6707 - f1_micro: 0.6171 - val_loss: 1.5238 - val_acc: 0.7374 - val_f1_micro: 0.6171\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9140 - acc: 0.6717 - f1_micro: 0.6171 - val_loss: 1.5328 - val_acc: 0.7412 - val_f1_micro: 0.6171\n",
      "\n",
      "Done with epoch: 60\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9186 - acc: 0.6683 - f1_micro: 0.6172 - val_loss: 1.5345 - val_acc: 0.7364 - val_f1_micro: 0.6172\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9187 - acc: 0.6680 - f1_micro: 0.6172 - val_loss: 1.5311 - val_acc: 0.7355 - val_f1_micro: 0.6172\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9183 - acc: 0.6688 - f1_micro: 0.6172 - val_loss: 1.5279 - val_acc: 0.7397 - val_f1_micro: 0.6172\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9157 - acc: 0.6700 - f1_micro: 0.6172 - val_loss: 1.5268 - val_acc: 0.7419 - val_f1_micro: 0.6173\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9132 - acc: 0.6700 - f1_micro: 0.6173 - val_loss: 1.5275 - val_acc: 0.7444 - val_f1_micro: 0.6173\n",
      "\n",
      "Done with epoch: 65\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9218 - acc: 0.6701 - f1_micro: 0.6173 - val_loss: 1.5284 - val_acc: 0.7375 - val_f1_micro: 0.6173\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9176 - acc: 0.6695 - f1_micro: 0.6173 - val_loss: 1.5287 - val_acc: 0.7425 - val_f1_micro: 0.6173\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9181 - acc: 0.6697 - f1_micro: 0.6174 - val_loss: 1.5254 - val_acc: 0.7304 - val_f1_micro: 0.6174\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9161 - acc: 0.6680 - f1_micro: 0.6174 - val_loss: 1.5287 - val_acc: 0.7375 - val_f1_micro: 0.6174\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9101 - acc: 0.6701 - f1_micro: 0.6174 - val_loss: 1.5288 - val_acc: 0.7424 - val_f1_micro: 0.6174\n",
      "\n",
      "Done with epoch: 70\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9076 - acc: 0.6702 - f1_micro: 0.6174 - val_loss: 1.5222 - val_acc: 0.7496 - val_f1_micro: 0.6175\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9161 - acc: 0.6712 - f1_micro: 0.6175 - val_loss: 1.5262 - val_acc: 0.7423 - val_f1_micro: 0.6175\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9112 - acc: 0.6719 - f1_micro: 0.6175 - val_loss: 1.5292 - val_acc: 0.7428 - val_f1_micro: 0.6175\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9248 - acc: 0.6686 - f1_micro: 0.6175 - val_loss: 1.5388 - val_acc: 0.7340 - val_f1_micro: 0.6175\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9124 - acc: 0.6708 - f1_micro: 0.6175 - val_loss: 1.5288 - val_acc: 0.7438 - val_f1_micro: 0.6176\n",
      "\n",
      "Done with epoch: 75\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9127 - acc: 0.6672 - f1_micro: 0.6176 - val_loss: 1.5232 - val_acc: 0.7396 - val_f1_micro: 0.6176\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9084 - acc: 0.6717 - f1_micro: 0.6176 - val_loss: 1.5325 - val_acc: 0.7345 - val_f1_micro: 0.6176\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9156 - acc: 0.6711 - f1_micro: 0.6176 - val_loss: 1.5301 - val_acc: 0.7365 - val_f1_micro: 0.6176\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9143 - acc: 0.6719 - f1_micro: 0.6176 - val_loss: 1.5262 - val_acc: 0.7413 - val_f1_micro: 0.6177\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9228 - acc: 0.6676 - f1_micro: 0.6177 - val_loss: 1.5310 - val_acc: 0.7364 - val_f1_micro: 0.6177\n",
      "\n",
      "Done with epoch: 80\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9089 - acc: 0.6713 - f1_micro: 0.6177 - val_loss: 1.5319 - val_acc: 0.7435 - val_f1_micro: 0.6177\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9145 - acc: 0.6706 - f1_micro: 0.6177 - val_loss: 1.5279 - val_acc: 0.7416 - val_f1_micro: 0.6177\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9085 - acc: 0.6704 - f1_micro: 0.6178 - val_loss: 1.5272 - val_acc: 0.7411 - val_f1_micro: 0.6178\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9151 - acc: 0.6681 - f1_micro: 0.6178 - val_loss: 1.5379 - val_acc: 0.7383 - val_f1_micro: 0.6178\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9109 - acc: 0.6725 - f1_micro: 0.6178 - val_loss: 1.5329 - val_acc: 0.7369 - val_f1_micro: 0.6178\n",
      "\n",
      "Done with epoch: 85\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9074 - acc: 0.6688 - f1_micro: 0.6178 - val_loss: 1.5381 - val_acc: 0.7372 - val_f1_micro: 0.6179\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9080 - acc: 0.6701 - f1_micro: 0.6179 - val_loss: 1.5309 - val_acc: 0.7388 - val_f1_micro: 0.6179\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9125 - acc: 0.6695 - f1_micro: 0.6179 - val_loss: 1.5329 - val_acc: 0.7421 - val_f1_micro: 0.6179\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9118 - acc: 0.6685 - f1_micro: 0.6179 - val_loss: 1.5257 - val_acc: 0.7449 - val_f1_micro: 0.6179\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9124 - acc: 0.6714 - f1_micro: 0.6180 - val_loss: 1.5223 - val_acc: 0.7432 - val_f1_micro: 0.6180\n",
      "\n",
      "Done with epoch: 90\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94731/94731 [==============================] - 0s - loss: 1.9131 - acc: 0.6711 - f1_micro: 0.6180 - val_loss: 1.5285 - val_acc: 0.7411 - val_f1_micro: 0.6180\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9154 - acc: 0.6713 - f1_micro: 0.6180 - val_loss: 1.5232 - val_acc: 0.7392 - val_f1_micro: 0.6180\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9101 - acc: 0.6670 - f1_micro: 0.6181 - val_loss: 1.5253 - val_acc: 0.7344 - val_f1_micro: 0.6181\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9152 - acc: 0.6685 - f1_micro: 0.6181 - val_loss: 1.5293 - val_acc: 0.7348 - val_f1_micro: 0.6181\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9085 - acc: 0.6697 - f1_micro: 0.6181 - val_loss: 1.5267 - val_acc: 0.7393 - val_f1_micro: 0.6181\n",
      "\n",
      "Done with epoch: 95\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9121 - acc: 0.6704 - f1_micro: 0.6181 - val_loss: 1.5282 - val_acc: 0.7481 - val_f1_micro: 0.6182\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9227 - acc: 0.6704 - f1_micro: 0.6182 - val_loss: 1.5314 - val_acc: 0.7371 - val_f1_micro: 0.6182\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9129 - acc: 0.6697 - f1_micro: 0.6182 - val_loss: 1.5234 - val_acc: 0.7386 - val_f1_micro: 0.6182\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9084 - acc: 0.6714 - f1_micro: 0.6182 - val_loss: 1.5235 - val_acc: 0.7372 - val_f1_micro: 0.6182\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 0s - loss: 1.9141 - acc: 0.6703 - f1_micro: 0.6183 - val_loss: 1.5295 - val_acc: 0.7438 - val_f1_micro: 0.6183\n",
      "\n",
      "Done with epoch: 100\n",
      "\n",
      "CPU times: user 1min 45s, sys: 10.6 s, total: 1min 56s\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "log_history_file = 'lstm-word2vec-fasttext-lsi.epoch.csv'\n",
    "model_name = 'models/tfidf-wv-fs-lsi-2010-2014-data_cat-crossentropy-2014-b-val-sc_tfidf_wv_fs_lsi.model'\n",
    "batch_size = 1200\n",
    "epochs = 5\n",
    "total_epochs = 100\n",
    "\n",
    "for i in xrange(0, total_epochs // epochs):\n",
    "    hist = model.fit(\n",
    "        training_inputs,\n",
    "        training_outputs,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.2,\n",
    "        validation_data=validation_data,\n",
    "    )\n",
    "\n",
    "    model.save(model_name.format(i))\n",
    "    print\n",
    "    print('Done with epoch: {}'.format((i + 1) * epochs))\n",
    "    with open(log_history_file, 'a') as fl:\n",
    "        fl.write(model_name + '\\n')\n",
    "        fl.write('Epoch {}\\n'.format((i + 1) * epochs))\n",
    "        fl.write('{}\\n'.format(datetime.now()))\n",
    "        fl.write('\\n'.join(['{}: {}'.format(k, v[0]) for k, v in hist.history.items()]))\n",
    "        fl.write('\\n\\n')\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.6427 - main_output_loss: 1.3490 - aux_output_loss: 1.4686 - main_output_acc: 0.7712 - main_output_f1_micro: 0.6905 - aux_output_acc: 0.7839 - aux_output_f1_micro: 0.1085 - val_loss: 1.4372 - val_main_output_loss: 1.1302 - val_aux_output_loss: 1.5348 - val_main_output_acc: 0.7941 - val_main_output_f1_micro: 0.6913 - val_aux_output_acc: 0.7884 - val_aux_output_f1_micro: 0.1086\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5833 - main_output_loss: 1.2980 - aux_output_loss: 1.4265 - main_output_acc: 0.7738 - main_output_f1_micro: 0.6921 - aux_output_acc: 0.7855 - aux_output_f1_micro: 0.1088 - val_loss: 1.4210 - val_main_output_loss: 1.1179 - val_aux_output_loss: 1.5153 - val_main_output_acc: 0.7967 - val_main_output_f1_micro: 0.6930 - val_aux_output_acc: 0.7949 - val_aux_output_f1_micro: 0.1090\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5656 - main_output_loss: 1.2841 - aux_output_loss: 1.4076 - main_output_acc: 0.7752 - main_output_f1_micro: 0.6938 - aux_output_acc: 0.7870 - aux_output_f1_micro: 0.1091 - val_loss: 1.4123 - val_main_output_loss: 1.1124 - val_aux_output_loss: 1.4995 - val_main_output_acc: 0.7930 - val_main_output_f1_micro: 0.6946 - val_aux_output_acc: 0.7916 - val_aux_output_f1_micro: 0.1093\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5551 - main_output_loss: 1.2755 - aux_output_loss: 1.3983 - main_output_acc: 0.7779 - main_output_f1_micro: 0.6955 - aux_output_acc: 0.7867 - aux_output_f1_micro: 0.1094 - val_loss: 1.4043 - val_main_output_loss: 1.1070 - val_aux_output_loss: 1.4866 - val_main_output_acc: 0.7988 - val_main_output_f1_micro: 0.6963 - val_aux_output_acc: 0.7918 - val_aux_output_f1_micro: 0.1096\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5504 - main_output_loss: 1.2725 - aux_output_loss: 1.3899 - main_output_acc: 0.7771 - main_output_f1_micro: 0.6971 - aux_output_acc: 0.7872 - aux_output_f1_micro: 0.1097 - val_loss: 1.4002 - val_main_output_loss: 1.1043 - val_aux_output_loss: 1.4796 - val_main_output_acc: 0.8088 - val_main_output_f1_micro: 0.6980 - val_aux_output_acc: 0.7916 - val_aux_output_f1_micro: 0.1099\n",
      "\n",
      "Done with epoch: 100\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5459 - main_output_loss: 1.2693 - aux_output_loss: 1.3833 - main_output_acc: 0.7773 - main_output_f1_micro: 0.6988 - aux_output_acc: 0.7896 - aux_output_f1_micro: 0.1100 - val_loss: 1.3938 - val_main_output_loss: 1.0999 - val_aux_output_loss: 1.4694 - val_main_output_acc: 0.8001 - val_main_output_f1_micro: 0.6996 - val_aux_output_acc: 0.7926 - val_aux_output_f1_micro: 0.1102\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5393 - main_output_loss: 1.2640 - aux_output_loss: 1.3764 - main_output_acc: 0.7776 - main_output_f1_micro: 0.7004 - aux_output_acc: 0.7896 - aux_output_f1_micro: 0.1103 - val_loss: 1.3912 - val_main_output_loss: 1.0979 - val_aux_output_loss: 1.4664 - val_main_output_acc: 0.7940 - val_main_output_f1_micro: 0.7012 - val_aux_output_acc: 0.7917 - val_aux_output_f1_micro: 0.1105\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5369 - main_output_loss: 1.2627 - aux_output_loss: 1.3708 - main_output_acc: 0.7815 - main_output_f1_micro: 0.7020 - aux_output_acc: 0.7890 - aux_output_f1_micro: 0.1106 - val_loss: 1.3821 - val_main_output_loss: 1.0902 - val_aux_output_loss: 1.4594 - val_main_output_acc: 0.8066 - val_main_output_f1_micro: 0.7028 - val_aux_output_acc: 0.7940 - val_aux_output_f1_micro: 0.1108\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5302 - main_output_loss: 1.2571 - aux_output_loss: 1.3656 - main_output_acc: 0.7796 - main_output_f1_micro: 0.7036 - aux_output_acc: 0.7897 - aux_output_f1_micro: 0.1109 - val_loss: 1.3878 - val_main_output_loss: 1.0954 - val_aux_output_loss: 1.4620 - val_main_output_acc: 0.7964 - val_main_output_f1_micro: 0.7044 - val_aux_output_acc: 0.7954 - val_aux_output_f1_micro: 0.1111\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5282 - main_output_loss: 1.2561 - aux_output_loss: 1.3605 - main_output_acc: 0.7775 - main_output_f1_micro: 0.7052 - aux_output_acc: 0.7913 - aux_output_f1_micro: 0.1112 - val_loss: 1.3855 - val_main_output_loss: 1.0954 - val_aux_output_loss: 1.4505 - val_main_output_acc: 0.7928 - val_main_output_f1_micro: 0.7059 - val_aux_output_acc: 0.7964 - val_aux_output_f1_micro: 0.1114\n",
      "\n",
      "Done with epoch: 105\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5262 - main_output_loss: 1.2551 - aux_output_loss: 1.3553 - main_output_acc: 0.7791 - main_output_f1_micro: 0.7067 - aux_output_acc: 0.7902 - aux_output_f1_micro: 0.1115 - val_loss: 1.3707 - val_main_output_loss: 1.0832 - val_aux_output_loss: 1.4377 - val_main_output_acc: 0.8034 - val_main_output_f1_micro: 0.7075 - val_aux_output_acc: 0.7948 - val_aux_output_f1_micro: 0.1117\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5205 - main_output_loss: 1.2508 - aux_output_loss: 1.3484 - main_output_acc: 0.7803 - main_output_f1_micro: 0.7083 - aux_output_acc: 0.7910 - aux_output_f1_micro: 0.1118 - val_loss: 1.3696 - val_main_output_loss: 1.0827 - val_aux_output_loss: 1.4348 - val_main_output_acc: 0.8018 - val_main_output_f1_micro: 0.7090 - val_aux_output_acc: 0.7929 - val_aux_output_f1_micro: 0.1120\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5220 - main_output_loss: 1.2527 - aux_output_loss: 1.3466 - main_output_acc: 0.7793 - main_output_f1_micro: 0.7098 - aux_output_acc: 0.7904 - aux_output_f1_micro: 0.1122 - val_loss: 1.3695 - val_main_output_loss: 1.0827 - val_aux_output_loss: 1.4341 - val_main_output_acc: 0.7963 - val_main_output_f1_micro: 0.7105 - val_aux_output_acc: 0.7926 - val_aux_output_f1_micro: 0.1123\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5216 - main_output_loss: 1.2530 - aux_output_loss: 1.3431 - main_output_acc: 0.7800 - main_output_f1_micro: 0.7113 - aux_output_acc: 0.7914 - aux_output_f1_micro: 0.1125 - val_loss: 1.3708 - val_main_output_loss: 1.0860 - val_aux_output_loss: 1.4240 - val_main_output_acc: 0.8011 - val_main_output_f1_micro: 0.7120 - val_aux_output_acc: 0.7966 - val_aux_output_f1_micro: 0.1126\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5163 - main_output_loss: 1.2486 - aux_output_loss: 1.3386 - main_output_acc: 0.7807 - main_output_f1_micro: 0.7128 - aux_output_acc: 0.7916 - aux_output_f1_micro: 0.1128 - val_loss: 1.3660 - val_main_output_loss: 1.0814 - val_aux_output_loss: 1.4232 - val_main_output_acc: 0.7929 - val_main_output_f1_micro: 0.7135 - val_aux_output_acc: 0.7930 - val_aux_output_f1_micro: 0.1130\n",
      "\n",
      "Done with epoch: 110\n",
      "\n",
      "Train on 94731 samples, validate on 9424 samples\n",
      "Epoch 1/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5152 - main_output_loss: 1.2484 - aux_output_loss: 1.3341 - main_output_acc: 0.7792 - main_output_f1_micro: 0.7142 - aux_output_acc: 0.7911 - aux_output_f1_micro: 0.1131 - val_loss: 1.3651 - val_main_output_loss: 1.0816 - val_aux_output_loss: 1.4173 - val_main_output_acc: 0.7956 - val_main_output_f1_micro: 0.7149 - val_aux_output_acc: 0.7927 - val_aux_output_f1_micro: 0.1133\n",
      "Epoch 2/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5089 - main_output_loss: 1.2427 - aux_output_loss: 1.3309 - main_output_acc: 0.7803 - main_output_f1_micro: 0.7156 - aux_output_acc: 0.7912 - aux_output_f1_micro: 0.1135 - val_loss: 1.3627 - val_main_output_loss: 1.0794 - val_aux_output_loss: 1.4167 - val_main_output_acc: 0.7989 - val_main_output_f1_micro: 0.7164 - val_aux_output_acc: 0.7968 - val_aux_output_f1_micro: 0.1136\n",
      "Epoch 3/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5082 - main_output_loss: 1.2431 - aux_output_loss: 1.3254 - main_output_acc: 0.7813 - main_output_f1_micro: 0.7171 - aux_output_acc: 0.7917 - aux_output_f1_micro: 0.1138 - val_loss: 1.3610 - val_main_output_loss: 1.0787 - val_aux_output_loss: 1.4114 - val_main_output_acc: 0.8054 - val_main_output_f1_micro: 0.7178 - val_aux_output_acc: 0.7916 - val_aux_output_f1_micro: 0.1139\n",
      "Epoch 4/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5043 - main_output_loss: 1.2400 - aux_output_loss: 1.3214 - main_output_acc: 0.7788 - main_output_f1_micro: 0.7185 - aux_output_acc: 0.7905 - aux_output_f1_micro: 0.1141 - val_loss: 1.3573 - val_main_output_loss: 1.0764 - val_aux_output_loss: 1.4045 - val_main_output_acc: 0.8025 - val_main_output_f1_micro: 0.7192 - val_aux_output_acc: 0.7962 - val_aux_output_f1_micro: 0.1143\n",
      "Epoch 5/5\n",
      "94731/94731 [==============================] - 51s - loss: 1.5045 - main_output_loss: 1.2409 - aux_output_loss: 1.3181 - main_output_acc: 0.7785 - main_output_f1_micro: 0.7199 - aux_output_acc: 0.7919 - aux_output_f1_micro: 0.1145 - val_loss: 1.3638 - val_main_output_loss: 1.0828 - val_aux_output_loss: 1.4050 - val_main_output_acc: 0.7982 - val_main_output_f1_micro: 0.7205 - val_aux_output_acc: 0.7963 - val_aux_output_f1_micro: 0.1146\n",
      "\n",
      "Done with epoch: 115\n",
      "\n",
      "CPU times: user 20min 20s, sys: 1min 53s, total: 22min 14s\n",
      "Wall time: 17min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total_epochs = 100\n",
    "for j in xrange(i, i + (total_epochs // epochs)):\n",
    "    hist = model.fit(\n",
    "        training_inputs,\n",
    "        training_outputs,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.2,\n",
    "        validation_data=validation_data,\n",
    "    )\n",
    "\n",
    "    model.save(model_name.format(i))\n",
    "    print\n",
    "    print('Done with epoch: {}'.format((j + 1) * epochs))\n",
    "    with open(log_history_file, 'a') as fl:\n",
    "        fl.write(model_name + '\\n')\n",
    "        fl.write('Epoch {}\\n'.format((j + 1) * epochs))\n",
    "        fl.write('{}\\n'.format(datetime.now()))\n",
    "        fl.write('\\n'.join(['{}: {}'.format(k, v[0]) for k, v in hist.history.items()]))\n",
    "        fl.write('\\n\\n')\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = keras.models.load_model(\n",
    "#     'models/lstm-word2vec-fasttext_2010-2014-data_categorical-crossentropy-2014-b-val-standard_scaled_wv_fs.model',\n",
    "#     custom_objects={'f1_micro': f1_micro}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = model.predict(\n",
    "    build_training_inputs(\n",
    "        wv_train[:100],\n",
    "        fs_train[:100],\n",
    "        tfidf_wv_train[:100],\n",
    "        tfidf_fs_train[:100],\n",
    "        tfidf_lsi_train[:100],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6775863d90>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGn1JREFUeJzt3X+wXHd53/H3Z/dK/kkkYwkjSwpSjKBRmBC7F8eGdkJq\nfshMkCbTltgTJmHqRsM0TknjaccuGZO6f7SUTH6QcQhO6kIYijFOQlRHVEONE6aM7Pi6gGPJFr6W\nDZIsIeEfso0lJO0+/eOcvffc1d39npWu9D33+vOaubN3d4/vfuf4nEfPPt/nfI8iAjMzW1hauQdg\nZmZzz8HdzGwBcnA3M1uAHNzNzBYgB3czswXIwd3MbAFycDczW4Ac3M3MFiAHdzOzBWgs1wcvW7Ys\n1qxZk+vjzczmpYcffvgHEbE8tV224L5mzRomJiZyfbyZ2bwk6bt1tnNZxsxsAUoGd0l3Sjoo6dEB\n70vSJyVNSnpE0hVzP0wzMxtFncz9M8CGIe9fC6wrfzYDnzr9YZmZ2elIBveI+Drw3JBNNgF/HoUH\ngKWSVszVAM3MbHRzUXNfCeypPN9bvmZmZpmc1QlVSZslTUiaOHTo0Nn8aDOzV5W5CO77gNWV56vK\n104SEXdExHhEjC9fnmzTNDOzUzQXwX0L8Ctl18xVwOGI2F/nP9zz3Ct8/TvO4M3M5lqdVsgvANuB\nN0vaK+kGSR+W9OFyk63AbmAS+FPg39T98Du/8RS/+cVvncKwzcxsmOQVqhFxfeL9AH79VD78eKfL\n8RPdU/lPzcxsiKxXqHa60InIOQQzswUpa3DvdoNO18HdzGyu5Q3uEThxNzObe3nLMhEuy5iZnQEu\ny5iZLUCZM/fisesAb2Y2p7LX3KuPZjbY8z88xm3/ayfHO24ftrTsZRlwO6RZHdt3P8ud33iKJ77/\ncu6h2DyQuc+9zNydiJglTZ0vToashkaUZZy5m6VNnS+eo7IaMgf33qMPVrOUjsuYNoKGlGV8sJql\n+HyxUTSjLOOD1Sypl7D7fLE6GhHcfayapXV8vtgImlGWcQ3RLMnni40ic5978eivmWZpLmPaKLIv\nHAY+WM3qcLeMjaIRNXcfq2Zp7paxUXj5AbN5wmUZG4XLMmbzhC/6s1Fkv4cq+GA1q2Oq5u61mKyG\nrME9vOSvWW1dt0LaCBrR5+6yjFlax8mQjaARNXcv+WuW1nUyZCPIXJYpHp2JmKW5AcFG0YyyjIO7\nWZIbEGwUjQjuvijDLC3C3TJWXyOuUPXXTLM0f9O1UTQiuDu2m6VNNyD4hLE0X8RkNk+4z91G0YjM\n3WUZszR3y9goGjGh6hqiWZq/6dooagV3SRsk7ZI0KenmWd7/cUn3S/qmpEckva/O351e8tcHq1lK\n12vL2AiSwV1SG7gduBZYD1wvaX3fZr8N3B0RlwPXAX9c58N9sJrV1/XyAzaCOpn7lcBkROyOiGPA\nXcCmvm0C+LHy9yXAM3U+3DVEs/p8vtgo6gT3lcCeyvO95WtVvwN8UNJeYCvwG7P9IUmbJU1Imjh0\n6NBUC6TLMmZpXlvGRjFXE6rXA5+JiFXA+4DPSTrpb0fEHRExHhHjy5cv952YzEbQ8VpMNoI6wX0f\nsLryfFX5WtUNwN0AEbEdOBdYlvrD/pppVp/73G0UdYL7Q8A6SWslLaaYMN3St833gGsAJP0kRXA/\nlPrDXhXSrD7ficlGkQzuEXECuBHYBjxG0RWzQ9JtkjaWm90E/JqkbwNfAD4UIxTSvZ67WZpv1mGj\nGKuzUURspZgorb52a+X3ncA7Rvng6vHpmrtZWriMaSPIeoVqjxdCMkvzbSltFNmCezB9gDpzN0tz\nt4yNohmZu49VsyT3udso8mXulePTZRmztI5bIW0EGcsy05yJmKVN36wj80BsXmhIWcbB3SzFV3Tb\nKPIF92pZxgerWdLUqpD+pms1NKNbxl8zzZJ63TLO3K2ORtTcnbmbpblbxkbRjLKMD1azJHfL2Cga\nMaHqr5lmab6hvI2iGWUZH6xmSV4V0kbhzN1snuidJ75zmdXRjCtUfayaJYW7ZWwEGTP36QPUZRmz\nNK8KaaNoRM3dB6tZmrtlbBTNaIX0sWqW5G4ZG0UjMndnImZpU5m7u2WshkbU3J2JmKVNZe5OhqyG\nRnTL+GA1S/OEqo2iEX3u7ts1S+vFdJ8vVkcjau7ORMzSvJ67jaIRmbsvpzZL60x1y2QeiM0Ljai5\nu1vGLG26W8bni6U1InN3cDdLc7eMjaIhd2LywWqW4szdRtGQK1R9sJql9GK6M3eroxllGU8QmQ1V\nzdb9TdfqyN4K2W7JmYhZQvUc8elidWQP7ovacg3RLKHjzN1GlL3mvqjdcuZullCdl/L5YnXUCu6S\nNkjaJWlS0s0DtvmApJ2Sdkj6n+m/Whygi9otL/lrllDN1v1N1+oYS20gqQ3cDrwb2As8JGlLROys\nbLMOuAV4R0Q8L+l1qb/bOzzHWi7LmKVUmw6cuVsddTL3K4HJiNgdEceAu4BNfdv8GnB7RDwPEBEH\nk3+1WpZxcDcbqleWkVxzt3rqBPeVwJ7K873la1VvAt4k6RuSHpC0YbY/JGmzpAlJEy+9/DIAi8dc\nczdL6Z0ji9otf9O1WuZqQnUMWAe8E7ge+FNJS/s3iog7ImI8IsYvvPDC4j9syUuYmiX0AvpiNyBY\nTXWC+z5gdeX5qvK1qr3Alog4HhFPAd+hCPYDTdXcXZYxS5rO3OUGBKulTnB/CFgnaa2kxcB1wJa+\nbb5MkbUjaRlFmWb3sD/ay9YXt0XHB6vZUL0EaMxlGaspGdwj4gRwI7ANeAy4OyJ2SLpN0sZys23A\ns5J2AvcD/z4inq0zgLF2y2UZs4Ret8wiX9FtNSVbIQEiYiuwte+1Wyu/B/Bb5c9oA2iJo8d9sJoN\nM1WWGWsRUXzzlZR5VNZk2W/WsXjMNXezlG6lWwbcDmlp2VeFLK5Q9YFqNkyvzj4V3H3OWEL2hcPG\nWp79N0vpVBoQwMtkW1ojFg7z7L/ZcB1n7jai7LfZG2t79t8spZepj/Uyd58zlpC15t4StCVPDpkl\ndPomVP1t11Ky1tzbLdFqyXeWMUs4qSzj4G4JWWvukmh5lTuzpKgsPwCuuVta3sxd8j1UzWroz9zd\nLWMpWWvu7ZZoyatCmqVMt0K6W8bqyXiFaiBByxOqZklTa8t4QtVqyp65t1sO7mYpvUy91wrpc8ZS\nstfcW/IVqmYp/csPuM/dUvL2ubdEu+UD1SxlekLVFzFZPVlXhWy55m5Wy8mrQuYcjc0HeWvuKi5i\nchZiNpyX/LVRZV1bptWSlx8wq6GXqS8ec83d6sl6hWprKnPPNgqzeaHTf4WqTxpLyL+2THmnMPft\nmg3WOz/GWr6IyeppxKqQ4IPVbJipbpkxX8Rk9WS/iKnVcmuXWcpJd2Ly6WIJmVshi4uYwAshmQ3T\nW39pqizj6G4JGTP3oKXiIiZwWcZsmF63zCJ3y1hNDZhQ9ey/WUp/Wcbni6XkbYUsFw4DvOyv2RD9\na8v4m66lZM3ce8sPgDMRs2F658eYl/y1mhqx/AA4EzEbpuuLmGxEebtlyuUHwN0yZsP0gvliL/lr\nNWW/iGnqClUfrGYD9RL16fXcMw7G5oWsC4dVL2Ly10yzwbq+E5ONKPtFTFNlGWfuZgO5LGOjqhXc\nJW2QtEvSpKSbh2z3zyWFpPE6f7ddaYV0ImI2WH+3jDN3S0kGd0lt4HbgWmA9cL2k9bNs9xrgI8CD\ntT9cokzcfbCaDdGNQIIxlzGtpjqZ+5XAZETsjohjwF3Aplm2+8/Ax4GjdT646HOvZu4+WM0G6XRj\n6v4H4PPF0uoE95XAnsrzveVrUyRdAayOiL+p/ckB7VZlyV9nImYDdSJoV+aofA9VSzntCVVJLeD3\ngJtqbLtZ0oSkiROdE17y16ym4rqQ4gd80Z+l1Qnu+4DVleerytd6XgO8BfhbSU8DVwFbZptUjYg7\nImI8Isbb7Tbykr9mtXS6MzN3r8VkKXWC+0PAOklrJS0GrgO29N6MiMMRsSwi1kTEGuABYGNETAz7\noxFFScZL/pqldboxY6E9lzEtJRncI+IEcCOwDXgMuDsidki6TdLG0/lwL/lrVk83iov+5PPFahqr\ns1FEbAW29r1264Bt31nrbwKqrArpr5lmg02VZTxHZTVlXxXSXzPN0oo+d3fLWH0Zlx+ImWUZZyJm\nA3W7Retwr1vGmbul5F0VcsadmHKOxKzZTu5z9wljwzXgTkzFcx+sZoN13S1jI8p6D1Xficmsnk6l\nW0ZyA4Kl5c3cZ9yJyQer2SC9bhkoOsycDFlKY7plHNvNButGTH3LbUvulrGkrHdiarW85K9ZHcWq\nkMXvrZa7ZSwta83dS/6a1dON6Qv+iszd54sNl7cs4yV/zWrpdmMqEWq1HNwtLXMr5PRaGc7czQbr\ndctAsSaTzxdLyXsRk8syZrX07sQELstYPZnLMl4rw6yObswsyzi2W0r24O61MszSZva5+7oQS8sa\n3KtL/vpgNRus22Wqbbjti5ishsZcxOSD1Wywk8oyToYsIX9Zxpm7WVJ/t4yTIUtpULdMzpGYNVvX\n3TI2oszB3Uv+mtXROalbxueLDZe/LOM+d7OkTtfLD9ho8t+JycsPmCUVyw8Uv7vP3erIXnOfmlD1\nwWo2UCema+7uc7c6srdC+iIms7QZ67m7W8ZqcFnGbB7o9t+JyeeLJeRf8tcTqmZJXhXSRpW95i5f\nxGSW1HW3jI0oe3AH1xDNUjozumWKYG82TPY+d/ANf81SvPyAjaoRmXurBeGD1WygbjemSpgtueZu\nadmXHygeXUM0G6YbM7tlPEdlKc0pyzgTMRuo03VZxkZTK7hL2iBpl6RJSTfP8v5vSdop6RFJ90l6\nQ60P9/rUZrV0o1LG9ByV1ZAM7pLawO3AtcB64HpJ6/s2+yYwHhE/DdwD/LdaH169nNqx3WygardM\nu+XWYUurk7lfCUxGxO6IOAbcBWyqbhAR90fEK+XTB4BVdT687VZIs1o6Xn7ARlQnuK8E9lSe7y1f\nG+QG4Cu1PrzXt+sJIrOh+pcf8PliKXM6oSrpg8A48IkB72+WNCFpAmZm7m7tMhusuiqkM3ero05w\n3wesrjxfVb42g6R3AR8FNkbEj2b7QxFxR0SMR8Q4VCZUPUFkNlBEEDHzfHEyZCl1gvtDwDpJayUt\nBq4DtlQ3kHQ58GmKwH6w9odXLmLywWo2u14FZmZZJuOAbF5IBveIOAHcCGwDHgPujogdkm6TtLHc\n7BPAhcCXJH1L0pYBf26GmcsPOLibzaZ3blS7ZXy+WMpYnY0iYiuwte+1Wyu/v+tUPnwqE3HN3Wyg\n3rnhbhkbRdYrVFVZfsDB3Wx2U5m7u2VsBM1ZfsAHq9mselm6lx+wUTQiuLda7pYxG6SXpWvG8gMO\n7jZcQ1aF9JK/ZoNMd8uUj16LyWpoxHru/pppNth0t4zXYrL6mlGW8ddMs4H6u2VaToashsZk7j5W\nzWbX3y3TdreM1ZA3uFe+ZjpzN5td79xwn7uNIm9Zpjr774PVbFa9skz1fIlwE4INlzlzLx49+282\n2HTmXjzvzVX5264N04jM3Uv+mg3Wi+HVOSrA33ZtqEZMqEqi4+PUbFbd6G+FLB69MqQN04gJ1bZ8\nT0izQU5eW6Z43d92bZhG9Lm3W+5zNxtktm4ZcFnGhmvE8gPyqpBmA83WLQP+tmvDNaLm3nZwn9Lp\nBh/760eZPPhy7qFYQ/QvP+BuGavDZZmG+d5zr/DZ7d9l244DuYdiDdE7Nabuf+CyjNXQiFbIlpcf\nmLL/8JEZj2b93TJtd8tYDQ25E5OzkJ79Lxyd8Wh20toy5Vnrc8aGyRzcfSemfgdeLIP7YQd3K3T7\numXkCVWrIVtwV3UQXn5gyjMvuCxjM510m71ecHfmbkNkzdx7im6Z3KNohgNlxv78K8c5eryTeTTW\nBFN97v3LD/iksSHyZe6azt1bLdcPe56plGNcmjGYZfmBljN3S2tE5t7yzQem7D98hMuWX1D8/oJL\nMzbdFdO76K9XlvFN5W2YRtTcffOBwpFjHV545ThX/PhFgDN3K/TOjVZ/t4wTIhsiX+Zeie7O3Au9\nSdTLp4K7M3eb7oo5aVVIJ0Sn7MSr4GtPIzL3lidUgenJ1DXLzuei8xc5czdglm4ZT6ielt2HXmb9\nx7Yx8fRzuYdyRjWi5t5u+UCF6cnUS5ecx4ol5zm4G3Byt0zv0aXMU/O1xw9y7ESXr+78fu6hnFEZ\nM/dqt0wzFg7bf/gIB1/KF1APlGWY1y85lxVLznVwN2Bwt4zvoXpqHtj9LADby8eFqjk198wHakTw\nwT97kH/92YlsY3jm8FFee8Fizl3UZsXSc11zN2C6K6atmRcxvQrKxnPuRKfLg7ufY1FbPLrvMIeP\nHM89pDOmGWWZBiw/MPHd53ny0A95ZO9hdjxzOMsYDhw+yut/7FwAViw5jxdeOc6RY76Q6dWul/hM\nrwpZPOY+Z+ajHc+8yEs/OsEvvW013YC/f2rh1t1rBXdJGyTtkjQp6eZZ3j9H0hfL9x+UtCb5N6uD\naBUTqjm/Zn7xoT1csLjN4naLL03szTKGZ144wqVLe8G9eHT2bv3dMl5+4NT1SjEf/rnLOGesxfYn\nF25pJhncJbWB24FrgfXA9ZLW9212A/B8RLwR+H3g48lPrkT33sGa61h9+Ucn+JtH9vP+t17Ke37q\nEv7qm/uyXPp/4MWjvL4M6r3HA667v+q5W2bubH/yWd74ugtZddH5/OM3XLSg6+51MvcrgcmI2B0R\nx4C7gE1922wCPlv+fg9wjarrC8xiZitk8Zhr9v/ebz/DkeMdPvC21fzS21Zz+Mjxsz6T3ruAacWS\n84CiYwZmLkdgr07dvm6Z8xePAfDn27/L91/08VHX8U6Xh55+jrdfdjEAb7/sYh7b/yLP/fBY5pGd\nGWM1tlkJ7Kk83wv87KBtIuKEpMPAxcAP6gyiN/u/4Q++PnUAn00HXjzKG193IZevXkoErFx6Hr/9\n5Uf55H1PnLUxnChP4BV9mft//crjfPrvnjxr47DmeaGc9Otl7D+54jXc9O438Uf3T/Lzv/u3rFx6\nXs7hzRvHO11eOdbh6p8ogvvVZZB//x/9X85b3M45tDOiTnCfM5I2A5sBLlq5dur196y/hMcPvEQn\n061l1l1yIR8YX40kJPjY+9fz5W/tO+vjuHz1Uv7puuUAnLuozUeuWccTB1866+Ow5lmx5DwuOn8R\nUCy69xvXrGPjz1zKn/zdkwu642Ou/ezai/m5Nxfn2FtXLeVDb1/DoZd+lHlU9QXBfTW3VWoSU9LV\nwO9ExHvL57cARMR/qWyzrdxmu6Qx4ACwPIb88fHx8ZiYyNd2aGY2H0l6OCLGU9vVqbk/BKyTtFbS\nYuA6YEvfNluAXy1//xfA14YFdjMzO7OSZZmyhn4jsA1oA3dGxA5JtwETEbEF+O/A5yRNAs9R/ANg\nZmaZ1Kq5R8RWYGvfa7dWfj8K/Mu5HZqZmZ2qRlyhamZmc8vB3cxsAXJwNzNbgBzczcwWIAd3M7MF\nKHkR0xn7YOklYFeWDx/NMmouo5CZxzn35stYPc651fRxviEilqc2OqvLD/TZVecqq9wkTXicc2e+\njBPmz1g9zrk1X8aZ4rKMmdkC5OBuZrYA5Qzud2T87FF4nHNrvowT5s9YPc65NV/GOVS2CVUzMztz\nXJYxM1uAsgT31A23c5G0WtL9knZK2iHpI+Xrr5X0VUlPlI8XNWCsbUnflHRv+XxteXPyyfJm5Ytz\njxFA0lJJ90h6XNJjkq5u6P78d+X/80clfUHSuU3Yp5LulHRQ0qOV12bdfyp8shzvI5KuyDzOT5T/\n3x+R9FeSllbeu6Uc5y5J7z1b4xw01sp7N0kKScvK59n26ek668G95g23czkB3BQR64GrgF8vx3Yz\ncF9ErAPuK5/n9hHgscrzjwO/X96k/HmKm5Y3wR8C/zsi/hHwVooxN2p/SloJ/FtgPCLeQrG09XU0\nY59+BtjQ99qg/XctsK782Qx86iyNEWYf51eBt0TETwPfAW4BKM+p64CfKv+bPy7jwtnyGU4eK5JW\nA+8Bvld5Oec+PT0RcVZ/gKuBbZXntwC3nO1x1BzrXwPvprjYakX52gqKHv2c41pFcVL/M+BeivuN\n/wAYm20fZxznEuApyrmdyutN25+9ewC/luLaj3uB9zZlnwJrgEdT+w/4NHD9bNvlGGffe78IfL78\nfcY5T3GviKtz7tPytXsoEpCngWVN2Ken85OjLDPbDbdXZhjHUJLWAJcDDwKXRMT+8q0DwCWZhtXz\nB8B/AHo3nb0YeCEiTpTPm7JP1wKHgP9RlpD+TNIFNGx/RsQ+4HcpMrb9wGHgYZq5T2Hw/mvyufWv\ngK+UvzdunJI2Afsi4tt9bzVurHV5QnUWki4E/gL4zYh4sfpeFP98Z2sxkvQLwMGIeDjXGEYwBlwB\nfCoiLgd+SF8JJvf+BChr1pso/jG6FLiAWb62N1ET9l+KpI9SlDw/n3sss5F0PvAfgVtT284nOYL7\nPmB15fmq8rVGkLSIIrB/PiL+snz5+5JWlO+vAA7mGh/wDmCjpKeBuyhKM38ILC1vTg7N2ad7gb0R\n8WD5/B6KYN+k/QnwLuCpiDgUEceBv6TYz03cpzB4/zXu3JL0IeAXgF8u/yGC5o3zMop/2L9dnler\ngP8n6fU0b6y15QjudW64nYUkUdwP9rGI+L3KW9UbgP8qRS0+i4i4JSJWRcQain33tYj4ZeB+ipuT\nQ+Yx9kTEAWCPpDeXL10D7KRB+7P0PeAqSeeXx0BvnI3bp6VB+28L8Ctlh8dVwOFK+eask7SBony4\nMSJeqby1BbhO0jmS1lJMVv59jjECRMQ/RMTrImJNeV7tBa4oj99G7dOR5Cj0A++jmD1/Evho7omH\nyrj+CcVX3EeAb5U/76Ooad8HPAH8H+C1ucdajvedwL3l7z9BcYJMAl8Czsk9vnJcPwNMlPv0y8BF\nTdyfwH8CHgceBT4HnNOEfQp8gWIe4DhF0Llh0P6jmFi/vTyv/oGi+yfnOCcp6tW9c+lPKtt/tBzn\nLuDa3Pu07/2nmZ5QzbZPT/fHV6iamS1AnlA1M1uAHNzNzBYgB3czswXIwd3MbAFycDczW4Ac3M3M\nFiAHdzOzBcjB3cxsAfr/Q+pesrK8p48AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f678e5f1ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "ix = 29\n",
    "pd.Series(g[ix]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([ 1, 98]),), (array([ 1, 98]),))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh = 0.5\n",
    "np.where(y_train[ix] == 1), np.where(g[ix] > thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "from gensim.models.lsimodel import LsiModel\n",
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = TfidfModel.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.dictionary')\n",
    "tfidf = TfidfModel.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.tfidf')\n",
    "lsi = LsiModel.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.lsi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wvmodel = Word2Vec.load('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fsmodel = fasttext.load_model('corpus/train_body_data-with_labels_False-retain_special_chars_False.with_test_data.csv.fasttext.model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_tfidf_word2vec(tokens, stopwords=[]):\n",
    "#     global wvmodel\n",
    "#     global tfidf\n",
    "    # This requires wvmodel to be present in the namespace.\n",
    "    wv_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords and w in wvmodel.wv.vocab)]\n",
    "    ).map(\n",
    "        lambda x: tfidf[dictionary.doc2bow(x)]\n",
    "    ).map(\n",
    "        lambda x: np.array([wvmodel[dictionary.id2token[id]] * w for id, w in x]).mean(axis=0) if len(x) > 0 else np.nan\n",
    "    )\n",
    "\n",
    "    return wv_feature_vec\n",
    "\n",
    "\n",
    "def transform_tfidf_fasttext(tokens, stopwords=[]):\n",
    "#     global fsmodel\n",
    "#     global tfidf\n",
    "    # This requires wvmodel to be present in the namespace.\n",
    "    fs_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    ).map(\n",
    "        lambda x: tfidf[dictionary.doc2bow(x)]\n",
    "    ).map(\n",
    "        lambda x: np.array([np.array(fsmodel[dictionary.id2token[id]]) * w for id, w in x]).mean(axis=0) if len(x) > 0 else np.nan\n",
    "    )\n",
    "\n",
    "    return fs_feature_vec\n",
    "\n",
    "\n",
    "def build_lsi_vector(l):\n",
    "    v = np.zeros(lsi.num_topics)\n",
    "    \n",
    "    for ix, vv in lsi[tfidf[dictionary.doc2bow(l)]]:\n",
    "        v[ix] = vv\n",
    "        \n",
    "    return v\n",
    "\n",
    "\n",
    "def transform_tfidf_lsi(tokens, stopwords=[]):\n",
    "#     global fsmodel\n",
    "#     global tfidf\n",
    "    # This requires wvmodel to be present in the namespace.\n",
    "    lsi_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    ).map(\n",
    "        lambda x: build_lsi_vector(x) if len(x) > 0 else np.nan\n",
    "    )\n",
    "\n",
    "    return lsi_feature_vec\n",
    "\n",
    "\n",
    "def transform_fasttext(tokens, stopwords=[]):\n",
    "    global fsmodel\n",
    "    # This requires fsmodel to be present in the namespace.\n",
    "    fs_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    ).map(lambda x: np.array([fsmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return fs_feature_vec\n",
    "\n",
    "\n",
    "def transform_unsupervised_sentiment_neuron(tokens, stopwords=[]):\n",
    "    # This requires fsmodel to be present in the namespace.\n",
    "    \n",
    "    usn_feature_vec = usnmodel.transform(tokens)\n",
    "\n",
    "    # usn_feature_vec = tokens.map(\n",
    "    #     lambda x: [w for w in x.split() if (w not in stopwords)]\n",
    "    # ).map(lambda x: np.array([usnmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return usn_feature_vec\n",
    "\n",
    "\n",
    "def transform_word2vec(tokens, stopwords=[]):\n",
    "    global wvmodel\n",
    "    # This requires wvmodel to be present in the namespace.\n",
    "    wv_feature_vec = tokens.map(\n",
    "        lambda x: [w for w in x.split() if (w not in stopwords and w in wvmodel.wv.vocab)]\n",
    "    ).map(lambda x: np.array([wvmodel[w] for w in x]).mean(axis=0) if len(x) > 0 else np.nan)\n",
    "\n",
    "    return wv_feature_vec\n",
    "\n",
    "\n",
    "def parallel_generate_word_vectors(samp, transformer, stopwords, batch, num_proc):\n",
    "    with Parallel(n_jobs=num_proc) as parallel:\n",
    "        dataset = []\n",
    "        is_break = False\n",
    "        i = 0\n",
    "\n",
    "        while not is_break:\n",
    "            payload = []\n",
    "\n",
    "            for j in xrange(num_proc):\n",
    "                t_df = samp[(i + j) * batch: (i + 1 + j) * batch]\n",
    "\n",
    "                if t_df.empty:\n",
    "                    is_break = True\n",
    "                    continue\n",
    "\n",
    "                payload.append(\n",
    "                    delayed(transformer)(\n",
    "                        t_df, stopwords\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            print('Current batch in main thread: {}'.format((i + j) * batch))\n",
    "\n",
    "            if payload:\n",
    "                results = parallel(payload)\n",
    "                dataset.extend(results)\n",
    "                i += num_proc\n",
    "\n",
    "    return pd.concat(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_classes(pred, scale_param=0.75, min_thresh=0.05, thresh = 0.5):\n",
    "#     mx = pred.mean() + 3 * pred.std()\n",
    "    return np.where(pred > thresh)[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2idx_transform(word, _word2idx):\n",
    "    return _word2idx.get(word, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features_for(df, min_batch=2000, stopwords=[], num_proc=7):\n",
    "    df_tokens = transform_text(df)\n",
    "    \n",
    "    batch = min(df_tokens.shape[0] / num_proc, min_batch)\n",
    "\n",
    "    print('Computing fs features...')\n",
    "    fvec = parallel_generate_word_vectors(df_tokens, transform_fasttext, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Computing wv features...')\n",
    "    wvec = parallel_generate_word_vectors(df_tokens, transform_word2vec, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Mapping word indices...')\n",
    "    word_indices = df_tokens.map(lambda x: [word2idx_transform(i, _word2idx) for i in x.split()])\n",
    "\n",
    "    print('Computing tfidf fs features...')\n",
    "    tfidf_fvec = parallel_generate_word_vectors(df_tokens, transform_tfidf_fasttext, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Computing tfidf wv features...')\n",
    "    tfidf_wvec = parallel_generate_word_vectors(df_tokens, transform_tfidf_word2vec, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "\n",
    "    print('Computing tfidf lsi features...')\n",
    "    tfidf_lsi = parallel_generate_word_vectors(df_tokens, transform_tfidf_lsi, stopwords=stopwords, batch=batch, num_proc=num_proc)\n",
    "    \n",
    "    return word_indices, wvec, fvec, tfidf_wvec, tfidf_fvec, tfidf_lsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/TestData.json') as fl:\n",
    "    data = json.load(fl)\n",
    "    test_df = pd.DataFrame(data['TestData']).T\n",
    "    del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fs features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Computing wv features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Mapping word indices...\n",
      "Computing tfidf fs features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Computing tfidf wv features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "Computing tfidf lsi features...\n",
      "Current batch in main thread: 6498\n",
      "Current batch in main thread: 14079\n",
      "CPU times: user 50.1 s, sys: 6.48 s, total: 56.6 s\n",
      "Wall time: 2min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_word_indices,test_wvec, test_fvec, test_tfidf_wvec, test_tfidf_fvec, test_tfidf_lsi = extract_features_for(\n",
    "    test_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert(np.all(test_wvec[test_wvec.isnull()].index == test_fvec[test_fvec.isnull()].index))\n",
    "test_null_index = test_wvec[test_wvec.isnull()].index.union(test_fvec[test_fvec.isnull()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'TestData_02543', u'TestData_05012', u'TestData_05830'], dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_null_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 344 ms, sys: 36 ms, total: 380 ms\n",
      "Wall time: 383 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "valid_test_index = test_word_indices.index.difference(test_null_index)\n",
    "x_test = test_word_indices.ix[valid_test_index]  # .map(lambda x: [top_token2ind.get(i, 0) for i in x])\n",
    "\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "wv_test = np.vstack(test_wvec.ix[valid_test_index])\n",
    "fs_test = np.vstack(test_fvec.ix[valid_test_index])\n",
    "\n",
    "tfidf_wv_test = np.vstack(test_tfidf_wvec.ix[valid_test_index])\n",
    "tfidf_fs_test = np.vstack(test_tfidf_fvec.ix[valid_test_index])\n",
    "tfidf_lsi_test = np.vstack(test_tfidf_lsi.ix[valid_test_index])\n",
    "\n",
    "wv_test = wv_sc.transform(wv_test)\n",
    "fs_test = fs_sc.transform(fs_test)\n",
    "\n",
    "tfidf_wv_test = tfidf_wv_sc.transform(tfidf_wv_test)\n",
    "tfidf_fs_test = tfidf_fs_sc.transform(tfidf_fs_test)\n",
    "tfidf_lsi_test = tfidf_lsi_sc.transform(tfidf_lsi_test)\n",
    "\n",
    "test_inputs = build_training_inputs(\n",
    "    wv_test,\n",
    "    fs_test,\n",
    "    tfidf_wv_test,\n",
    "    tfidf_fs_test,\n",
    "    tfidf_lsi_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_probas = model.predict(test_inputs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_test_probas = test_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   3.51521989e-09,   3.23756189e-10, ...,\n",
       "          5.97743299e-10,   1.83255998e-13,   0.00000000e+00],\n",
       "       [  6.50782562e-29,   1.56475357e-06,   3.82902817e-06, ...,\n",
       "          1.69156135e-06,   4.58016647e-09,   1.05622823e-27],\n",
       "       [  0.00000000e+00,   6.99282132e-10,   1.03787148e-08, ...,\n",
       "          1.18757149e-09,   2.83694548e-16,   0.00000000e+00],\n",
       "       ..., \n",
       "       [  1.39064109e-16,   5.45442244e-03,   3.08843195e-01, ...,\n",
       "          6.54218226e-08,   1.21962780e-03,   1.13630343e-16],\n",
       "       [  3.10283707e-22,   1.89735810e-03,   2.62519025e-04, ...,\n",
       "          4.38363259e-06,   2.97837602e-07,   4.08869687e-22],\n",
       "       [  3.73695219e-25,   1.48586929e-04,   4.95965534e-04, ...,\n",
       "          8.57271687e-07,   2.35180209e-09,   7.00528846e-25]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_test_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2542, 5011, 5829]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_index = [int(s.split('_')[1]) - 1 for s in test_null_index]  # Subtract 1 since test index starts at 1 while enumerate starts at 0\n",
    "skip_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7578, 160), (7581, 3))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_test_probas.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36 ms, sys: 0 ns, total: 36 ms\n",
      "Wall time: 33.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# valid_test_feature_vec found below!\n",
    "thresh = 0.225\n",
    "test_values = np.zeros([main_test_probas.shape[0], len(topics)])\n",
    "for ix, pred in enumerate(main_test_probas):\n",
    "    for v in get_classes(pred, thresh=thresh):\n",
    "        test_values[ix][v] = 1\n",
    "\n",
    "test_sub_df = pd.DataFrame(\n",
    "    test_values,\n",
    "    index=test_df.ix[test_df.index.difference(test_null_index)].index,\n",
    "    columns=topics\n",
    ")\n",
    "\n",
    "null_test_df = pd.DataFrame(\n",
    "    np.zeros((len(test_null_index), len(topics))),\n",
    "    index=test_null_index,\n",
    "    columns=topics\n",
    ")\n",
    "\n",
    "test_sub_df = test_sub_df.append(null_test_df)\n",
    "test_sub_df = test_sub_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 9627 (0.5), 14297 (0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14663.0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14432.0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13897.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12489.0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7581.000000\n",
       "mean      882.691070\n",
       "std       621.585386\n",
       "min         0.000000\n",
       "25%       552.000000\n",
       "50%       770.000000\n",
       "75%      1026.000000\n",
       "max      8171.000000\n",
       "Name: bodyText, dtype: float64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_word_indices.map(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1382.0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_word_indices.map(len).quantile(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1223"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df.ix['TestData_04490'].bodyText.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'main_output_f1_micro'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-db68406f0e0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'main_output_f1_micro'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'main_output_f1_micro'"
     ]
    }
   ],
   "source": [
    "hist.history['main_output_f1_micro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94731/94731 [==============================] - 1s - loss: 1.8059 - acc: 0.6847 - f1_micro: 0.6776 - val_loss: 1.4254 - val_acc: 0.7536 - val_f1_micro: 0.6777\n"
     ]
    }
   ],
   "source": [
    "print '94731/94731 [==============================] - 1s - loss: 1.8059 - acc: 0.6847 - f1_micro: 0.6776 - val_loss: 1.4254 - val_acc: 0.7536 - val_f1_micro: 0.6777'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_filename = 'tfidf_wv_300-fs_300-lsi_300-deep_stack_net-epochs_260-f1_0.6776-data_2010_2014-val_data_2014-thresh_{}-with_sc_wv_fs_lsi.csv'.format(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_sub_df.astype(int).reset_index().rename(\n",
    "    columns={'index': 'id'}\n",
    ").sort_values('id').to_csv(\n",
    "    sub_filename, \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7581, 160)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TestData_04490\tThe World Health Organisation has convened an ...\t[]\t28-01-2016\n",
    "TestData_04550\tSpraying pesticides will fail to deal with the...\t[]\t02-02-2016\n",
    "TestData_05683\tViolent protests at Trump rally in California ...\t[]\t03-06-2016\n",
    "TestData_05869\tLast weekend, we saw the darkest side of human...\t[]\t17-06-2016\n",
    "TestData_06148\tAs dusk falls over Copacabana beach, Ubira San...\t[]\t16-07-2016\n",
    "TestData_06291\tIt is 3pm and yet another patient is brought t...\t[]\t27-07-2016\n",
    "TestData_06610\tHuddled around their hives, beekeepers around ...\t[]\t04-09-2016\n",
    "TestData_06708\tA United Nations high-level panel on access to...\t[]\t14-09-2016\n",
    "TestData_07263\tWHO: Zika virus is no longer a world threat Th...\t[]\t19-11-2016\n",
    "TestData_07478\t1 World Health Organisation declares a public ...\t[]\t18-12-2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "guncrime        1.0\n",
       "usguncontrol    1.0\n",
       "Name: TestData_05869, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = 5868\n",
    "test_sub_df.iloc[ix][test_sub_df.iloc[ix] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36 ms, sys: 0 ns, total: 36 ms\n",
      "Wall time: 32.6 ms\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# adjust_index = 0\n",
    "# # valid_test_feature_vec found below!\n",
    "# test_values = np.zeros([test_df.shape[0], len(topics)])\n",
    "# for ix, pred in enumerate(main_test_probas):\n",
    "#     if ix in skip_index:\n",
    "#         test_values[ix] = np.nan\n",
    "#         # Increment adjust index so that we have the correct index for other samples\n",
    "#         adjust_index += 1\n",
    "#         continue\n",
    "\n",
    "#     for v in get_classes(pred, thresh=0.05):\n",
    "#         test_values[ix + adjust_index][v] = 1\n",
    "\n",
    "# test_sub_df = pd.DataFrame(test_values, columns=sorted(topics), index=test_df.index)\n",
    "\n",
    "# q = test_sub_df.sum(axis=1)\n",
    "# assert(len(q[q.isnull()].index.difference(test_null_index)) == 0)\n",
    "\n",
    "# test_sub_df = test_sub_df.fillna(0)\n",
    "\n",
    "# # for i in test_feature_vec[test_feature_vec.isnull()].index:\n",
    "# #     test_sub_df.ix[i] = np.zeros(len(topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestData_02543    0.0\n",
       "TestData_05012    0.0\n",
       "TestData_05830    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.ix[test_null_index].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11656.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub_df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sub_df.astype(int).reset_index().rename(\n",
    "    columns={'index': 'id'}\n",
    ").sort_values('id').to_csv(\n",
    "    'lstm_300-word2vec_300-fasttext_300-maxlen_500-dense_64_64_64-cat_cross-epoch_210-batch_size_750-val_main_output_f1_micro_0.5760-main_output_f1_micro_0.5751-main_output_loss_0.9143-data_2010_2013-val_data_2014-thresh_0.05.csv', \n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: zikavirus, dtype: float64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = test_sub_df['zikavirus']\n",
    "e[e==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14328"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_submission = pd.read_csv('basic_nn_submission_0.649_accuracy_multi_class.csv')\n",
    "top_submission.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9280"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_index_lstm_sub = pd.read_csv('lstm.2014b_training_700_maxlen_64cell_100epochs_0.0025_threshold.csv')\n",
    "wrong_index_lstm_sub.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34952"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_sub = pd.read_csv('basic_nn_submission_full_training_data_0.9958_validation_accuracy_binary_crossentropy.csv')\n",
    "some_sub.set_index('id').sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2197, 160)\n",
      "(3957, 160)\n",
      "(12, 160)\n",
      "(1503, 160)\n"
     ]
    }
   ],
   "source": [
    "print top_submission.set_index('id')[top_submission.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print wrong_index_lstm_sub.set_index('id')[wrong_index_lstm_sub.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print some_sub.set_index('id')[some_sub.set_index('id').sum(axis=1) == 0].shape\n",
    "\n",
    "print test_sub_df[test_sub_df.sum(axis=1) == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestData_00011     0\n",
       "TestData_00012     0\n",
       "TestData_00015     0\n",
       "TestData_00027     3\n",
       "TestData_00029     0\n",
       "TestData_00038     1\n",
       "TestData_00042     5\n",
       "TestData_00053     4\n",
       "TestData_00056     1\n",
       "TestData_00060     1\n",
       "TestData_00066     0\n",
       "TestData_00085     0\n",
       "TestData_00087     1\n",
       "TestData_00090     0\n",
       "TestData_00092     0\n",
       "TestData_00107     3\n",
       "TestData_00111     0\n",
       "TestData_00114     0\n",
       "TestData_00115     1\n",
       "TestData_00118     0\n",
       "TestData_00119     0\n",
       "TestData_00121     0\n",
       "TestData_00123     0\n",
       "TestData_00125     0\n",
       "TestData_00127     0\n",
       "TestData_00128     1\n",
       "TestData_00139     1\n",
       "TestData_00140     1\n",
       "TestData_00144     0\n",
       "TestData_00147     2\n",
       "                  ..\n",
       "TestData_07445     0\n",
       "TestData_07456     3\n",
       "TestData_07461     1\n",
       "TestData_07462     4\n",
       "TestData_07465     0\n",
       "TestData_07468     0\n",
       "TestData_07471     1\n",
       "TestData_07475     0\n",
       "TestData_07486    10\n",
       "TestData_07495     1\n",
       "TestData_07509     0\n",
       "TestData_07514     3\n",
       "TestData_07515     1\n",
       "TestData_07523     0\n",
       "TestData_07533     2\n",
       "TestData_07534     2\n",
       "TestData_07542     1\n",
       "TestData_07544     2\n",
       "TestData_07545     0\n",
       "TestData_07552     2\n",
       "TestData_07556     5\n",
       "TestData_07563     1\n",
       "TestData_07565     0\n",
       "TestData_07566     0\n",
       "TestData_07569     0\n",
       "TestData_07571     3\n",
       "TestData_07572     1\n",
       "TestData_07579     6\n",
       "TestData_07580     2\n",
       "TestData_07581     3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_submission.set_index('id').ix[q[q == 0].index].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1222,)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.sum(axis=1)\n",
    "q[q==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7581.000000\n",
       "mean        2.160929\n",
       "std         1.739411\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         2.000000\n",
       "75%         3.000000\n",
       "max        13.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = trainingY.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    236286.000000\n",
       "mean          1.392787\n",
       "std           0.762577\n",
       "min           1.000000\n",
       "25%           1.000000\n",
       "50%           1.000000\n",
       "75%           2.000000\n",
       "max          15.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bodyText</th>\n",
       "      <th>topics</th>\n",
       "      <th>webPublicationDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TestData_03241</th>\n",
       "      <td>A special British police unit was put on stand...</td>\n",
       "      <td>[]</td>\n",
       "      <td>15-11-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_04088</th>\n",
       "      <td>The youngest convict in a fatal gang-rape in N...</td>\n",
       "      <td>[]</td>\n",
       "      <td>20-12-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_06306</th>\n",
       "      <td>Former New York City mayor Rudy Giuliani has s...</td>\n",
       "      <td>[]</td>\n",
       "      <td>28-07-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_06083</th>\n",
       "      <td>John Cantlie, the British journalist who has b...</td>\n",
       "      <td>[]</td>\n",
       "      <td>13-07-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TestData_05896</th>\n",
       "      <td>Lawyers for the companies that manufactured an...</td>\n",
       "      <td>[]</td>\n",
       "      <td>20-06-2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         bodyText topics  \\\n",
       "TestData_03241  A special British police unit was put on stand...     []   \n",
       "TestData_04088  The youngest convict in a fatal gang-rape in N...     []   \n",
       "TestData_06306  Former New York City mayor Rudy Giuliani has s...     []   \n",
       "TestData_06083  John Cantlie, the British journalist who has b...     []   \n",
       "TestData_05896  Lawyers for the companies that manufactured an...     []   \n",
       "\n",
       "               webPublicationDate  \n",
       "TestData_03241         15-11-2015  \n",
       "TestData_04088         20-12-2015  \n",
       "TestData_06306         28-07-2016  \n",
       "TestData_06083         13-07-2016  \n",
       "TestData_05896         20-06-2016  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ix = 'TestData_03241'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "london                1.0\n",
       "metropolitanpolice    1.0\n",
       "police                1.0\n",
       "uksecurity            1.0\n",
       "Name: TestData_03241, dtype: float64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ukcrime    1\n",
       "Name: TestData_04088, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = top_submission.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "humanrights    1\n",
       "india          1\n",
       "protest        1\n",
       "ukcrime        1\n",
       "Name: TestData_04088, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = some_sub.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "humanrights    1\n",
       "Name: TestData_02924, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = wrong_index_lstm_sub.set_index('id').ix[test_ix]\n",
    "q[q>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Counter-terrorism policy\n",
    " \n",
    "Foreign policy\n",
    " \n",
    "Defence policy\n",
    " \n",
    "Islamic State\n",
    " \n",
    "Syria\n",
    " \n",
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = trainingY.sum()\n",
    "unseen_topics = s[s.isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activism',\n",
       " 'bastilledaytruckattack',\n",
       " 'berlinchristmasmarketattack',\n",
       " 'brusselsattacks',\n",
       " 'charliehebdoattack',\n",
       " 'francetrainattack',\n",
       " 'munichshooting',\n",
       " 'orlandoterrorattack',\n",
       " 'parisattacks',\n",
       " 'peaceandreconciliation',\n",
       " 'sanbernardinoshooting',\n",
       " 'tunisiaattack2015',\n",
       " 'turkeycoupattempt',\n",
       " 'zikavirus'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(topics).intersection(unseen_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activism\n",
      "afghanistan\n",
      "aid\n",
      "algerianhostagecrisis\n",
      "alqaida\n",
      "alshabaab\n",
      "antiwar\n",
      "arabandmiddleeastprotests\n",
      "armstrade\n",
      "australianguncontrol\n",
      "australiansecurityandcounterterrorism\n",
      "bastilledaytruckattack\n",
      "belgium\n",
      "berlinchristmasmarketattack\n",
      "bigdata\n",
      "biometrics\n",
      "bokoharam\n",
      "bostonmarathonbombing\n",
      "britisharmy\n",
      "brusselsattacks\n",
      "cameroon\n",
      "carers\n",
      "charliehebdoattack\n",
      "chemicalweapons\n",
      "clusterbombs\n",
      "cobra\n",
      "conflictanddevelopment\n",
      "controversy\n",
      "criminaljustice\n",
      "cybercrime\n",
      "cyberwar\n",
      "darknet\n",
      "dataprotection\n",
      "debate\n",
      "defence\n",
      "deflation\n",
      "drones\n",
      "drugs\n",
      "drugspolicy\n",
      "drugstrade\n",
      "earthquakes\n",
      "ebola\n",
      "economy\n",
      "egypt\n",
      "encryption\n",
      "energy\n",
      "espionage\n",
      "ethics\n",
      "europeanarrestwarrant\n",
      "europeancourtofhumanrights\n",
      "events\n",
      "extradition\n",
      "famine\n",
      "farright\n",
      "firefighters\n",
      "forensicscience\n",
      "france\n",
      "francetrainattack\n",
      "freedomofspeech\n",
      "genevaconventions\n",
      "germany\n",
      "guncrime\n",
      "hacking\n",
      "hashtags\n",
      "helicoptercrashes\n",
      "humanitarianresponse\n",
      "humanrights\n",
      "humanrightsact\n",
      "humantrafficking\n",
      "immigration\n",
      "india\n",
      "indonesia\n",
      "internallydisplacedpeople\n",
      "internationalcourtofjustice\n",
      "internationalcriminaljustice\n",
      "internetsafety\n",
      "iraq\n",
      "isis\n",
      "israel\n",
      "jordan\n",
      "jubilee\n",
      "judiciary\n",
      "july7\n",
      "justiceandsecurity\n",
      "kenya\n",
      "knifecrime\n",
      "lebanon\n",
      "libya\n",
      "localgovernment\n",
      "logistics\n",
      "london\n",
      "londonriots\n",
      "malaysia\n",
      "mali\n",
      "malware\n",
      "metropolitanpolice\n",
      "middleeastpeacetalks\n",
      "migration\n",
      "military\n",
      "ministryofdefence\n",
      "morocco\n",
      "mrsa\n",
      "mumbaiterrorattacks\n",
      "munichshooting\n",
      "naturaldisasters\n",
      "nigeria\n",
      "nuclearweapons\n",
      "occupy\n",
      "organisedcrime\n",
      "orlandoterrorattack\n",
      "osamabinladen\n",
      "paris\n",
      "parisattacks\n",
      "peaceandreconciliation\n",
      "philippines\n",
      "piracy\n",
      "planecrashes\n",
      "police\n",
      "protest\n",
      "refugees\n",
      "religion\n",
      "retirementage\n",
      "rio20earthsummit\n",
      "royalairforce\n",
      "royalnavy\n",
      "russia\n",
      "sanbernardinoshooting\n",
      "saudiarabia\n",
      "september11\n",
      "slavery\n",
      "somalia\n",
      "southafrica\n",
      "southchinasea\n",
      "stopandsearch\n",
      "surveillance\n",
      "sydneysiege\n",
      "syria\n",
      "taliban\n",
      "terrorism\n",
      "thailand\n",
      "torture\n",
      "traincrashes\n",
      "transport\n",
      "tunisiaattack2015\n",
      "turkey\n",
      "turkeycoupattempt\n",
      "ukcrime\n",
      "uksecurity\n",
      "uksupremecourt\n",
      "undercoverpoliceandpolicing\n",
      "unitednations\n",
      "usguncontrol\n",
      "values\n",
      "warcrimes\n",
      "warreporting\n",
      "weaponstechnology\n",
      "womeninbusiness\n",
      "woolwichattack\n",
      "worldmigration\n",
      "zikavirus\n"
     ]
    }
   ],
   "source": [
    "for i in topics:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsolatorio/ml-ai/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3445929"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(wvmodel['zika'], np.vstack(test_wvec.dropna())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsolatorio/ml-ai/local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.38107796869050226"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(fsmodel['zika'], np.vstack(test_fvec.dropna())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              The World Health Organisation has convened an ...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           28-01-2016\n",
       "Name: TestData_04490, dtype: object"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[4488 + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              The United Nations security council has called...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           17-09-2016\n",
       "Name: TestData_06730, dtype: object"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[6727 + 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bodyText              We are deeply concerned that the counter-terro...\n",
       "topics                                                               []\n",
       "webPublicationDate                                           02-02-2015\n",
       "Name: TestData_00360, dtype: object"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.ix[359]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drugstrade    1.0\n",
       "Name: TestData_04490, dtype: float64"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = test_sub_df.iloc[4488 + 1]\n",
    "q[q > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
